============================================
    Debtmap v0.2.3
============================================

[TARGET] TOP 10 RECOMMENDATIONS

#1 SCORE: 39.8 [LOW - FILE AGGREGATE]
â”œâ”€ ./src/cache/shared_cache.rs (16 functions, total score: 75.8)
â”œâ”€ WHY: File aggregate combines complexity scores from 16 individual functions to identify files with widespread technical debt. Unlike single file-level issues (god objects, high line count), this represents accumulated complexity across multiple functions. 5 functions exceed complexity thresholds.
â”œâ”€ ACTION: Prioritize refactoring the most complex functions. Break down large functions, extract reusable components, and improve error handling.
â”‚  â”œâ”€ 1. Review and refactor top 5 problematic functions
â”‚  â”œâ”€ 2. Extract common patterns into helper functions
â”‚  â”œâ”€ 3. Add unit tests for complex logic sections
â”‚  â””â”€ 4. Consider splitting file if it exceeds 500 lines
â”œâ”€ IMPACT: Reduce overall file complexity by 31%, improve test coverage, enable safer refactoring
â”œâ”€ METRICS: Functions: 16, Problematic: 5, Avg complexity: 4.7
â”œâ”€ SCORING: Aggregate: LOW | Avg per function: 2.5 | Max: 10.2
â””â”€ DEPS: 5 high-complexity functions identified
   â”œâ”€ SharedCache::trigger_pruning: 10.2
   â”œâ”€ SharedCache::clear_project: 8.8
   â”œâ”€ SharedCache::retry_with_backoff: 7.4
   â”œâ”€ SharedCache::migrate_from_local: 6.0
   â””â”€ SharedCache::put_with_config: 5.3

#2 SCORE: 37.7 [LOW - FILE AGGREGATE]
â”œâ”€ ./src/io/writers/enhanced_markdown/mod.rs (20 functions, total score: 76.7)
â”œâ”€ WHY: File aggregate combines complexity scores from 20 individual functions to identify files with widespread technical debt. Unlike single file-level issues (god objects, high line count), this represents accumulated complexity across multiple functions. 2 functions exceed complexity thresholds.
â”œâ”€ ACTION: Prioritize refactoring the most complex functions. Break down large functions, extract reusable components, and improve error handling.
â”‚  â”œâ”€ 1. Review and refactor top 5 problematic functions
â”‚  â”œâ”€ 2. Extract common patterns into helper functions
â”‚  â”œâ”€ 3. Add unit tests for complex logic sections
â”‚  â””â”€ 4. Consider splitting file if it exceeds 500 lines
â”œâ”€ IMPACT: Reduce overall file complexity by 10%, improve test coverage, enable safer refactoring
â”œâ”€ METRICS: Functions: 20, Problematic: 2, Avg complexity: 3.8
â”œâ”€ SCORING: Aggregate: LOW | Avg per function: 1.9 | Max: 8.9
â””â”€ DEPS: 2 high-complexity functions identified
   â”œâ”€ EnhancedMarkdownWriter::write_executive_summary: 8.9
   â”œâ”€ EnhancedMarkdownWriter::write_recommendations: 8.1
   â”œâ”€ EnhancedMarkdownWriter::write_complexity_hotspots: 4.8
   â”œâ”€ EnhancedMarkdownWriter::write_statistics: 4.4
   â””â”€ EnhancedMarkdownWriter::write_risk_distribution: 3.9

#3 SCORE: 30.8 [LOW - FILE AGGREGATE]
â”œâ”€ ./src/analyzers/javascript/detectors/resource.rs (9 functions, total score: 57.7)
â”œâ”€ WHY: File aggregate combines complexity scores from 9 individual functions to identify files with widespread technical debt. Unlike single file-level issues (god objects, high line count), this represents accumulated complexity across multiple functions. 7 functions exceed complexity thresholds.
â”œâ”€ ACTION: Prioritize refactoring the most complex functions. Break down large functions, extract reusable components, and improve error handling.
â”‚  â”œâ”€ 1. Review and refactor top 5 problematic functions
â”‚  â”œâ”€ 2. Extract common patterns into helper functions
â”‚  â”œâ”€ 3. Add unit tests for complex logic sections
â”‚  â””â”€ 4. Consider splitting file if it exceeds 500 lines
â”œâ”€ IMPACT: Reduce overall file complexity by 78%, improve test coverage, enable safer refactoring
â”œâ”€ METRICS: Functions: 9, Problematic: 7, Avg complexity: 6.4
â”œâ”€ SCORING: Aggregate: LOW | Avg per function: 3.4 | Max: 11.1
â””â”€ DEPS: 7 high-complexity functions identified
   â”œâ”€ detect_event_listener_leaks: 11.1
   â”œâ”€ detect_worker_leaks: 8.9
   â”œâ”€ process_timer_match: 7.2
   â”œâ”€ extract_cleared_variables: 6.8
   â””â”€ ResourceManagementIssue::to_debt_item: 6.0

#4 SCORE: 28.8 [LOW - FILE AGGREGATE]
â”œâ”€ ./src/resource/python/circular_ref.rs (7 functions, total score: 58.7)
â”œâ”€ WHY: File aggregate combines complexity scores from 7 individual functions to identify files with widespread technical debt. Unlike single file-level issues (god objects, high line count), this represents accumulated complexity across multiple functions. 6 functions exceed complexity thresholds.
â”œâ”€ ACTION: Prioritize refactoring the most complex functions. Break down large functions, extract reusable components, and improve error handling.
â”‚  â”œâ”€ 1. Review and refactor top 5 problematic functions
â”‚  â”œâ”€ 2. Extract common patterns into helper functions
â”‚  â”œâ”€ 3. Add unit tests for complex logic sections
â”‚  â””â”€ 4. Consider splitting file if it exceeds 500 lines
â”œâ”€ IMPACT: Reduce overall file complexity by 86%, improve test coverage, enable safer refactoring
â”œâ”€ METRICS: Functions: 7, Problematic: 6, Avg complexity: 8.4
â”œâ”€ SCORING: Aggregate: LOW | Avg per function: 4.1 | Max: 17.0
â””â”€ DEPS: 6 high-complexity functions identified
   â”œâ”€ PythonCircularRefDetector::detect_circular_references: 17.0
   â”œâ”€ PythonCircularRefDetector::check_for_circular_pattern: 10.7
   â”œâ”€ PythonCircularRefDetector::detect_issues: 8.2
   â”œâ”€ PythonCircularRefDetector::analyze_init_statement: 7.4
   â””â”€ PythonCircularRefDetector::analyze_classes: 7.3

#5 SCORE: 24.0 [LOW - FILE AGGREGATE]
â”œâ”€ ./src/priority/formatter_markdown.rs (5 functions, total score: 53.7)
â”œâ”€ WHY: File aggregate combines complexity scores from 5 individual functions to identify files with widespread technical debt. Unlike single file-level issues (god objects, high line count), this represents accumulated complexity across multiple functions. 5 functions exceed complexity thresholds.
â”œâ”€ ACTION: Prioritize refactoring the most complex functions. Break down large functions, extract reusable components, and improve error handling.
â”‚  â”œâ”€ 1. Review and refactor top 5 problematic functions
â”‚  â”œâ”€ 2. Extract common patterns into helper functions
â”‚  â”œâ”€ 3. Add unit tests for complex logic sections
â”‚  â””â”€ 4. Consider splitting file if it exceeds 500 lines
â”œâ”€ IMPACT: Reduce overall file complexity by 100%, improve test coverage, enable safer refactoring
â”œâ”€ METRICS: Functions: 5, Problematic: 5, Avg complexity: 10.7
â”œâ”€ SCORING: Aggregate: LOW | Avg per function: 4.8 | Max: 14.4
â””â”€ DEPS: 5 high-complexity functions identified
   â”œâ”€ format_priority_item_markdown: 14.4
   â”œâ”€ format_file_priority_item_markdown: 13.6
   â”œâ”€ format_file_aggregate_item_markdown: 13.0
   â”œâ”€ format_file_impact: 6.9
   â””â”€ format_impact: 5.8

#6 SCORE: 23.3 [LOW - FILE AGGREGATE]
â”œâ”€ ./src/priority/formatter.rs (4 functions, total score: 58.2)
â”œâ”€ WHY: File aggregate combines complexity scores from 4 individual functions to identify files with widespread technical debt. Unlike single file-level issues (god objects, high line count), this represents accumulated complexity across multiple functions. 4 functions exceed complexity thresholds.
â”œâ”€ ACTION: Prioritize refactoring the most complex functions. Break down large functions, extract reusable components, and improve error handling.
â”‚  â”œâ”€ 1. Review and refactor top 4 problematic functions
â”‚  â”œâ”€ 2. Extract common patterns into helper functions
â”‚  â”œâ”€ 3. Add unit tests for complex logic sections
â”‚  â””â”€ 4. Consider splitting file if it exceeds 500 lines
â”œâ”€ IMPACT: Reduce overall file complexity by 100%, improve test coverage, enable safer refactoring
â”œâ”€ METRICS: Functions: 4, Problematic: 4, Avg complexity: 14.5
â”œâ”€ SCORING: Aggregate: LOW | Avg per function: 5.8 | Max: 16.7
â””â”€ DEPS: 4 high-complexity functions identified
   â”œâ”€ format_file_priority_item: 16.7
   â”œâ”€ format_file_aggregate_item: 16.7
   â”œâ”€ format_priority_item: 16.7
   â””â”€ format_impact: 8.1

#7 SCORE: 21.2 [ðŸ”´ UNTESTED] [CRITICAL]
- LOCATION: ./src/refactoring/mod.rs:343 PatternRecognitionEngine::generate_recommendations()
- WHY: Low complexity (10), minor refactoring needed
- ACTION: Extract 2 helper functions using early returns
   - 1. Apply guard clause pattern:
   - 2.   â€¢ Use ? operator for early error returns
   - 3.   â€¢ Extract validation to separate function
   - 4.   â€¢ Use match expressions over if-else chains
   - 5. Add unit tests focusing on edge cases and error paths
- IMPACT: -5 complexity, -11.0 risk
- COMPLEXITY: cyclomatic=10 (adj:5), branches=10, cognitive=29, nesting=3, entropy=0.35

#8 SCORE: 17.4 [LOW - FILE AGGREGATE]
â”œâ”€ ./src/risk/lcov.rs (9 functions, total score: 43.5)
â”œâ”€ WHY: File aggregate combines complexity scores from 9 individual functions to identify files with widespread technical debt. Unlike single file-level issues (god objects, high line count), this represents accumulated complexity across multiple functions. 3 functions exceed complexity thresholds.
â”œâ”€ ACTION: Prioritize refactoring the most complex functions. Break down large functions, extract reusable components, and improve error handling.
â”‚  â”œâ”€ 1. Review and refactor top 5 problematic functions
â”‚  â”œâ”€ 2. Extract common patterns into helper functions
â”‚  â”œâ”€ 3. Add unit tests for complex logic sections
â”‚  â””â”€ 4. Consider splitting file if it exceeds 500 lines
â”œâ”€ IMPACT: Reduce overall file complexity by 33%, improve test coverage, enable safer refactoring
â”œâ”€ METRICS: Functions: 9, Problematic: 3, Avg complexity: 4.8
â”œâ”€ SCORING: Aggregate: LOW | Avg per function: 1.9 | Max: 9.8
â””â”€ DEPS: 3 high-complexity functions identified
   â”œâ”€ find_functions_by_path: 9.8
   â”œâ”€ parse_lcov_file: 9.6
   â”œâ”€ find_function_by_name: 6.6
   â”œâ”€ LcovData::get_function_coverage_with_line: 3.0
   â””â”€ calculate_function_coverage_data: 3.0

#9 SCORE: 16.2 [ðŸ”´ UNTESTED] [CRITICAL]
- LOCATION: ./src/complexity/languages/python.rs:669 PythonEntropyAnalyzer::collect_branches_from_stmt()
- WHY: Parser complexity (29), use combinators
- ACTION: Refactor using nom or pest parser combinators
   - 1. Break parsing into composable units:
   - 2.   â€¢ Define atomic parsers for basic elements
   - 3.   â€¢ Combine parsers using combinators
   - 4.   â€¢ Separate tokenization from parsing
   - 5. Consider using a parser generator:
   - 6.   â€¢ pest for PEG grammars
   - 7.   â€¢ lalrpop for LR(1) grammars
   - 8. Add fuzz testing with cargo-fuzz for parser robustness
- IMPACT: -14 complexity, -11.9 risk
- COMPLEXITY: cyclomatic=29 (adj:14), branches=29, cognitive=60, nesting=4, entropy=0.29

#10 SCORE: 15.6 [ðŸ”´ UNTESTED] [CRITICAL]
- LOCATION: ./src/organization/god_object_analysis.rs:177 infer_responsibility_from_method()
- WHY: Parser complexity (15), use combinators
- ACTION: Refactor using nom or pest parser combinators
   - 1. Break parsing into composable units:
   - 2.   â€¢ Define atomic parsers for basic elements
   - 3.   â€¢ Combine parsers using combinators
   - 4.   â€¢ Separate tokenization from parsing
   - 5. Add fuzz testing with cargo-fuzz for parser robustness
- IMPACT: -7 complexity, -12.0 risk
- COMPLEXITY: cyclomatic=15 (adj:7), branches=15, cognitive=51, nesting=7, entropy=0.31

[STATS] TOTAL DEBT SCORE: 2093
