<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Debtmap Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="Comprehensive guide to Debtmap code complexity and technical debt analyzer">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Debtmap Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/iepathos/debtmap" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<blockquote>
<p>üöß <strong>Early Prototype</strong> - This project is under active development and APIs may change</p>
</blockquote>
<p>Debtmap is a code complexity and technical debt analyzer that identifies which code to refactor for maximum cognitive debt reduction and which code to test for maximum risk reduction.</p>
<h2 id="what-is-debtmap"><a class="header" href="#what-is-debtmap">What is Debtmap?</a></h2>
<p>Unlike traditional static analysis tools that simply flag complex code, Debtmap answers two critical questions:</p>
<ol>
<li><strong>‚ÄúWhat should I refactor to reduce cognitive burden?‚Äù</strong> - Identifies overly complex code that slows down development</li>
<li><strong>‚ÄúWhat should I test first to reduce the most risk?‚Äù</strong> - Pinpoints untested complex code that threatens stability</li>
</ol>
<p>Debtmap analyzes your codebase to identify complexity hotspots, technical debt patterns, and architectural risks. It supports Rust, Python, JavaScript, and TypeScript with full AST parsing and analysis capabilities. Rust includes additional advanced features like macro expansion and trait tracking.</p>
<p><strong>What Makes Debtmap Different:</strong></p>
<ul>
<li><strong>Coverage-Risk Correlation</strong>: Combines complexity metrics with test coverage to identify genuinely risky code (high complexity + low coverage = critical risk)</li>
<li><strong>Multi-Factor Analysis</strong>: Analyzes complexity, coverage, dependencies, and call graphs for comprehensive prioritization</li>
<li><strong>Reduced False Positives</strong>: Uses entropy analysis and pattern detection to distinguish genuinely complex code from repetitive patterns, reducing false positives by up to 70%. This is achieved through an advanced token classification system that categorizes code tokens and applies weighted entropy to accurately assess complexity.</li>
<li><strong>Actionable Guidance</strong>: Provides specific recommendations like ‚Äúextract nested conditions‚Äù or ‚Äúsplit this 80-line function‚Äù with quantified impact metrics</li>
<li><strong>Performance</strong>: Significantly faster than Java/Python-based competitors (written in Rust with parallel processing)</li>
</ul>
<h2 id="why-use-debtmap"><a class="header" href="#why-use-debtmap">Why Use Debtmap?</a></h2>
<p>Debtmap helps you make data-driven decisions about where to focus your refactoring and testing efforts:</p>
<ul>
<li><strong>Identify Complexity</strong> - Find complex functions and modules that need refactoring, with concrete metrics showing which changes will have the most impact</li>
<li><strong>Detect Technical Debt</strong> - Discover 30+ debt patterns including code smells, security vulnerabilities, resource management issues, and architectural problems</li>
<li><strong>Assess Risk</strong> - Prioritize improvements based on sophisticated risk scoring that combines complexity, test coverage, and dependency impact</li>
<li><strong>Track Quality</strong> - Monitor code quality metrics over time with the <code>compare</code> command (which can use <code>--plan</code> to automatically extract target locations from implementation plans and track improvements) to verify that refactoring efforts achieved their goals</li>
<li><strong>Get Actionable Recommendations</strong> - Receive specific guidance like ‚Äúrefactoring this will reduce complexity by 60%‚Äù or ‚Äútesting this will reduce risk by 5%‚Äù</li>
<li><strong>Automated Debt Reduction</strong> - Integrates with <a href="./prodigy-integration.html">Prodigy workflows</a> for AI-driven automated refactoring with iterative validation and testing (via external integration)</li>
</ul>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<h3 id="analysis-capabilities"><a class="header" href="#analysis-capabilities">Analysis Capabilities</a></h3>
<ul>
<li><strong>Multi-language support</strong> - Full support for Rust, Python, JavaScript, and TypeScript with AST parsing, complexity analysis, and debt detection</li>
<li><strong>Reduced false positives</strong> - Uses entropy analysis and pattern detection to distinguish genuinely complex code from repetitive patterns (up to 70% reduction)</li>
<li><strong>Token classification system</strong> - Advanced token categorization with weighted entropy for accurate complexity assessment</li>
<li><strong>Threshold presets</strong> - Quick setup with strict, balanced (default), or lenient presets matching different project types and quality standards</li>
<li><strong>Comprehensive debt detection</strong> - Identifies 30+ technical debt patterns across security (5 types), code organization (god objects, feature envy, magic values), resource management (5 types), testing quality (3 types), and error handling (4 types: error swallowing, poor error propagation, panic patterns, inadequate exception handling)</li>
<li><strong>Security vulnerability detection</strong> - Finds hardcoded secrets, weak crypto, SQL injection risks, and unsafe code patterns</li>
<li><strong>Resource management analysis</strong> - Identifies inefficient allocations, nested loops, and blocking I/O patterns</li>
<li><strong>Code organization analysis</strong> - Detects god objects, feature envy, primitive obsession, and magic values</li>
<li><strong>Testing quality assessment</strong> - Analyzes test complexity, flaky patterns, and assertion quality</li>
<li><strong>File-level aggregation</strong> - Multiple aggregation methods (sum, weighted, logarithmic) for identifying files needing organizational refactoring</li>
<li><strong>Context-aware analysis</strong> - Reduces false positives through intelligent context detection (enabled by default)</li>
</ul>
<h3 id="risk-analysis--prioritization"><a class="header" href="#risk-analysis--prioritization">Risk Analysis &amp; Prioritization</a></h3>
<ul>
<li><strong>Coverage-based risk analysis</strong> - Correlates complexity with test coverage to identify truly risky code</li>
<li><strong>Risk-driven testing recommendations</strong> - Prioritizes testing efforts based on complexity-coverage correlation and dependency impact</li>
<li><strong>Call graph analysis</strong> - Tracks upstream callers and downstream callees to understand dependency impact</li>
<li><strong>Tiered prioritization</strong> - Multi-stage pipeline (zero coverage, complexity-risk, critical path, dependency impact, effort optimization) surfaces critical architectural issues above simple testing gaps</li>
<li><strong>Quantified impact</strong> - Shows concrete metrics like ‚Äúrefactoring this will reduce complexity by 60%‚Äù</li>
</ul>
<h3 id="performance--output"><a class="header" href="#performance--output">Performance &amp; Output</a></h3>
<ul>
<li><strong>Parallel processing</strong> - Built with Rust and Rayon for blazing-fast analysis of large codebases</li>
<li><strong>Multiple output formats</strong> - JSON (legacy and unified structures), Markdown, and human-readable terminal formats for different tool integration needs</li>
<li><strong>Configurable thresholds</strong> - Customize complexity and duplication thresholds to match your standards</li>
<li><strong>Incremental analysis</strong> - Smart caching system for analyzing only changed files</li>
<li><strong>Intelligent caching</strong> - Smart cache system with automatic pruning, configurable strategies (LRU, LFU, FIFO), location options (local/shared/custom path), and environment-based configuration for fast repeated analysis</li>
<li><strong>Verbosity controls</strong> - Multiple verbosity levels (-v, -vv, -vvv) for progressive detail</li>
</ul>
<h3 id="configuration--customization"><a class="header" href="#configuration--customization">Configuration &amp; Customization</a></h3>
<ul>
<li><strong>Flexible suppression</strong> - Inline comment-based suppression for specific code sections</li>
<li><strong>Configuration file</strong> - <code>.debtmap.toml</code> or <code>debtmap.toml</code> for project-specific settings</li>
<li><strong>Test-friendly</strong> - Easily exclude test fixtures and example code from debt analysis</li>
<li><strong>Macro expansion support</strong> - Handles Rust macro expansions with configurable warnings</li>
</ul>
<h3 id="commands"><a class="header" href="#commands">Commands</a></h3>
<ul>
<li><strong><code>analyze</code></strong> - Comprehensive debt analysis with unified prioritization</li>
<li><strong><code>validate</code></strong> - Enforce quality thresholds in CI/CD pipelines</li>
<li><strong><code>compare</code></strong> - Track improvements over time and verify refactoring goals</li>
<li><strong><code>init</code></strong> - Generate configuration file with sensible defaults (‚Äìforce to overwrite)</li>
</ul>
<h2 id="target-audience"><a class="header" href="#target-audience">Target Audience</a></h2>
<p>Debtmap is designed for:</p>
<ul>
<li><strong>Development teams</strong> - Get concrete metrics for planning sprints. Know exactly which refactoring will reduce complexity by 60% or which function needs 6 unit tests for full coverage.</li>
<li><strong>Engineering managers</strong> - Track quality trends over time with the <code>compare</code> command. Monitor whether refactoring efforts are actually improving codebase health.</li>
<li><strong>Code reviewers</strong> - Focus reviews on high-risk areas identified by Debtmap. Prioritize reviewing untested complex code over simple utility functions.</li>
<li><strong>Developers refactoring legacy codebases</strong> - Receive actionable guidance like ‚Äúextract nested conditions‚Äù, ‚Äúsplit this 80-line function into 3 smaller functions‚Äù, or ‚Äúadd error handling for this catch block‚Äù.</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>Ready to analyze your codebase? Check out:</p>
<ul>
<li><a href="./getting-started.html">Getting Started</a> - Installation and first analysis</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Understanding the metrics and output</li>
<li><a href="./output-formats.html">Output Formats</a> - JSON, Markdown, and terminal formats</li>
</ul>
<p><strong>Tip:</strong> Start with <code>debtmap analyze . --summary</code> for a quick overview of your codebase health before diving into detailed analysis.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="why-debtmap"><a class="header" href="#why-debtmap">Why Debtmap?</a></h1>
<p>Technical debt analysis tools are everywhere. So why another one? Debtmap takes a fundamentally different approach to code quality analysis‚Äîone that reduces false positives and gives you actionable insights instead of just flagging ‚Äúcomplex‚Äù code.</p>
<h2 id="the-problem-with-traditional-static-analysis"><a class="header" href="#the-problem-with-traditional-static-analysis">The Problem with Traditional Static Analysis</a></h2>
<p>Most static analysis tools flag code as ‚Äúcomplex‚Äù based purely on metrics like cyclomatic complexity or lines of code. The problem? Not all complexity is equal.</p>
<p>Consider this common pattern:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn validate_config(config: &amp;Config) -&gt; Result&lt;()&gt; {
    if config.output_dir.is_none() {
        return Err(anyhow!("output_dir required"))
    }
    if config.max_workers.is_none() {
        return Err(anyhow!("max_workers required"))
    }
    if config.timeout_secs.is_none() {
        return Err(anyhow!("timeout_secs required"))
    }
    if config.log_level.is_none() {
        return Err(anyhow!("log_level required"))
    }
    if config.cache_dir.is_none() {
        return Err(anyhow!("cache_dir required"))
    }
    // ... 15 more similar checks
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Traditional tools say:</strong> ‚ÄúCyclomatic complexity: 20 - CRITICAL! Refactor immediately!‚Äù</p>
<p><strong>Reality:</strong> This is a simple validation function with a repetitive pattern. Yes, it has 20 branches, but they‚Äôre all identical in structure. An experienced developer can read and understand this in seconds.</p>
<p>Now compare with this function:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn reconcile_state(current: &amp;State, desired: &amp;State) -&gt; Vec&lt;Action&gt; {
    let mut actions = vec![];

    match (current.mode, desired.mode) {
        (Mode::Active, Mode::Standby) =&gt; {
            if current.has_active_connections() {
                actions.push(Action::DrainConnections);
                actions.push(Action::WaitForDrain);
            }
            actions.push(Action::TransitionToStandby);
        }
        (Mode::Standby, Mode::Active) =&gt; {
            if desired.requires_warmup() {
                actions.push(Action::Warmup);
            }
            actions.push(Action::TransitionToActive);
        }
        (Mode::Active, Mode::Maintenance) =&gt; {
            // Complex state transitions based on multiple conditions
            if current.has_pending_operations() {
                if desired.force_maintenance {
                    actions.push(Action::AbortPending);
                } else {
                    actions.push(Action::FinishPending);
                }
            }
            actions.push(Action::TransitionToMaintenance);
        }
        // ... more complex state transitions
        _ =&gt; {}
    }

    actions
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Traditional tools say:</strong> ‚ÄúCyclomatic complexity: 8 - moderate‚Äù</p>
<p><strong>Reality:</strong> This function involves complex state machine logic with conditional transitions, side effects, and non-obvious control flow. It‚Äôs genuinely complex and error-prone.</p>
<p><strong>The key insight:</strong> Traditional metrics treat both functions equally, but they‚Äôre fundamentally different in terms of cognitive load and risk.</p>
<h2 id="debtmaps-unique-approach"><a class="header" href="#debtmaps-unique-approach">Debtmap‚Äôs Unique Approach</a></h2>
<h3 id="1-entropy-based-complexity-analysis"><a class="header" href="#1-entropy-based-complexity-analysis">1. Entropy-Based Complexity Analysis</a></h3>
<p>Debtmap uses information theory to distinguish between genuinely complex code and repetitive pattern-based code.</p>
<p><strong>How it works:</strong></p>
<ul>
<li>Calculate the <strong>variety</strong> of code patterns in a function</li>
<li>High variety (many different patterns) = high entropy = genuinely complex</li>
<li>Low variety (repetitive patterns) = low entropy = simple despite high branch count</li>
</ul>
<p><strong>Applied to our examples:</strong></p>
<pre><code>validate_config():
- Cyclomatic complexity: 20
- Pattern entropy: 0.3 (low - all branches identical)
- Entropy-adjusted complexity: 5
- Assessment: Low risk despite high branch count

reconcile_state():
- Cyclomatic complexity: 8
- Pattern entropy: 0.85 (high - diverse conditional logic)
- Entropy-adjusted complexity: 9
- Assessment: High risk - genuinely complex logic
</code></pre>
<p>This approach <strong>significantly reduces false positives</strong> compared to traditional cyclomatic complexity metrics by recognizing that repetitive patterns are easier to understand than diverse, complex logic.</p>
<h3 id="2-coverage-risk-correlation"><a class="header" href="#2-coverage-risk-correlation">2. Coverage-Risk Correlation</a></h3>
<p>Debtmap is the only Rust analysis tool that natively combines code complexity with test coverage to compute risk scores.</p>
<p><strong>Why this matters:</strong></p>
<ul>
<li>Complex code with good tests = managed risk</li>
<li>Simple code without tests = unmanaged risk (but low priority)</li>
<li>Complex code without tests = CRITICAL gap</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Function A: Complex but well-tested
fn parse_query(sql: &amp;str) -&gt; Result&lt;Query&gt; {
    // Complexity: 15, Coverage: 95%
    // Risk Score: 3.2 (moderate - complexity managed by tests)
}

// Function B: Moderate complexity, no tests
fn apply_migrations(db: &amp;mut Database) -&gt; Result&lt;()&gt; {
    // Complexity: 8, Coverage: 0%
    // Risk Score: 8.9 (critical - untested with moderate complexity)
}
<span class="boring">}</span></code></pre></pre>
<p>Debtmap integrates with LCOV coverage data to automatically prioritize Function B over Function A, even though A is more complex. This is because the risk is about <strong>untested complexity</strong>, not just complexity alone.</p>
<p><strong>What makes this unique:</strong></p>
<p>Debtmap is the only Rust-focused tool that natively combines complexity analysis with LCOV coverage data to compute risk scores. While other tools support coverage reporting, they don‚Äôt correlate it with complexity metrics to prioritize technical debt and testing efforts.</p>
<h3 id="3-actionable-recommendations"><a class="header" href="#3-actionable-recommendations">3. Actionable Recommendations</a></h3>
<p>Most tools tell you <strong>what</strong> is wrong. Debtmap tells you <strong>what to do about it</strong> and <strong>what impact it will have</strong>.</p>
<p><strong>Compare:</strong></p>
<p><strong>SonarQube:</strong></p>
<pre><code>Function 'process_request' has complexity 15 (threshold: 10)
Severity: Major
</code></pre>
<p><strong>Debtmap:</strong></p>
<pre><code>#1 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/handlers.rs:127 process_request()
‚îú‚îÄ ACTION: Add 8 unit tests for full coverage
‚îú‚îÄ IMPACT: -5.2 risk reduction
‚îú‚îÄ WHY: Complex logic (cyclo=15) with 0% coverage
‚îî‚îÄ SUGGEST: Extract validation to separate functions, test each independently
</code></pre>
<p>Debtmap tells you:</p>
<ul>
<li><strong>Specific location</strong> (file:line)</li>
<li><strong>Quantified gap</strong> (8 missing tests)</li>
<li><strong>Expected impact</strong> (-5.2 risk reduction)</li>
<li><strong>Rationale</strong> (complexity + no coverage)</li>
<li><strong>Refactoring suggestions</strong> (extract functions)</li>
</ul>
<h3 id="4-context-aware-analysis"><a class="header" href="#4-context-aware-analysis">4. Context-Aware Analysis</a></h3>
<p>Debtmap understands that not all code needs the same level of scrutiny.</p>
<p><strong>Entry Points:</strong> Main functions, CLI handlers, and framework integration points are typically tested via integration tests, not unit tests. Debtmap‚Äôs analysis accounts for this:</p>
<pre><pre class="playground"><code class="language-rust">// Entry point - flagged as low priority for unit test coverage
fn main() {
    // Debtmap: "Integration test coverage expected - low priority"
}

// Core business logic - flagged as high priority
fn calculate_risk_score(metrics: &amp;Metrics) -&gt; f64 {
    // Debtmap: "High complexity + low coverage = CRITICAL"
}</code></pre></pre>
<p><strong>Call Graph Analysis:</strong> Debtmap traces function dependencies to prioritize functions called by many untested paths:</p>
<pre><code>parse_input() [untested]
  ‚îú‚îÄ called by: main() [integration tested]
  ‚îî‚îÄ called by: process_batch() [untested]

Priority: HIGH (called from untested code path)
</code></pre>
<h3 id="5-performance"><a class="header" href="#5-performance">5. Performance</a></h3>
<p>Debtmap is written in Rust and uses parallel processing for analysis. Being a native Rust binary with no JVM overhead, it‚Äôs designed for fast local development workflow integration.</p>
<p><strong>Typical analysis time:</strong></p>
<ul>
<li>Small project (~10k LOC): 1-2 seconds</li>
<li>Medium project (~50k LOC): 5-8 seconds</li>
<li>Large project (~200k LOC): 20-30 seconds</li>
</ul>
<p>This speed means you can run debtmap in your local development workflow without breaking flow, not just in CI.</p>
<h2 id="what-problem-does-debtmap-solve"><a class="header" href="#what-problem-does-debtmap-solve">What Problem Does Debtmap Solve?</a></h2>
<p>Debtmap addresses a gap that existing tools don‚Äôt fill: <strong>quantified technical debt prioritization with actionable refactoring guidance</strong>.</p>
<h3 id="the-gap-in-existing-tools"><a class="header" href="#the-gap-in-existing-tools">The Gap in Existing Tools</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Tool Type</th><th>What It Does</th><th>What It Doesn‚Äôt Do</th></tr></thead><tbody>
<tr><td><strong>Linters</strong> (clippy, ESLint)</td><td>Find code style issues and common mistakes</td><td>Don‚Äôt quantify risk or prioritize by impact</td></tr>
<tr><td><strong>Complexity Analyzers</strong> (SonarQube, CodeClimate)</td><td>Flag complex code</td><td>Don‚Äôt correlate with test coverage or provide refactoring impact estimates</td></tr>
<tr><td><strong>Coverage Tools</strong> (tarpaulin, codecov)</td><td>Show what code is tested</td><td>Don‚Äôt identify which untested code is most risky</td></tr>
</tbody></table>
</div>
<p><strong>Note:</strong> Debtmap is not a security scanner. Use tools like <code>cargo-audit</code> and <code>cargo-geiger</code> for security vulnerability detection. Debtmap focuses on technical debt prioritization, though complex untested code can sometimes harbor security issues.</p>
<p><strong>What Debtmap uniquely provides:</strong></p>
<ol>
<li><strong>Quantified Debt Scoring</strong> - Not just ‚Äúthis is complex,‚Äù but ‚Äúthis scores 8.9/10 on risk‚Äù</li>
<li><strong>Coverage-Risk Correlation</strong> - Identifies untested complex code, not just complex code</li>
<li><strong>Impact Quantification</strong> - ‚ÄúAdding 6 tests will reduce risk by 3.7 points‚Äù</li>
<li><strong>Actionable Recommendations</strong> - Specific refactoring suggestions with effort estimates</li>
<li><strong>Dependency-Aware Prioritization</strong> - Prioritizes code that impacts many other functions</li>
</ol>
<h3 id="debtmap-vs-traditional-tools"><a class="header" href="#debtmap-vs-traditional-tools">Debtmap vs Traditional Tools</a></h3>
<p><strong>SonarQube / CodeClimate:</strong></p>
<ul>
<li><strong>They say:</strong> ‚ÄúFunction has complexity 15 (threshold exceeded)‚Äù</li>
<li><strong>Debtmap says:</strong> ‚ÄúAdd 8 tests (-5.2 risk). Extract validation logic to reduce complexity by 60%‚Äù</li>
</ul>
<p><strong>Coverage Tools (tarpaulin, codecov):</strong></p>
<ul>
<li><strong>They say:</strong> ‚Äú67% line coverage, 54% branch coverage‚Äù</li>
<li><strong>Debtmap says:</strong> ‚Äú3 critical gaps: untested complex functions that are called from 12+ code paths‚Äù</li>
</ul>
<p><strong>Linters (clippy):</strong></p>
<ul>
<li><strong>They say:</strong> ‚ÄúConsider using Iterator::any() instead of a for loop‚Äù</li>
<li><strong>Debtmap says:</strong> ‚ÄúThis function has high cognitive complexity (12) and is called by 8 untested modules - prioritize adding tests before refactoring‚Äù</li>
</ul>
<h3 id="when-to-use-debtmap"><a class="header" href="#when-to-use-debtmap">When to Use Debtmap</a></h3>
<p><strong>Use Debtmap when you need to:</strong></p>
<ul>
<li>Decide which technical debt to tackle first (limited time/resources)</li>
<li>Identify critical testing gaps (high-complexity, zero-coverage code)</li>
<li>Quantify the impact of refactoring efforts</li>
<li>Reduce false positives from repetitive validation code</li>
<li>Prioritize refactoring based on risk, not just complexity</li>
<li>Get specific, actionable recommendations with effort estimates</li>
</ul>
<p><strong>Use other tools for different needs:</strong></p>
<ul>
<li><strong>clippy</strong> - Catch Rust idiom violations and common mistakes</li>
<li><strong>tarpaulin</strong> - Generate LCOV coverage data (Debtmap analyzes it)</li>
<li><strong>SonarQube</strong> - Multi-language analysis with centralized dashboards</li>
</ul>
<p><strong>Security is a separate concern:</strong></p>
<ul>
<li><strong>cargo-audit</strong> - Find known vulnerabilities in dependencies</li>
<li><strong>cargo-geiger</strong> - Detect unsafe code usage</li>
<li>Debtmap doesn‚Äôt scan for security issues, though complex code may harbor security risks</li>
</ul>
<h3 id="recommended-workflow"><a class="header" href="#recommended-workflow">Recommended Workflow</a></h3>
<p>Debtmap works <strong>alongside</strong> existing tools, not instead of them:</p>
<pre><code class="language-bash"># 1. Local development loop (before commit)
cargo fmt                    # Format code
cargo clippy                 # Check idioms and common issues
cargo test                   # Run tests
debtmap analyze .            # Identify new technical debt

# 2. CI/CD pipeline (PR validation)
cargo test --all-features    # Full test suite
cargo clippy -- -D warnings  # Fail on warnings
debtmap validate .           # Enforce debt thresholds

# 3. Weekly planning (prioritize work)
cargo tarpaulin --out lcov   # Generate coverage
debtmap analyze . --lcov lcov.info --top 20
# Review top 20 debt items, plan sprint work

# 4. Monthly review (track trends)
debtmap analyze . --format json --output debt-$(date +%Y%m).json
debtmap compare --before debt-202410.json --after debt-202411.json
</code></pre>
<h3 id="the-bottom-line"><a class="header" href="#the-bottom-line">The Bottom Line</a></h3>
<p><strong>Debtmap isn‚Äôt a replacement for linters or coverage tools.</strong> It solves a different problem: turning raw complexity and coverage data into <strong>prioritized, actionable technical debt recommendations</strong>.</p>
<p>If you‚Äôre asking ‚ÄúWhere should I focus my refactoring efforts?‚Äù or ‚ÄúWhich code needs tests most urgently?‚Äù, that‚Äôs what Debtmap is built for.</p>
<h2 id="key-differentiators"><a class="header" href="#key-differentiators">Key Differentiators</a></h2>
<ol>
<li><strong>Entropy analysis</strong> - Reduces false positives from repetitive code</li>
<li><strong>Native coverage integration</strong> - Built-in LCOV support for risk scoring</li>
<li><strong>Actionable recommendations</strong> - Specific steps with quantified impact</li>
<li><strong>Context-aware</strong> - Understands entry points, call graphs, and testing patterns</li>
<li><strong>Fast</strong> - Rust performance for local development workflow</li>
<li><strong>Tiered prioritization</strong> - Critical/High/Moderate/Low classification with clear rationale</li>
</ol>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Ready to try it? Head to <a href="getting-started.html">Getting Started</a> to install debtmap and run your first analysis.</p>
<p>Want to understand how it works under the hood? See <a href="architecture.html">Architecture</a> for the analysis pipeline.</p>
<p>Have questions? Check the <a href="faq.html">FAQ</a> for common questions and answers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h1>
<p>This guide will help you install Debtmap and run your first analysis in just a few minutes.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>Before installing Debtmap, you‚Äôll need:</p>
<ul>
<li><strong>For pre-built binaries</strong>: No prerequisites! The install script handles everything.</li>
<li><strong>For cargo install or building from source</strong>:
<ul>
<li>Rust toolchain (rustc and cargo)</li>
<li>Supported platforms: Linux, macOS, Windows</li>
<li>Rust edition 2021 or later</li>
</ul>
</li>
</ul>
<p><strong>Optional</strong> (for coverage-based risk analysis):</p>
<ul>
<li><strong>Rust projects</strong>: <code>cargo-tarpaulin</code> for coverage data</li>
<li><strong>JavaScript/TypeScript</strong>: Jest or other tools generating LCOV format</li>
<li><strong>Python</strong>: pytest with coverage plugin</li>
</ul>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<h3 id="quick-install-recommended"><a class="header" href="#quick-install-recommended">Quick Install (Recommended)</a></h3>
<p>Install the latest release with a single command:</p>
<pre><code class="language-bash">curl -sSL https://raw.githubusercontent.com/iepathos/debtmap/master/install.sh | bash
</code></pre>
<p>Or with wget:</p>
<pre><code class="language-bash">wget -qO- https://raw.githubusercontent.com/iepathos/debtmap/master/install.sh | bash
</code></pre>
<p>This will:</p>
<ul>
<li>Automatically detect your OS and architecture</li>
<li>Download the appropriate pre-built binary from the latest GitHub release</li>
<li>Install debtmap to <code>~/.cargo/bin</code> if it exists, otherwise <code>~/.local/bin</code></li>
<li>Offer to automatically add the install directory to your PATH if needed</li>
</ul>
<h3 id="using-cargo"><a class="header" href="#using-cargo">Using Cargo</a></h3>
<p>If you have Rust installed:</p>
<pre><code class="language-bash">cargo install debtmap
</code></pre>
<h3 id="from-source"><a class="header" href="#from-source">From Source</a></h3>
<p>For the latest development version:</p>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/iepathos/debtmap.git
cd debtmap

# Build and install
cargo install --path .
</code></pre>
<h3 id="verify-installation"><a class="header" href="#verify-installation">Verify Installation</a></h3>
<p>After installation, verify Debtmap is working:</p>
<pre><code class="language-bash"># Check version
debtmap --version

# See available commands
debtmap --help
</code></pre>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="installation-issues"><a class="header" href="#installation-issues">Installation Issues</a></h3>
<ul>
<li><strong>Binary not in PATH</strong>: Add <code>~/.cargo/bin</code> or <code>~/.local/bin</code> to your PATH
<pre><code class="language-bash">export PATH="$HOME/.cargo/bin:$PATH"  # Add to ~/.bashrc or ~/.zshrc
</code></pre>
</li>
<li><strong>Permission issues</strong>: Run the install script with your current user (don‚Äôt use sudo)</li>
<li><strong>Cargo not found</strong>: Install Rust from https://rustup.rs</li>
</ul>
<h3 id="first-run-issues"><a class="header" href="#first-run-issues">First Run Issues</a></h3>
<ul>
<li>
<p><strong>Empty output or no items found</strong>: Check that your project contains supported source files (<code>.rs</code>, <code>.py</code>, <code>.js</code>, <code>.ts</code>, <code>.tsx</code>). Verify with <code>debtmap analyze . -vvv</code> for debug output.</p>
</li>
<li>
<p><strong>Parser failures</strong>: If analysis fails with parsing errors:</p>
<pre><code class="language-bash"># Run with verbose output to identify problematic files
debtmap analyze . -vv
# Exclude problematic files temporarily
debtmap init  # Creates .debtmap.toml
# Edit .debtmap.toml to add ignore patterns
</code></pre>
</li>
<li>
<p><strong>Unexpected results</strong>: First run builds cache and may take longer. For fresh analysis:</p>
<pre><code class="language-bash">debtmap analyze . --clear-cache
</code></pre>
</li>
<li>
<p><strong>Performance issues</strong>: For large codebases (10,000+ files):</p>
<pre><code class="language-bash"># Limit parallel jobs to reduce memory usage
debtmap analyze . --jobs 4
# Or analyze specific directories
debtmap analyze ./src
</code></pre>
</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<p>Here are the most common commands to get you started:</p>
<pre><code class="language-bash"># Analyze current directory (simplest command)
debtmap analyze .

# Analyze with coverage data for risk scoring (recommended)
# Note: --lcov is a shorthand alias for --coverage-file
debtmap analyze . --lcov target/coverage/lcov.info

# Generate coverage first (for Rust projects)
cargo tarpaulin --out lcov --output-dir target/coverage
debtmap analyze . --lcov target/coverage/lcov.info

# Analyze with custom thresholds
# Note: threshold-duplication specifies minimum lines of duplicated code to detect
debtmap analyze ./src --threshold-complexity 15 --threshold-duplication 50

# Output as JSON (for CI/CD integration)
debtmap analyze ./src --format json --output report.json

# Show only top 10 high-priority issues
debtmap analyze . --top 10

# Initialize configuration file for project-specific settings
debtmap init

# Validate against thresholds (CI/CD integration)
debtmap validate ./src --max-debt-density 5.0

# Validate using config file settings
debtmap validate . --config .debtmap.toml --max-debt-density 5.0

# Compare before/after to track improvements
debtmap analyze . --format json --output before.json
# ... make improvements ...
debtmap analyze . --format json --output after.json
debtmap compare --before before.json --after after.json

# Advanced comparison: focus on specific function
debtmap compare --before before.json --after after.json --target-location src/main.rs:main:10

# Extract target from implementation plan
debtmap compare --before before.json --after after.json --plan IMPLEMENTATION_PLAN.md
</code></pre>
<h3 id="advanced-options"><a class="header" href="#advanced-options">Advanced Options</a></h3>
<p>Debtmap provides many powerful options to customize your analysis:</p>
<p><strong>Verbosity Levels:</strong></p>
<pre><code class="language-bash"># Show main factors contributing to scores
debtmap analyze . -v

# Show detailed calculations
debtmap analyze . -vv

# Show all debug information
debtmap analyze . -vvv
</code></pre>
<p><strong>Filtering and Prioritization:</strong></p>
<pre><code class="language-bash"># Only show high-priority items
debtmap analyze . --min-priority high

# Filter by specific categories
debtmap analyze . --filter Architecture,Testing

# Group results by debt category
debtmap analyze . --group-by-category
</code></pre>
<p><strong>Cache Management:</strong></p>
<pre><code class="language-bash"># Skip cache for fresh analysis
debtmap analyze . --no-cache

# Clear cache and rebuild
debtmap analyze . --clear-cache

# View cache statistics
debtmap analyze . --cache-stats

# Specify custom cache location
debtmap analyze . --cache-location /custom/path

# Migrate cache from local to shared location
debtmap analyze . --migrate-cache
</code></pre>
<p><strong>Performance Control:</strong></p>
<pre><code class="language-bash"># Limit parallel jobs
debtmap analyze . --jobs 4

# Disable parallel processing
debtmap analyze . --no-parallel
</code></pre>
<p><strong>Output Control:</strong></p>
<pre><code class="language-bash"># Plain output (no colors/emoji, for CI/CD)
debtmap analyze . --plain

# Compact summary output
debtmap analyze . --summary

# Control aggregation behavior
debtmap analyze . --aggregate-only          # Show only aggregated results
debtmap analyze . --no-aggregation          # Skip aggregation entirely
debtmap analyze . --aggregation-method sum  # Choose aggregation method

# Adjust detail level in output
debtmap analyze . --detail-level high       # More detailed output
</code></pre>
<p><strong>Expert Options:</strong></p>
<p>These advanced options are available for power users and specialized use cases:</p>
<pre><code class="language-bash"># Analysis behavior
--semantic-off              # Disable semantic analysis
--no-context-aware          # Disable context-aware analysis
--multi-pass                # Enable multi-pass analysis for deeper insights
--validate-loc              # Validate lines of code calculations

# Rust-specific options
--verbose-macro-warnings    # Show detailed macro expansion warnings
--show-macro-stats          # Display macro usage statistics

# Filtering and thresholds
--threshold-preset &lt;name&gt;   # Use predefined threshold preset
--min-problematic &lt;count&gt;   # Minimum problematic items to report
--max-files &lt;count&gt;         # Limit analysis to N files
--no-god-object             # Disable god object detection

# Advanced reporting
--attribution               # Include code attribution information
</code></pre>
<p>For detailed documentation of these options, run <code>debtmap analyze --help</code>.</p>
<h2 id="first-analysis"><a class="header" href="#first-analysis">First Analysis</a></h2>
<p>Let‚Äôs run your first analysis! Navigate to a project directory and run:</p>
<pre><code class="language-bash">debtmap analyze .
</code></pre>
<p><strong>What happens during analysis:</strong></p>
<ol>
<li><strong>File Discovery</strong> - Debtmap scans your project for supported source files (Rust, Python, JavaScript, TypeScript)</li>
<li><strong>Parsing</strong> - Each file is parsed into an Abstract Syntax Tree (AST)</li>
<li><strong>Metrics Calculation</strong> - Complexity, debt patterns, and risk scores are computed</li>
<li><strong>Prioritization</strong> - Results are ranked by priority (CRITICAL, HIGH, MEDIUM, LOW)</li>
<li><strong>Output</strong> - Results are displayed in your chosen format</li>
</ol>
<p><strong>Expected timing</strong>: Analyzing a 10,000 LOC project typically takes 2-5 seconds. The first run may be slightly slower as Debtmap builds its cache.</p>
<p><strong>About Caching:</strong>
Debtmap caches parsed ASTs and computed metrics to speed up subsequent analyses:</p>
<ul>
<li><strong>Cache location</strong>: <code>XDG_CACHE_HOME/debtmap</code> on Linux, <code>~/Library/Caches/debtmap</code> on macOS, <code>%LOCALAPPDATA%/debtmap</code> on Windows</li>
<li><strong>What‚Äôs cached</strong>: Parsed ASTs and computed metrics for each file</li>
<li><strong>Invalidation</strong>: Cache is automatically invalidated when files are modified</li>
<li><strong>Management</strong>: Use <code>--clear-cache</code> to clear, <code>--no-cache</code> to skip, or <code>--cache-stats</code> to view statistics</li>
</ul>
<h2 id="language-support"><a class="header" href="#language-support">Language Support</a></h2>
<p>Debtmap supports multiple programming languages with varying feature completeness:</p>
<h3 id="rust-full-support"><a class="header" href="#rust-full-support">Rust (Full Support)</a></h3>
<p>All analysis features available:</p>
<ul>
<li>Complexity metrics (cyclomatic, cognitive, nesting, lines)</li>
<li>Technical debt detection (code smells, anti-patterns)</li>
<li>Test gap analysis with coverage integration</li>
<li>Advanced features:
<ul>
<li>Trait detection and analysis</li>
<li>Function purity analysis</li>
<li>Call graph generation</li>
<li>Macro expansion tracking</li>
</ul>
</li>
</ul>
<h3 id="python-partial-support"><a class="header" href="#python-partial-support">Python (Partial Support)</a></h3>
<p>Core features available:</p>
<ul>
<li>Complexity metrics (cyclomatic, cognitive, nesting, lines)</li>
<li>Basic debt detection (code smells, god objects)</li>
<li>Test gap analysis with coverage integration</li>
</ul>
<p><strong>Not yet available</strong>: Purity analysis, detailed call graphs</p>
<h3 id="javascripttypescript-partial-support"><a class="header" href="#javascripttypescript-partial-support">JavaScript/TypeScript (Partial Support)</a></h3>
<p>Core features available:</p>
<ul>
<li>Complexity metrics (cyclomatic, cognitive, nesting, lines)</li>
<li>Basic debt detection (code smells, god objects)</li>
<li>Test gap analysis with coverage integration</li>
</ul>
<p><strong>Not yet available</strong>: Purity analysis, detailed call graphs</p>
<p><strong>Note</strong>: All languages benefit from coverage integration for accurate risk assessment. The core analysis workflow (complexity ‚Üí debt patterns ‚Üí prioritization) works consistently across all supported languages.</p>
<h2 id="example-output"><a class="header" href="#example-output">Example Output</a></h2>
<p>When you run <code>debtmap analyze .</code>, you‚Äôll see output like this:</p>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    PRIORITY TECHNICAL DEBT FIXES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéØ TOP 3 RECOMMENDATIONS (by unified priority)

#1 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/analyzers/rust_call_graph.rs:38 add_function_to_graph()
‚îú‚îÄ ACTION: Add 6 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=6, branches=6, cognitive=8, nesting=2, lines=32
‚îú‚îÄ DEPENDENCIES: 0 upstream, 11 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=6, cog=8)

#2 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/debt/smells.rs:196 detect_data_clumps()
‚îú‚îÄ ACTION: Add 5 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=5, branches=5, cognitive=11, nesting=5, lines=31
‚îú‚îÄ DEPENDENCIES: 0 upstream, 4 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=5, cog=11)

#3 SCORE: 8.6 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/risk/context/dependency.rs:247 explain()
‚îú‚îÄ ACTION: Add 5 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.6 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=5, branches=5, cognitive=9, nesting=1, lines=24
‚îú‚îÄ DEPENDENCIES: 0 upstream, 1 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=5, cog=9)


üìä TOTAL DEBT SCORE: 4907
üìà OVERALL COVERAGE: 67.12%
</code></pre>
<h2 id="understanding-the-output"><a class="header" href="#understanding-the-output">Understanding the Output</a></h2>
<p>Let‚Äôs break down what this output means:</p>
<h3 id="priority-levels"><a class="header" href="#priority-levels">Priority Levels</a></h3>
<ul>
<li><strong>CRITICAL</strong> (9.0-10.0): Immediate action required - high complexity with no test coverage</li>
<li><strong>HIGH</strong> (7.0-8.9): Should be addressed soon - moderate-high complexity with poor coverage</li>
<li><strong>MEDIUM</strong> (5.0-6.9): Plan for next sprint - moderate complexity or partial coverage gaps</li>
<li><strong>LOW</strong> (3.0-4.9): Nice to have - well-tested or simple functions</li>
</ul>
<p><strong>Note:</strong> These are default priority thresholds. You can customize them in <code>.debtmap.toml</code> under the <code>[tiers]</code> section to match your team‚Äôs standards.</p>
<h3 id="key-metrics"><a class="header" href="#key-metrics">Key Metrics</a></h3>
<ul>
<li>
<p><strong>Unified Score</strong> (0-10 scale): Overall priority combining complexity, coverage, and dependencies</p>
<ul>
<li>Higher score = higher priority</li>
<li>Takes into account multiple risk factors</li>
</ul>
</li>
<li>
<p><strong>Debt Type</strong>: Category of the issue</p>
<ul>
<li><code>TestGap</code>: Missing test coverage</li>
<li><code>Complexity</code>: Exceeds complexity thresholds</li>
<li><code>Duplication</code>: Repeated code blocks</li>
<li><code>CodeSmell</code>: Anti-patterns and bad practices</li>
</ul>
</li>
<li>
<p><strong>Complexity Metrics</strong>:</p>
<ul>
<li><strong>Cyclomatic</strong>: Number of decision points (branches, loops)</li>
<li><strong>Cognitive</strong>: How difficult the code is to understand</li>
<li><strong>Nesting</strong>: Maximum indentation depth</li>
<li><strong>Lines</strong>: Function length</li>
</ul>
</li>
<li>
<p><strong>Dependencies</strong>:</p>
<ul>
<li><strong>Upstream callers</strong>: Functions that call this function</li>
<li><strong>Downstream callees</strong>: Functions this function calls</li>
<li>More dependencies = higher impact when this code breaks</li>
</ul>
</li>
</ul>
<h3 id="recommendation-structure"><a class="header" href="#recommendation-structure">Recommendation Structure</a></h3>
<p>Each recommendation shows:</p>
<ul>
<li><strong>ACTION</strong>: What you should do (e.g., ‚ÄúAdd 6 unit tests‚Äù)</li>
<li><strong>IMPACT</strong>: Expected improvement (e.g., ‚ÄúFull test coverage, -3.7 risk‚Äù)</li>
<li><strong>WHY</strong>: The reasoning behind this recommendation</li>
</ul>
<h3 id="organizing-results"><a class="header" href="#organizing-results">Organizing Results</a></h3>
<p>When analyzing large codebases, you can organize and filter results to focus on specific areas:</p>
<p><strong>Group by Debt Category:</strong></p>
<pre><code class="language-bash">debtmap analyze . --group-by-category
</code></pre>
<p>This organizes results by type: Architecture, Testing, Performance, CodeQuality</p>
<p><strong>Filter by Priority:</strong></p>
<pre><code class="language-bash"># Show only high and critical priority items
debtmap analyze . --min-priority high

# Combine with --top to limit results
debtmap analyze . --min-priority high --top 10
</code></pre>
<p><strong>Filter by Category:</strong></p>
<pre><code class="language-bash"># Focus on specific debt types
debtmap analyze . --filter Architecture,Testing

# Available categories: Architecture, Testing, Performance, CodeQuality
</code></pre>
<p>These filtering options help you focus on specific types of technical debt, making it easier to plan targeted improvements.</p>
<h3 id="summary-statistics"><a class="header" href="#summary-statistics">Summary Statistics</a></h3>
<ul>
<li>
<p><strong>Total Debt Score</strong>: Sum of all debt scores across your codebase</p>
<ul>
<li>Lower is better</li>
<li>Track over time to measure improvement</li>
</ul>
</li>
<li>
<p><strong>Overall Coverage</strong>: Percentage of code covered by tests</p>
<ul>
<li>Only shown when coverage data is provided</li>
</ul>
</li>
</ul>
<h3 id="output-formats"><a class="header" href="#output-formats">Output Formats</a></h3>
<p>Debtmap supports multiple output formats:</p>
<ul>
<li><strong>Terminal</strong> (default): Human-readable colored output with tables</li>
<li><strong>JSON</strong>: Machine-readable format for CI/CD integration</li>
<li><strong>Markdown</strong>: Documentation-friendly format for reports</li>
</ul>
<p>Example JSON output:</p>
<pre><code class="language-bash"># By default, JSON uses legacy format
debtmap analyze . --format json --output report.json

# For the new unified format (with consistent structure and type field):
debtmap analyze . --format json --output-format unified --output report.json
</code></pre>
<p><strong>JSON Format Options:</strong></p>
<ul>
<li><strong>legacy</strong> (default): Uses <code>{File: {...}}</code> and <code>{Function: {...}}</code> wrappers for backward compatibility with existing tools</li>
<li><strong>unified</strong>: New format (spec 108) with consistent structure and <code>type</code> field for all items</li>
</ul>
<p>Recommendation: Use <code>unified</code> for new integrations, <code>legacy</code> only for compatibility with existing tooling.</p>
<p>Example Markdown output:</p>
<pre><code class="language-bash">debtmap analyze . --format markdown --output report.md
</code></pre>
<h2 id="whats-next"><a class="header" href="#whats-next">What‚Äôs Next?</a></h2>
<p>Now that you‚Äôve run your first analysis, explore these topics:</p>
<ul>
<li><strong><a href="./analysis-guide.html">Analysis Guide</a></strong> - Deep dive into complexity metrics, debt patterns, and risk scoring</li>
<li><strong><a href="./output-formats.html">Output Formats</a></strong> - Detailed guide to JSON schema and integration options</li>
<li><strong>Configuration</strong> - Customize thresholds and filters with <code>.debtmap.toml</code></li>
<li><strong>CI/CD Integration</strong> - Use the <code>validate</code> command to enforce quality gates</li>
</ul>
<h3 id="generate-a-configuration-file"><a class="header" href="#generate-a-configuration-file">Generate a Configuration File</a></h3>
<p>Create a project-specific configuration:</p>
<pre><code class="language-bash">debtmap init
</code></pre>
<p>This creates a <code>.debtmap.toml</code> file with sensible defaults that you can customize for your project.</p>
<p><strong>Example Configuration File:</strong></p>
<p>Here‚Äôs a typical <code>.debtmap.toml</code> with common settings:</p>
<pre><code class="language-toml"># Debtmap Configuration File
# Generated by: debtmap init

# Analysis thresholds
[thresholds]
complexity = 10        # Flag functions with cyclomatic complexity &gt; 10
duplication = 40       # Minimum lines for duplicate code detection
file_size = 500        # Warn on files exceeding 500 lines

# Priority tier boundaries (for unified priority scores 0-10)
[tiers]
critical = 9.0         # Score &gt;= 9.0 = CRITICAL priority
high = 7.0             # Score &gt;= 7.0 = HIGH priority
medium = 5.0           # Score &gt;= 5.0 = MEDIUM priority
# Anything below 5.0 = LOW priority

# Risk scoring weights (must sum to 1.0)
[weights]
coverage = 0.4         # Weight for test coverage gaps
complexity = 0.35      # Weight for complexity metrics
dependencies = 0.25    # Weight for call graph dependencies

# Language-specific settings
[languages]
rust = true            # Enable Rust analysis
python = true          # Enable Python analysis
javascript = true      # Enable JavaScript/TypeScript analysis

# Files and directories to ignore
[ignore]
patterns = [
    "**/target/**",     # Rust build artifacts
    "**/node_modules/**", # JavaScript dependencies
    "**/__pycache__/**", # Python bytecode
    "**/tests/**",      # Test directories (optional)
    "**/*.test.ts",     # Test files (optional)
]

# God object detection thresholds
[god_object]
methods = 20           # Warn on classes/modules with &gt; 20 methods
lines = 500            # Warn on classes/modules with &gt; 500 lines

# Entropy-based complexity detection
[entropy]
enabled = true         # Enable entropy analysis
threshold = 0.7        # Flag functions with entropy &gt; 0.7
</code></pre>
<p><strong>Key Configuration Options:</strong></p>
<p>The configuration file allows you to customize:</p>
<ul>
<li><strong>Threshold customization</strong> - Adjust complexity, duplication, and file size thresholds</li>
<li><strong>Scoring weights</strong> - Fine-tune how coverage, complexity, and dependencies are weighted</li>
<li><strong>Language selection</strong> - Enable/disable specific language analyzers</li>
<li><strong>Ignore patterns</strong> - Exclude test files or generated code from analysis</li>
<li><strong>God object thresholds</strong> - Configure what constitutes a ‚Äúgod object‚Äù anti-pattern</li>
<li><strong>Entropy analysis</strong> - Control entropy-based complexity detection</li>
<li><strong>Priority tiers</strong> - Customize CRITICAL/HIGH/MEDIUM/LOW threshold ranges</li>
</ul>
<p>See the Configuration chapter for complete documentation of all available options.</p>
<h3 id="try-analysis-with-coverage"><a class="header" href="#try-analysis-with-coverage">Try Analysis with Coverage</a></h3>
<p>For more accurate risk assessment, run analysis with coverage data. Coverage helps Debtmap identify <strong>truly risky code</strong> - functions that are both complex AND untested.</p>
<h4 id="generating-coverage-data"><a class="header" href="#generating-coverage-data">Generating Coverage Data</a></h4>
<p><strong>Rust Projects:</strong></p>
<pre><code class="language-bash"># Install cargo-tarpaulin if not already installed
cargo install cargo-tarpaulin

# Generate LCOV coverage report
cargo tarpaulin --out lcov --output-dir target/coverage

# Run debtmap with coverage
debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<p><strong>Python Projects:</strong></p>
<pre><code class="language-bash"># Install coverage plugin if not already installed
pip install pytest-cov

# Generate LCOV coverage report
pytest --cov=. --cov-report=lcov:coverage.lcov

# Run debtmap with coverage
debtmap analyze . --lcov coverage.lcov
</code></pre>
<p><strong>JavaScript/TypeScript Projects:</strong></p>
<pre><code class="language-bash"># Using Jest (add to package.json or run directly)
jest --coverage --coverageReporters=lcov

# Run debtmap with coverage
debtmap analyze . --lcov coverage/lcov.info

# Using NYC with other test runners
npx nyc --reporter=lcovonly npm test
debtmap analyze . --lcov coverage/lcov.info

# Using Vitest
vitest run --coverage --coverage.reporter=lcov
debtmap analyze . --lcov coverage/lcov-report/lcov.info
</code></pre>
<p><strong>Note</strong>: The <code>--lcov</code> flag is a shorthand alias for <code>--coverage-file</code>. Both accept LCOV format coverage reports.</p>
<hr />
<p><strong>Need help?</strong> Report issues at https://github.com/iepathos/debtmap/issues</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli-reference"><a class="header" href="#cli-reference">CLI Reference</a></h1>
<p>Complete reference for Debtmap command-line interface.</p>
<h2 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h2>
<pre><code class="language-bash"># Basic analysis
debtmap analyze src/

# With coverage integration
debtmap analyze src/ --coverage-file coverage.lcov

# Generate JSON report
debtmap analyze . --format json --output report.json

# Show top 10 priority items only
debtmap analyze . --top 10 --min-priority high

# Initialize configuration and validate
debtmap init
debtmap validate . --config debtmap.toml
</code></pre>
<h2 id="commands-1"><a class="header" href="#commands-1">Commands</a></h2>
<p>Debtmap provides five main commands:</p>
<h3 id="analyze"><a class="header" href="#analyze"><code>analyze</code></a></h3>
<p>Analyze code for complexity and technical debt.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap analyze &lt;PATH&gt; [OPTIONS]
</code></pre>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>&lt;PATH&gt;</code> - Path to analyze (file or directory)</li>
</ul>
<p><strong>Description:</strong>
Primary command for code analysis. Supports multiple output formats (json, markdown, terminal), coverage file integration, caching, parallel processing, context-aware risk analysis, and comprehensive filtering options.</p>
<p>See <a href="cli-reference.html#options">Options</a> section below for all available flags.</p>
<h3 id="init"><a class="header" href="#init"><code>init</code></a></h3>
<p>Initialize a Debtmap configuration file.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap init [OPTIONS]
</code></pre>
<p><strong>Options:</strong></p>
<ul>
<li><code>-f, --force</code> - Force overwrite existing config</li>
</ul>
<p><strong>Description:</strong>
Creates a <code>debtmap.toml</code> configuration file in the current directory with default settings. Use <code>--force</code> to overwrite an existing configuration file.</p>
<h3 id="validate"><a class="header" href="#validate"><code>validate</code></a></h3>
<p>Validate code against thresholds defined in configuration file.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap validate &lt;PATH&gt; [OPTIONS]
</code></pre>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>&lt;PATH&gt;</code> - Path to analyze</li>
</ul>
<p><strong>Options:</strong></p>
<p><em>Configuration &amp; Output:</em></p>
<ul>
<li><code>-c, --config &lt;CONFIG&gt;</code> - Configuration file path</li>
<li><code>-f, --format &lt;FORMAT&gt;</code> - Output format: json, markdown, terminal</li>
<li><code>-o, --output &lt;OUTPUT&gt;</code> - Output file path (defaults to stdout)</li>
</ul>
<p><em>Coverage &amp; Context:</em></p>
<ul>
<li><code>--coverage-file &lt;PATH&gt;</code> / <code>--lcov &lt;PATH&gt;</code> - LCOV coverage file for risk analysis</li>
<li><code>--context</code> / <code>--enable-context</code> - Enable context-aware risk analysis</li>
<li><code>--context-providers &lt;PROVIDERS&gt;</code> - Context providers to use (comma-separated)</li>
<li><code>--disable-context &lt;PROVIDERS&gt;</code> - Disable specific context providers</li>
</ul>
<p><em>Thresholds &amp; Validation:</em></p>
<ul>
<li><code>--max-debt-density &lt;N&gt;</code> - Maximum debt density allowed (per 1000 LOC)</li>
</ul>
<p><em>Display Filtering:</em></p>
<ul>
<li><code>--top &lt;N&gt;</code> / <code>--head &lt;N&gt;</code> - Show only top N priority items</li>
<li><code>--tail &lt;N&gt;</code> - Show only bottom N priority items</li>
<li><code>-s, --summary</code> - Use summary format with tiered priority display</li>
</ul>
<p><em>Analysis Control:</em></p>
<ul>
<li><code>--semantic-off</code> - Disable semantic analysis (fallback mode)</li>
</ul>
<p><em>Performance Control:</em></p>
<ul>
<li><code>--no-parallel</code> - Disable parallel call graph construction (enabled by default)</li>
<li><code>-j, --jobs &lt;N&gt;</code> - Number of threads for parallel processing (0 = use all cores)
<ul>
<li>Can also use <code>DEBTMAP_JOBS</code> environment variable</li>
</ul>
</li>
</ul>
<p><em>Debugging &amp; Verbosity:</em></p>
<ul>
<li><code>-v, --verbose</code> - Increase verbosity level (can be repeated: -v, -vv, -vvv)</li>
</ul>
<p><strong>Description:</strong>
Similar to <code>analyze</code> but enforces thresholds defined in configuration file. Returns non-zero exit code if thresholds are exceeded, making it suitable for CI/CD integration.</p>
<p>The <code>validate</code> command supports a focused subset of <code>analyze</code> options, primarily for output control, coverage integration, context-aware analysis, and display filtering.</p>
<p><strong>Note:</strong> The following <code>analyze</code> options are NOT available in the <code>validate</code> command:</p>
<ul>
<li><code>--threshold-complexity</code>, <code>--threshold-duplication</code>, <code>--threshold-preset</code> (configure these in <code>.debtmap.toml</code> instead)</li>
<li><code>--cache-*</code> options (caching control)</li>
<li><code>--languages</code> (language filtering)</li>
</ul>
<p><strong>Note:</strong> The <code>--explain-score</code> flag exists in the <code>validate</code> command but is deprecated (hidden). Use <code>-v</code>, <code>-vv</code>, or <code>-vvv</code> for verbosity instead.</p>
<p>Configure analysis thresholds in your <code>.debtmap.toml</code> configuration file for use with the <code>validate</code> command.</p>
<p><strong>Exit Codes:</strong></p>
<ul>
<li><code>0</code> - Success (no errors, all thresholds passed)</li>
<li>Non-zero - Failure (errors occurred or thresholds exceeded)</li>
</ul>
<h3 id="compare"><a class="header" href="#compare"><code>compare</code></a></h3>
<p>Compare two analysis results and generate a diff report.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap compare --before &lt;FILE&gt; --after &lt;FILE&gt; [OPTIONS]
</code></pre>
<p><strong>Required Options:</strong></p>
<ul>
<li><code>--before &lt;FILE&gt;</code> - Path to ‚Äúbefore‚Äù analysis JSON</li>
<li><code>--after &lt;FILE&gt;</code> - Path to ‚Äúafter‚Äù analysis JSON</li>
</ul>
<p><strong>Optional Target Location:</strong></p>
<ul>
<li><code>--plan &lt;FILE&gt;</code> - Path to implementation plan (to extract target location)</li>
<li><code>--target-location &lt;LOCATION&gt;</code> - Target location in format <code>file:function:line</code></li>
</ul>
<p><strong>Note:</strong> <code>--plan</code> and <code>--target-location</code> are mutually exclusive options. Using both together will cause a CLI error:</p>
<pre><code>error: the argument '--plan &lt;FILE&gt;' cannot be used with '--target-location &lt;LOCATION&gt;'
</code></pre>
<p>Use one or the other to specify the target location.</p>
<p><strong>Output Options:</strong></p>
<ul>
<li><code>-f, --format &lt;FORMAT&gt;</code> - Output format: json, markdown, terminal (default: json)</li>
<li><code>-o, --output &lt;OUTPUT&gt;</code> - Output file (defaults to stdout)</li>
</ul>
<p><strong>Description:</strong>
Compares two analysis results and generates a diff showing improvements or regressions in code quality metrics.</p>
<h3 id="validate-improvement"><a class="header" href="#validate-improvement"><code>validate-improvement</code></a></h3>
<p>Validate that technical debt improvements meet quality thresholds.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap validate-improvement --comparison &lt;FILE&gt; [OPTIONS]
</code></pre>
<p><strong>Required Options:</strong></p>
<ul>
<li><code>--comparison &lt;FILE&gt;</code> - Path to comparison JSON file (from <code>debtmap compare</code>)</li>
</ul>
<p><strong>Optional Options:</strong></p>
<ul>
<li><code>-o, --output &lt;FILE&gt;</code> - Output file path for validation results (default: <code>.prodigy/debtmap-validation.json</code>)</li>
<li><code>--previous-validation &lt;FILE&gt;</code> - Path to previous validation result for trend tracking</li>
<li><code>--threshold &lt;N&gt;</code> - Improvement threshold percentage (default: 75.0)</li>
<li><code>-f, --format &lt;FORMAT&gt;</code> - Output format: json, markdown, terminal (default: json)</li>
<li><code>--quiet</code> - Suppress console output (useful for automation)</li>
</ul>
<p><strong>Description:</strong>
Validates improvement quality by analyzing comparison output from <code>debtmap compare</code>. Calculates a composite improvement score based on:</p>
<ul>
<li>Target item improvement (50% weight)</li>
<li>Overall project health (30% weight)</li>
<li>Absence of regressions (20% weight)</li>
</ul>
<p>When <code>--previous-validation</code> is provided, tracks progress trends across multiple attempts and provides recommendations for continuing or adjusting the improvement approach.</p>
<p><strong>Example:</strong></p>
<pre><code class="language-bash"># Basic validation
debtmap validate-improvement --comparison comparison.json

# With trend tracking and custom threshold
debtmap validate-improvement \
  --comparison .prodigy/comparison.json \
  --previous-validation .prodigy/validation.json \
  --output .prodigy/validation.json \
  --threshold 80.0
</code></pre>
<h2 id="options"><a class="header" href="#options">Options</a></h2>
<p>Options are organized by category for clarity. Most options apply to the <code>analyze</code> command, with a subset available for <code>validate</code>.</p>
<h3 id="output-control"><a class="header" href="#output-control">Output Control</a></h3>
<p>Control how analysis results are formatted and displayed.</p>
<p><strong>Format Options:</strong></p>
<ul>
<li><code>-f, --format &lt;FORMAT&gt;</code> - Output format: json, markdown, terminal (default: terminal for analyze)</li>
<li><code>--output-format &lt;JSON_FORMAT&gt;</code> - JSON structure format: legacy or unified (default: legacy)
<ul>
<li><code>legacy</code> - Current format with <code>{File: {...}}</code> and <code>{Function: {...}}</code> wrappers</li>
<li><code>unified</code> - New format with consistent structure and ‚Äòtype‚Äô field</li>
</ul>
</li>
<li><code>-o, --output &lt;OUTPUT&gt;</code> - Output file path (defaults to stdout)</li>
<li><code>--plain</code> - Plain output mode: ASCII-only, no colors, no emoji, machine-parseable</li>
</ul>
<p><strong>Display Filtering:</strong></p>
<ul>
<li><code>--top &lt;N&gt;</code> / <code>--head &lt;N&gt;</code> - Show only top N priority items</li>
<li><code>--tail &lt;N&gt;</code> - Show only bottom N priority items (lowest priority)</li>
<li><code>-s, --summary</code> - Use summary format with tiered priority display (compact output)</li>
<li><code>--compact</code> - Use compact output format (minimal details, top metrics only). Conflicts with verbosity flags (-v, -vv, -vvv)</li>
<li><code>--min-priority &lt;PRIORITY&gt;</code> - Minimum priority to display: low, medium, high, critical</li>
<li><code>--filter &lt;CATEGORIES&gt;</code> - Filter by debt categories (comma-separated)</li>
<li><code>--aggregate-only</code> - Show only aggregated file-level scores</li>
<li><code>--group-by-category</code> - Group output by debt category</li>
</ul>
<p><strong>Dependency Display Options:</strong></p>
<ul>
<li><code>--show-dependencies</code> - Show caller/callee information in output</li>
<li><code>--no-dependencies</code> - Hide dependency information (conflicts with ‚Äìshow-dependencies)</li>
<li><code>--max-callers &lt;N&gt;</code> - Maximum number of callers to display (default: 5)</li>
<li><code>--max-callees &lt;N&gt;</code> - Maximum number of callees to display (default: 5)</li>
<li><code>--show-external-calls</code> - Include external crate calls in dependencies</li>
<li><code>--show-std-lib-calls</code> - Include standard library calls in dependencies</li>
</ul>
<h3 id="analysis-control"><a class="header" href="#analysis-control">Analysis Control</a></h3>
<p>Configure analysis behavior, thresholds, and language selection.</p>
<p><strong>Thresholds:</strong></p>
<ul>
<li><code>--threshold-complexity &lt;N&gt;</code> - Complexity threshold (default: 10) [analyze command]</li>
<li><code>--threshold-duplication &lt;N&gt;</code> - Duplication threshold in lines (default: 50) [analyze command]</li>
<li><code>--threshold-preset &lt;PRESET&gt;</code> - Complexity threshold preset: strict, balanced, lenient [analyze command]
<ul>
<li><code>strict</code> - Strict thresholds for high code quality standards</li>
<li><code>balanced</code> - Balanced thresholds for typical projects (default)</li>
<li><code>lenient</code> - Lenient thresholds for legacy or complex domains</li>
</ul>
</li>
<li><code>--max-debt-density &lt;N&gt;</code> - Maximum debt density allowed per 1000 LOC [validate command]</li>
</ul>
<p><strong>Note:</strong> Threshold options (<code>--threshold-complexity</code>, <code>--threshold-duplication</code>, <code>--threshold-preset</code>) are command-line options for the <code>analyze</code> command. For the <code>validate</code> command, these thresholds are configured via the <code>--config</code> file (<code>debtmap.toml</code>) rather than as command-line flags.</p>
<p><strong>Language Selection:</strong></p>
<ul>
<li><code>--languages &lt;LANGS&gt;</code> - Comma-separated list of languages to analyze
<ul>
<li>Example: <code>--languages rust,python,javascript</code></li>
<li>Supported: rust, python, javascript, typescript</li>
</ul>
</li>
</ul>
<p><strong>Analysis Modes:</strong></p>
<ul>
<li><code>--semantic-off</code> - Disable semantic analysis (fallback mode)</li>
<li><code>--no-context-aware</code> - Disable context-aware false positive reduction (enabled by default)</li>
<li><code>--multi-pass</code> - Enable multi-pass analysis with attribution</li>
<li><code>--attribution</code> - Show complexity attribution details</li>
</ul>
<p><strong>Functional Programming Analysis:</strong></p>
<ul>
<li><code>--ast-functional-analysis</code> - Enable AST-based functional composition analysis (spec 111)
<ul>
<li>Analyzes code for functional programming patterns and composition</li>
<li>Detects pure functions, immutability, and side effects</li>
</ul>
</li>
<li><code>--functional-analysis-profile &lt;PROFILE&gt;</code> - Set functional analysis profile
<ul>
<li><code>strict</code> - Strict functional purity requirements (for pure FP codebases)</li>
<li><code>balanced</code> - Balanced analysis suitable for mixed paradigms (default)</li>
<li><code>lenient</code> - Lenient thresholds for imperative codebases</li>
</ul>
</li>
</ul>
<h3 id="context--coverage"><a class="header" href="#context--coverage">Context &amp; Coverage</a></h3>
<p>Enable context-aware risk analysis and integrate test coverage data.</p>
<p><strong>Context-Aware Risk Analysis:</strong></p>
<ul>
<li><code>--context</code> / <code>--enable-context</code> - Enable context-aware risk analysis</li>
<li><code>--context-providers &lt;PROVIDERS&gt;</code> - Context providers to use (comma-separated)
<ul>
<li>Available: <code>critical_path</code>, <code>dependency</code>, <code>git_history</code></li>
<li>Example: <code>--context-providers critical_path,git_history</code></li>
</ul>
</li>
<li><code>--disable-context &lt;PROVIDERS&gt;</code> - Disable specific context providers (comma-separated)</li>
</ul>
<p><strong>Coverage Integration:</strong></p>
<ul>
<li><code>--coverage-file &lt;PATH&gt;</code> / <code>--lcov &lt;PATH&gt;</code> - LCOV coverage file for risk analysis
<ul>
<li>Coverage data dampens debt scores for well-tested code (multiplier = 1.0 - coverage)</li>
<li>Surfaces untested complex functions as higher priority</li>
<li>Total debt score with coverage ‚â§ score without coverage</li>
</ul>
</li>
<li><code>--validate-loc</code> - Validate LOC consistency across analysis modes (with/without coverage)</li>
</ul>
<h3 id="performance--caching"><a class="header" href="#performance--caching">Performance &amp; Caching</a></h3>
<p>Optimize analysis performance through parallelization and caching.</p>
<p><strong>Parallel Processing:</strong></p>
<ul>
<li><code>--no-parallel</code> - Disable parallel call graph construction (enabled by default)</li>
<li><code>-j, --jobs &lt;N&gt;</code> - Number of threads for parallel processing
<ul>
<li><code>0</code> = use all available CPU cores (default)</li>
<li>Specify number to limit thread count</li>
</ul>
</li>
</ul>
<p><strong>Caching:</strong></p>
<ul>
<li><code>--no-cache</code> - Disable caching for this run (caching is enabled by default)</li>
<li><code>--clear-cache</code> - Clear cache before running analysis</li>
<li><code>--force-cache-rebuild</code> - Force cache rebuild (same as ‚Äìclear-cache)</li>
<li><code>--cache-stats</code> - Show cache statistics and location</li>
<li><code>--migrate-cache</code> - Migrate cache from local to shared location</li>
<li><code>--cache-location &lt;LOCATION&gt;</code> - Cache location strategy: local, shared, or path
<ul>
<li>Can also be set via <code>DEBTMAP_CACHE_DIR</code> environment variable</li>
<li>Affects where analysis results are cached for faster subsequent runs</li>
</ul>
</li>
</ul>
<p><strong>Other Performance:</strong></p>
<ul>
<li><code>--max-files &lt;N&gt;</code> - Maximum number of files to analyze (0 = no limit)</li>
</ul>
<h3 id="debugging--verbosity"><a class="header" href="#debugging--verbosity">Debugging &amp; Verbosity</a></h3>
<p>Control diagnostic output and debugging information.</p>
<p><strong>Verbosity Levels:</strong></p>
<ul>
<li><code>-v, --verbose</code> - Increase verbosity level (can be repeated: -v, -vv, -vvv)
<ul>
<li><code>-v</code> - Show main score factors</li>
<li><code>-vv</code> - Show detailed calculations</li>
<li><code>-vvv</code> - Show all debug information</li>
</ul>
</li>
</ul>
<p><strong>Specialized Debugging:</strong></p>
<ul>
<li><code>--explain-metrics</code> - Explain metric definitions and formulas (measured vs estimated)</li>
<li><code>--verbose-macro-warnings</code> - Show verbose macro parsing warnings (Rust analysis)</li>
<li><code>--show-macro-stats</code> - Show macro expansion statistics at end of analysis</li>
<li><code>--detail-level &lt;LEVEL&gt;</code> - Detail level for diagnostic reports
<ul>
<li>Options: summary, standard, comprehensive, debug (default: standard)</li>
</ul>
</li>
</ul>
<p><strong>Call Graph Debugging:</strong></p>
<ul>
<li><code>--debug-call-graph</code> - Enable detailed call graph debugging with resolution information</li>
<li><code>--trace-function &lt;FUNCTIONS&gt;</code> - Trace specific functions during call resolution (comma-separated)
<ul>
<li>Example: <code>--trace-function 'my_function,another_function'</code></li>
</ul>
</li>
<li><code>--call-graph-stats</code> - Show only call graph statistics (no detailed failure list)</li>
<li><code>--validate-call-graph</code> - Validate call graph structure and report issues</li>
<li><code>--debug-format &lt;FORMAT&gt;</code> - Debug output format: text or json (default: text)
<ul>
<li>Use with call graph debugging flags to control output format</li>
</ul>
</li>
</ul>
<h3 id="aggregation"><a class="header" href="#aggregation">Aggregation</a></h3>
<p>Control file-level aggregation and god object detection.</p>
<p><strong>File Aggregation:</strong></p>
<ul>
<li><code>--aggregate-only</code> - Show only aggregated file-level scores</li>
<li><code>--no-aggregation</code> - Disable file-level aggregation</li>
<li><code>--aggregation-method &lt;METHOD&gt;</code> - File aggregation method (default: weighted_sum)
<ul>
<li>Options: sum, weighted_sum, logarithmic_sum, max_plus_average</li>
</ul>
</li>
<li><code>--min-problematic &lt;N&gt;</code> - Minimum number of problematic functions for file aggregation</li>
<li><code>--no-god-object</code> - Disable god object detection</li>
</ul>
<h3 id="option-aliases"><a class="header" href="#option-aliases">Option Aliases</a></h3>
<p>Common option shortcuts and aliases for convenience:</p>
<ul>
<li><code>--lcov</code> is alias for <code>--coverage-file</code></li>
<li><code>--enable-context</code> is alias for <code>--context</code></li>
<li><code>--head</code> is alias for <code>--top</code></li>
<li><code>-s</code> is short form for <code>--summary</code></li>
<li><code>-v</code> is short form for <code>--verbose</code></li>
<li><code>-f</code> is short form for <code>--format</code></li>
<li><code>-o</code> is short form for <code>--output</code></li>
<li><code>-c</code> is short form for <code>--config</code></li>
<li><code>-j</code> is short form for <code>--jobs</code></li>
</ul>
<h3 id="deprecated-options"><a class="header" href="#deprecated-options">Deprecated Options</a></h3>
<p>The following options are deprecated and should be migrated:</p>
<ul>
<li><code>--cache</code> (hidden) - <strong>Deprecated:</strong> caching is now enabled by default
<ul>
<li><strong>Migration:</strong> Remove this flag, use <code>--no-cache</code> to disable if needed</li>
</ul>
</li>
<li><code>--explain-score</code> (hidden) - <strong>Deprecated:</strong> use <code>-v</code> instead
<ul>
<li><strong>Migration:</strong> Use <code>-v</code>, <code>-vv</code>, or <code>-vvv</code> for increasing verbosity levels</li>
</ul>
</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="configuration-file"><a class="header" href="#configuration-file">Configuration File</a></h3>
<p>Created via <code>debtmap init</code> command. The configuration file (<code>debtmap.toml</code>) is used by the <code>validate</code> command for threshold enforcement and default settings.</p>
<p><strong>Creating Configuration:</strong></p>
<pre><code class="language-bash"># Create new config
debtmap init

# Overwrite existing config
debtmap init --force
</code></pre>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<ul>
<li><code>DEBTMAP_CACHE_DIR</code> - Cache location (same as <code>--cache-location</code> flag)
<ul>
<li>Example: <code>export DEBTMAP_CACHE_DIR=/shared/team/cache</code></li>
<li>Affects where analysis results are cached for faster subsequent runs</li>
</ul>
</li>
<li><code>DEBTMAP_JOBS</code> - Number of threads for parallel processing (same as <code>--jobs</code> / <code>-j</code> flag)
<ul>
<li>Example: <code>export DEBTMAP_JOBS=8  # Same as --jobs 8</code></li>
<li>Use <code>0</code> to utilize all available CPU cores</li>
<li>Controls thread pool size for parallel call graph construction</li>
</ul>
</li>
</ul>
<h3 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h3>
<p>Get help for any command:</p>
<pre><code class="language-bash"># General help
debtmap --help

# Command-specific help
debtmap analyze --help
debtmap validate --help
debtmap compare --help
debtmap init --help
</code></pre>
<h2 id="common-workflows"><a class="header" href="#common-workflows">Common Workflows</a></h2>
<h3 id="basic-analysis"><a class="header" href="#basic-analysis">Basic Analysis</a></h3>
<p>Analyze a project and view results in terminal:</p>
<pre><code class="language-bash">debtmap analyze src/
</code></pre>
<p>Generate JSON report for further processing:</p>
<pre><code class="language-bash">debtmap analyze . --format json --output report.json
</code></pre>
<p>Generate Markdown report:</p>
<pre><code class="language-bash">debtmap analyze . --format markdown --output report.md
</code></pre>
<h3 id="coverage-integrated-analysis"><a class="header" href="#coverage-integrated-analysis">Coverage-Integrated Analysis</a></h3>
<p>Analyze with test coverage to surface untested complex code:</p>
<pre><code class="language-bash"># Generate coverage file first (example for Rust)
cargo tarpaulin --out lcov

# Run analysis with coverage
debtmap analyze src/ --coverage-file lcov.info
</code></pre>
<p>Coverage dampens debt scores for well-tested code, making untested complex functions more visible.</p>
<h3 id="context-aware-analysis"><a class="header" href="#context-aware-analysis">Context-Aware Analysis</a></h3>
<p>Enable context providers for risk-aware prioritization:</p>
<pre><code class="language-bash"># Use all context providers
debtmap analyze . --context

# Use specific context providers
debtmap analyze . --context --context-providers critical_path,git_history
</code></pre>
<p>Context-aware analysis reduces false positives and prioritizes code based on:</p>
<ul>
<li>Critical execution paths</li>
<li>Dependency relationships</li>
<li>Git history (change frequency)</li>
</ul>
<h3 id="filtered--focused-analysis"><a class="header" href="#filtered--focused-analysis">Filtered &amp; Focused Analysis</a></h3>
<p>Show only top priority items:</p>
<pre><code class="language-bash">debtmap analyze . --top 10 --min-priority high
</code></pre>
<p>Filter by specific debt categories:</p>
<pre><code class="language-bash">debtmap analyze . --filter complexity,duplication
</code></pre>
<p>Use summary mode for compact output:</p>
<pre><code class="language-bash">debtmap analyze . --summary
</code></pre>
<p>Show only file-level aggregations:</p>
<pre><code class="language-bash">debtmap analyze . --aggregate-only
</code></pre>
<h3 id="performance-tuning"><a class="header" href="#performance-tuning">Performance Tuning</a></h3>
<p>Control parallelization:</p>
<pre><code class="language-bash"># Use 8 threads
debtmap analyze . --jobs 8

# Disable parallel processing
debtmap analyze . --no-parallel
</code></pre>
<p>Manage caching:</p>
<pre><code class="language-bash"># Use shared cache location
debtmap analyze . --cache-location shared

# Clear cache and rebuild
debtmap analyze . --clear-cache

# Show cache statistics
debtmap analyze . --cache-stats
</code></pre>
<p>Limit analysis scope:</p>
<pre><code class="language-bash"># Analyze maximum 100 files
debtmap analyze . --max-files 100

# Analyze specific languages only
debtmap analyze . --languages rust,python
</code></pre>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<p>Use the <code>validate</code> command in CI/CD pipelines:</p>
<pre><code class="language-bash"># Initialize configuration (one time)
debtmap init

# Edit debtmap.toml to set thresholds
# ...

# In CI pipeline: validate against thresholds
debtmap validate . --config debtmap.toml --max-debt-density 50
</code></pre>
<p>The <code>validate</code> command returns non-zero exit code if thresholds are exceeded, failing the build.</p>
<h3 id="comparison--tracking"><a class="header" href="#comparison--tracking">Comparison &amp; Tracking</a></h3>
<p>Compare analysis results before and after changes:</p>
<pre><code class="language-bash"># Before changes
debtmap analyze . --format json --output before.json

# Make code changes...

# After changes
debtmap analyze . --format json --output after.json

# Generate comparison report
debtmap compare --before before.json --after after.json --format markdown
</code></pre>
<p>With implementation plan:</p>
<pre><code class="language-bash">debtmap compare --before before.json --after after.json --plan IMPLEMENTATION_PLAN.md
</code></pre>
<h3 id="debugging-analysis"><a class="header" href="#debugging-analysis">Debugging Analysis</a></h3>
<p>Increase verbosity to understand scoring:</p>
<pre><code class="language-bash"># Show main score factors
debtmap analyze src/ -v

# Show detailed calculations
debtmap analyze src/ -vv

# Show all debug information
debtmap analyze src/ -vvv
</code></pre>
<p>Debug call graph resolution issues:</p>
<pre><code class="language-bash"># Enable call graph debugging
debtmap analyze . --debug-call-graph

# Trace specific functions
debtmap analyze . --debug-call-graph --trace-function 'problematic_function'

# Validate call graph structure
debtmap analyze . --validate-call-graph --debug-format json
</code></pre>
<p>Show macro expansion statistics (Rust):</p>
<pre><code class="language-bash">debtmap analyze . --show-macro-stats --verbose-macro-warnings
</code></pre>
<p>Use detailed diagnostic reports:</p>
<pre><code class="language-bash">debtmap analyze . --detail-level comprehensive
</code></pre>
<p>Analyze functional programming patterns:</p>
<pre><code class="language-bash"># Enable functional analysis
debtmap analyze . --ast-functional-analysis

# Use strict profile for pure FP codebases
debtmap analyze . --ast-functional-analysis --functional-analysis-profile strict
</code></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="basic-analysis-1"><a class="header" href="#basic-analysis-1">Basic Analysis</a></h3>
<pre><code class="language-bash"># Analyze current directory
debtmap analyze .

# Analyze specific directory
debtmap analyze src/

# Generate JSON output
debtmap analyze . --format json --output report.json
</code></pre>
<h3 id="with-coverage"><a class="header" href="#with-coverage">With Coverage</a></h3>
<pre><code class="language-bash"># Analyze with LCOV coverage file
debtmap analyze src/ --coverage-file coverage.lcov

# Alternative alias
debtmap analyze src/ --lcov coverage.lcov
</code></pre>
<h3 id="context-aware-analysis-1"><a class="header" href="#context-aware-analysis-1">Context-Aware Analysis</a></h3>
<pre><code class="language-bash"># Enable all context providers
debtmap analyze . --context

# Use specific context providers
debtmap analyze . --context --context-providers critical_path,git_history

# Disable specific providers
debtmap analyze . --context --disable-context dependency
</code></pre>
<h3 id="filtered-output"><a class="header" href="#filtered-output">Filtered Output</a></h3>
<pre><code class="language-bash"># Top 10 priority items only
debtmap analyze . --top 10

# High priority and above
debtmap analyze . --min-priority high

# Specific categories
debtmap analyze . --filter complexity,duplication

# Summary format
debtmap analyze . --summary

# Group by category
debtmap analyze . --group-by-category
</code></pre>
<h3 id="performance-tuning-1"><a class="header" href="#performance-tuning-1">Performance Tuning</a></h3>
<pre><code class="language-bash"># Use 8 threads
debtmap analyze . --jobs 8

# Disable parallelization
debtmap analyze . --no-parallel

# Limit file count
debtmap analyze . --max-files 100

# Shared cache
debtmap analyze . --cache-location shared

# Clear and rebuild cache
debtmap analyze . --clear-cache
</code></pre>
<h3 id="validation"><a class="header" href="#validation">Validation</a></h3>
<pre><code class="language-bash"># Initialize config
debtmap init --force

# Validate against config
debtmap validate . --config debtmap.toml

# With max debt density threshold
debtmap validate . --max-debt-density 50
</code></pre>
<h3 id="comparison"><a class="header" href="#comparison">Comparison</a></h3>
<pre><code class="language-bash"># Compare two analyses
debtmap compare --before before.json --after after.json

# With markdown output
debtmap compare --before before.json --after after.json --format markdown

# With implementation plan
debtmap compare --before before.json --after after.json --plan IMPLEMENTATION_PLAN.md

# With target location
debtmap compare --before before.json --after after.json --target-location "src/main.rs:process_file:42"
</code></pre>
<h3 id="language-selection"><a class="header" href="#language-selection">Language Selection</a></h3>
<pre><code class="language-bash"># Analyze only Rust files
debtmap analyze . --languages rust

# Multiple languages
debtmap analyze . --languages rust,python,javascript
</code></pre>
<h3 id="threshold-configuration"><a class="header" href="#threshold-configuration">Threshold Configuration</a></h3>
<pre><code class="language-bash"># Custom complexity threshold
debtmap analyze . --threshold-complexity 15

# Use preset
debtmap analyze . --threshold-preset strict

# Custom duplication threshold
debtmap analyze . --threshold-duplication 100
</code></pre>
<h3 id="plainmachine-readable-output"><a class="header" href="#plainmachine-readable-output">Plain/Machine-Readable Output</a></h3>
<pre><code class="language-bash"># Plain output (no colors, no emoji)
debtmap analyze . --plain

# Combine with JSON for CI
debtmap analyze . --format json --plain --output report.json
</code></pre>
<h3 id="advanced-debugging"><a class="header" href="#advanced-debugging">Advanced Debugging</a></h3>
<pre><code class="language-bash"># Call graph debugging with detailed information
debtmap analyze . --debug-call-graph --debug-format json

# Trace specific functions during call resolution
debtmap analyze . --debug-call-graph --trace-function 'process_file,analyze_complexity'

# Validate call graph structure
debtmap analyze . --validate-call-graph

# Show only call graph statistics
debtmap analyze . --debug-call-graph --call-graph-stats

# Functional programming analysis with strict profile
debtmap analyze . --ast-functional-analysis --functional-analysis-profile strict

# Explain metric definitions
debtmap analyze . --explain-metrics -v
</code></pre>
<h2 id="command-compatibility-matrix"><a class="header" href="#command-compatibility-matrix">Command Compatibility Matrix</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>analyze</th><th>validate</th><th>compare</th><th>init</th></tr></thead><tbody>
<tr><td><code>&lt;PATH&gt;</code> argument</td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--format</code></td><td>‚úì</td><td>‚úì</td><td>‚úì</td><td>‚úó</td></tr>
<tr><td><code>--output</code></td><td>‚úì</td><td>‚úì</td><td>‚úì</td><td>‚úó</td></tr>
<tr><td><code>--coverage-file</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--context</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--threshold-*</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--top / --tail</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--cache-*</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--jobs</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--no-parallel</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--verbose</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--explain-metrics</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--debug-call-graph</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--trace-function</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--call-graph-stats</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--validate-call-graph</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--debug-format</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--show-dependencies</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--no-dependencies</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--max-callers</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--max-callees</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--show-external-calls</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--show-std-lib-calls</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--ast-functional-analysis</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--functional-analysis-profile</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--config</code></td><td>‚úó</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--before / --after</code></td><td>‚úó</td><td>‚úó</td><td>‚úì</td><td>‚úó</td></tr>
<tr><td><code>--force</code></td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td>‚úì</td></tr>
</tbody></table>
</div>
<p><strong>Note:</strong> The <code>validate</code> command supports output control (<code>--format</code>, <code>--output</code>), coverage integration (<code>--coverage-file</code>), context-aware analysis (<code>--context</code>), display filtering (<code>--top</code>, <code>--tail</code>, <code>--summary</code>), performance control (<code>--jobs</code>, <code>--no-parallel</code>), and verbosity options (<code>--verbose</code>) from the <code>analyze</code> command. Analysis thresholds (<code>--threshold-complexity</code>, <code>--threshold-duplication</code>, <code>--threshold-preset</code>) are configured via the <code>--config</code> file rather than as command-line options. Debugging features like call graph debugging and functional analysis are specific to the <code>analyze</code> command.</p>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="performance-issues"><a class="header" href="#performance-issues">Performance Issues</a></h3>
<p><strong>Problem:</strong> Analysis is slow on large codebases</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Use more threads (if you have CPU cores available)
debtmap analyze . --jobs 16

# Enable caching (on by default, but ensure it's not disabled)
debtmap analyze . # caching is automatic

# Use shared cache for team
debtmap analyze . --cache-location shared

# Limit analysis scope
debtmap analyze . --max-files 500 --languages rust
</code></pre>
<h3 id="memory-issues"><a class="header" href="#memory-issues">Memory Issues</a></h3>
<p><strong>Problem:</strong> Analysis runs out of memory</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Disable parallelization
debtmap analyze . --no-parallel

# Limit file count
debtmap analyze . --max-files 100

# Analyze in batches by language
debtmap analyze . --languages rust
debtmap analyze . --languages python
</code></pre>
<h3 id="output-issues"><a class="header" href="#output-issues">Output Issues</a></h3>
<p><strong>Problem:</strong> Terminal output has garbled characters</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash"># Use plain mode
debtmap analyze . --plain
</code></pre>
<p><strong>Problem:</strong> Want machine-readable output</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash"># Use JSON with plain mode
debtmap analyze . --format json --plain --output report.json
</code></pre>
<h3 id="cache-issues"><a class="header" href="#cache-issues">Cache Issues</a></h3>
<p><strong>Problem:</strong> Stale cached results</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Clear cache
debtmap analyze . --clear-cache

# Check cache statistics
debtmap analyze . --cache-stats

# Disable cache temporarily
debtmap analyze . --no-cache
</code></pre>
<h3 id="threshold-issues"><a class="header" href="#threshold-issues">Threshold Issues</a></h3>
<p><strong>Problem:</strong> Too many items flagged</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Use lenient preset
debtmap analyze . --threshold-preset lenient

# Increase threshold
debtmap analyze . --threshold-complexity 20

# Filter to high priority only
debtmap analyze . --min-priority high
</code></pre>
<p><strong>Problem:</strong> Not enough items flagged</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Use strict preset
debtmap analyze . --threshold-preset strict

# Lower threshold
debtmap analyze . --threshold-complexity 5

# Show all items
debtmap analyze . --min-priority low
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="regular-analysis"><a class="header" href="#regular-analysis">Regular Analysis</a></h3>
<p>Run analysis regularly to track code quality trends:</p>
<pre><code class="language-bash"># Daily in CI
debtmap validate . --config debtmap.toml

# Weekly deep analysis with coverage
debtmap analyze . --coverage-file coverage.lcov --format json --output weekly-report.json
</code></pre>
<h3 id="team-workflows"><a class="header" href="#team-workflows">Team Workflows</a></h3>
<p>Use shared cache for consistent team experience:</p>
<pre><code class="language-bash"># Set environment variable for all team members
export DEBTMAP_CACHE_DIR=/shared/team/debtmap-cache

# Or use flag
debtmap analyze . --cache-location shared
</code></pre>
<h3 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h3>
<p>For large codebases:</p>
<pre><code class="language-bash"># Use maximum parallelization
debtmap analyze . --jobs 0  # 0 = all cores

# Cache aggressively
debtmap analyze . --cache-location shared

# Focus on changed files in CI
# (implement via custom scripts to analyze git diff)
</code></pre>
<h3 id="integration-with-coverage"><a class="header" href="#integration-with-coverage">Integration with Coverage</a></h3>
<p>Always analyze with coverage when available:</p>
<pre><code class="language-bash"># Rust example
cargo tarpaulin --out lcov
debtmap analyze src/ --coverage-file lcov.info

# Python example
pytest --cov --cov-report=lcov
debtmap analyze . --coverage-file coverage.lcov
</code></pre>
<p>Coverage integration helps prioritize untested complex code.</p>
<h2 id="additional-tools"><a class="header" href="#additional-tools">Additional Tools</a></h2>
<h3 id="prodigy-validate-debtmap-improvement"><a class="header" href="#prodigy-validate-debtmap-improvement">prodigy-validate-debtmap-improvement</a></h3>
<p>Specialized validation tool for Prodigy workflow integration.</p>
<p><strong>Description:</strong>
This binary is part of the Prodigy workflow system and provides specialized validation for Debtmap improvement workflows.</p>
<p><strong>Usage:</strong>
See Prodigy documentation for detailed usage instructions.</p>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<ul>
<li><a href="./configuration.html">Configuration Format</a> - Detailed configuration file format</li>
<li><a href="./output-formats.html">Output Formats</a> - Understanding JSON, Markdown, and Terminal output</li>
<li><a href="./coverage.html">Coverage Integration</a> - Integrating test coverage data</li>
<li><a href="./context-providers.html">Context Providers</a> - Understanding context-aware analysis</li>
<li><a href="./examples.html">Examples</a> - More comprehensive usage examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="analysis-guide"><a class="header" href="#analysis-guide">Analysis Guide</a></h1>
<p>This guide explains Debtmap‚Äôs analysis capabilities, metrics, and methodologies in depth. Use this to understand what Debtmap measures, how it scores technical debt, and how to interpret analysis results for maximum impact.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Debtmap analyzes code through multiple lenses to provide a comprehensive view of technical health:</p>
<ul>
<li><strong>Complexity Metrics</strong> - Quantifies how difficult code is to understand and test</li>
<li><strong>Debt Patterns</strong> - Identifies 13 types of technical debt requiring attention</li>
<li><strong>Risk Scoring</strong> - Correlates complexity with test coverage to find truly risky code</li>
<li><strong>Prioritization</strong> - Ranks findings by impact to guide refactoring efforts</li>
</ul>
<p>The goal is to move beyond simple ‚Äúhere are your problems‚Äù to ‚Äúhere‚Äôs what to fix first and why.‚Äù</p>
<h2 id="complexity-metrics"><a class="header" href="#complexity-metrics">Complexity Metrics</a></h2>
<p>Debtmap measures complexity using multiple complementary approaches. Each metric captures a different aspect of code difficulty.</p>
<h3 id="cyclomatic-complexity"><a class="header" href="#cyclomatic-complexity">Cyclomatic Complexity</a></h3>
<p>Measures the number of linearly independent paths through code - essentially counting decision points.</p>
<p><strong>How it works:</strong></p>
<ul>
<li>Start with a base complexity of 1</li>
<li>Add 1 for each: <code>if</code>, <code>else if</code>, <code>match</code> arm, <code>while</code>, <code>for</code>, <code>&amp;&amp;</code>, <code>||</code>, <code>?</code> operator</li>
<li>Does NOT increase for <code>else</code> (it‚Äôs the alternate path, not a new decision)</li>
</ul>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>1-5</strong>: Simple, easy to test - typically needs 1-3 test cases</li>
<li><strong>6-10</strong>: Moderate complexity - needs 4-8 test cases</li>
<li><strong>11-20</strong>: Complex, consider refactoring - needs 9+ test cases</li>
<li><strong>20+</strong>: Very complex, high risk - difficult to test thoroughly</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn validate_user(age: u32, has_license: bool, country: &amp;str) -&gt; bool {
    // Complexity: 4
    // Base (1) + if (1) + &amp;&amp; (1) + match (1) = 4
    if age &gt;= 18 &amp;&amp; has_license {
        match country {
            "US" | "CA" =&gt; true,
            _ =&gt; false,
        }
    } else {
        false
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cognitive-complexity"><a class="header" href="#cognitive-complexity">Cognitive Complexity</a></h3>
<p>Measures how difficult code is to understand by considering nesting depth and control flow interruptions.</p>
<p><strong>How it differs from cyclomatic:</strong></p>
<ul>
<li>Nesting increases weight (deeply nested code is harder to understand)</li>
<li>Linear sequences don‚Äôt increase complexity (easier to follow)</li>
<li>Breaks and continues add complexity (interrupt normal flow)</li>
</ul>
<p><strong>Calculation:</strong></p>
<ul>
<li>Each structure (if, loop, match) gets a base score</li>
<li>Nesting multiplies the weight (nested structures = harder to understand)</li>
<li>Break/continue/return in middle of function adds cognitive load</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cyclomatic: 5, Cognitive: 8
fn process_items(items: Vec&lt;Item&gt;) -&gt; Vec&lt;Result&gt; {
    let mut results = vec![];

    for item in items {                    // +1 cognitive
        if item.is_valid() {               // +2 (nested in loop)
            match item.type {              // +3 (nested 2 levels)
                Type::A =&gt; results.push(process_a(item)),
                Type::B =&gt; {
                    if item.priority &gt; 5 { // +4 (nested 3 levels)
                        results.push(process_b_priority(item));
                    }
                }
                _ =&gt; continue,             // +1 (control flow interruption)
            }
        }
    }

    results
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>0-5</strong>: Trivial - anyone can understand</li>
<li><strong>6-10</strong>: Simple - straightforward logic</li>
<li><strong>11-20</strong>: Moderate - requires careful reading</li>
<li><strong>21-40</strong>: Complex - difficult to understand</li>
<li><strong>40+</strong>: Very complex - needs refactoring</li>
</ul>
<h3 id="entropy-based-complexity-analysis"><a class="header" href="#entropy-based-complexity-analysis">Entropy-Based Complexity Analysis</a></h3>
<p>Uses information theory to distinguish genuinely complex code from pattern-based repetitive code. This dramatically reduces false positives for validation functions, dispatchers, and configuration parsers.</p>
<p><strong>How it works:</strong></p>
<ol>
<li>
<p><strong>Token Entropy</strong> (0.0-1.0): Measures variety in code tokens</p>
<ul>
<li>High entropy (0.7+): Diverse logic, genuinely complex</li>
<li>Low entropy (0.0-0.4): Repetitive patterns, less complex than it appears</li>
</ul>
</li>
<li>
<p><strong>Pattern Repetition</strong> (0.0-1.0): Detects repetitive structures in AST</p>
<ul>
<li>High repetition (0.7+): Similar blocks repeated (validation checks, case handlers)</li>
<li>Low repetition: Unique logic throughout</li>
</ul>
</li>
<li>
<p><strong>Branch Similarity</strong> (0.0-1.0): Analyzes similarity between conditional branches</p>
<ul>
<li>High similarity (0.8+): Branches do similar things (consistent handling)</li>
<li>Low similarity: Each branch has unique logic</li>
</ul>
</li>
<li>
<p><strong>Token Classification</strong>: Categorizes tokens by type with weighted importance</p>
<ul>
<li>Variables, methods, literals weighted differently</li>
<li>Focuses on structural complexity over superficial differences</li>
</ul>
</li>
</ol>
<p><strong>Dampening logic:</strong> Dampening is applied when multiple factors indicate repetitive patterns:</p>
<ul>
<li>Low token entropy (&lt; 0.4) indicates simple, repetitive patterns</li>
<li>High pattern repetition (&gt; 0.6) shows similar code blocks</li>
<li>High branch similarity (&gt; 0.7) indicates consistent branching logic</li>
</ul>
<p>When these conditions are met:</p>
<pre><code>effective_complexity = entropy √ó pattern_factor √ó similarity_factor
</code></pre>
<p><strong>Dampening cap:</strong> The dampening factor has a minimum of 0.7, ensuring no more than 30% reduction in complexity scores. This prevents over-correction of pattern-based code and maintains a baseline complexity floor for functions that still require understanding and maintenance.</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Without entropy: Cyclomatic = 15 (appears very complex)
// With entropy: Effective = 5 (pattern-based, dampened 67%)
fn validate_config(config: &amp;Config) -&gt; Result&lt;(), ValidationError&gt; {
    if config.name.is_empty() { return Err(ValidationError::EmptyName); }
    if config.port == 0 { return Err(ValidationError::InvalidPort); }
    if config.host.is_empty() { return Err(ValidationError::EmptyHost); }
    if config.timeout == 0 { return Err(ValidationError::InvalidTimeout); }
    // ... 11 more similar checks
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Enable in <code>.debtmap.toml</code>:</strong></p>
<pre><code class="language-toml">[entropy]
enabled = true                 # Enable entropy analysis (default: true)
weight = 0.5                  # Weight in adjustment (0.0-1.0)
use_classification = true     # Advanced token classification
pattern_threshold = 0.7       # Pattern detection threshold
entropy_threshold = 0.4       # Entropy below this triggers dampening
branch_threshold = 0.8        # Branch similarity threshold
max_combined_reduction = 0.3  # Maximum 30% reduction
</code></pre>
<p><strong>Output fields in EntropyScore:</strong></p>
<ul>
<li><code>unique_variables</code>: Count of distinct variables in the function (measures variable diversity)</li>
<li><code>max_nesting</code>: Maximum nesting depth detected (contributes to dampening calculation)</li>
<li><code>dampening_applied</code>: Actual dampening factor applied to the complexity score</li>
</ul>
<h3 id="nesting-depth"><a class="header" href="#nesting-depth">Nesting Depth</a></h3>
<p>Maximum level of indentation in a function. Deep nesting makes code hard to follow.</p>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>1-2</strong>: Flat, easy to read</li>
<li><strong>3-4</strong>: Moderate nesting</li>
<li><strong>5+</strong>: Deep nesting, consider extracting functions</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Nesting depth: 4 (difficult to follow)
fn process(data: Data) -&gt; Result&lt;Output&gt; {
    if data.is_valid() {                    // Level 1
        for item in data.items {            // Level 2
            if item.active {                // Level 3
                match item.type {           // Level 4
                    Type::A =&gt; { /* ... */ }
                    Type::B =&gt; { /* ... */ }
                }
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Refactored:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Nesting depth: 2 (much clearer)
fn process(data: Data) -&gt; Result&lt;Output&gt; {
    if !data.is_valid() {
        return Err(Error::Invalid);
    }

    data.items
        .iter()
        .filter(|item| item.active)
        .map(|item| process_item(item))     // Extract to separate function
        .collect()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="function-length"><a class="header" href="#function-length">Function Length</a></h3>
<p>Number of lines in a function. Long functions often violate single responsibility principle.</p>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>1-20 lines</strong>: Good - focused, single purpose</li>
<li><strong>21-50 lines</strong>: Acceptable - may have multiple steps</li>
<li><strong>51-100 lines</strong>: Long - consider breaking up</li>
<li><strong>100+ lines</strong>: Very long - definitely needs refactoring</li>
</ul>
<p><strong>Why length matters:</strong></p>
<ul>
<li>Harder to understand and remember</li>
<li>Harder to test thoroughly</li>
<li>Often violates single responsibility</li>
<li>Difficult to reuse</li>
</ul>
<h3 id="constructor-detection"><a class="header" href="#constructor-detection">Constructor Detection</a></h3>
<p>Debtmap identifies constructor functions using AST-based analysis (Spec 122), which goes beyond simple name-based detection to catch non-standard constructor patterns.</p>
<p><strong>Detection Strategy:</strong></p>
<ol>
<li><strong>Return Type Analysis</strong>: Functions returning <code>Self</code>, <code>Result&lt;Self&gt;</code>, or <code>Option&lt;Self&gt;</code></li>
<li><strong>Body Pattern Analysis</strong>: Struct initialization or simple field assignments</li>
<li><strong>Complexity Check</strong>: Low cyclomatic complexity (‚â§5), no loops, minimal branching</li>
</ol>
<p><strong>Why AST-based detection?</strong></p>
<p>Name-based detection (looking for <code>new</code>, <code>new_*</code>, <code>from_*</code>) misses non-standard constructors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Caught by name-based detection
fn new() -&gt; Self {
    Self { timeout: 30 }
}

// Missed by name-based, caught by AST detection
pub fn create_default_client() -&gt; Self {
    Self { timeout: Duration::from_secs(30) }
}

pub fn initialized() -&gt; Self {
    Self::new()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Builder vs Constructor:</strong></p>
<p>AST analysis distinguishes between constructors and builder methods:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Constructor: creates new instance
pub fn new(timeout: u32) -&gt; Self {
    Self { timeout }
}

// Builder method: modifies existing instance (NOT a constructor)
pub fn set_timeout(mut self, timeout: Duration) -&gt; Self {
    self.timeout = timeout;
    self  // Returns modified self, not new instance
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Detection Criteria:</strong></p>
<p>A function is classified as a constructor if:</p>
<ul>
<li>Returns <code>Self</code>, <code>Result&lt;Self&gt;</code>, or <code>Option&lt;Self&gt;</code></li>
<li>Contains struct initialization (<code>Self { ... }</code>) without loops</li>
<li>OR delegates to another constructor (<code>Self::new()</code>) with minimal logic</li>
</ul>
<p><strong>Fallback Behavior:</strong></p>
<p>If AST parsing fails (syntax errors, unsupported language), Debtmap gracefully falls back to name-based detection (Spec 117):</p>
<ul>
<li><code>new</code>, <code>new_*</code></li>
<li><code>try_new*</code></li>
<li><code>from_*</code></li>
</ul>
<p>This ensures analysis always completes, even on partially broken code.</p>
<p><strong>Performance:</strong></p>
<p>AST-based detection adds &lt; 5% overhead compared to name-only detection. See benchmarks:</p>
<pre><code class="language-bash">cargo bench --bench constructor_detection_bench
</code></pre>
<p><strong>Why it matters:</strong></p>
<p>Accurately identifying constructors helps:</p>
<ul>
<li>Exclude them from complexity thresholds (constructors naturally have high complexity)</li>
<li>Focus refactoring on business logic, not initialization code</li>
<li>Understand initialization patterns across the codebase</li>
</ul>
<h2 id="debt-patterns"><a class="header" href="#debt-patterns">Debt Patterns</a></h2>
<p>Debtmap detects 25 types of technical debt, organized into 4 strategic categories. Each debt type is mapped to a category that guides prioritization and remediation strategies.</p>
<h3 id="debt-type-enum"><a class="header" href="#debt-type-enum">Debt Type Enum</a></h3>
<p>The <code>DebtType</code> enum defines all specific debt patterns that Debtmap can detect:</p>
<p><strong>Testing Debt:</strong></p>
<ul>
<li><code>TestingGap</code> - Functions with insufficient test coverage</li>
<li><code>TestTodo</code> - TODO comments in test code</li>
<li><code>TestComplexity</code> - Test functions exceeding complexity thresholds</li>
<li><code>TestDuplication</code> - Duplicated code in test files</li>
<li><code>TestComplexityHotspot</code> - Complex test logic that‚Äôs hard to maintain</li>
<li><code>AssertionComplexity</code> - Complex test assertions</li>
<li><code>FlakyTestPattern</code> - Non-deterministic test behavior</li>
</ul>
<p><strong>Architecture Debt:</strong></p>
<ul>
<li><code>ComplexityHotspot</code> - Functions exceeding complexity thresholds</li>
<li><code>DeadCode</code> - Unreachable or unused code</li>
<li><code>GodObject</code> - Classes with too many responsibilities</li>
<li><code>GodModule</code> - Modules with too many responsibilities</li>
<li><code>FeatureEnvy</code> - Using more data from other objects than own</li>
<li><code>PrimitiveObsession</code> - Overusing basic types instead of domain objects</li>
<li><code>MagicValues</code> - Unexplained literal values</li>
</ul>
<p><strong>Performance Debt:</strong></p>
<ul>
<li><code>AllocationInefficiency</code> - Inefficient memory allocations</li>
<li><code>StringConcatenation</code> - Inefficient string building in loops</li>
<li><code>NestedLoops</code> - Multiple nested iterations (O(n¬≤) or worse)</li>
<li><code>BlockingIO</code> - Blocking I/O in async contexts</li>
<li><code>SuboptimalDataStructure</code> - Wrong data structure for access pattern</li>
<li><code>AsyncMisuse</code> - Improper async/await usage</li>
<li><code>ResourceLeak</code> - Resources not properly released</li>
<li><code>CollectionInefficiency</code> - Inefficient collection operations</li>
</ul>
<p><strong>Code Quality Debt:</strong></p>
<ul>
<li><code>Risk</code> - High-risk code (complex + poorly tested)</li>
<li><code>Duplication</code> - Duplicated code blocks</li>
<li><code>ErrorSwallowing</code> - Errors caught but ignored</li>
</ul>
<h3 id="debt-categories"><a class="header" href="#debt-categories">Debt Categories</a></h3>
<p>The <code>DebtCategory</code> enum groups debt types into strategic categories:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum DebtCategory {
    Architecture,  // Structure, design, complexity
    Testing,       // Coverage, test quality
    Performance,   // Speed, memory, efficiency
    CodeQuality,   // Maintainability, readability
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Category Mapping:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Debt Type</th><th>Category</th><th>Strategic Focus</th></tr></thead><tbody>
<tr><td>ComplexityHotspot, DeadCode, GodObject, GodModule, FeatureEnvy, PrimitiveObsession, MagicValues</td><td>Architecture</td><td>Structural improvements, design patterns</td></tr>
<tr><td>TestingGap, TestTodo, TestComplexity, TestDuplication, TestComplexityHotspot, AssertionComplexity, FlakyTestPattern</td><td>Testing</td><td>Test coverage, test quality</td></tr>
<tr><td>AllocationInefficiency, StringConcatenation, NestedLoops, BlockingIO, SuboptimalDataStructure, AsyncMisuse, ResourceLeak, CollectionInefficiency</td><td>Performance</td><td>Runtime efficiency, resource usage</td></tr>
<tr><td>Risk, Duplication, ErrorSwallowing</td><td>CodeQuality</td><td>Maintainability, reliability</td></tr>
</tbody></table>
</div>
<p><strong>Language-Specific Debt Patterns:</strong></p>
<p>Some debt patterns only apply to languages with specific features:</p>
<ul>
<li><strong>BlockingIO, AsyncMisuse</strong>: Async-capable languages (Rust, JavaScript, TypeScript)</li>
<li><strong>AllocationInefficiency, ResourceLeak</strong>: Languages with manual memory management (Rust)</li>
<li><strong>Error handling patterns</strong>: Vary by language error model (Result in Rust, exceptions in Python/JS)</li>
</ul>
<p>Debtmap automatically applies only the relevant debt patterns for each language during analysis.</p>
<h3 id="examples-by-category"><a class="header" href="#examples-by-category">Examples by Category</a></h3>
<h4 id="architecture-debt"><a class="header" href="#architecture-debt">Architecture Debt</a></h4>
<p><strong>ComplexityHotspot</strong>: Functions exceeding complexity thresholds</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cyclomatic: 22, Cognitive: 35
fn process_transaction(tx: Transaction, account: &amp;mut Account) -&gt; Result&lt;Receipt&gt; {
    if tx.amount &lt;= 0 {
        return Err(Error::InvalidAmount);
    }
    // ... deeply nested logic with many branches
    Ok(receipt)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Cyclomatic &gt; 10 OR Cognitive &gt; 15 (configurable)
<strong>Action</strong>: Break into smaller functions, extract validation, simplify control flow</p>
<p><strong>GodObject / GodModule</strong>: Too many responsibilities</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// God module: handles parsing, validation, storage, notifications
mod user_service {
    fn parse_user() { /* ... */ }
    fn validate_user() { /* ... */ }
    fn save_user() { /* ... */ }
    fn send_email() { /* ... */ }
    fn log_activity() { /* ... */ }
    // ... 20+ more functions
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Complexity-weighted scoring system (see detailed explanation below)
<strong>Action</strong>: Split into focused modules (parser, validator, repository, notifier)</p>
<h4 id="complexity-weighted-god-object-detection"><a class="header" href="#complexity-weighted-god-object-detection">Complexity-Weighted God Object Detection</a></h4>
<p>Debtmap uses <strong>complexity-weighted scoring</strong> for god object detection to reduce false positives on well-refactored code. This ensures that a file with 100 simple helper functions doesn‚Äôt rank higher than a file with 10 complex functions.</p>
<p><strong>The Problem:</strong></p>
<p>Traditional god object detection counts methods:</p>
<ul>
<li>File A: 100 methods (average complexity: 1.5) ‚Üí Flagged as god object</li>
<li>File B: 10 methods (average complexity: 17.0) ‚Üí Not flagged</li>
</ul>
<p>But File A might be a well-organized utility module with many small helpers, while File B is truly problematic with highly complex functions that need refactoring.</p>
<p><strong>The Solution:</strong></p>
<p>Debtmap weights each function by its cyclomatic complexity using this formula:</p>
<pre><code>weight = (max(1, complexity) / 3)^1.5
</code></pre>
<p><strong>Weight Examples:</strong></p>
<ul>
<li>Simple helper (complexity 1): weight ‚âà 0.19</li>
<li>Baseline function (complexity 3): weight = 1.0</li>
<li>Moderate function (complexity 9): weight ‚âà 5.2</li>
<li>Complex function (complexity 17): weight ‚âà 13.5</li>
<li>Critical function (complexity 33): weight ‚âà 36.5</li>
</ul>
<p><strong>God Object Score Calculation:</strong></p>
<pre><code>weighted_method_count = sum(weight for each function)
complexity_penalty = 0.7 if avg_complexity &lt; 3, 1.0 if 3-10, 1.5 if &gt; 10

god_object_score = (
    (weighted_method_count / threshold) * 40% +
    (field_count / threshold) * 20% +
    (responsibility_count / threshold) * 15% +
    (lines_of_code / 500) * 25%
) * complexity_penalty
</code></pre>
<p><strong>Threshold</strong>: God object detected if <code>score &gt;= 70.0</code></p>
<p><strong>Real-World Example:</strong></p>
<pre><code>shared_cache.rs:
  - 100 functions, average complexity: 1.5
  - Weighted score: ~19.0 (100 * 0.19)
  - God object score: 45.2
  - Result: Not a god object ‚úì

legacy_parser.rs:
  - 10 functions, average complexity: 17.0
  - Weighted score: ~135.0 (10 * 13.5)
  - God object score: 87.3
  - Result: God object detected ‚úì
</code></pre>
<p><strong>Benefits:</strong></p>
<ul>
<li><strong>Reduces false positives</strong> on utility modules with many simple functions</li>
<li><strong>Focuses attention</strong> on truly problematic complex modules</li>
<li><strong>Rewards good refactoring</strong> - breaking large functions into small helpers improves score</li>
<li><strong>Aligns with reality</strong> - complexity matters more than count for maintainability</li>
</ul>
<p><strong>How to View:</strong></p>
<p>When Debtmap detects a god object, the output includes:</p>
<ul>
<li>Raw method count</li>
<li>Weighted method count</li>
<li>Average complexity</li>
<li>God object score</li>
<li>Recommended module splits based on responsibility clustering</li>
</ul>
<p><strong>MagicValues</strong>: Unexplained literals</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Magic numbers
fn calculate_price(quantity: u32) -&gt; f64 {
    quantity as f64 * 19.99 + 5.0  // What are these numbers?
}

// Good: Named constants
const UNIT_PRICE: f64 = 19.99;
const SHIPPING_COST: f64 = 5.0;
fn calculate_price(quantity: u32) -&gt; f64 {
    quantity as f64 * UNIT_PRICE + SHIPPING_COST
}
<span class="boring">}</span></code></pre></pre>
<h4 id="testing-debt"><a class="header" href="#testing-debt">Testing Debt</a></h4>
<p><strong>TestingGap</strong>: Functions with insufficient test coverage</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 0% coverage - critical business logic untested
fn calculate_tax(amount: f64, region: &amp;str) -&gt; f64 {
    // Complex tax calculation logic
    // No tests exist for this function!
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Coverage data shows function has &lt; 80% line coverage
<strong>Action</strong>: Add unit tests to cover all branches and edge cases</p>
<p><strong>TestComplexity</strong>: Test functions too complex</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn complex_test() {
    // Cyclomatic: 12 (too complex for a test)
    for input in test_cases {
        if input.is_special() {
            match input.type {
                /* complex test logic */
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Test functions with cyclomatic &gt; 10 or cognitive &gt; 15
<strong>Action</strong>: Split into multiple focused tests, use test fixtures</p>
<p><strong>FlakyTestPattern</strong>: Non-deterministic tests</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn flaky_test() {
    let result = async_operation().await;  // Timing-dependent
    thread::sleep(Duration::from_millis(100));  // Race condition!
    assert_eq!(result.status, "complete");
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Pattern analysis for timing dependencies, random values
<strong>Action</strong>: Use mocks, deterministic test data, proper async test utilities</p>
<h4 id="performance-debt"><a class="header" href="#performance-debt">Performance Debt</a></h4>
<p><strong>AllocationInefficiency</strong>: Excessive allocations</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Allocates on every iteration
fn process_items(items: &amp;[Item]) -&gt; Vec&lt;String&gt; {
    let mut results = Vec::new();
    for item in items {
        results.push(item.name.clone());  // Unnecessary clone
    }
    results
}

// Good: Pre-allocate, avoid clones
fn process_items(items: &amp;[Item]) -&gt; Vec&lt;&amp;str&gt; {
    items.iter().map(|item| item.name.as_str()).collect()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>BlockingIO</strong>: Blocking operations in async contexts</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Blocks async runtime
async fn load_data() -&gt; Result&lt;Data&gt; {
    let file = std::fs::read_to_string("data.json")?;  // Blocking!
    parse_json(&amp;file)
}

// Good: Async I/O
async fn load_data() -&gt; Result&lt;Data&gt; {
    let file = tokio::fs::read_to_string("data.json").await?;
    parse_json(&amp;file)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>NestedLoops</strong>: O(n¬≤) or worse complexity</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: O(n¬≤) nested loops
fn find_duplicates(items: &amp;[Item]) -&gt; Vec&lt;(Item, Item)&gt; {
    let mut dupes = vec![];
    for i in 0..items.len() {
        for j in i+1..items.len() {
            if items[i] == items[j] {
                dupes.push((items[i].clone(), items[j].clone()));
            }
        }
    }
    dupes
}

// Good: O(n) with HashSet
fn find_duplicates(items: &amp;[Item]) -&gt; Vec&lt;Item&gt; {
    let mut seen = HashSet::new();
    items.iter().filter(|item| !seen.insert(item)).cloned().collect()
}
<span class="boring">}</span></code></pre></pre>
<h4 id="code-quality-debt"><a class="header" href="#code-quality-debt">Code Quality Debt</a></h4>
<p><strong>Duplication</strong>: Duplicated code blocks</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// File A:
fn process_user(user: User) -&gt; Result&lt;()&gt; {
    validate_email(&amp;user.email)?;
    validate_age(user.age)?;
    save_to_database(&amp;user)?;
    send_welcome_email(&amp;user.email)?;
    Ok(())
}

// File B: Duplicated validation
fn process_admin(admin: Admin) -&gt; Result&lt;()&gt; {
    validate_email(&amp;admin.email)?;  // Duplicated
    validate_age(admin.age)?;       // Duplicated
    save_to_database(&amp;admin)?;
    grant_admin_privileges(&amp;admin)?;
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Similar code blocks &gt; 50 lines (configurable)
<strong>Action</strong>: Extract shared code into reusable functions</p>
<p><strong>ErrorSwallowing</strong>: Errors caught but ignored</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Error swallowed, no context
match risky_operation() {
    Ok(result) =&gt; process(result),
    Err(_) =&gt; {}, // Silent failure!
}

// Good: Error handled with context
match risky_operation() {
    Ok(result) =&gt; process(result),
    Err(e) =&gt; {
        log::error!("Risky operation failed: {}", e);
        return Err(e.into());
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Empty catch blocks, ignored Results
<strong>Action</strong>: Add proper error logging and propagation</p>
<p><strong>Risk</strong>: High-risk code (complex + poorly tested)</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cyclomatic: 18, Coverage: 20%, Risk Score: 47.6 (HIGH)
fn process_payment(tx: Transaction) -&gt; Result&lt;Receipt&gt; {
    // Complex payment logic with minimal testing
    // High risk of bugs in production
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Combines complexity metrics with coverage data
<strong>Action</strong>: Either add comprehensive tests OR refactor to reduce complexity</p>
<h3 id="debt-scoring-formula"><a class="header" href="#debt-scoring-formula">Debt Scoring Formula</a></h3>
<p>Each debt item gets a score based on priority and type:</p>
<pre><code>debt_score = priority_weight √ó type_weight
</code></pre>
<p><strong>Priority weights:</strong></p>
<ul>
<li>Low = 1</li>
<li>Medium = 3</li>
<li>High = 5</li>
<li>Critical = 10</li>
</ul>
<p><strong>Combined examples:</strong></p>
<ul>
<li>Low Todo = 1 √ó 1 = 1</li>
<li>Medium Fixme = 3 √ó 2 = 6</li>
<li>High Complexity = 5 √ó 5 = 25</li>
<li>Critical Complexity = 10 √ó 5 = 50</li>
</ul>
<p><strong>Total debt score</strong> = Sum of all debt item scores</p>
<p>Lower is better. Track over time to measure improvement.</p>
<h2 id="risk-scoring"><a class="header" href="#risk-scoring">Risk Scoring</a></h2>
<p>Debtmap‚Äôs risk scoring identifies code that is both complex AND poorly tested - the true risk hotspots.</p>
<h3 id="unified-scoring-system"><a class="header" href="#unified-scoring-system">Unified Scoring System</a></h3>
<p>Debtmap uses a <strong>unified scoring system</strong> (0-10 scale) as the primary prioritization mechanism. This multi-factor approach balances complexity, test coverage, and dependency impact, adjusted by function role.</p>
<h4 id="score-scale-and-priority-classifications"><a class="header" href="#score-scale-and-priority-classifications">Score Scale and Priority Classifications</a></h4>
<p>Functions receive scores from 0 (minimal risk) to 10 (critical risk):</p>
<div class="table-wrapper"><table><thead><tr><th>Score Range</th><th>Priority</th><th>Description</th><th>Action</th></tr></thead><tbody>
<tr><td><strong>9.0-10.0</strong></td><td>Critical</td><td>Severe risk requiring immediate attention</td><td>Address immediately</td></tr>
<tr><td><strong>7.0-8.9</strong></td><td>High</td><td>Significant risk, should be addressed soon</td><td>Plan for this sprint</td></tr>
<tr><td><strong>5.0-6.9</strong></td><td>Medium</td><td>Moderate risk, plan for future work</td><td>Schedule for next sprint</td></tr>
<tr><td><strong>3.0-4.9</strong></td><td>Low</td><td>Minor risk, lower priority</td><td>Monitor and address as time permits</td></tr>
<tr><td><strong>0.0-2.9</strong></td><td>Minimal</td><td>Well-managed code</td><td>Continue monitoring</td></tr>
</tbody></table>
</div>
<h4 id="scoring-formula"><a class="header" href="#scoring-formula">Scoring Formula</a></h4>
<p>The unified score combines three weighted factors:</p>
<pre><code>Base Score = (Complexity Factor √ó 0.40) + (Coverage Factor √ó 0.40) + (Dependency Factor √ó 0.20)

Final Score = Base Score √ó Role Multiplier
</code></pre>
<p><strong>Factor Calculations:</strong></p>
<p><strong>Complexity Factor</strong> (0-10 scale):</p>
<pre><code>Complexity Factor = min(10, ((cyclomatic / 10) + (cognitive / 20)) √ó 5)
</code></pre>
<p>Normalized to 0-10 range based on cyclomatic and cognitive complexity.</p>
<p><strong>Coverage Factor</strong> (0-10 scale):</p>
<pre><code>Coverage Factor = 10 √ó (1 - coverage_percentage) √ó complexity_weight
</code></pre>
<p>Uncovered complex code scores higher than uncovered simple code. Coverage dampens the score - well-tested code gets lower scores.</p>
<p><strong>Dependency Factor</strong> (0-10 scale):
Based on call graph analysis with specific thresholds:</p>
<ul>
<li><strong>High impact</strong> (score 8-10): 5+ upstream callers, or on critical path from entry point (adds 2-3 points)</li>
<li><strong>Moderate impact</strong> (score 4-6): 2-4 upstream callers</li>
<li><strong>Low impact</strong> (score 1-3): 0-1 upstream callers</li>
<li><strong>Critical path bonus</strong>: Being on a critical path from an entry point adds 2-3 points to the base dependency score</li>
</ul>
<h4 id="default-weights"><a class="header" href="#default-weights">Default Weights</a></h4>
<p>The scoring formula uses configurable weights (default values shown):</p>
<ul>
<li><strong>Complexity: 40%</strong> - How difficult the code is to understand and test</li>
<li><strong>Coverage: 40%</strong> - How well the code is tested</li>
<li><strong>Dependency: 20%</strong> - How many other functions depend on this code</li>
</ul>
<p>These weights can be adjusted in <code>.debtmap.toml</code> to match your team‚Äôs priorities.</p>
<h4 id="role-based-prioritization"><a class="header" href="#role-based-prioritization">Role-Based Prioritization</a></h4>
<p>The unified score is multiplied by a <strong>role multiplier</strong> based on the function‚Äôs semantic classification:</p>
<div class="table-wrapper"><table><thead><tr><th>Role</th><th>Multiplier</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><strong>Entry Points</strong></td><td>1.5√ó</td><td>main(), HTTP handlers, API endpoints</td><td>User-facing code where bugs have immediate impact</td></tr>
<tr><td><strong>Business Logic</strong></td><td>1.2√ó</td><td>Core domain functions, algorithms</td><td>Critical functionality</td></tr>
<tr><td><strong>Data Access</strong></td><td>1.0√ó</td><td>Database queries, file I/O</td><td>Baseline importance</td></tr>
<tr><td><strong>Infrastructure</strong></td><td>0.8√ó</td><td>Logging, configuration, monitoring</td><td>Supporting code</td></tr>
<tr><td><strong>Utilities</strong></td><td>0.5√ó</td><td>Helpers, formatters, converters</td><td>Lower impact</td></tr>
<tr><td><strong>Test Code</strong></td><td>0.1√ó</td><td>Test functions, fixtures, mocks</td><td>Internal quality</td></tr>
</tbody></table>
</div>
<p><strong>How role classification works:</strong></p>
<p>Debtmap identifies function roles through pattern analysis:</p>
<ul>
<li><strong>Entry points</strong>: Functions named <code>main</code>, handlers with routing decorators, public API functions</li>
<li><strong>Business logic</strong>: Core domain operations, calculation functions, decision-making code</li>
<li><strong>Data access</strong>: Database queries, file operations, network calls</li>
<li><strong>Infrastructure</strong>: Logging, config parsing, monitoring, error handling</li>
<li><strong>Utilities</strong>: Helper functions, formatters, type converters, validators</li>
<li><strong>Test code</strong>: Functions in test modules, test functions, fixtures</li>
</ul>
<p><strong>Example: Same complexity, different priorities</strong></p>
<p>Consider a function with base score 8.0:</p>
<pre><code>If classified as Entry Point:
  Final Score = 8.0 √ó 1.5 = 12.0 (capped at 10.0) ‚Üí CRITICAL priority

If classified as Business Logic:
  Final Score = 8.0 √ó 1.2 = 9.6 ‚Üí CRITICAL priority

If classified as Data Access:
  Final Score = 8.0 √ó 1.0 = 8.0 ‚Üí HIGH priority

If classified as Utility:
  Final Score = 8.0 √ó 0.5 = 4.0 ‚Üí LOW priority
</code></pre>
<p>This ensures that complex code in critical paths gets higher priority than equally complex utility code.</p>
<h4 id="coverage-propagation"><a class="header" href="#coverage-propagation">Coverage Propagation</a></h4>
<p>Coverage impact flows through the call graph using <strong>transitive coverage</strong>:</p>
<pre><code>Transitive Coverage = Direct Coverage + Œ£(Caller Coverage √ó Weight)
</code></pre>
<p><strong>How it works:</strong></p>
<p>Functions called by well-tested code inherit some coverage benefit, reducing their urgency. This helps identify which untested functions are on critical paths versus safely isolated utilities.</p>
<p><strong>Example scenarios:</strong></p>
<p><strong>Scenario 1: Untested function with well-tested callers</strong></p>
<pre><code>Function A: 0% direct coverage
  Called by:
    - handle_request (95% coverage)
    - process_payment (90% coverage)
    - validate_order (88% coverage)

Transitive coverage: ~40% (inherits coverage benefit from callers)
Final priority: Lower than isolated 0% coverage function
</code></pre>
<p><strong>Scenario 2: Untested function on critical path</strong></p>
<pre><code>Function B: 0% direct coverage
  Called by:
    - main (0% coverage)
    - startup (10% coverage)

Transitive coverage: ~5% (minimal coverage benefit)
Final priority: Higher - on critical path with no safety net
</code></pre>
<p>Coverage propagation prevents false alarms about utility functions called only by well-tested code, while highlighting genuinely risky untested code on critical paths.</p>
<h4 id="unified-score-example"><a class="header" href="#unified-score-example">Unified Score Example</a></h4>
<pre><code>Function: process_payment
  Location: src/payments.rs:145

Metrics:
  - Cyclomatic complexity: 18
  - Cognitive complexity: 25
  - Test coverage: 20%
  - Upstream callers: 3 (high dependency)
  - Role: Business Logic

Calculation:
  Complexity Factor = min(10, ((18/10) + (25/20)) √ó 5) = min(10, 8.75) = 8.75
  Coverage Factor = 10 √ó (1 - 0.20) √ó 1.0 = 8.0
  Dependency Factor = 7.5 (3 upstream callers, moderate impact)

  Base Score = (8.75 √ó 0.40) + (8.0 √ó 0.40) + (7.5 √ó 0.20)
             = 3.5 + 3.2 + 1.5
             = 8.2

  Final Score = 8.2 √ó 1.2 (Business Logic multiplier)
              = 9.84 ‚Üí CRITICAL priority
</code></pre>
<h3 id="legacy-risk-scoring-pre-02x"><a class="header" href="#legacy-risk-scoring-pre-02x">Legacy Risk Scoring (Pre-0.2.x)</a></h3>
<p>Prior to the unified scoring system, Debtmap used a simpler additive risk formula. This is still available for compatibility but unified scoring is now the default and provides better prioritization.</p>
<h3 id="risk-categories"><a class="header" href="#risk-categories">Risk Categories</a></h3>
<p><strong>Note:</strong> The <code>RiskLevel</code> enum (Low, Medium, High, Critical) is used for <strong>legacy risk scoring compatibility</strong>. When using <strong>unified scoring</strong> (0-10 scale), refer to the priority classifications shown in the Unified Scoring System section above.</p>
<h4 id="legacy-risklevel-enum"><a class="header" href="#legacy-risklevel-enum">Legacy RiskLevel Enum</a></h4>
<p>For legacy risk scoring, Debtmap classifies functions into four risk levels:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum RiskLevel {
    Low,       // Score &lt; 10
    Medium,    // Score 10-24
    High,      // Score 25-49
    Critical,  // Score ‚â• 50
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Critical</strong> (legacy score ‚â• 50)</p>
<ul>
<li>High complexity (cyclomatic &gt; 15) AND low coverage (&lt; 30%)</li>
<li>Untested code that‚Äôs likely to break and hard to fix</li>
<li><strong>Action</strong>: Immediate attention required - add tests or refactor</li>
</ul>
<p><strong>High</strong> (legacy score 25-49)</p>
<ul>
<li>High complexity (cyclomatic &gt; 10) AND moderate coverage (&lt; 60%)</li>
<li>Risky code with incomplete testing</li>
<li><strong>Action</strong>: Should be addressed soon</li>
</ul>
<p><strong>Medium</strong> (legacy score 10-24)</p>
<ul>
<li>Moderate complexity (cyclomatic &gt; 5) AND low coverage (&lt; 50%)</li>
<li>OR: High complexity with good coverage</li>
<li><strong>Action</strong>: Plan for next sprint</li>
</ul>
<p><strong>Low</strong> (legacy score &lt; 10)</p>
<ul>
<li>Low complexity OR high coverage</li>
<li>Well-managed code</li>
<li><strong>Action</strong>: Monitor, low priority</li>
</ul>
<h4 id="unified-scoring-priority-levels"><a class="header" href="#unified-scoring-priority-levels">Unified Scoring Priority Levels</a></h4>
<p>When using unified scoring (default), functions are classified using the 0-10 scale:</p>
<ul>
<li><strong>Critical</strong> (9.0-10.0): Immediate attention</li>
<li><strong>High</strong> (7.0-8.9): Address this sprint</li>
<li><strong>Medium</strong> (5.0-6.9): Plan for next sprint</li>
<li><strong>Low</strong> (3.0-4.9): Monitor and address as time permits</li>
<li><strong>Minimal</strong> (0.0-2.9): Well-managed code</li>
</ul>
<p><strong>Well-tested complex code</strong> is an <strong>outcome</strong> in both systems, not a separate category:</p>
<ul>
<li>Complex function (cyclomatic 18, cognitive 25) with 95% coverage</li>
<li>Unified score: ~2.5 (Minimal priority due to coverage dampening)</li>
<li>Legacy risk score: ~8 (Low risk)</li>
<li>Falls into low-priority categories because good testing mitigates complexity</li>
<li>This is the desired state for inherently complex business logic</li>
</ul>
<h3 id="legacy-risk-calculation"><a class="header" href="#legacy-risk-calculation">Legacy Risk Calculation</a></h3>
<p><strong>Note:</strong> The legacy risk calculation is still supported for compatibility but has been superseded by the unified scoring system (see above). Unified scoring provides better prioritization through its multi-factor, weighted approach with role-based adjustments.</p>
<p>The legacy risk score uses a simpler additive formula:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>risk_score = complexity_factor + coverage_factor + debt_factor

where:
  complexity_factor = (cyclomatic / 5) + (cognitive / 10)
  coverage_factor = (1 - coverage_percentage) √ó 50
  debt_factor = debt_score / 10  // If debt data available
<span class="boring">}</span></code></pre></pre>
<p><strong>Example (legacy scoring):</strong></p>
<pre><code>Function: process_payment
  - Cyclomatic complexity: 18
  - Cognitive complexity: 25
  - Coverage: 20%
  - Debt score: 15

Calculation:
  complexity_factor = (18 / 5) + (25 / 10) = 3.6 + 2.5 = 6.1
  coverage_factor = (1 - 0.20) √ó 50 = 40
  debt_factor = 15 / 10 = 1.5

  risk_score = 6.1 + 40 + 1.5 = 47.6 (HIGH RISK)
</code></pre>
<p><strong>When to use legacy scoring:</strong></p>
<ul>
<li>Comparing with historical data from older Debtmap versions</li>
<li>Teams with existing workflows built around the old scale</li>
<li>Gradual migration to unified scoring</li>
</ul>
<p><strong>Why unified scoring is better:</strong></p>
<ul>
<li>Normalized 0-10 scale is more intuitive</li>
<li>Weighted factors (40% complexity, 40% coverage, 20% dependency) provide better balance</li>
<li>Role multipliers adjust priority based on function importance</li>
<li>Coverage propagation reduces false positives for utility functions</li>
</ul>
<h3 id="test-effort-assessment"><a class="header" href="#test-effort-assessment">Test Effort Assessment</a></h3>
<p>Debtmap estimates testing difficulty based on cognitive complexity:</p>
<p><strong>Difficulty Levels:</strong></p>
<ul>
<li><strong>Trivial</strong> (cognitive &lt; 5): 1-2 test cases, &lt; 1 hour</li>
<li><strong>Simple</strong> (cognitive 5-10): 3-5 test cases, 1-2 hours</li>
<li><strong>Moderate</strong> (cognitive 10-20): 6-10 test cases, 2-4 hours</li>
<li><strong>Complex</strong> (cognitive 20-40): 11-20 test cases, 4-8 hours</li>
<li><strong>VeryComplex</strong> (cognitive &gt; 40): 20+ test cases, 8+ hours</li>
</ul>
<p><strong>Test Effort includes:</strong></p>
<ul>
<li><strong>Cognitive load</strong>: How hard to understand the function</li>
<li><strong>Branch count</strong>: Number of paths to test</li>
<li><strong>Recommended test cases</strong>: Suggested number of tests</li>
</ul>
<h3 id="risk-distribution"><a class="header" href="#risk-distribution">Risk Distribution</a></h3>
<p>Debtmap provides codebase-wide risk metrics:</p>
<pre><code class="language-json">{
  "risk_distribution": {
    "critical_count": 12,
    "high_count": 45,
    "medium_count": 123,
    "low_count": 456,
    "minimal_count": 234,
    "total_functions": 870
  },
  "codebase_risk_score": 1247.5
}
</code></pre>
<p><strong>Interpreting distribution:</strong></p>
<ul>
<li><strong>Healthy codebase</strong>: Most functions in Low/Minimal priority (unified scoring) or Low/WellTested (legacy)</li>
<li><strong>Needs attention</strong>: Many Critical/High priority functions</li>
<li><strong>Technical debt</strong>: High codebase risk score</li>
</ul>
<p><strong>Note on minimal_count:</strong></p>
<p>In unified scoring (0-10 scale), <code>minimal_count</code> represents functions scoring 0-2.9, which includes:</p>
<ul>
<li>Simple utility functions</li>
<li>Helper functions with low complexity</li>
<li>Well-tested complex code that scores low due to coverage dampening</li>
</ul>
<p>This is not a separate risk category but an <strong>outcome</strong> of the unified scoring system. Complex business logic with 95% test coverage appropriately receives a minimal score, reflecting that good testing mitigates complexity risk.</p>
<p><strong>Important:</strong> <code>minimal_count</code> does not appear in the standard <code>risk_categories</code> from features.json (Low, Medium, High, Critical, WellTested). It‚Äôs specific to unified scoring‚Äôs 0-10 scale priority classifications (Minimal, Low, Medium, High, Critical).</p>
<h3 id="testing-recommendations"><a class="header" href="#testing-recommendations">Testing Recommendations</a></h3>
<p>When coverage data is provided, Debtmap generates prioritized testing recommendations with ROI analysis:</p>
<pre><code class="language-json">{
  "function": "process_transaction",
  "file": "src/payments.rs",
  "line": 145,
  "current_risk": 47.6,
  "potential_risk_reduction": 35.2,
  "test_effort_estimate": {
    "estimated_difficulty": "Complex",
    "cognitive_load": 25,
    "branch_count": 18,
    "recommended_test_cases": 12
  },
  "roi": 4.4,
  "rationale": "High complexity with low coverage (20%) and 3 downstream dependencies. Testing will reduce risk by 74%.",
  "dependencies": {
    "upstream_callers": ["handle_payment_request"],
    "downstream_callees": ["validate_amount", "check_balance", "record_transaction"]
  }
}
</code></pre>
<p><strong>ROI calculation:</strong></p>
<pre><code>roi = potential_risk_reduction / estimated_effort_hours
</code></pre>
<p>Higher ROI = better return on testing investment</p>
<h2 id="interpreting-results"><a class="header" href="#interpreting-results">Interpreting Results</a></h2>
<h3 id="understanding-output-formats"><a class="header" href="#understanding-output-formats">Understanding Output Formats</a></h3>
<p>Debtmap provides three output formats:</p>
<p><strong>Terminal</strong> (default): Human-readable with colors and tables</p>
<pre><code class="language-bash">debtmap analyze .
</code></pre>
<p><strong>JSON</strong>: Machine-readable for CI/CD integration</p>
<pre><code class="language-bash">debtmap analyze . --format json --output report.json
</code></pre>
<p><strong>Markdown</strong>: Documentation-friendly</p>
<pre><code class="language-bash">debtmap analyze . --format markdown --output report.md
</code></pre>
<h3 id="json-structure"><a class="header" href="#json-structure">JSON Structure</a></h3>
<pre><code class="language-json">{
  "timestamp": "2025-10-09T12:00:00Z",
  "project_path": "/path/to/project",
  "complexity": {
    "metrics": [
      {
        "name": "process_data",
        "file": "src/main.rs",
        "line": 42,
        "cyclomatic": 15,
        "cognitive": 22,
        "est_branches": 20,
        "nesting": 4,
        "length": 68,
        "is_test": false,
        "visibility": "Public",
        "is_trait_method": false,
        "in_test_module": false,
        "entropy_score": {
          "token_entropy": 0.65,
          "pattern_repetition": 0.25,
          "branch_similarity": 0.30,
          "effective_complexity": 0.85
        },
        "is_pure": false,
        "purity_confidence": 0.8,
        "detected_patterns": ["validation_pattern"],
        "upstream_callers": ["main", "process_request"],
        "downstream_callees": ["validate", "save", "notify"]
      }
    ],
    "summary": {
      "total_functions": 150,
      "average_complexity": 5.3,
      "max_complexity": 22,
      "high_complexity_count": 8
    }
  },
  "technical_debt": {
    "items": [
      {
        "id": "complexity_src_main_rs_42",
        "debt_type": "Complexity",
        "priority": "High",
        "file": "src/main.rs",
        "line": 42,
        "column": 1,
        "message": "Function exceeds complexity threshold",
        "context": "Cyclomatic: 15, Cognitive: 22"
      }
    ],
    "by_type": {
      "Complexity": [...],
      "Duplication": [...],
      "Todo": [...]
    }
  }
}
</code></pre>
<h4 id="json-output-format-variants"><a class="header" href="#json-output-format-variants">JSON Output Format Variants</a></h4>
<p>Debtmap supports two JSON output format variants for different integration needs:</p>
<p><strong>Legacy Format (default):</strong></p>
<ul>
<li>Uses wrapper objects: <code>{"File": {...}}</code> and <code>{"Function": {...}}</code></li>
<li>Compatible with existing tooling and scripts</li>
<li>Shown in the JSON structure example above</li>
</ul>
<p><strong>Unified Format (spec 108 - future enhancement):</strong></p>
<ul>
<li>Uses consistent structure with <code>"type"</code> field discriminator</li>
<li>Simpler parsing for new integrations</li>
<li>Example structure:</li>
</ul>
<pre><code class="language-json">{
  "type": "function",
  "name": "process_data",
  "file": "src/main.rs",
  "line": 42,
  "metrics": { /* ... */ }
}
</code></pre>
<p><strong>Note:</strong> The unified format is currently an internal representation and is <strong>not available</strong> as a user-facing CLI option. The legacy format remains the stable default for all current integrations. If you need the unified format exposed as a CLI option (<code>--format json-unified</code>), please open a feature request on GitHub.</p>
<h3 id="reading-function-metrics"><a class="header" href="#reading-function-metrics">Reading Function Metrics</a></h3>
<p><strong>Key fields:</strong></p>
<ul>
<li><code>cyclomatic</code>: Decision points - guides test case count</li>
<li><code>cognitive</code>: Understanding difficulty - guides refactoring priority</li>
<li><code>est_branches</code>: Estimated execution paths (formula: max(nesting_depth, 1) √ó cyclomatic √∑ 3) - approximates test cases needed for branch coverage</li>
<li><code>nesting</code>: Indentation depth - signals need for extraction</li>
<li><code>length</code>: Lines of code - signals SRP violations</li>
<li><code>visibility</code>: Function visibility (<code>"Private"</code>, <code>"Crate"</code>, or <code>"Public"</code> from FunctionVisibility enum)</li>
<li><code>is_pure</code>: No side effects - easier to test (Option type, may be None)</li>
<li><code>purity_confidence</code>: How certain we are about purity 0.0-1.0 (Option type, may be None)</li>
<li><code>is_trait_method</code>: Whether this function implements a trait method</li>
<li><code>in_test_module</code>: Whether function is inside a <code>#[cfg(test)]</code> module</li>
<li><code>detected_patterns</code>: Complexity adjustment patterns identified (e.g., ‚Äúvalidation_pattern‚Äù)</li>
<li><code>entropy_score</code>: Pattern analysis for false positive reduction</li>
<li><code>upstream_callers</code>: Impact radius if this function breaks</li>
<li><code>downstream_callees</code>: Functions this depends on</li>
</ul>
<p><strong>Entropy interpretation:</strong></p>
<ul>
<li><code>token_entropy &lt; 0.4</code>: Repetitive code, likely pattern-based</li>
<li><code>pattern_repetition &gt; 0.7</code>: High similarity between blocks</li>
<li><code>branch_similarity &gt; 0.8</code>: Similar conditional branches</li>
<li><code>effective_complexity &lt; 1.0</code>: Dampening applied</li>
</ul>
<h3 id="prioritizing-work"><a class="header" href="#prioritizing-work">Prioritizing Work</a></h3>
<p>Debtmap provides multiple prioritization strategies, with <strong>unified scoring (0-10 scale)</strong> as the recommended default for most workflows:</p>
<p><strong>1. By Unified Score (default - recommended)</strong></p>
<pre><code class="language-bash">debtmap analyze . --top 10
</code></pre>
<p>Shows top 10 items by <strong>combined complexity, coverage, and dependency factors</strong>, weighted and adjusted by function role.</p>
<p><strong>Why use unified scoring:</strong></p>
<ul>
<li>Balances complexity (40%), coverage (40%), and dependency impact (20%)</li>
<li>Adjusts for function importance (entry points prioritized over utilities)</li>
<li>Normalized 0-10 scale is intuitive and consistent</li>
<li>Reduces false positives through coverage propagation</li>
<li>Best for <strong>sprint planning</strong> and <strong>function-level refactoring decisions</strong></li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-bash"># Show top 20 critical items
debtmap analyze . --min-priority 7.0 --top 20

# Focus on high-impact functions (score &gt;= 7.0)
debtmap analyze . --format json | jq '.functions[] | select(.unified_score &gt;= 7.0)'
</code></pre>
<p><strong>2. By Risk Category (legacy compatibility)</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority high
</code></pre>
<p>Shows only HIGH and CRITICAL priority items using legacy risk scoring.</p>
<p><strong>Note:</strong> Legacy risk scoring uses additive formulas and unbounded scales. Prefer unified scoring for new workflows.</p>
<p><strong>3. By Debt Type</strong></p>
<pre><code class="language-bash">debtmap analyze . --filter Architecture,Testing
</code></pre>
<p>Focuses on specific categories:</p>
<ul>
<li><code>Architecture</code>: God objects, complexity, dead code</li>
<li><code>Testing</code>: Coverage gaps, test quality</li>
<li><code>Performance</code>: Resource leaks, inefficiencies</li>
<li><code>CodeQuality</code>: Code smells, maintainability</li>
</ul>
<p><strong>4. By ROI (with coverage)</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.lcov --top 20
</code></pre>
<p>Prioritizes by return on investment for testing/refactoring. Combines unified scoring with test effort estimates to identify high-value work.</p>
<p><strong>Choosing the right strategy:</strong></p>
<ul>
<li><strong>Sprint planning for developers</strong>: Use unified scoring (<code>--top N</code>)</li>
<li><strong>Architectural review</strong>: Use tiered prioritization (<code>--summary</code>)</li>
<li><strong>Category-focused work</strong>: Use debt type filtering (<code>--filter</code>)</li>
<li><strong>Testing priorities</strong>: Use ROI analysis with coverage data (<code>--lcov</code>)</li>
<li><strong>Historical comparisons</strong>: Use legacy risk scoring (for consistency with old reports)</li>
</ul>
<h3 id="tiered-prioritization"><a class="header" href="#tiered-prioritization">Tiered Prioritization</a></h3>
<p><strong>Note:</strong> Tiered prioritization uses <strong>traditional debt scoring</strong> (additive, higher = worse) and is complementary to the unified scoring system (0-10 scale). Both systems can be used together:</p>
<ul>
<li><strong>Unified scoring</strong> (0-10 scale): Best for <strong>function-level prioritization</strong> and sprint planning</li>
<li><strong>Tiered prioritization</strong> (debt tiers): Best for <strong>architectural focus</strong> and strategic debt planning</li>
</ul>
<p>Use <code>--summary</code> for tiered view focusing on architectural issues, or default output for function-level unified scores.</p>
<p>Debtmap uses a tier-based system to map debt scores to actionable priority levels. Each tier includes effort estimates and strategic guidance for efficient debt remediation.</p>
<h4 id="tier-levels"><a class="header" href="#tier-levels">Tier Levels</a></h4>
<p>The <code>Tier</code> enum defines four priority levels based on score thresholds:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Tier {
    Critical,  // Score ‚â• 90
    High,      // Score 70-89.9
    Moderate,  // Score 50-69.9
    Low,       // Score &lt; 50
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Score-to-Tier Mapping:</strong></p>
<ul>
<li><strong>Critical</strong> (‚â• 90): Immediate action required - blocks progress</li>
<li><strong>High</strong> (70-89.9): Should be addressed this sprint</li>
<li><strong>Moderate</strong> (50-69.9): Plan for next sprint</li>
<li><strong>Low</strong> (&lt; 50): Background maintenance work</li>
</ul>
<h4 id="effort-estimates-per-tier"><a class="header" href="#effort-estimates-per-tier">Effort Estimates Per Tier</a></h4>
<p>Each tier includes estimated effort based on typical remediation patterns:</p>
<div class="table-wrapper"><table><thead><tr><th>Tier</th><th>Estimated Effort</th><th>Typical Work</th></tr></thead><tbody>
<tr><td><strong>Critical</strong></td><td>1-2 days</td><td>Major refactoring, comprehensive testing, architectural changes</td></tr>
<tr><td><strong>High</strong></td><td>2-4 hours</td><td>Extract functions, add test coverage, fix resource leaks</td></tr>
<tr><td><strong>Moderate</strong></td><td>1-2 hours</td><td>Simplify logic, reduce duplication, improve error handling</td></tr>
<tr><td><strong>Low</strong></td><td>30 minutes</td><td>Address TODOs, minor cleanup, documentation</td></tr>
</tbody></table>
</div>
<p><strong>Effort calculation considers:</strong></p>
<ul>
<li>Complexity metrics (cyclomatic, cognitive)</li>
<li>Test coverage gaps</li>
<li>Number of dependencies (upstream/downstream)</li>
<li>Debt category (Architecture debt takes longer than CodeQuality)</li>
</ul>
<h4 id="tiered-display-grouping"><a class="header" href="#tiered-display-grouping">Tiered Display Grouping</a></h4>
<p><code>TieredDisplay</code> groups similar debt items for batch action recommendations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TieredDisplay {
    pub tier: Tier,
    pub items: Vec&lt;DebtItem&gt;,
    pub total_score: f64,
    pub estimated_total_effort_hours: f64,
    pub batch_recommendations: Vec&lt;String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Grouping strategy:</strong></p>
<ul>
<li>Groups items by tier and similarity pattern</li>
<li>Prevents grouping of god objects (always show individually)</li>
<li>Prevents grouping of Critical items (each needs individual attention)</li>
<li>Suggests batch actions for similar Low/Moderate items</li>
</ul>
<p><strong>Example batch recommendations:</strong></p>
<pre><code class="language-json">{
  "tier": "Moderate",
  "total_score": 245.8,
  "estimated_total_effort_hours": 12.5,
  "batch_recommendations": [
    "Extract 5 validation functions from similar patterns",
    "Add test coverage for 8 moderately complex functions (grouped by module)",
    "Refactor 3 functions with similar nested loop patterns"
  ]
}
</code></pre>
<h4 id="using-tiered-prioritization"><a class="header" href="#using-tiered-prioritization">Using Tiered Prioritization</a></h4>
<p><strong>1. Start with Critical tier:</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority critical
</code></pre>
<p>Focus on items with score ‚â• 90. These typically represent:</p>
<ul>
<li>Complex functions with 0% coverage</li>
<li>God objects blocking feature development</li>
<li>Critical resource leaks or security issues</li>
</ul>
<p><strong>2. Plan High tier work:</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority high --format json &gt; sprint-plan.json
</code></pre>
<p>Schedule 2-4 hours per item for this sprint. Look for:</p>
<ul>
<li>Functions approaching complexity thresholds</li>
<li>Moderate coverage gaps on important code paths</li>
<li>Performance bottlenecks with clear solutions</li>
</ul>
<p><strong>3. Batch Moderate tier items:</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority moderate
</code></pre>
<p>Review batch recommendations. Examples:</p>
<ul>
<li>‚Äú10 validation functions detected - extract common pattern‚Äù</li>
<li>‚Äú5 similar test files with duplication - create shared fixtures‚Äù</li>
<li>‚Äú8 functions with magic values - create constants module‚Äù</li>
</ul>
<p><strong>4. Schedule Low tier background work:</strong>
Address during slack time or as warm-up tasks for new contributors.</p>
<h4 id="strategic-guidance-by-tier"><a class="header" href="#strategic-guidance-by-tier">Strategic Guidance by Tier</a></h4>
<p><strong>Critical Tier Strategy:</strong></p>
<ul>
<li><strong>Block new features</strong> until addressed</li>
<li><strong>Pair programming</strong> recommended for complex items</li>
<li><strong>Architectural review</strong> before major refactoring</li>
<li><strong>Comprehensive testing</strong> after changes</li>
</ul>
<p><strong>High Tier Strategy:</strong></p>
<ul>
<li><strong>Sprint planning priority</strong></li>
<li><strong>Impact analysis</strong> before changes</li>
<li><strong>Code review</strong> from senior developers</li>
<li><strong>Integration testing</strong> after changes</li>
</ul>
<p><strong>Moderate Tier Strategy:</strong></p>
<ul>
<li><strong>Batch similar items</strong> for efficiency</li>
<li><strong>Extract patterns</strong> across multiple files</li>
<li><strong>Incremental improvement</strong> over multiple PRs</li>
<li><strong>Regression testing</strong> for affected areas</li>
</ul>
<p><strong>Low Tier Strategy:</strong></p>
<ul>
<li><strong>Good first issues</strong> for new contributors</li>
<li><strong>Documentation improvements</strong></li>
<li><strong>Code cleanup</strong> during refactoring nearby code</li>
<li><strong>Technical debt gardening</strong> sessions</li>
</ul>
<h3 id="categorized-debt-analysis"><a class="header" href="#categorized-debt-analysis">Categorized Debt Analysis</a></h3>
<p>Debtmap provides <code>CategorizedDebt</code> analysis that groups debt items by category and identifies cross-category dependencies. This helps teams understand strategic relationships between different types of technical debt.</p>
<h4 id="categorysummary"><a class="header" href="#categorysummary">CategorySummary</a></h4>
<p>Each category gets a summary with metrics for planning:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CategorySummary {
    pub category: DebtCategory,
    pub total_score: f64,
    pub item_count: usize,
    pub estimated_effort_hours: f64,
    pub average_severity: f64,
    pub top_items: Vec&lt;DebtItem&gt;,  // Up to 5 highest priority
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Effort estimation formulas:</strong></p>
<ul>
<li><strong>Architecture debt</strong>: <code>complexity_score / 10 √ó 2</code> hours (structural changes take longer)</li>
<li><strong>Testing debt</strong>: <code>complexity_score / 10 √ó 1.5</code> hours (writing tests)</li>
<li><strong>Performance debt</strong>: <code>complexity_score / 10 √ó 1.8</code> hours (profiling + optimization)</li>
<li><strong>CodeQuality debt</strong>: <code>complexity_score / 10 √ó 1.2</code> hours (refactoring)</li>
</ul>
<p><strong>Example category summary:</strong></p>
<pre><code class="language-json">{
  "category": "Architecture",
  "total_score": 487.5,
  "item_count": 15,
  "estimated_effort_hours": 97.5,
  "average_severity": 32.5,
  "top_items": [
    {
      "debt_type": "GodObject",
      "file": "src/services/user_service.rs",
      "score": 95.0,
      "estimated_effort_hours": 16.0
    },
    {
      "debt_type": "ComplexityHotspot",
      "file": "src/payments/processor.rs",
      "score": 87.3,
      "estimated_effort_hours": 14.0
    }
  ]
}
</code></pre>
<h4 id="cross-category-dependencies"><a class="header" href="#cross-category-dependencies">Cross-Category Dependencies</a></h4>
<p><code>CrossCategoryDependency</code> identifies blocking relationships between different debt categories:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CrossCategoryDependency {
    pub from_category: DebtCategory,
    pub to_category: DebtCategory,
    pub blocking_items: Vec&lt;(DebtItem, DebtItem)&gt;,
    pub impact_level: ImpactLevel,  // Critical, High, Medium, Low
    pub recommendation: String,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Common dependency patterns:</strong></p>
<p><strong>1. Architecture blocks Testing:</strong></p>
<ul>
<li><strong>Pattern</strong>: God objects are too complex to test effectively</li>
<li><strong>Example</strong>: <code>UserService</code> has 50+ functions, making comprehensive testing impractical</li>
<li><strong>Impact</strong>: Critical - cannot improve test coverage without refactoring</li>
<li><strong>Recommendation</strong>: ‚ÄúSplit god object into 4-5 focused modules before adding tests‚Äù</li>
</ul>
<p><strong>2. Async issues require Architecture changes:</strong></p>
<ul>
<li><strong>Pattern</strong>: Blocking I/O in async contexts requires architectural redesign</li>
<li><strong>Example</strong>: Sync database calls in async handlers</li>
<li><strong>Impact</strong>: High - performance problems require design changes</li>
<li><strong>Recommendation</strong>: ‚ÄúIntroduce async database layer before optimizing handlers‚Äù</li>
</ul>
<p><strong>3. Complexity affects Testability:</strong></p>
<ul>
<li><strong>Pattern</strong>: High cyclomatic complexity makes thorough testing difficult</li>
<li><strong>Example</strong>: Function with 22 branches needs 22+ test cases</li>
<li><strong>Impact</strong>: High - testing effort grows exponentially with complexity</li>
<li><strong>Recommendation</strong>: ‚ÄúReduce complexity to &lt; 10 before writing comprehensive tests‚Äù</li>
</ul>
<p><strong>4. Performance requires Architecture:</strong></p>
<ul>
<li><strong>Pattern</strong>: O(n¬≤) nested loops need different data structures</li>
<li><strong>Example</strong>: Linear search in loops should use HashMap</li>
<li><strong>Impact</strong>: Medium - optimization requires structural changes</li>
<li><strong>Recommendation</strong>: ‚ÄúRefactor data structure before micro-optimizations‚Äù</li>
</ul>
<p><strong>Example cross-category dependency:</strong></p>
<pre><code class="language-json">{
  "from_category": "Architecture",
  "to_category": "Testing",
  "impact_level": "Critical",
  "blocking_items": [
    {
      "blocker": {
        "debt_type": "GodObject",
        "file": "src/services/user_service.rs",
        "functions": 52,
        "score": 95.0
      },
      "blocked": {
        "debt_type": "TestingGap",
        "file": "src/services/user_service.rs",
        "coverage": 15,
        "score": 78.0
      }
    }
  ],
  "recommendation": "Split UserService into focused modules (auth, profile, settings, notifications) before attempting to improve test coverage. Current structure makes comprehensive testing impractical.",
  "estimated_unblock_effort_hours": 16.0
}
</code></pre>
<h4 id="using-categorized-debt-analysis"><a class="header" href="#using-categorized-debt-analysis">Using Categorized Debt Analysis</a></h4>
<p><strong>View all category summaries:</strong></p>
<pre><code class="language-bash">debtmap analyze . --format json | jq '.categorized_debt.summaries'
</code></pre>
<p><strong>Focus on specific category:</strong></p>
<pre><code class="language-bash">debtmap analyze . --filter Architecture --top 10
</code></pre>
<p><strong>Identify blocking relationships:</strong></p>
<pre><code class="language-bash">debtmap analyze . --format json | jq '.categorized_debt.cross_category_dependencies[] | select(.impact_level == "Critical")'
</code></pre>
<p><strong>Strategic planning workflow:</strong></p>
<ol>
<li>
<p><strong>Review category summaries:</strong></p>
<ul>
<li>Identify which category has highest total score</li>
<li>Check estimated effort hours per category</li>
<li>Note average severity to gauge urgency</li>
</ul>
</li>
<li>
<p><strong>Check cross-category dependencies:</strong></p>
<ul>
<li>Find Critical and High impact blockers</li>
<li>Prioritize blockers before blocked items</li>
<li>Plan architectural changes before optimization</li>
</ul>
</li>
<li>
<p><strong>Plan remediation order:</strong></p>
<pre><code>Example decision tree:
- Architecture score &gt; 400? ‚Üí Address god objects first
- Testing gap with low complexity? ‚Üí Quick wins, add tests
- Performance issues + architecture debt? ‚Üí Refactor structure first
- High code quality debt but good architecture? ‚Üí Incremental cleanup
</code></pre>
</li>
<li>
<p><strong>Use category-specific strategies:</strong></p>
<ul>
<li><strong>Architecture</strong>: Pair programming, design reviews, incremental refactoring</li>
<li><strong>Testing</strong>: TDD for new code, characterization tests for legacy</li>
<li><strong>Performance</strong>: Profiling first, optimize hot paths, avoid premature optimization</li>
<li><strong>CodeQuality</strong>: Code review focus, linting rules, consistent patterns</li>
</ul>
</li>
</ol>
<h4 id="categorizeddebt-output-structure"><a class="header" href="#categorizeddebt-output-structure">CategorizedDebt Output Structure</a></h4>
<pre><code class="language-json">{
  "categorized_debt": {
    "summaries": [
      {
        "category": "Architecture",
        "total_score": 487.5,
        "item_count": 15,
        "estimated_effort_hours": 97.5,
        "average_severity": 32.5,
        "top_items": [...]
      },
      {
        "category": "Testing",
        "total_score": 356.2,
        "item_count": 23,
        "estimated_effort_hours": 53.4,
        "average_severity": 15.5,
        "top_items": [...]
      },
      {
        "category": "Performance",
        "total_score": 234.8,
        "item_count": 12,
        "estimated_effort_hours": 42.3,
        "average_severity": 19.6,
        "top_items": [...]
      },
      {
        "category": "CodeQuality",
        "total_score": 189.3,
        "item_count": 31,
        "estimated_effort_hours": 22.7,
        "average_severity": 6.1,
        "top_items": [...]
      }
    ],
    "cross_category_dependencies": [
      {
        "from_category": "Architecture",
        "to_category": "Testing",
        "impact_level": "Critical",
        "blocking_items": [...],
        "recommendation": "..."
      }
    ]
  }
}
</code></pre>
<h3 id="debt-density-metric"><a class="header" href="#debt-density-metric">Debt Density Metric</a></h3>
<p>Debt density normalizes technical debt scores across projects of different sizes, providing a per-1000-lines-of-code metric for fair comparison.</p>
<h4 id="formula"><a class="header" href="#formula">Formula</a></h4>
<pre><code>debt_density = (total_debt_score / total_lines_of_code) √ó 1000
</code></pre>
<p><strong>Example calculation:</strong></p>
<pre><code>Project A:
  - Total debt score: 1,250
  - Total lines of code: 25,000
  - Debt density: (1,250 / 25,000) √ó 1000 = 50

Project B:
  - Total debt score: 2,500
  - Total lines of code: 50,000
  - Debt density: (2,500 / 50,000) √ó 1000 = 50
</code></pre>
<p>Projects A and B have <strong>equal debt density</strong> (50) despite B having twice the absolute debt, because B is also twice as large. They have proportionally similar technical debt.</p>
<h4 id="interpretation-guidelines"><a class="header" href="#interpretation-guidelines">Interpretation Guidelines</a></h4>
<p>Use these thresholds to assess codebase health:</p>
<div class="table-wrapper"><table><thead><tr><th>Debt Density</th><th>Assessment</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>0-50</strong></td><td>Clean</td><td>Well-maintained codebase, minimal debt</td></tr>
<tr><td><strong>51-100</strong></td><td>Moderate</td><td>Typical technical debt, manageable</td></tr>
<tr><td><strong>101-150</strong></td><td>High</td><td>Significant debt, prioritize remediation</td></tr>
<tr><td><strong>150+</strong></td><td>Critical</td><td>Severe debt burden, may impede development</td></tr>
</tbody></table>
</div>
<p><strong>Context matters:</strong></p>
<ul>
<li><strong>Early-stage projects</strong>: Often have higher density (rapid iteration)</li>
<li><strong>Mature projects</strong>: Should trend toward lower density over time</li>
<li><strong>Legacy systems</strong>: May have high density, track trend over time</li>
<li><strong>Greenfield rewrites</strong>: Aim for density &lt; 50</li>
</ul>
<h4 id="using-debt-density"><a class="header" href="#using-debt-density">Using Debt Density</a></h4>
<p><strong>1. Compare projects fairly:</strong></p>
<pre><code class="language-bash"># Small microservice (5,000 LOC, debt = 250)
# Debt density: 50

# Large monolith (100,000 LOC, debt = 5,000)
# Debt density: 50

# Equal health despite size difference
</code></pre>
<p><strong>2. Track improvement over time:</strong></p>
<pre><code>Sprint 1: 50,000 LOC, debt = 7,500, density = 150 (High)
Sprint 5: 52,000 LOC, debt = 6,500, density = 125 (Improving)
Sprint 10: 54,000 LOC, debt = 4,860, density = 90 (Moderate)
</code></pre>
<p><strong>3. Set team goals:</strong></p>
<pre><code>Current density: 120
Target density: &lt; 80 (by Q4)
Reduction needed: 40 points

Strategy:
- Fix 2-3 Critical items per sprint
- Prevent new debt (enforce thresholds)
- Refactor before adding features in high-debt modules
</code></pre>
<p><strong>4. Benchmark across teams/projects:</strong></p>
<pre><code class="language-json">{
  "team_metrics": [
    {
      "project": "auth-service",
      "debt_density": 45,
      "assessment": "Clean",
      "trend": "stable"
    },
    {
      "project": "billing-service",
      "debt_density": 95,
      "assessment": "Moderate",
      "trend": "improving"
    },
    {
      "project": "legacy-api",
      "debt_density": 165,
      "assessment": "Critical",
      "trend": "worsening"
    }
  ]
}
</code></pre>
<h4 id="limitations"><a class="header" href="#limitations">Limitations</a></h4>
<p><strong>Debt density doesn‚Äôt account for:</strong></p>
<ul>
<li><strong>Code importance</strong>: 100 LOC in payment logic ‚â† 100 LOC in logging utils</li>
<li><strong>Complexity distribution</strong>: One 1000-line god object vs. 1000 simple functions</li>
<li><strong>Test coverage</strong>: 50% coverage on critical paths vs. low-priority features</li>
<li><strong>Team familiarity</strong>: New codebase vs. well-understood legacy system</li>
</ul>
<p><strong>Best practices:</strong></p>
<ul>
<li>Use density as <strong>one metric among many</strong></li>
<li>Combine with category analysis and tiered prioritization</li>
<li>Focus on <strong>trend</strong> (improving/stable/worsening) over absolute number</li>
<li>Consider <strong>debt per module</strong> for more granular insights</li>
</ul>
<h4 id="debt-density-in-cicd"><a class="header" href="#debt-density-in-cicd">Debt Density in CI/CD</a></h4>
<p><strong>Track density over time:</strong></p>
<pre><code class="language-bash"># Generate report with density
debtmap analyze . --format json --output debt-report.json

# Extract density for trending
DENSITY=$(jq '.debt_density' debt-report.json)

# Store in metrics database
echo "debtmap.density:${DENSITY}|g" | nc -u -w0 statsd 8125
</code></pre>
<p><strong>Set threshold gates:</strong></p>
<pre><code class="language-yaml"># .github/workflows/debt-check.yml
- name: Check debt density
  run: |
    DENSITY=$(debtmap analyze . --format json | jq '.debt_density')
    if (( $(echo "$DENSITY &gt; 150" | bc -l) )); then
      echo "‚ùå Debt density too high: $DENSITY (limit: 150)"
      exit 1
    fi
    echo "‚úÖ Debt density acceptable: $DENSITY"
</code></pre>
<h3 id="actionable-insights"><a class="header" href="#actionable-insights">Actionable Insights</a></h3>
<p>Each recommendation includes:</p>
<p><strong>ACTION</strong>: What to do</p>
<ul>
<li>‚ÄúAdd 6 unit tests for full coverage‚Äù</li>
<li>‚ÄúRefactor into 3 smaller functions‚Äù</li>
<li>‚ÄúExtract validation to separate function‚Äù</li>
</ul>
<p><strong>IMPACT</strong>: Expected improvement</p>
<ul>
<li>‚ÄúFull test coverage, -3.7 risk‚Äù</li>
<li>‚ÄúReduce complexity from 22 to 8‚Äù</li>
<li>‚ÄúEliminate 120 lines of duplication‚Äù</li>
</ul>
<p><strong>WHY</strong>: Rationale</p>
<ul>
<li>‚ÄúBusiness logic with 0% coverage, manageable complexity‚Äù</li>
<li>‚ÄúHigh complexity with low coverage threatens stability‚Äù</li>
<li>‚ÄúRepeated validation pattern across 5 files‚Äù</li>
</ul>
<p><strong>Example workflow:</strong></p>
<ol>
<li>Run analysis with coverage: <code>debtmap analyze . --lcov coverage.lcov</code></li>
<li>Filter to CRITICAL items: <code>--min-priority critical</code></li>
<li>Review top 5 recommendations</li>
<li>Start with highest ROI items</li>
<li>Rerun analysis to track progress</li>
</ol>
<h3 id="common-patterns-to-recognize"><a class="header" href="#common-patterns-to-recognize">Common Patterns to Recognize</a></h3>
<p><strong>Pattern 1: High Complexity, Well Tested</strong></p>
<pre><code>Complexity: 25, Coverage: 95%, Risk: LOW
</code></pre>
<p>This is actually good! Complex but thoroughly tested code. Learn from this approach.</p>
<p><strong>Pattern 2: Moderate Complexity, No Tests</strong></p>
<pre><code>Complexity: 12, Coverage: 0%, Risk: CRITICAL
</code></pre>
<p>Highest priority - manageable complexity, should be easy to test.</p>
<p><strong>Pattern 3: Low Complexity, No Tests</strong></p>
<pre><code>Complexity: 3, Coverage: 0%, Risk: LOW
</code></pre>
<p>Low priority - simple code, less risky without tests.</p>
<p><strong>Pattern 4: Repetitive High Complexity (Dampened)</strong></p>
<pre><code>Cyclomatic: 20, Effective: 7 (65% dampened), Risk: LOW
</code></pre>
<p>Validation or dispatch pattern - looks complex but is repetitive. Lower priority.</p>
<p><strong>Pattern 5: God Object</strong></p>
<pre><code>File: services.rs, Functions: 50+, Responsibilities: 15+
</code></pre>
<p>Architectural issue - split before adding features.</p>
<h2 id="analyzer-types"><a class="header" href="#analyzer-types">Analyzer Types</a></h2>
<p>Debtmap supports multiple programming languages with varying levels of analysis capability.</p>
<h3 id="supported-languages"><a class="header" href="#supported-languages">Supported Languages</a></h3>
<p><strong>Rust</strong> (Full Support)</p>
<ul>
<li><strong>Parser</strong>: syn (native Rust AST)</li>
<li><strong>Capabilities</strong>:
<ul>
<li>Full complexity metrics (cyclomatic, cognitive, entropy)</li>
<li>Trait implementation tracking</li>
<li>Purity detection with confidence scoring</li>
<li>Call graph analysis (upstream callers, downstream callees)</li>
<li>Semantic function classification (entry points, business logic, data access, infrastructure, utilities, test code)</li>
<li>Enhanced call graph with transitive relationships</li>
<li>Macro expansion support for accurate complexity analysis</li>
<li>Pattern-based adjustments for macros and code generation</li>
<li>Visibility tracking (pub, pub(crate), private)</li>
<li>Test module detection (#[cfg(test)])</li>
</ul>
</li>
</ul>
<p><strong>Semantic Classification:</strong></p>
<p>Debtmap automatically identifies function roles in Rust code to apply appropriate role multipliers in unified scoring:</p>
<ul>
<li><strong>Entry Points</strong>: Functions named <code>main</code>, <code>start</code>, or public functions in <code>bin/</code> modules</li>
<li><strong>Business Logic</strong>: Core domain functions with complex logic, algorithms, business rules</li>
<li><strong>Data Access</strong>: Functions performing database queries, file I/O, network operations</li>
<li><strong>Infrastructure</strong>: Logging, configuration, monitoring, error handling utilities</li>
<li><strong>Utilities</strong>: Helper functions, formatters, type converters, validation functions</li>
<li><strong>Test Code</strong>: Functions in <code>#[cfg(test)]</code> modules, functions with <code>#[test]</code> attribute</li>
</ul>
<p>This classification feeds directly into the unified scoring system‚Äôs role multiplier (see Risk Scoring section).</p>
<p><strong>Python</strong> (Partial Support)</p>
<ul>
<li><strong>Parser</strong>: rustpython-parser</li>
<li><strong>Capabilities</strong>:
<ul>
<li>Complexity metrics (cyclomatic, cognitive)</li>
<li>Python-specific error handling patterns</li>
<li>Purity detection for pure functions</li>
<li>Basic debt pattern detection</li>
<li>Limited call graph support</li>
</ul>
</li>
</ul>
<p><strong>JavaScript</strong> (Partial Support)</p>
<ul>
<li><strong>Parser</strong>: tree-sitter (JavaScript grammar)</li>
<li><strong>File extensions</strong>: .js, .jsx, .mjs, .cjs</li>
<li><strong>Capabilities</strong>:
<ul>
<li>ECMAScript complexity patterns</li>
<li>Basic complexity metrics</li>
<li>Function extraction</li>
<li>Limited pattern detection</li>
</ul>
</li>
</ul>
<p><strong>TypeScript</strong> (Partial Support)</p>
<ul>
<li><strong>Parser</strong>: tree-sitter (TypeScript grammar)</li>
<li><strong>File extensions</strong>: .ts, .tsx, .mts, .cts</li>
<li><strong>Capabilities</strong>:
<ul>
<li>Similar to JavaScript support</li>
<li>Type information currently not utilized</li>
<li>Basic complexity metrics</li>
<li>Limited pattern detection</li>
</ul>
</li>
</ul>
<p><strong>Unsupported Languages:</strong></p>
<p>Debtmap‚Äôs <code>Language</code> enum contains only the four supported languages: Rust, Python, JavaScript, and TypeScript. Files with unsupported extensions are filtered out during the file discovery phase and never reach the analysis stage.</p>
<p>Files with extensions like <code>.cpp</code> (C++), <code>.java</code>, <code>.go</code>, <code>.rb</code> (Ruby), <code>.php</code>, <code>.cs</code> (C#), <code>.swift</code>, <code>.kt</code> (Kotlin), <code>.scala</code>, and others are silently filtered during discovery.</p>
<p><strong>File filtering behavior:</strong></p>
<ul>
<li>Discovery scans project for files matching supported extensions</li>
<li>Unsupported files are skipped silently (no warnings or errors)</li>
<li>No analysis, metrics, or debt patterns are generated for filtered files</li>
<li>Use <code>--languages</code> flag to explicitly control which languages to analyze</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-bash"># Only analyze Rust files (skip Python/JS/TS)
debtmap analyze . --languages rust

# Analyze Rust and Python only
debtmap analyze . --languages rust,python
</code></pre>
<h3 id="language-detection"><a class="header" href="#language-detection">Language Detection</a></h3>
<p>Automatic detection by file extension:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let language = Language::from_path(&amp;path);
<span class="boring">}</span></code></pre></pre>
<p>Explicit language selection:</p>
<pre><code class="language-bash">debtmap analyze . --languages rust,python
</code></pre>
<h3 id="extensibility"><a class="header" href="#extensibility">Extensibility</a></h3>
<p>Debtmap‚Äôs architecture allows adding new languages:</p>
<ol>
<li><strong>Implement Analyzer trait:</strong></li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Analyzer: Send + Sync {
    fn parse(&amp;self, content: &amp;str, path: PathBuf) -&gt; Result&lt;Ast&gt;;
    fn analyze(&amp;self, ast: &amp;Ast) -&gt; FileMetrics;
    fn language(&amp;self) -&gt; Language;
}
<span class="boring">}</span></code></pre></pre>
<ol start="2">
<li><strong>Register in get_analyzer():</strong></li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get_analyzer(language: Language) -&gt; Box&lt;dyn Analyzer&gt; {
    match language {
        Language::Rust =&gt; Box::new(RustAnalyzer::new()),
        Language::YourLanguage =&gt; Box::new(YourAnalyzer::new()),
        // ...
    }
}
<span class="boring">}</span></code></pre></pre>
<p>See <code>src/analyzers/rust.rs</code> for a complete implementation example.</p>
<h2 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h2>
<h3 id="purity-detection"><a class="header" href="#purity-detection">Purity Detection</a></h3>
<p>Debtmap detects pure functions - those without side effects that always return the same output for the same input.</p>
<p><strong>What makes a function pure:</strong></p>
<ul>
<li>No I/O operations (file, network, database)</li>
<li>No mutable global state</li>
<li>No random number generation</li>
<li>No system calls</li>
<li>Deterministic output</li>
</ul>
<p><strong>Purity detection is optional:</strong></p>
<ul>
<li>Both <code>is_pure</code> and <code>purity_confidence</code> are <code>Option</code> types</li>
<li>May be <code>None</code> for some functions or languages where detection is not available</li>
<li>Rust has the most comprehensive purity detection support</li>
</ul>
<p><strong>Confidence scoring (when available):</strong></p>
<ul>
<li><strong>0.9-1.0</strong>: Very confident (no side effects detected)</li>
<li><strong>0.7-0.8</strong>: Likely pure (minimal suspicious patterns)</li>
<li><strong>0.5-0.6</strong>: Uncertain (some suspicious patterns)</li>
<li><strong>0.0-0.4</strong>: Likely impure (side effects detected)</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pure: confidence = 0.95
fn calculate_total(items: &amp;[Item]) -&gt; f64 {
    items.iter().map(|i| i.price).sum()
}

// Impure: confidence = 0.1 (I/O detected)
fn save_total(items: &amp;[Item]) -&gt; Result&lt;()&gt; {
    let total = items.iter().map(|i| i.price).sum();
    write_to_file(total)  // Side effect!
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Benefits:</strong></p>
<ul>
<li>Pure functions are easier to test</li>
<li>Can be safely cached or memoized</li>
<li>Safe to parallelize</li>
<li>Easier to reason about</li>
</ul>
<h3 id="data-flow-analysis"><a class="header" href="#data-flow-analysis">Data Flow Analysis</a></h3>
<p>Debtmap builds a comprehensive <code>DataFlowGraph</code> that extends basic call graph analysis with variable dependencies, data transformations, I/O operations, and purity tracking.</p>
<h4 id="call-graph-foundation"><a class="header" href="#call-graph-foundation">Call Graph Foundation</a></h4>
<p><strong>Upstream callers</strong> - Who calls this function</p>
<ul>
<li>Indicates impact radius</li>
<li>More callers = higher impact if it breaks</li>
</ul>
<p><strong>Downstream callees</strong> - What this function calls</p>
<ul>
<li>Indicates dependencies</li>
<li>More callees = more integration testing needed</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-json">{
  "name": "process_payment",
  "upstream_callers": [
    "handle_checkout",
    "process_subscription",
    "handle_refund"
  ],
  "downstream_callees": [
    "validate_payment_method",
    "calculate_fees",
    "record_transaction",
    "send_receipt"
  ]
}
</code></pre>
<h4 id="variable-dependency-tracking"><a class="header" href="#variable-dependency-tracking">Variable Dependency Tracking</a></h4>
<p><code>DataFlowGraph</code> tracks which variables each function depends on:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DataFlowGraph {
    // Maps function_id -&gt; set of variable names used
    variable_dependencies: HashMap&lt;String, HashSet&lt;String&gt;&gt;,
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>What it tracks:</strong></p>
<ul>
<li>Local variables accessed in function body</li>
<li>Function parameters</li>
<li>Captured variables (closures)</li>
<li>Mutable vs immutable references</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Identify functions coupled through shared state</li>
<li>Detect potential side effect chains</li>
<li>Guide refactoring to reduce coupling</li>
</ul>
<p><strong>Example output:</strong></p>
<pre><code class="language-json">{
  "function": "calculate_total",
  "variable_dependencies": ["items", "tax_rate", "discount", "total"],
  "parameter_count": 3,
  "local_var_count": 1
}
</code></pre>
<h4 id="data-transformation-patterns"><a class="header" href="#data-transformation-patterns">Data Transformation Patterns</a></h4>
<p><code>DataFlowGraph</code> identifies common functional programming patterns:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum TransformationType {
    Map,        // Transform each element
    Filter,     // Select subset of elements
    Reduce,     // Aggregate to single value
    FlatMap,    // Transform and flatten
    Unknown,    // Other transformations
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Pattern detection:</strong></p>
<ul>
<li>Recognizes iterator chains (<code>.map()</code>, <code>.filter()</code>, <code>.fold()</code>)</li>
<li>Identifies functional vs imperative data flow</li>
<li>Tracks input/output variable relationships</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected as: Filter ‚Üí Map ‚Üí Reduce pattern
fn total_active_users(users: &amp;[User]) -&gt; f64 {
    users.iter()
        .filter(|u| u.active)      // Filter transformation
        .map(|u| u.balance)        // Map transformation
        .sum()                      // Reduce transformation
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Transformation metadata:</strong></p>
<pre><code class="language-json">{
  "function": "total_active_users",
  "input_vars": ["users"],
  "output_vars": ["sum_result"],
  "transformation_type": "Reduce",
  "is_functional_style": true,
  "pipeline_length": 3
}
</code></pre>
<h4 id="io-operation-detection"><a class="header" href="#io-operation-detection">I/O Operation Detection</a></h4>
<p>Tracks functions performing I/O operations for purity and performance analysis:</p>
<p><strong>I/O categories tracked:</strong></p>
<ul>
<li><strong>File I/O</strong>: <code>std::fs</code>, <code>File::open</code>, <code>read_to_string</code></li>
<li><strong>Network I/O</strong>: HTTP requests, socket operations</li>
<li><strong>Database I/O</strong>: SQL queries, ORM operations</li>
<li><strong>System calls</strong>: Process spawning, environment access</li>
<li><strong>Blocking operations</strong>: <code>thread::sleep</code>, synchronous I/O in async</li>
</ul>
<p><strong>Example detection:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected I/O operations: FileRead, FileWrite
fn save_config(config: &amp;Config, path: &amp;Path) -&gt; Result&lt;()&gt; {
    let json = serde_json::to_string(config)?;  // No I/O
    std::fs::write(path, json)?;                 // FileWrite detected
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>I/O metadata:</strong></p>
<pre><code class="language-json">{
  "function": "save_config",
  "io_operations": ["FileWrite"],
  "is_blocking": true,
  "affects_purity": true,
  "async_safe": false
}
</code></pre>
<h4 id="purity-analysis-integration"><a class="header" href="#purity-analysis-integration">Purity Analysis Integration</a></h4>
<p><code>DataFlowGraph</code> integrates with purity detection to provide comprehensive side effect analysis:</p>
<p><strong>Side effect tracking:</strong></p>
<ul>
<li>I/O operations (file, network, console)</li>
<li>Global state mutations</li>
<li>Random number generation</li>
<li>System time access</li>
<li>Non-deterministic behavior</li>
</ul>
<p><strong>Purity confidence factors:</strong></p>
<ul>
<li><strong>1.0</strong>: Pure mathematical function, no side effects</li>
<li><strong>0.8</strong>: Pure with deterministic data transformations</li>
<li><strong>0.5</strong>: Mixed - some suspicious patterns</li>
<li><strong>0.2</strong>: Likely impure - I/O detected</li>
<li><strong>0.0</strong>: Definitely impure - multiple side effects</li>
</ul>
<p><strong>Example analysis:</strong></p>
<pre><code class="language-json">{
  "function": "calculate_discount",
  "is_pure": true,
  "purity_confidence": 0.95,
  "side_effects": [],
  "deterministic": true,
  "safe_to_parallelize": true,
  "safe_to_cache": true
}
</code></pre>
<h4 id="modification-impact-analysis"><a class="header" href="#modification-impact-analysis">Modification Impact Analysis</a></h4>
<p><code>DataFlowGraph</code> calculates the impact of modifying a function:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ModificationImpact {
    pub function_name: String,
    pub affected_functions: Vec&lt;String&gt;,  // Upstream callers
    pub dependency_count: usize,          // Downstream callees
    pub has_side_effects: bool,
    pub risk_level: RiskLevel,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Risk level calculation:</strong></p>
<ul>
<li><strong>Critical</strong>: Many upstream callers + side effects + low test coverage</li>
<li><strong>High</strong>: Many callers OR side effects with moderate coverage</li>
<li><strong>Medium</strong>: Few callers with side effects OR many callers with good coverage</li>
<li><strong>Low</strong>: Few callers, no side effects, or well-tested</li>
</ul>
<p><strong>Example impact analysis:</strong></p>
<pre><code class="language-json">{
  "function": "validate_payment_method",
  "modification_impact": {
    "affected_functions": [
      "process_payment",
      "refund_payment",
      "update_payment_method",
      "validate_subscription"
    ],
    "affected_count": 4,
    "dependency_count": 8,
    "has_side_effects": true,
    "io_operations": ["DatabaseRead", "NetworkCall"],
    "risk_level": "High",
    "recommendation": "Comprehensive testing required - 4 functions depend on this, performs I/O"
  }
}
</code></pre>
<p><strong>Using modification impact:</strong></p>
<pre><code class="language-bash"># Analyze impact before refactoring
debtmap analyze . --format json | jq '.functions[] | select(.name == "validate_payment_method") | .modification_impact'
</code></pre>
<p><strong>Impact analysis uses:</strong></p>
<ul>
<li><strong>Refactoring planning</strong>: Understand blast radius before changes</li>
<li><strong>Test prioritization</strong>: Focus tests on high-impact functions</li>
<li><strong>Code review</strong>: Flag high-risk changes for extra scrutiny</li>
<li><strong>Dependency management</strong>: Identify tightly coupled components</li>
</ul>
<h4 id="dataflowgraph-methods"><a class="header" href="#dataflowgraph-methods">DataFlowGraph Methods</a></h4>
<p>Key methods for data flow analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add function with its dependencies
pub fn add_function(&amp;mut self, function_id: String, callees: Vec&lt;String&gt;)

// Track variable dependencies
pub fn add_variable_dependency(&amp;mut self, function_id: String, var_name: String)

// Record I/O operations
pub fn add_io_operation(&amp;mut self, function_id: String, io_type: IoType)

// Calculate modification impact
pub fn calculate_modification_impact(&amp;self, function_id: &amp;str) -&gt; ModificationImpact

// Get all functions affected by a change
pub fn get_affected_functions(&amp;self, function_id: &amp;str) -&gt; Vec&lt;String&gt;

// Find functions with side effects
pub fn find_functions_with_side_effects(&amp;self) -&gt; Vec&lt;String&gt;
<span class="boring">}</span></code></pre></pre>
<p><strong>Integration in analysis pipeline:</strong></p>
<ol>
<li>Parser builds initial call graph</li>
<li>DataFlowGraph extends with variable/I/O tracking</li>
<li>Purity analyzer adds side effect information</li>
<li>Modification impact calculated for each function</li>
<li>Results used in prioritization and risk scoring</li>
</ol>
<p><strong>Connection to Unified Scoring:</strong></p>
<p>The dependency analysis from DataFlowGraph directly feeds into the <strong>unified scoring system‚Äôs dependency factor</strong> (20% weight):</p>
<ul>
<li><strong>Dependency Factor Calculation</strong>: Functions with high upstream caller count or on critical paths from entry points receive higher dependency scores (8-10)</li>
<li><strong>Isolated Utilities</strong>: Functions with few or no callers score lower (1-3) on dependency factor</li>
<li><strong>Impact Prioritization</strong>: This helps prioritize functions where bugs have wider impact across the codebase</li>
<li><strong>Modification Risk</strong>: The modification impact analysis uses dependency data to calculate blast radius when changes are made</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code>Function: validate_payment_method
  Upstream callers: 4 (high impact)
  ‚Üí Dependency Factor: 8.0

Function: format_currency_string
  Upstream callers: 0 (utility)
  ‚Üí Dependency Factor: 1.5

Both have same complexity, but validate_payment_method gets higher unified score
due to its critical role in the call graph.
</code></pre>
<p>This integration ensures that the unified scoring system considers not just internal function complexity and test coverage, but also the function‚Äôs importance in the broader codebase architecture.</p>
<h3 id="entropy-based-complexity"><a class="header" href="#entropy-based-complexity">Entropy-Based Complexity</a></h3>
<p>Advanced pattern detection to reduce false positives.</p>
<p><strong>Token Classification:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum TokenType {
    Variable,     // Weight: 1.0
    Method,       // Weight: 1.5 (more important)
    Literal,      // Weight: 0.5 (less important)
    Keyword,      // Weight: 0.8
    Operator,     // Weight: 0.6
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Shannon Entropy Calculation:</strong></p>
<pre><code>H(X) = -Œ£ p(x) √ó log‚ÇÇ(p(x))
</code></pre>
<p>where p(x) is the probability of each token type.</p>
<p><strong>Dampening Decision:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if entropy_score.token_entropy &lt; 0.4
   &amp;&amp; entropy_score.pattern_repetition &gt; 0.6
   &amp;&amp; entropy_score.branch_similarity &gt; 0.7
{
    // Apply dampening
    effective_complexity = base_complexity √ó (1 - dampening_factor);
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Output explanation:</strong></p>
<pre><code>Function: validate_input
  Cyclomatic: 15 ‚Üí Effective: 5
  Reasoning:
    - High pattern repetition detected (85%)
    - Low token entropy indicates simple patterns (0.32)
    - Similar branch structures found (92% similarity)
    - Complexity reduced by 67% due to pattern-based code
</code></pre>
<h3 id="entropy-analysis-caching"><a class="header" href="#entropy-analysis-caching">Entropy Analysis Caching</a></h3>
<p><code>EntropyAnalyzer</code> includes an LRU-style cache for performance optimization when analyzing large codebases or performing repeated analysis.</p>
<h4 id="cache-structure"><a class="header" href="#cache-structure">Cache Structure</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct CacheEntry {
    score: EntropyScore,
    timestamp: Instant,
    hit_count: usize,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Cache configuration:</strong></p>
<ul>
<li><strong>Default size</strong>: 1000 entries</li>
<li><strong>Eviction policy</strong>: LRU (Least Recently Used)</li>
<li><strong>Memory per entry</strong>: ~128 bytes</li>
<li><strong>Total memory overhead</strong>: ~128 KB for default size</li>
</ul>
<h4 id="cache-statistics"><a class="header" href="#cache-statistics">Cache Statistics</a></h4>
<p>The analyzer tracks cache performance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CacheStats {
    pub hits: usize,
    pub misses: usize,
    pub evictions: usize,
    pub hit_rate: f64,
    pub memory_bytes: usize,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Example stats output:</strong></p>
<pre><code class="language-json">{
  "entropy_cache_stats": {
    "hits": 3427,
    "misses": 1573,
    "evictions": 573,
    "hit_rate": 0.685,
    "memory_bytes": 128000
  }
}
</code></pre>
<p><strong>Hit rate interpretation:</strong></p>
<ul>
<li><strong>&gt; 0.7</strong>: Excellent - many repeated analyses, cache is effective</li>
<li><strong>0.4-0.7</strong>: Good - moderate reuse, typical for incremental analysis</li>
<li><strong>&lt; 0.4</strong>: Low - mostly unique functions, cache less helpful</li>
</ul>
<h4 id="performance-benefits"><a class="header" href="#performance-benefits">Performance Benefits</a></h4>
<p><strong>Typical performance gains:</strong></p>
<ul>
<li><strong>Cold analysis</strong>: 100ms baseline (no cache benefit)</li>
<li><strong>Incremental analysis</strong>: 30-40ms (~60-70% faster) for unchanged functions</li>
<li><strong>Re-analysis</strong>: 15-20ms (~80-85% faster) for recently analyzed functions</li>
</ul>
<p><strong>Best for:</strong></p>
<ul>
<li><strong>Watch mode</strong>: Analyzing on file save (repeated analysis of same files)</li>
<li><strong>CI/CD</strong>: Comparing feature branch to main (overlap in functions)</li>
<li><strong>Large codebases</strong>: Many similar functions benefit from pattern caching</li>
</ul>
<p><strong>Memory estimation:</strong></p>
<pre><code>Total cache memory = entry_count √ó 128 bytes

Examples:
- 1,000 entries: ~128 KB (default)
- 5,000 entries: ~640 KB (large projects)
- 10,000 entries: ~1.25 MB (very large)
</code></pre>
<h4 id="cache-management"><a class="header" href="#cache-management">Cache Management</a></h4>
<p><strong>Automatic eviction:</strong></p>
<ul>
<li>When cache reaches size limit, oldest entries evicted</li>
<li>Hit count influences retention (frequently accessed stay longer)</li>
<li>Timestamp used for LRU ordering</li>
</ul>
<p><strong>Cache invalidation:</strong></p>
<ul>
<li>Function source changes invalidate entry</li>
<li>Cache cleared between major analysis runs</li>
<li>No manual invalidation needed</li>
</ul>
<p><strong>Configuration (if exposed in future):</strong></p>
<pre><code class="language-toml">[entropy.cache]
enabled = true
size = 1000           # Number of entries
ttl_seconds = 3600    # Optional: expire after 1 hour
</code></pre>
<h3 id="context-aware-analysis-2"><a class="header" href="#context-aware-analysis-2">Context-Aware Analysis</a></h3>
<p>Debtmap adjusts analysis based on code context:</p>
<p><strong>Pattern Recognition:</strong></p>
<ul>
<li>Validation patterns (repetitive checks)</li>
<li>Dispatcher patterns (routing logic)</li>
<li>Builder patterns (fluent APIs)</li>
<li>Configuration parsers (key-value processing)</li>
</ul>
<p><strong>Adjustment Strategies:</strong></p>
<ul>
<li>Reduce false positives for recognized patterns</li>
<li>Apply appropriate thresholds by pattern type</li>
<li>Consider pattern confidence in scoring</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Recognized as "validation_pattern"
// Complexity dampening applied
fn validate_user_input(input: &amp;UserInput) -&gt; Result&lt;()&gt; {
    if input.name.is_empty() { return Err(Error::EmptyName); }
    if input.email.is_empty() { return Err(Error::EmptyEmail); }
    if input.age &lt; 13 { return Err(Error::TooYoung); }
    // ... more similar validations
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="coverage-integration"><a class="header" href="#coverage-integration">Coverage Integration</a></h3>
<p>Debtmap parses LCOV coverage data for risk analysis:</p>
<p><strong>LCOV Support:</strong></p>
<ul>
<li>Standard format from most coverage tools</li>
<li>Line-level coverage tracking</li>
<li>Function-level aggregation</li>
</ul>
<p><strong>Coverage Index:</strong></p>
<ul>
<li>O(1) exact name lookups (~0.5Œºs)</li>
<li>O(log n) line-based fallback (~5-8Œºs)</li>
<li>~200 bytes per function</li>
<li>Thread-safe (Arc<CoverageIndex>)</li>
</ul>
<h4 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h4>
<p><strong>Index Build Performance:</strong></p>
<ul>
<li>Index construction: O(n), approximately 20-30ms for 5,000 functions</li>
<li>Memory usage: ~200 bytes per record (~2MB for 5,000 functions)</li>
<li>Scales linearly with function count</li>
</ul>
<p><strong>Lookup Performance:</strong></p>
<ul>
<li>Exact match (function name): O(1) average, ~0.5Œºs per lookup</li>
<li>Line-based fallback: O(log n), ~5-8Œºs per lookup</li>
<li>Cache-friendly data structure for hot paths</li>
</ul>
<p><strong>Analysis Overhead:</strong></p>
<ul>
<li>Coverage integration overhead: ~2.5x baseline analysis time</li>
<li>Target overhead: ‚â§3x (maintained through optimizations)</li>
<li>Example timing: 53ms baseline ‚Üí 130ms with coverage (2.45x overhead)</li>
<li>Overhead includes index build + lookups + coverage propagation</li>
</ul>
<p><strong>When to use coverage integration:</strong></p>
<ul>
<li><strong>Skip coverage</strong> (faster iteration): For rapid development iteration or quick local checks, omit <code>--lcov</code> to get baseline results 2.5x faster</li>
<li><strong>Include coverage</strong> (comprehensive analysis): Use coverage integration for final validation, sprint planning, and CI/CD gates where comprehensive risk analysis is needed</li>
</ul>
<p><strong>Thread Safety:</strong></p>
<ul>
<li>Coverage index wrapped in <code>Arc&lt;CoverageIndex&gt;</code> for lock-free parallel access</li>
<li>Multiple analyzer threads can query coverage simultaneously</li>
<li>No contention on reads, suitable for parallel analysis pipelines</li>
</ul>
<p><strong>Memory Footprint:</strong></p>
<pre><code>Total memory = (function_count √ó 200 bytes) + index overhead

Examples:
- 1,000 functions: ~200 KB
- 5,000 functions: ~2 MB
- 10,000 functions: ~4 MB
</code></pre>
<p><strong>Scalability:</strong></p>
<ul>
<li>Tested with codebases up to 10,000 functions</li>
<li>Performance remains predictable and acceptable</li>
<li>Memory usage stays bounded and reasonable</li>
</ul>
<p><strong>Generating coverage:</strong></p>
<pre><code class="language-bash"># Rust
cargo tarpaulin --out lcov --output-dir target/coverage

# Python
pytest --cov --cov-report=lcov

# JavaScript/TypeScript
jest --coverage --coverageReporters=lcov

# Go
go test -coverprofile=coverage.out
gocover-cobertura &lt; coverage.out &gt; coverage.lcov
</code></pre>
<p><strong>Using with Debtmap:</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<p><strong>Coverage dampening:</strong>
When coverage data is provided, debt scores are dampened for well-tested code:</p>
<pre><code>final_score = base_score √ó (1 - coverage_percentage)
</code></pre>
<p>This ensures well-tested complex code gets lower priority than untested simple code.</p>
<h2 id="example-outputs"><a class="header" href="#example-outputs">Example Outputs</a></h2>
<h3 id="high-complexity-function-needs-refactoring"><a class="header" href="#high-complexity-function-needs-refactoring">High Complexity Function (Needs Refactoring)</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>#1 SCORE: 9.2 [CRITICAL]
‚îú‚îÄ COMPLEXITY: ./src/payments/processor.rs:145 process_transaction()
‚îú‚îÄ ACTION: Refactor into 4 smaller functions
‚îú‚îÄ IMPACT: Reduce complexity from 25 to 8, improve testability
‚îú‚îÄ COMPLEXITY: cyclomatic=25, branches=25, cognitive=38, nesting=5, lines=120
‚îú‚îÄ DEPENDENCIES: 3 upstream, 8 downstream
‚îî‚îÄ WHY: Exceeds all complexity thresholds, difficult to test and maintain
</code></pre>
<p><strong>JSON Output:</strong></p>
<pre><code class="language-json">{
  "id": "complexity_src_payments_processor_rs_145",
  "debt_type": "Complexity",
  "priority": "Critical",
  "file": "src/payments/processor.rs",
  "line": 145,
  "message": "Function exceeds complexity threshold",
  "context": "Cyclomatic: 25, Cognitive: 38, Nesting: 5",
  "function_metrics": {
    "name": "process_transaction",
    "cyclomatic": 25,
    "cognitive": 38,
    "nesting": 5,
    "length": 120,
    "is_pure": false,
    "purity_confidence": 0.15,
    "upstream_callers": ["handle_payment", "handle_subscription", "handle_refund"],
    "downstream_callees": ["validate", "calculate_fees", "record_transaction", "send_receipt", "update_balance", "log_transaction", "check_fraud", "notify_user"]
  }
}
</code></pre>
<h3 id="well-tested-complex-function-good-example"><a class="header" href="#well-tested-complex-function-good-example">Well-Tested Complex Function (Good Example)</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>Function: calculate_tax (WELL TESTED - Good Example!)
  File: src/tax/calculator.rs:78
  Complexity: Cyclomatic=18, Cognitive=22
  Coverage: 98%
  Risk: LOW

  Why this is good:
  - High complexity is necessary (tax rules are complex)
  - Thoroughly tested with 45 test cases
  - Clear documentation of edge cases
  - Good example to follow for other complex logic
</code></pre>
<h3 id="test-gap-needs-testing"><a class="header" href="#test-gap-needs-testing">Test Gap (Needs Testing)</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>#2 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/analyzers/rust_call_graph.rs:38 add_function_to_graph()
‚îú‚îÄ ACTION: Add 6 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk reduction
‚îú‚îÄ COMPLEXITY: cyclomatic=6, branches=6, cognitive=8, nesting=2, lines=32
‚îú‚îÄ DEPENDENCIES: 0 upstream, 11 downstream
‚îú‚îÄ TEST EFFORT: Simple (2-3 hours)
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=6, cog=8)
    High impact - 11 functions depend on this
</code></pre>
<p><strong>JSON Output:</strong></p>
<pre><code class="language-json">{
  "function": "add_function_to_graph",
  "file": "src/analyzers/rust_call_graph.rs",
  "line": 38,
  "current_risk": 8.9,
  "potential_risk_reduction": 3.7,
  "recommendation": {
    "action": "Add unit tests",
    "details": "Add 6 unit tests for full coverage",
    "effort_estimate": "2-3 hours"
  },
  "test_effort": {
    "estimated_difficulty": "Simple",
    "cognitive_load": 8,
    "branch_count": 6,
    "recommended_test_cases": 6
  },
  "complexity": {
    "cyclomatic": 6,
    "cognitive": 8,
    "nesting": 2,
    "length": 32
  },
  "dependencies": {
    "upstream_callers": [],
    "downstream_callees": [
      "get_function_name", "extract_parameters", "parse_return_type",
      "add_to_registry", "update_call_sites", "resolve_types",
      "track_visibility", "record_location", "increment_counter",
      "validate_signature", "log_registration"
    ]
  },
  "roi": 4.5
}
</code></pre>
<h3 id="entropy-dampened-validation-function"><a class="header" href="#entropy-dampened-validation-function">Entropy-Dampened Validation Function</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>Function: validate_config
  File: src/config/validator.rs:23
  Cyclomatic: 20 ‚Üí Effective: 7 (65% dampened)
  Risk: LOW

  Entropy Analysis:
    ‚îú‚îÄ Token Entropy: 0.28 (low variety - repetitive patterns)
    ‚îú‚îÄ Pattern Repetition: 0.88 (high similarity between checks)
    ‚îú‚îÄ Branch Similarity: 0.91 (consistent validation structure)
    ‚îî‚îÄ Reasoning: Complexity reduced by 65% due to pattern-based code

  This appears complex but is actually a repetitive validation pattern.
  Lower priority for refactoring.
</code></pre>
<h3 id="beforeafter-refactoring-comparison"><a class="header" href="#beforeafter-refactoring-comparison">Before/After Refactoring Comparison</a></h3>
<p><strong>Before:</strong></p>
<pre><code>Function: process_order
  Cyclomatic: 22
  Cognitive: 35
  Coverage: 15%
  Risk Score: 52.3 (CRITICAL)
  Debt Score: 50 (Critical Complexity)
</code></pre>
<p><strong>After:</strong></p>
<pre><code>Function: process_order (refactored)
  Cyclomatic: 5
  Cognitive: 6
  Coverage: 92%
  Risk Score: 2.1 (LOW)
  Debt Score: 0 (no debt)

Extracted functions:
  - validate_order (Cyclomatic: 4, Coverage: 100%)
  - calculate_totals (Cyclomatic: 3, Coverage: 95%)
  - apply_discounts (Cyclomatic: 6, Coverage: 88%)
  - finalize_order (Cyclomatic: 4, Coverage: 90%)

Impact:
  ‚úì Complexity reduced by 77%
  ‚úì Coverage improved by 513%
  ‚úì Risk reduced by 96%
  ‚úì Created 4 focused, testable functions
</code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li><strong><a href="./output-formats.html">Output Formats</a></strong> - Detailed JSON schema and integration patterns</li>
<li><strong><a href="./configuration.html">Configuration</a></strong> - Customize thresholds and analysis behavior</li>
</ul>
<p>For questions or issues, visit <a href="https://github.com/iepathos/debtmap/issues">GitHub Issues</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="compare-analysis"><a class="header" href="#compare-analysis">Compare Analysis</a></h1>
<p>The <code>compare</code> command enables you to track technical debt changes over time by comparing two analysis results. This is essential for validating refactoring efforts, detecting regressions in pull requests, and monitoring project health trends.</p>
<h2 id="implementation-status"><a class="header" href="#implementation-status">Implementation Status</a></h2>
<p><strong>Current Implementation (Available Now)</strong>:</p>
<ul>
<li>‚úÖ Basic validation comparing before/after analyses</li>
<li>‚úÖ Resolved items tracking (debt eliminated)</li>
<li>‚úÖ Improved items detection (score reduction ‚â• 30%)</li>
<li>‚úÖ New critical items detection (regressions)</li>
<li>‚úÖ Unchanged critical items tracking</li>
<li>‚úÖ Project health summaries</li>
<li>‚úÖ JSON output format</li>
<li>‚úÖ CI/CD integration support</li>
</ul>
<p><strong>Planned Features (Coming Soon)</strong>:</p>
<ul>
<li>üöß Target location tracking with fuzzy matching</li>
<li>üöß Detailed improvement percentage calculations (per-item)</li>
<li>üöß Markdown and terminal output formats</li>
<li>üöß Implementation plan parsing for target extraction</li>
<li>üöß Match strategies (Exact, FuzzyFunction, FuzzyFile)</li>
</ul>
<p><strong>Note</strong>: This chapter documents both current and planned features. Current implementation focuses on validation workflows (resolved, improved, new critical items). Full comparison features including target tracking are under development.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>The compare command analyzes differences between ‚Äúbefore‚Äù and ‚Äúafter‚Äù debtmap analyses, providing:</p>
<ul>
<li><strong>Validation tracking</strong> - Verify debt items are resolved or improved</li>
<li><strong>Project health metrics</strong> - Track overall debt trends across your codebase</li>
<li><strong>Regression detection</strong> - Identify new critical debt items introduced (score ‚â• 8.0)</li>
<li><strong>Improvement tracking</strong> - Measure and celebrate debt reduction</li>
<li><strong>CI/CD integration</strong> - Automate quality gates in your pipeline</li>
</ul>
<h2 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h2>
<h3 id="command-syntax"><a class="header" href="#command-syntax">Command Syntax</a></h3>
<pre><code class="language-bash">debtmap compare \
  --before path/to/before.json \
  --after path/to/after.json \
  --output validation.json
</code></pre>
<h3 id="command-line-options"><a class="header" href="#command-line-options">Command-Line Options</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Required</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--before FILE</code></td><td>Yes</td><td>Path to ‚Äúbefore‚Äù analysis JSON</td></tr>
<tr><td><code>--after FILE</code></td><td>Yes</td><td>Path to ‚Äúafter‚Äù analysis JSON</td></tr>
<tr><td><code>--output FILE</code></td><td>No</td><td>Output file path (default: stdout)</td></tr>
</tbody></table>
</div>
<p><strong>Currently Available</strong>: Basic comparison with JSON output showing resolved, improved, and new critical items.</p>
<p><strong>Planned Options</strong> (not yet implemented):</p>
<ul>
<li><code>--plan FILE</code> - Implementation plan to extract target location</li>
<li><code>--target-location LOCATION</code> - Manual target location</li>
<li><code>--format FORMAT</code> - Output format (markdown, terminal)</li>
</ul>
<h2 id="target-location-tracking"><a class="header" href="#target-location-tracking">Target Location Tracking</a></h2>
<blockquote>
<p><strong>‚ö†Ô∏è Planned Feature</strong>: Target location tracking with fuzzy matching is currently under development. The types are defined in <code>src/comparison/types.rs</code> but not yet implemented in the compare command. This section describes the planned functionality.</p>
</blockquote>
<p>Target location tracking will allow you to monitor specific code locations through refactoring changes.</p>
<h3 id="location-format-planned"><a class="header" href="#location-format-planned">Location Format (Planned)</a></h3>
<p>Target locations will use the format: <code>file:function:line</code></p>
<p>Examples:</p>
<ul>
<li><code>src/main.rs:complex_function:42</code></li>
<li><code>lib/parser.rs:parse_expression:156</code></li>
<li><code>api/handler.rs:process_request:89</code></li>
</ul>
<h3 id="specifying-target-locations-planned"><a class="header" href="#specifying-target-locations-planned">Specifying Target Locations (Planned)</a></h3>
<h4 id="option-1-via-implementation-plan"><a class="header" href="#option-1-via-implementation-plan">Option 1: Via Implementation Plan</a></h4>
<p>Create an <code>IMPLEMENTATION_PLAN.md</code> file with a target location section:</p>
<pre><code class="language-markdown"># Implementation Plan

## Target Item
**Location**: ./src/example.rs:complex_function:45
**Current Debt Score**: 85.5
**Severity**: critical

## Problem Analysis
The `complex_function` has high cognitive complexity...

## Proposed Solution
1. Extract nested conditionals into separate functions
2. Use early returns to reduce nesting depth
3. Add comprehensive unit tests
</code></pre>
<p>Then run compare with the plan:</p>
<pre><code class="language-bash">debtmap compare --before before.json --after after.json --plan IMPLEMENTATION_PLAN.md
</code></pre>
<h4 id="option-2-manual-target-location"><a class="header" href="#option-2-manual-target-location">Option 2: Manual Target Location</a></h4>
<p>Specify the target directly via command-line:</p>
<pre><code class="language-bash">debtmap compare \
  --before before.json \
  --after after.json \
  --target-location "src/example.rs:complex_function:45"
</code></pre>
<h3 id="matching-strategies-planned"><a class="header" href="#matching-strategies-planned">Matching Strategies (Planned)</a></h3>
<p>Debtmap will use intelligent matching to find your target item even when code changes:</p>
<div class="table-wrapper"><table><thead><tr><th>Strategy</th><th>When Used</th><th>Confidence</th></tr></thead><tbody>
<tr><td><strong>Exact</strong></td><td>Location matches exactly</td><td>1.0</td></tr>
<tr><td><strong>FuzzyFunction</strong></td><td>Function moved but name unchanged</td><td>0.8 - 0.95</td></tr>
<tr><td><strong>FuzzyFile</strong></td><td>File changed but function exists</td><td>0.6 - 0.8</td></tr>
</tbody></table>
</div>
<p>The comparison result will include the match strategy and confidence score used.</p>
<h3 id="target-status-values-planned"><a class="header" href="#target-status-values-planned">Target Status Values (Planned)</a></h3>
<p>After comparing, the target item will have one of these statuses:</p>
<ul>
<li><strong>Resolved</strong> - Item no longer exists in after analysis (debt eliminated!)</li>
<li><strong>Improved</strong> - Item exists but with lower debt score</li>
<li><strong>Unchanged</strong> - Item exists with similar metrics (within 5%)</li>
<li><strong>Regressed</strong> - Item exists but got worse</li>
<li><strong>NotFoundBefore</strong> - Item didn‚Äôt exist in before analysis</li>
<li><strong>NotFound</strong> - Item not found in either analysis</li>
</ul>
<h2 id="project-health-metrics"><a class="header" href="#project-health-metrics">Project Health Metrics</a></h2>
<p>The compare command tracks project-wide health metrics to show overall trends.</p>
<h3 id="tracked-metrics"><a class="header" href="#tracked-metrics">Tracked Metrics</a></h3>
<pre><code class="language-json">{
  "project_health": {
    "before": {
      "total_debt_score": 450.5,
      "total_items": 25,
      "critical_items": 5,
      "high_priority_items": 12,
      "average_score": 18.02
    },
    "after": {
      "total_debt_score": 380.2,
      "total_items": 22,
      "critical_items": 3,
      "high_priority_items": 10,
      "average_score": 17.28
    },
    "changes": {
      "debt_score_change": -70.3,
      "debt_score_change_pct": -15.6,
      "items_change": -3,
      "critical_items_change": -2
    }
  }
}
</code></pre>
<h3 id="understanding-metrics"><a class="header" href="#understanding-metrics">Understanding Metrics</a></h3>
<ul>
<li><strong>total_debt_score</strong> - Sum of all debt item scores</li>
<li><strong>total_items</strong> - Total number of debt items detected</li>
<li><strong>critical_items</strong> - Items with score ‚â• 8.0 (critical threshold)</li>
<li><strong>high_priority_items</strong> - Items requiring attention</li>
<li><strong>average_score</strong> - Mean debt score across all items</li>
<li><strong>debt_score_change</strong> - Absolute change in total debt</li>
<li><strong>debt_score_change_pct</strong> - Percentage change in total debt</li>
</ul>
<h3 id="debt-trends"><a class="header" href="#debt-trends">Debt Trends</a></h3>
<p>The comparison calculates an overall debt trend based on the percentage change:</p>
<ul>
<li><strong>Improving</strong> - Debt decreased by more than 5%</li>
<li><strong>Stable</strong> - Debt changed by less than 5% (within normal variance)</li>
<li><strong>Regressing</strong> - Debt increased by more than 5%</li>
</ul>
<h2 id="regression-detection"><a class="header" href="#regression-detection">Regression Detection</a></h2>
<p>Regressions are new critical debt items (score ‚â• 8.0) that appear in the after analysis.</p>
<h3 id="what-counts-as-a-regression"><a class="header" href="#what-counts-as-a-regression">What Counts as a Regression</a></h3>
<p>A regression is detected when:</p>
<ol>
<li>An item exists in the after analysis</li>
<li>The item does NOT exist in the before analysis</li>
<li>The item has a debt score ‚â• 8.0 (critical severity threshold)</li>
</ol>
<h3 id="regression-output"><a class="header" href="#regression-output">Regression Output</a></h3>
<blockquote>
<p><strong>Note</strong>: Current implementation tracks new critical items. Full regression details (debt_type, description) are planned for future releases.</p>
</blockquote>
<p><strong>Current Output Structure</strong> (ValidationResult):</p>
<pre><code class="language-json">{
  "gaps": {
    "new_critical_item_1": {
      "description": "New critical debt item detected",
      "location": "src/new_feature.rs:process_data",
      "severity": "critical",
      "suggested_fix": "...",
      "current_score": 9.5
    }
  },
  "remaining_issues": [
    "New critical item: src/new_feature.rs:process_data (score: 9.5)"
  ]
}
</code></pre>
<p><strong>Planned Output Structure</strong> (ComparisonResult):</p>
<pre><code class="language-json">{
  "regressions": [
    {
      "location": "src/new_feature.rs:process_data:23",
      "score": 9.5,
      "debt_type": "high_complexity",
      "description": "Function has cyclomatic complexity of 12 and cognitive complexity of 15"
    }
  ]
}
</code></pre>
<h3 id="using-regressions-in-cicd"><a class="header" href="#using-regressions-in-cicd">Using Regressions in CI/CD</a></h3>
<p>Fail your CI build if regressions are detected:</p>
<pre><code class="language-bash"># Run comparison
debtmap compare --before before.json --after after.json --output result.json

# Check completion status (current implementation)
STATUS=$(jq -r '.status' result.json)
COMPLETION=$(jq '.completion_percentage' result.json)

if [ "$STATUS" = "regression_detected" ]; then
  echo "‚ùå Regression detected - new critical debt items found"
  exit 1
fi

# Or check for remaining critical issues
REMAINING=$(jq '.remaining_issues | length' result.json)
if [ "$REMAINING" -gt 0 ]; then
  echo "‚ö†Ô∏è Warning: $REMAINING remaining issues"
  jq '.remaining_issues[]' result.json
fi
</code></pre>
<h2 id="improvement-tracking"><a class="header" href="#improvement-tracking">Improvement Tracking</a></h2>
<p>Debtmap tracks two types of improvements:</p>
<h3 id="improvement-types"><a class="header" href="#improvement-types">Improvement Types</a></h3>
<ol>
<li><strong>Resolved</strong> - Debt item completely eliminated (no longer in after analysis)</li>
<li><strong>Improved</strong> - Debt item still exists but score reduced by ‚â• 30%</li>
</ol>
<h3 id="current-implementation"><a class="header" href="#current-implementation">Current Implementation</a></h3>
<p>The current implementation provides improvements as human-readable strings in the ValidationResult:</p>
<pre><code class="language-json">{
  "improvements": [
    "2 high priority items resolved",
    "Average complexity reduction: 35%",
    "3 items showed improvement (score reduction ‚â• 30%)"
  ],
  "completion_percentage": 75.0,
  "status": "good_progress"
}
</code></pre>
<h3 id="planned-detailed-improvement-metrics"><a class="header" href="#planned-detailed-improvement-metrics">Planned: Detailed Improvement Metrics</a></h3>
<p>Future versions will include per-item improvement metrics:</p>
<pre><code class="language-json">{
  "improvements": {
    "score_reduction_pct": 45.2,
    "complexity_reduction_pct": 38.7,
    "coverage_improvement_pct": 25.0
  }
}
</code></pre>
<ul>
<li><strong>score_reduction_pct</strong> - Percentage reduction in overall debt score</li>
<li><strong>complexity_reduction_pct</strong> - Reduction in cyclomatic/cognitive complexity</li>
<li><strong>coverage_improvement_pct</strong> - Increase in test coverage</li>
</ul>
<h3 id="planned-improvement-items-list"><a class="header" href="#planned-improvement-items-list">Planned: Improvement Items List</a></h3>
<pre><code class="language-json">{
  "improvements": [
    {
      "location": "src/example.rs:complex_function:45",
      "before_score": 10.5,
      "after_score": 4.1,
      "improvement_type": "ScoreReduced"
    },
    {
      "location": "src/legacy.rs:old_code:120",
      "before_score": 9.0,
      "after_score": null,
      "improvement_type": "Resolved"
    }
  ]
}
</code></pre>
<h2 id="beforeafter-metrics"><a class="header" href="#beforeafter-metrics">Before/After Metrics</a></h2>
<blockquote>
<p><strong>‚ö†Ô∏è Planned Feature</strong>: Detailed target item tracking with before/after metrics is under development.</p>
</blockquote>
<h3 id="current-implementation-1"><a class="header" href="#current-implementation-1">Current Implementation</a></h3>
<p>The current implementation provides before/after summaries at the project level:</p>
<pre><code class="language-json">{
  "before_summary": {
    "total_items": 25,
    "high_priority_items": 8,
    "average_score": 6.5
  },
  "after_summary": {
    "total_items": 22,
    "high_priority_items": 5,
    "average_score": 5.2
  }
}
</code></pre>
<h3 id="planned-target-metrics-structure"><a class="header" href="#planned-target-metrics-structure">Planned: Target Metrics Structure</a></h3>
<p>Future versions will support detailed target item comparison:</p>
<pre><code class="language-json">{
  "target_item": {
    "location": "src/example.rs:complex_function:45",
    "match_strategy": "Exact",
    "match_confidence": 1.0,
    "matched_items_count": 1,
    "before": {
      "score": 10.5,
      "cyclomatic_complexity": 8,
      "cognitive_complexity": 15,
      "coverage": 45.0,
      "function_length": 120,
      "nesting_depth": 4
    },
    "after": {
      "score": 4.1,
      "cyclomatic_complexity": 3,
      "cognitive_complexity": 5,
      "coverage": 85.0,
      "function_length": 45,
      "nesting_depth": 2
    },
    "improvements": {
      "score_reduction_pct": 62.5,
      "complexity_reduction_pct": 66.7,
      "coverage_improvement_pct": 88.9
    },
    "status": "Improved"
  }
}
</code></pre>
<h3 id="planned-metric-aggregation"><a class="header" href="#planned-metric-aggregation">Planned: Metric Aggregation</a></h3>
<p>When multiple items match the target location (due to fuzzy matching), metrics will be aggregated:</p>
<ul>
<li><strong>score</strong> - Average across matched items</li>
<li><strong>cyclomatic_complexity</strong> - Average</li>
<li><strong>cognitive_complexity</strong> - Average</li>
<li><strong>coverage</strong> - Average</li>
<li><strong>function_length</strong> - Average</li>
<li><strong>nesting_depth</strong> - Maximum (worst case)</li>
</ul>
<p>The <code>matched_items_count</code> field will tell you how many items were aggregated.</p>
<h3 id="validating-refactoring-success"><a class="header" href="#validating-refactoring-success">Validating Refactoring Success</a></h3>
<p>Use the current validation output to verify your refactoring:</p>
<pre><code class="language-bash"># Check validation completion
COMPLETION=$(jq '.completion_percentage' result.json)
STATUS=$(jq -r '.status' result.json)

echo "Completion: ${COMPLETION}%"
echo "Status: $STATUS"

# Check for improvements
jq '.improvements[]' result.json

# Verify no regressions
REMAINING=$(jq '.remaining_issues | length' result.json)
if [ "$REMAINING" -eq 0 ]; then
  echo "‚úÖ All issues resolved!"
else
  echo "‚ö†Ô∏è $REMAINING issues remaining"
fi
</code></pre>
<h2 id="output-formats-1"><a class="header" href="#output-formats-1">Output Formats</a></h2>
<h3 id="json-format-current"><a class="header" href="#json-format-current">JSON Format (Current)</a></h3>
<p>The current JSON format provides validation results:</p>
<pre><code class="language-bash">debtmap compare --before before.json --after after.json --output result.json
</code></pre>
<p>The ValidationResult JSON output includes:</p>
<ul>
<li><code>completion_percentage</code> - Percentage of debt resolved/improved</li>
<li><code>status</code> - Overall status (good_progress, regression_detected, etc.)</li>
<li><code>improvements</code> - List of improvement descriptions</li>
<li><code>remaining_issues</code> - List of issues still present</li>
<li><code>gaps</code> - Detailed gap analysis with locations and scores</li>
<li><code>before_summary</code> - Summary of before analysis</li>
<li><code>after_summary</code> - Summary of after analysis</li>
</ul>
<p>Example output:</p>
<pre><code class="language-json">{
  "completion_percentage": 75.0,
  "status": "good_progress",
  "improvements": [
    "2 high priority items resolved",
    "Average complexity reduction: 35%"
  ],
  "remaining_issues": [
    "1 unchanged critical item: src/legacy.rs:old_function"
  ],
  "gaps": {},
  "before_summary": {
    "total_items": 25,
    "high_priority_items": 8,
    "average_score": 6.5
  },
  "after_summary": {
    "total_items": 22,
    "high_priority_items": 5,
    "average_score": 5.2
  }
}
</code></pre>
<h3 id="markdown-format-planned"><a class="header" href="#markdown-format-planned">Markdown Format (Planned)</a></h3>
<blockquote>
<p><strong>üöß Coming Soon</strong>: Markdown output format for human-readable reports.</p>
</blockquote>
<p>Planned for pull request comments and documentation:</p>
<pre><code class="language-bash">debtmap compare --before before.json --after after.json --format markdown
</code></pre>
<p>The markdown output will be suitable for:</p>
<ul>
<li>Pull request comments</li>
<li>Documentation</li>
<li>Email reports</li>
<li>Team dashboards</li>
</ul>
<h2 id="cicd-integration-1"><a class="header" href="#cicd-integration-1">CI/CD Integration</a></h2>
<h3 id="github-actions-example"><a class="header" href="#github-actions-example">GitHub Actions Example</a></h3>
<pre><code class="language-yaml">name: Technical Debt Check

on: [pull_request]

jobs:
  debt-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Need history for before/after

      - name: Install debtmap
        run: cargo install debtmap

      - name: Analyze main branch
        run: |
          git checkout main
          debtmap analyze --output before.json

      - name: Analyze PR branch
        run: |
          git checkout ${{ github.head_ref }}
          debtmap analyze --output after.json

      - name: Compare analyses
        run: |
          debtmap compare \
            --before before.json \
            --after after.json \
            --output validation.json

      - name: Check validation result
        run: |
          STATUS=$(jq -r '.status' validation.json)
          COMPLETION=$(jq '.completion_percentage' validation.json)

          echo "Validation Status: $STATUS"
          echo "Completion: ${COMPLETION}%"

          # Fail on regression
          if [ "$STATUS" = "regression_detected" ]; then
            echo "‚ùå Regression detected"
            jq '.remaining_issues[]' validation.json
            exit 1
          fi

          # Warn on incomplete
          if (( $(echo "$COMPLETION &lt; 50" | bc -l) )); then
            echo "‚ö†Ô∏è Warning: Only ${COMPLETION}% complete"
          fi

      - name: Post validation to PR
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const validation = JSON.parse(fs.readFileSync('validation.json', 'utf8'));

            const body = `## Debt Validation Results

            **Status:** ${validation.status}
            **Completion:** ${validation.completion_percentage}%

            ### Improvements
            ${validation.improvements.map(i =&gt; `- ${i}`).join('\n')}

            ${validation.remaining_issues.length &gt; 0 ? `
            ### Remaining Issues
            ${validation.remaining_issues.map(i =&gt; `- ${i}`).join('\n')}
            ` : ''}`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
</code></pre>
<h3 id="gitlab-ci-example"><a class="header" href="#gitlab-ci-example">GitLab CI Example</a></h3>
<pre><code class="language-yaml">debt_check:
  stage: test
  script:
    # Analyze main branch
    - git fetch origin main
    - git checkout origin/main
    - debtmap analyze --output before.json

    # Analyze current branch
    - git checkout $CI_COMMIT_SHA
    - debtmap analyze --output after.json

    # Compare and check status
    - debtmap compare --before before.json --after after.json --output validation.json
    - |
      STATUS=$(jq -r '.status' validation.json)
      COMPLETION=$(jq '.completion_percentage' validation.json)

      echo "Status: $STATUS"
      echo "Completion: ${COMPLETION}%"

      if [ "$STATUS" = "regression_detected" ]; then
        echo "Failed: Regression detected"
        jq '.remaining_issues[]' validation.json
        exit 1
      fi
  artifacts:
    paths:
      - before.json
      - after.json
      - validation.json
    expire_in: 1 week
</code></pre>
<h3 id="best-practices-for-cicd"><a class="header" href="#best-practices-for-cicd">Best Practices for CI/CD</a></h3>
<ol>
<li><strong>Store analyses as artifacts</strong> - Keep before/after JSON for debugging</li>
<li><strong>Check status field</strong> - Use <code>status</code> to determine pass/fail</li>
<li><strong>Track completion percentage</strong> - Monitor progress toward debt resolution</li>
<li><strong>Review improvements</strong> - Celebrate and document successful refactorings</li>
<li><strong>Act on remaining issues</strong> - Create follow-up tasks for unresolved items</li>
<li><strong>Set completion thresholds</strong> - Require minimum completion percentage for merges</li>
</ol>
<h2 id="practical-examples"><a class="header" href="#practical-examples">Practical Examples</a></h2>
<h3 id="example-1-basic-comparison"><a class="header" href="#example-1-basic-comparison">Example 1: Basic Comparison</a></h3>
<p>Compare two analyses to track debt changes:</p>
<pre><code class="language-bash"># Run before analysis
debtmap analyze --output before.json

# Make changes to codebase...

# Run after analysis
debtmap analyze --output after.json

# Compare
debtmap compare --before before.json --after after.json --output validation.json

# Check results
cat validation.json | jq '.'
# Output shows: completion_percentage, status, improvements, remaining_issues
</code></pre>
<h3 id="example-2-validating-function-refactoring"><a class="header" href="#example-2-validating-function-refactoring">Example 2: Validating Function Refactoring</a></h3>
<blockquote>
<p><strong>Note</strong>: Target location tracking is planned. Current implementation validates overall improvements.</p>
</blockquote>
<p>Validate your refactoring work:</p>
<pre><code class="language-bash"># Run before analysis
debtmap analyze --output before.json

# Identify high-priority items to fix
jq '.items[] | select(.unified_score.final_score &gt;= 8.0)' before.json

# Refactor the high-priority functions...

# Run after analysis
debtmap analyze --output after.json

# Compare and validate
debtmap compare \
  --before before.json \
  --after after.json \
  --output validation.json

# Check validation results
STATUS=$(jq -r '.status' validation.json)
COMPLETION=$(jq '.completion_percentage' validation.json)

echo "Status: $STATUS"
echo "Completion: ${COMPLETION}%"

# Review improvements
jq '.improvements[]' validation.json
</code></pre>
<h3 id="example-3-detecting-pr-regressions"><a class="header" href="#example-3-detecting-pr-regressions">Example 3: Detecting PR Regressions</a></h3>
<p>Check if a pull request introduces new critical debt:</p>
<pre><code class="language-bash"># Analyze base branch
git checkout main
debtmap analyze --output main.json

# Analyze PR branch
git checkout feature/new-feature
debtmap analyze --output feature.json

# Compare
debtmap compare \
  --before main.json \
  --after feature.json \
  --output validation.json

# Check status
STATUS=$(jq -r '.status' validation.json)
echo "Validation Status: $STATUS"

# Example output structure:
jq '.' validation.json
# {
#   "completion_percentage": 100.0,
#   "status": "all_resolved",  // or "regression_detected"
#   "improvements": ["All items resolved"],
#   "remaining_issues": [],
#   "gaps": {},
#   "before_summary": {...},
#   "after_summary": {...}
# }
</code></pre>
<h3 id="example-4-monitoring-project-health-over-releases"><a class="header" href="#example-4-monitoring-project-health-over-releases">Example 4: Monitoring Project Health Over Releases</a></h3>
<p>Track overall project health across releases:</p>
<pre><code class="language-bash"># Analyze release v1.0
git checkout v1.0
debtmap analyze --output v1.0.json

# Analyze release v1.1
git checkout v1.1
debtmap analyze --output v1.1.json

# Compare
debtmap compare \
  --before v1.0.json \
  --after v1.1.json \
  --output v1.0-to-v1.1.json

# Check summaries
echo "Before (v1.0):"
jq '.before_summary' v1.0-to-v1.1.json

echo "After (v1.1):"
jq '.after_summary' v1.0-to-v1.1.json

# Calculate improvement
BEFORE_AVG=$(jq '.before_summary.average_score' v1.0-to-v1.1.json)
AFTER_AVG=$(jq '.after_summary.average_score' v1.0-to-v1.1.json)
echo "Average score change: $BEFORE_AVG ‚Üí $AFTER_AVG"
</code></pre>
<h3 id="example-5-full-cicd-workflow"><a class="header" href="#example-5-full-cicd-workflow">Example 5: Full CI/CD Workflow</a></h3>
<p>Complete workflow for continuous debt monitoring:</p>
<pre><code class="language-bash">#!/bin/bash
# ci-debt-check.sh

set -e

BEFORE="before.json"
AFTER="after.json"
VALIDATION="validation.json"

# Step 1: Analyze baseline (main branch)
echo "üìä Analyzing baseline..."
git checkout main
debtmap analyze --output "$BEFORE"

# Step 2: Analyze current branch
echo "üìä Analyzing current branch..."
git checkout -
debtmap analyze --output "$AFTER"

# Step 3: Run validation
echo "üîç Running validation..."
debtmap compare \
  --before "$BEFORE" \
  --after "$AFTER" \
  --output "$VALIDATION"

# Step 4: Extract metrics
STATUS=$(jq -r '.status' "$VALIDATION")
COMPLETION=$(jq '.completion_percentage' "$VALIDATION")
IMPROVEMENTS=$(jq '.improvements | length' "$VALIDATION")
REMAINING=$(jq '.remaining_issues | length' "$VALIDATION")

echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "üìà Debt Validation Results"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "Status: $STATUS"
echo "Completion: ${COMPLETION}%"
echo "Improvements: $IMPROVEMENTS"
echo "Remaining Issues: $REMAINING"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

# Step 5: Quality gate
if [ "$STATUS" = "regression_detected" ]; then
  echo "‚ùå FAILED: Regression detected"
  jq '.remaining_issues[]' "$VALIDATION"
  exit 1
fi

if (( $(echo "$COMPLETION &lt; 50" | bc -l) )); then
  echo "‚ö†Ô∏è  WARNING: Completion below 50%"
  # Don't fail, just warn
fi

if [ "$STATUS" = "all_resolved" ]; then
  echo "üéâ SUCCESS: All debt items resolved!"
fi

echo "‚úÖ PASSED: No regressions detected"
</code></pre>
<h3 id="example-6-interpreting-different-status-outcomes"><a class="header" href="#example-6-interpreting-different-status-outcomes">Example 6: Interpreting Different Status Outcomes</a></h3>
<p>Understanding what each validation status means:</p>
<pre><code class="language-bash"># Run validation
debtmap compare --before before.json --after after.json --output validation.json

# Check validation status
STATUS=$(jq -r '.status' validation.json)
COMPLETION=$(jq '.completion_percentage' validation.json)

case "$STATUS" in
  "all_resolved")
    echo "üéâ Success! All debt items eliminated."
    echo "Completion: 100%"
    ;;
  "good_progress")
    echo "‚úÖ Good progress! Completion: ${COMPLETION}%"
    jq '.improvements[]' validation.json
    ;;
  "some_improvement")
    echo "‚û°Ô∏è  Some improvement detected: ${COMPLETION}%"
    echo "Remaining issues to address:"
    jq '.remaining_issues[]' validation.json
    ;;
  "regression_detected")
    echo "‚ùå Regression detected!"
    echo "New critical items or increased debt:"
    jq '.remaining_issues[]' validation.json
    ;;
  "no_change")
    echo "‚ÑπÔ∏è  No significant changes detected"
    echo "Consider refactoring high-priority items."
    ;;
esac
</code></pre>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="understanding-validation-status"><a class="header" href="#understanding-validation-status">Understanding Validation Status</a></h3>
<p><strong>Issue</strong>: Confused about what validation status means</p>
<p><strong>Solution</strong>: Check the <code>status</code> field in validation output:</p>
<ul>
<li><code>all_resolved</code> - All debt items from before analysis are resolved (100% completion)</li>
<li><code>good_progress</code> - Significant improvements made (typically &gt;70% completion)</li>
<li><code>some_improvement</code> - Some items improved but work remains (&lt;70% completion)</li>
<li><code>regression_detected</code> - New critical items detected or debt increased</li>
<li><code>no_change</code> - No significant changes in debt metrics</li>
</ul>
<p><strong>Check completion percentage</strong>:</p>
<pre><code class="language-bash">COMPLETION=$(jq '.completion_percentage' validation.json)
echo "Validation is ${COMPLETION}% complete"
</code></pre>
<h3 id="no-improvements-detected"><a class="header" href="#no-improvements-detected">No Improvements Detected</a></h3>
<p><strong>Issue</strong>: Made changes but validation shows no improvements</p>
<p><strong>Possible causes</strong>:</p>
<ol>
<li>Changes didn‚Äôt reduce debt scores by ‚â•30% (improvement threshold)</li>
<li>Refactored items had scores &lt;8.0 (not tracked as critical)</li>
<li>Changes were neutral (e.g., code moved but complexity unchanged)</li>
</ol>
<p><strong>Solution</strong>: Check the details:</p>
<pre><code class="language-bash"># Compare before/after summaries
jq '.before_summary' validation.json
jq '.after_summary' validation.json

# Look for high-priority items in before analysis
jq '.items[] | select(.unified_score.final_score &gt;= 8.0)' before.json
</code></pre>
<h3 id="json-parsing-errors"><a class="header" href="#json-parsing-errors">JSON Parsing Errors</a></h3>
<p><strong>Problem</strong>: <code>Error parsing JSON file</code></p>
<p><strong>Solutions</strong>:</p>
<ol>
<li>Verify the file is valid JSON: <code>jq . before.json</code></li>
<li>Ensure the file is a debtmap analysis output</li>
<li>Check file permissions and path</li>
<li>Regenerate the analysis if corrupted</li>
</ol>
<h3 id="understanding-validation-status-values"><a class="header" href="#understanding-validation-status-values">Understanding Validation Status Values</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Status</th><th>Meaning</th><th>Action Required</th></tr></thead><tbody>
<tr><td><code>all_resolved</code></td><td>All items eliminated</td><td>‚úÖ Celebrate! Document what worked</td></tr>
<tr><td><code>good_progress</code></td><td>Significant improvement</td><td>‚úÖ Good progress, verify remaining items</td></tr>
<tr><td><code>some_improvement</code></td><td>Partial improvement</td><td>‚ö†Ô∏è Continue refactoring remaining issues</td></tr>
<tr><td><code>regression_detected</code></td><td>New critical debt</td><td>‚ùå Investigate and fix before merging</td></tr>
<tr><td><code>no_change</code></td><td>No significant change</td><td>‚ö†Ô∏è Review approach, may need different strategy</td></tr>
</tbody></table>
</div>
<h3 id="handling-missing-files"><a class="header" href="#handling-missing-files">Handling Missing Files</a></h3>
<p><strong>Problem</strong>: <code>No such file or directory</code></p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Verify files exist
ls -la before.json after.json

# Check current directory
pwd

# Use absolute paths if needed
debtmap compare \
  --before /absolute/path/to/before.json \
  --after /absolute/path/to/after.json
</code></pre>
<h3 id="interpreting-edge-cases"><a class="header" href="#interpreting-edge-cases">Interpreting Edge Cases</a></h3>
<p><strong>Empty After Analysis</strong>:</p>
<pre><code class="language-json">{
  "summary": {
    "resolved_count": 25,
    "overall_debt_trend": "Improving"
  }
}
</code></pre>
<p>All debt items resolved - excellent work!</p>
<p><strong>Empty Before Analysis</strong>:</p>
<pre><code class="language-json">{
  "summary": {
    "new_critical_count": 15,
    "overall_debt_trend": "Regressing"
  }
}
</code></pre>
<p>New project or first analysis - establish baseline for future comparisons.</p>
<p><strong>Identical Analyses</strong>:</p>
<pre><code class="language-json">{
  "summary": {
    "overall_debt_trend": "Stable",
    "new_critical_count": 0,
    "resolved_count": 0
  }
}
</code></pre>
<p>No changes detected - either no code changes or changes were neutral to debt.</p>
<h2 id="related-documentation"><a class="header" href="#related-documentation">Related Documentation</a></h2>
<ul>
<li><a href="validation.html">Validation Command</a> - Validate implementation plans match analysis</li>
<li><a href="prodigy-integration.html">Prodigy Integration</a> - Automated refactoring workflows</li>
<li><a href="output-formats.html">Output Formats</a> - Understanding analysis JSON structure</li>
<li><a href="scoring-strategies.html">Scoring Strategies</a> - How debt scores are calculated</li>
<li><a href="ci-cd.html">CI/CD Integration</a> - Advanced pipeline configurations</li>
</ul>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>The compare command provides validation for refactoring efforts:</p>
<p><strong>Current Capabilities:</strong></p>
<ul>
<li>‚úÖ Validate debt resolution with before/after comparison</li>
<li>‚úÖ Detect regressions (new critical items with score ‚â• 8.0)</li>
<li>‚úÖ Track resolved items and improvements (‚â•30% score reduction)</li>
<li>‚úÖ Calculate completion percentage for validation workflows</li>
<li>‚úÖ Automate quality gates in CI/CD pipelines</li>
<li>‚úÖ Generate structured JSON output for programmatic use</li>
</ul>
<p><strong>Coming Soon:</strong></p>
<ul>
<li>üöß Target location tracking with fuzzy matching</li>
<li>üöß Detailed per-item improvement metrics</li>
<li>üöß Markdown and terminal output formats</li>
<li>üöß Implementation plan parsing for target extraction</li>
</ul>
<p>Use the compare command regularly to maintain visibility into your codebase‚Äôs technical health and ensure continuous improvement. The current implementation focuses on validation workflows - perfect for CI/CD integration and refactoring validation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h1>
<p>Debtmap is highly configurable through a <code>.debtmap.toml</code> file. This chapter explains how to customize Debtmap‚Äôs behavior for your project‚Äôs specific needs.</p>
<h2 id="config-files"><a class="header" href="#config-files">Config Files</a></h2>
<p>Debtmap uses <strong>TOML format</strong> for configuration files (<code>.debtmap.toml</code>). TOML provides a clear, readable syntax well-suited for configuration.</p>
<h3 id="creating-a-configuration-file"><a class="header" href="#creating-a-configuration-file">Creating a Configuration File</a></h3>
<p>Debtmap looks for a <code>.debtmap.toml</code> file in the current directory and up to 10 parent directories. To create an initial configuration:</p>
<pre><code class="language-bash">debtmap init
</code></pre>
<p>This command creates a <code>.debtmap.toml</code> file with sensible defaults.</p>
<h3 id="configuration-file-discovery"><a class="header" href="#configuration-file-discovery">Configuration File Discovery</a></h3>
<p>When you run <code>debtmap</code>, it searches for <code>.debtmap.toml</code> starting in your current directory and traversing up to 10 parent directories. The first configuration file found is used.</p>
<p>If no configuration file is found, Debtmap uses built-in defaults that work well for most projects.</p>
<h3 id="basic-example"><a class="header" href="#basic-example">Basic Example</a></h3>
<p>Here‚Äôs a minimal <code>.debtmap.toml</code> configuration:</p>
<pre><code class="language-toml">[scoring]
coverage = 0.50      # 50% weight for test coverage gaps
complexity = 0.35    # 35% weight for code complexity
dependency = 0.15    # 15% weight for dependency criticality

[thresholds]
complexity = 10
max_file_length = 500
max_function_length = 50

[languages]
enabled = ["rust", "python", "javascript", "typescript"]
</code></pre>
<h2 id="scoring-configuration"><a class="header" href="#scoring-configuration">Scoring Configuration</a></h2>
<h3 id="scoring-weights"><a class="header" href="#scoring-weights">Scoring Weights</a></h3>
<p>The <code>[scoring]</code> section controls how different factors contribute to the overall debt score. Debtmap uses a <strong>weighted sum model</strong> where weights must sum to 1.0.</p>
<pre><code class="language-toml">[scoring]
coverage = 0.50      # Weight for test coverage gaps (default: 0.50)
complexity = 0.35    # Weight for code complexity (default: 0.35)
dependency = 0.15    # Weight for dependency criticality (default: 0.15)
</code></pre>
<p><strong>Active weights</strong> (used in scoring):</p>
<ul>
<li><code>coverage</code> - Prioritizes untested code (default: 0.50)</li>
<li><code>complexity</code> - Identifies complex areas (default: 0.35)</li>
<li><code>dependency</code> - Considers impact radius (default: 0.15)</li>
</ul>
<p><strong>Unused weights</strong> (reserved for future features):</p>
<ul>
<li><code>semantic</code> - Not currently used (default: 0.00)</li>
<li><code>security</code> - Not currently used (default: 0.00)</li>
<li><code>organization</code> - Not currently used (default: 0.00)</li>
</ul>
<p><strong>Validation rules:</strong></p>
<ul>
<li>All weights must be between 0.0 and 1.0</li>
<li>Active weights (coverage + complexity + dependency) must sum to 1.0 (¬±0.001 tolerance)</li>
<li>If weights don‚Äôt sum to 1.0, they will be automatically normalized</li>
</ul>
<p><strong>Example - Prioritize complexity over coverage:</strong></p>
<pre><code class="language-toml">[scoring]
coverage = 0.30
complexity = 0.55
dependency = 0.15
</code></pre>
<h3 id="role-multipliers"><a class="header" href="#role-multipliers">Role Multipliers</a></h3>
<p>Role multipliers adjust complexity scores based on a function‚Äôs semantic role:</p>
<pre><code class="language-toml">[role_multipliers]
pure_logic = 1.2        # Prioritize pure computation (default: 1.2)
orchestrator = 0.8      # Reduce for delegation functions (default: 0.8)
io_wrapper = 0.7        # Reduce for I/O wrappers (default: 0.7)
entry_point = 0.9       # Slight reduction for main/CLI (default: 0.9)
pattern_match = 0.6     # Reduce for pattern matching (default: 0.6)
debug = 0.3             # Debug/diagnostic functions (default: 0.3)
unknown = 1.0           # No adjustment (default: 1.0)
</code></pre>
<p>These multipliers help reduce false positives by recognizing that different function types have naturally different complexity levels. The <strong>debug</strong> role has the lowest multiplier (0.3) since debug and diagnostic functions typically have low testing priority.</p>
<h3 id="role-based-scoring-configuration"><a class="header" href="#role-based-scoring-configuration">Role-Based Scoring Configuration</a></h3>
<p>DebtMap uses a two-stage role adjustment mechanism to accurately score functions based on their architectural role and testing strategy. This section explains how to configure both stages.</p>
<h4 id="stage-1-role-coverage-weights"><a class="header" href="#stage-1-role-coverage-weights">Stage 1: Role Coverage Weights</a></h4>
<p>The first stage adjusts how much coverage gaps penalize different function types. This recognizes that not all functions need the same level of unit test coverage.</p>
<p><strong>Configuration</strong> (<code>.debtmap.toml</code> under <code>[scoring.role_coverage_weights]</code>):</p>
<pre><code class="language-toml">[scoring.role_coverage_weights]
entry_point = 0.6       # Reduce coverage penalty (often integration tested)
orchestrator = 0.8      # Reduce coverage penalty (tested via higher-level tests)
pure_logic = 1.0        # Pure logic should have unit tests, no reduction (default: 1.0)
io_wrapper = 0.5        # I/O wrappers are integration tested (default: 0.5)
pattern_match = 1.0     # Standard penalty
debug = 0.3             # Debug functions have lowest coverage expectations (default: 0.3)
unknown = 1.0           # Standard penalty (default behavior)
</code></pre>
<p><strong>Rationale</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Function Role</th><th>Weight</th><th>Why This Value?</th></tr></thead><tbody>
<tr><td><strong>Entry Point</strong></td><td>0.6</td><td>CLI handlers, HTTP routes, <code>main</code> functions are integration tested, not unit tested</td></tr>
<tr><td><strong>Orchestrator</strong></td><td>0.8</td><td>Coordination functions tested via higher-level tests</td></tr>
<tr><td><strong>Pure Logic</strong></td><td>1.0</td><td>Core business logic should have unit tests (default: 1.0)</td></tr>
<tr><td><strong>I/O Wrapper</strong></td><td>0.5</td><td>File/network operations tested via integration tests (default: 0.5)</td></tr>
<tr><td><strong>Pattern Match</strong></td><td>1.0</td><td>Standard coverage expectations</td></tr>
<tr><td><strong>Debug</strong></td><td>0.3</td><td>Debug/diagnostic functions have lowest testing priority (default: 0.3)</td></tr>
<tr><td><strong>Unknown</strong></td><td>1.0</td><td>Default when role cannot be determined</td></tr>
</tbody></table>
</div>
<p><strong>Example Impact</strong>:</p>
<pre><code class="language-toml"># Emphasize pure logic testing strongly
[scoring.role_coverage_weights]
pure_logic = 1.5        # 50% higher penalty for untested logic
entry_point = 0.5       # 50% lower penalty for untested entry points
io_wrapper = 0.4        # 60% lower penalty for untested I/O

# Conservative approach (smaller adjustments)
[scoring.role_coverage_weights]
pure_logic = 1.1        # Only 10% increase
entry_point = 0.9       # Only 10% decrease
</code></pre>
<p><strong>How It Works</strong>:</p>
<p>When a function has 0% coverage:</p>
<ul>
<li><strong>Entry Point</strong> (weight 0.6): Gets 60% penalty instead of 100% penalty</li>
<li><strong>Pure Logic</strong> (weight 1.0): Gets 100% penalty (standard emphasis on testing)</li>
<li><strong>I/O Wrapper</strong> (weight 0.5): Gets 50% penalty</li>
</ul>
<p>This prevents entry points from dominating the priority list due to low unit test coverage while emphasizing the importance of testing pure business logic.</p>
<h4 id="stage-2-role-multiplier-with-clamping"><a class="header" href="#stage-2-role-multiplier-with-clamping">Stage 2: Role Multiplier with Clamping</a></h4>
<p>The second stage applies a final role-based multiplier to reflect architectural importance. This multiplier is <strong>clamped by default</strong> to prevent extreme score variations.</p>
<p><strong>Configuration</strong> (<code>.debtmap.toml</code> under <code>[scoring.role_multiplier]</code>):</p>
<pre><code class="language-toml">[scoring.role_multiplier]
clamp_min = 0.3           # Minimum multiplier (default: 0.3)
clamp_max = 1.8           # Maximum multiplier (default: 1.8)
enable_clamping = true    # Enable clamping (default: true)
</code></pre>
<p><strong>Parameters</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>clamp_min</code></td><td>0.3</td><td>Minimum allowed multiplier - prevents functions from becoming invisible</td></tr>
<tr><td><code>clamp_max</code></td><td>1.8</td><td>Maximum allowed multiplier - prevents extreme score spikes</td></tr>
<tr><td><code>enable_clamping</code></td><td>true</td><td>Whether to apply clamping (disable for prototyping only)</td></tr>
</tbody></table>
</div>
<p><strong>Clamp Range Rationale</strong>:</p>
<p><strong>Default [0.3, 1.8]</strong>: Balances differentiation with stability</p>
<ul>
<li>
<p><strong>Lower bound (0.3)</strong>: I/O wrappers still contribute 30% of their base score</p>
<ul>
<li>Prevents them from becoming invisible in the priority list</li>
<li>Ensures simple wrappers aren‚Äôt completely ignored</li>
</ul>
</li>
<li>
<p><strong>Upper bound (1.8)</strong>: Critical functions get at most 180% of base score</p>
<ul>
<li>Prevents one complex function from dominating the entire list</li>
<li>Maintains balanced prioritization across different issues</li>
</ul>
</li>
</ul>
<p><strong>When to Adjust Clamp Range</strong>:</p>
<pre><code class="language-toml"># Wider range for more differentiation
[scoring.role_multiplier]
clamp_min = 0.2           # Allow more reduction
clamp_max = 2.5           # Allow more emphasis

# Narrower range for more stability
[scoring.role_multiplier]
clamp_min = 0.5           # Less reduction
clamp_max = 1.5           # Less emphasis

# Disable clamping (not recommended for production)
[scoring.role_multiplier]
enable_clamping = false   # Allow unclamped multipliers
# Warning: May cause unstable prioritization
</code></pre>
<p><strong>When to Disable Clamping</strong>:</p>
<ul>
<li><strong>Prototyping</strong>: Testing extreme multiplier values for custom scoring strategies</li>
<li><strong>Special cases</strong>: Very specific project needs requiring wide multiplier ranges</li>
<li><strong>Not recommended</strong> for production use as it can lead to unstable prioritization</li>
</ul>
<p><strong>Example Impact</strong>:</p>
<p>Without clamping:</p>
<pre><code>Function: critical_business_logic (Pure Logic)
  Base Score: 45.0
  Role Multiplier: 2.5 (unclamped)
  Final Score: 112.5 (dominates entire list)
</code></pre>
<p>With clamping (default):</p>
<pre><code>Function: critical_business_logic (Pure Logic)
  Base Score: 45.0
  Role Multiplier: 1.8 (clamped from 2.5)
  Final Score: 81.0 (high priority, but balanced)
</code></pre>
<h4 id="complete-example-configuration"><a class="header" href="#complete-example-configuration">Complete Example Configuration</a></h4>
<p>Here‚Äôs a complete example showing both stages configured together:</p>
<pre><code class="language-toml"># Stage 1: Coverage weight adjustments
[scoring.role_coverage_weights]
pure_logic = 1.0        # Pure logic should have unit tests (default: 1.0)
entry_point = 0.6       # Reduce penalty for integration-tested entry points
orchestrator = 0.8      # Partially reduce penalty for orchestrators
io_wrapper = 0.5        # I/O wrappers are integration tested (default: 0.5)
pattern_match = 1.0     # Standard
debug = 0.3             # Debug functions have lowest coverage expectations (default: 0.3)
unknown = 1.0           # Standard

# Stage 2: Role multiplier with clamping
[scoring.role_multiplier]
clamp_min = 0.3         # I/O wrappers contribute at least 30%
clamp_max = 1.8         # Critical functions get at most 180%
enable_clamping = true  # Keep clamping enabled for stability
</code></pre>
<h4 id="how-the-two-stages-work-together"><a class="header" href="#how-the-two-stages-work-together">How the Two Stages Work Together</a></h4>
<p>The two-stage approach ensures role-based coverage adjustments and architectural importance multipliers work independently:</p>
<p><strong>Example Workflow</strong>:</p>
<pre><code>1. Calculate base score from complexity (10) and dependencies (5)
   ‚Üí Base = 15.0

2. Stage 1: Apply coverage weight based on role (Entry Point, weight 0.6)
   ‚Üí Coverage penalty reduced from 1.0 to 0.4
   ‚Üí Preliminary score = 15.0 √ó 0.4 = 6.0

3. Stage 2: Apply clamped role multiplier (Entry Point, multiplier 1.2)
   ‚Üí Clamped to [0.3, 1.8] ‚Üí stays 1.2
   ‚Üí Final score = 6.0 √ó 1.2 = 7.2
</code></pre>
<p><strong>Key Benefits</strong>:</p>
<ul>
<li>Coverage adjustments don‚Äôt interfere with role multiplier</li>
<li>Both mechanisms contribute independently to final score</li>
<li>Clamping prevents instability from extreme values</li>
<li>Configuration flexibility for different project needs</li>
</ul>
<h4 id="verification"><a class="header" href="#verification">Verification</a></h4>
<p>To see how role-based adjustments affect your codebase:</p>
<pre><code class="language-bash"># Show detailed scoring breakdown
debtmap analyze . --verbose

# Look for lines like:
#   Coverage Weight: 0.6 (Entry Point adjustment)
#   Adjusted Coverage Penalty: 0.4 (reduced from 1.0)
#   Role Multiplier: 1.2 (clamped from 1.5)
</code></pre>
<p>For more details on how role-based adjustments reduce false positives, see the <a href="./scoring-strategies.html#role-based-adjustments">Role-Based Adjustments</a> section in the Scoring Strategies guide.</p>
<h2 id="thresholds-configuration"><a class="header" href="#thresholds-configuration">Thresholds Configuration</a></h2>
<h3 id="basic-thresholds"><a class="header" href="#basic-thresholds">Basic Thresholds</a></h3>
<p>Control when code is flagged as technical debt:</p>
<pre><code class="language-toml">[thresholds]
complexity = 10                      # Cyclomatic complexity threshold
duplication = 50                     # Duplication threshold
max_file_length = 500                # Maximum lines per file
max_function_length = 50             # Maximum lines per function
</code></pre>
<p><strong>Note:</strong> The TOML configuration accepts <code>max_file_length</code> (shown above), which maps to the internal struct field <code>max_file_lines</code>. Both names refer to the same setting.</p>
<h3 id="minimum-thresholds"><a class="header" href="#minimum-thresholds">Minimum Thresholds</a></h3>
<p>Filter out trivial functions that aren‚Äôt really technical debt:</p>
<pre><code class="language-toml">[thresholds]
minimum_debt_score = 2.0              # Only show items with debt score ‚â• 2.0
minimum_cyclomatic_complexity = 3     # Ignore functions with cyclomatic &lt; 3
minimum_cognitive_complexity = 5      # Ignore functions with cognitive &lt; 5
minimum_risk_score = 2.0              # Only show Risk items with score ‚â• 2.0
</code></pre>
<p>These minimum thresholds help focus on significant issues by filtering out simple functions with minor complexity.</p>
<h3 id="validation-thresholds"><a class="header" href="#validation-thresholds">Validation Thresholds</a></h3>
<p>The <code>[thresholds.validation]</code> subsection configures limits for the <code>debtmap validate</code> command:</p>
<pre><code class="language-toml">[thresholds.validation]
max_average_complexity = 10.0         # Maximum allowed average complexity (default: 10.0)
max_high_complexity_count = 100       # DEPRECATED: Use max_debt_density instead (default: 100)
max_debt_items = 2000                 # DEPRECATED: Use max_debt_density instead (default: 2000)
max_total_debt_score = 10000          # Maximum total debt score (default: 10000)
max_codebase_risk_score = 7.0         # Maximum codebase risk score (default: 7.0)
max_high_risk_functions = 50          # DEPRECATED: Use max_debt_density instead (default: 50)
min_coverage_percentage = 0.0         # Minimum required coverage % (default: 0.0)
max_debt_density = 50.0               # Maximum debt per 1000 LOC (default: 50.0)
</code></pre>
<p><strong>Deprecated Fields (v0.3.0+):</strong></p>
<p>The following validation thresholds are <strong>deprecated</strong> since v0.3.0 and will be removed in v1.0:</p>
<ul>
<li><code>max_high_complexity_count</code> - Replaced by <code>max_debt_density</code> (scale-independent)</li>
<li><code>max_debt_items</code> - Replaced by <code>max_debt_density</code> (scale-independent)</li>
<li><code>max_high_risk_functions</code> - Replaced by <code>max_debt_density</code> (scale-independent)</li>
</ul>
<p><strong>Migration:</strong> Use <code>max_debt_density</code> instead, which provides a scale-independent metric (debt per 1000 lines of code). This allows the same threshold to work across codebases of different sizes.</p>
<p>Use <code>debtmap validate</code> in CI to enforce code quality standards:</p>
<pre><code class="language-bash"># Fail build if validation thresholds are exceeded
debtmap validate
</code></pre>
<h2 id="language-configuration"><a class="header" href="#language-configuration">Language Configuration</a></h2>
<h3 id="enabling-languages"><a class="header" href="#enabling-languages">Enabling Languages</a></h3>
<p>Specify which languages to analyze:</p>
<pre><code class="language-toml">[languages]
enabled = ["rust", "python", "javascript", "typescript"]
</code></pre>
<h3 id="language-specific-features"><a class="header" href="#language-specific-features">Language-Specific Features</a></h3>
<p>Configure features for individual languages:</p>
<pre><code class="language-toml">[languages.rust]
detect_dead_code = false        # Rust: disabled by default (compiler handles it)
detect_complexity = true
detect_duplication = true

[languages.python]
detect_dead_code = true
detect_complexity = true
detect_duplication = true

[languages.javascript]
detect_dead_code = true
detect_complexity = true
detect_duplication = true

[languages.typescript]
detect_dead_code = true
detect_complexity = true
detect_duplication = true
</code></pre>
<p><strong>Note:</strong> Rust‚Äôs dead code detection is disabled by default since the Rust compiler already provides excellent unused code warnings.</p>
<h2 id="exclusion-patterns"><a class="header" href="#exclusion-patterns">Exclusion Patterns</a></h2>
<h3 id="file-and-directory-exclusion"><a class="header" href="#file-and-directory-exclusion">File and Directory Exclusion</a></h3>
<p>Use glob patterns to exclude files and directories from analysis:</p>
<pre><code class="language-toml">[ignore]
patterns = [
    "target/**",              # Rust build output
    "venv/**",                # Python virtual environment
    "node_modules/**",        # JavaScript dependencies
    "*.min.js",               # Minified files
    "benches/**",             # Benchmark code
    "tests/**/*",             # Test files
    "**/test_*.rs",           # Test files (prefix)
    "**/*_test.rs",           # Test files (suffix)
    "**/fixtures/**",         # Test fixtures
    "**/mocks/**",            # Mock implementations
    "**/stubs/**",            # Stub implementations
    "**/examples/**",         # Example code
    "**/demo/**",             # Demo code
]
</code></pre>
<p><strong>Glob pattern syntax:</strong></p>
<ul>
<li><code>*</code> - Matches any characters except <code>/</code></li>
<li><code>**</code> - Matches any characters including <code>/</code> (recursive)</li>
<li><code>?</code> - Matches a single character</li>
<li><code>[abc]</code> - Matches any character in the set</li>
</ul>
<p><strong>Note:</strong> Function-level filtering (e.g., ignoring specific function name patterns) is handled by role detection and context-aware analysis rather than explicit ignore patterns. See the Context-Aware Detection section for function-level filtering options.</p>
<h2 id="display-configuration"><a class="header" href="#display-configuration">Display Configuration</a></h2>
<p>Control how results are displayed:</p>
<pre><code class="language-toml">[display]
tiered = true           # Use tiered priority display (default: true)
items_per_tier = 5      # Show 5 items per tier (default: 5)
</code></pre>
<p>When <code>tiered = true</code>, Debtmap groups results into priority tiers (Critical, High, Medium, Low) and shows the top items from each tier.</p>
<h2 id="output-configuration"><a class="header" href="#output-configuration">Output Configuration</a></h2>
<p>Set the default output format:</p>
<pre><code class="language-toml">[output]
default_format = "terminal"    # Options: "terminal", "json", "markdown"
</code></pre>
<p><strong>Supported formats:</strong></p>
<ul>
<li><code>"terminal"</code> - Human-readable colored output for the terminal (default)</li>
<li><code>"json"</code> - Machine-readable JSON for integration with other tools</li>
<li><code>"markdown"</code> - Markdown format for documentation and reports</li>
</ul>
<p>This can be overridden with the <code>--format</code> CLI flag:</p>
<pre><code class="language-bash">debtmap analyze --format json      # JSON output
debtmap analyze --format markdown  # Markdown output
</code></pre>
<h2 id="normalization-configuration"><a class="header" href="#normalization-configuration">Normalization Configuration</a></h2>
<p>Control how raw scores are normalized to a 0-10 scale:</p>
<pre><code class="language-toml">[normalization]
linear_threshold = 10.0         # Use linear scaling below this value
logarithmic_threshold = 100.0   # Use logarithmic scaling above this value
sqrt_multiplier = 3.33          # Multiplier for square root scaling
log_multiplier = 10.0           # Multiplier for logarithmic scaling
show_raw_scores = true          # Show both raw and normalized scores
</code></pre>
<p>Normalization ensures scores are comparable across different codebases and prevents extreme outliers from dominating the results.</p>
<h2 id="advanced-configuration"><a class="header" href="#advanced-configuration">Advanced Configuration</a></h2>
<h3 id="entropy-based-complexity-scoring"><a class="header" href="#entropy-based-complexity-scoring">Entropy-Based Complexity Scoring</a></h3>
<p>Entropy analysis helps identify repetitive code patterns (like large match statements) that inflate complexity metrics:</p>
<pre><code class="language-toml">[entropy]
enabled = true                      # Enable entropy analysis (default: true)
weight = 1.0                        # Weight in complexity adjustment (default: 1.0)
min_tokens = 20                     # Minimum tokens for analysis (default: 20)
pattern_threshold = 0.7             # Pattern similarity threshold (default: 0.7)
entropy_threshold = 0.4             # Low entropy threshold (default: 0.4)
branch_threshold = 0.8              # Branch similarity threshold (default: 0.8)
use_classification = false          # Use smarter token classification (default: false)

# Maximum reductions to prevent over-correction
max_repetition_reduction = 0.20     # Max 20% reduction for repetition (default: 0.20)
max_entropy_reduction = 0.15        # Max 15% reduction for low entropy (default: 0.15)
max_branch_reduction = 0.25         # Max 25% reduction for similar branches (default: 0.25)
max_combined_reduction = 0.30       # Max 30% total reduction (default: 0.30)
</code></pre>
<p>Entropy scoring reduces false positives from functions like parsers and state machines that have high cyclomatic complexity but are actually simple and maintainable.</p>
<h3 id="god-object-detection"><a class="header" href="#god-object-detection">God Object Detection</a></h3>
<p>Configure detection of classes/structs with too many responsibilities:</p>
<pre><code class="language-toml">[god_object_detection]
enabled = true

# Rust-specific thresholds
[god_object_detection.rust]
max_methods = 20        # Maximum methods before flagging (default: 20)
max_fields = 15         # Maximum fields before flagging (default: 15)
max_traits = 5          # Maximum implemented traits
max_lines = 1000        # Maximum lines of code
max_complexity = 200    # Maximum total complexity

# Python-specific thresholds
[god_object_detection.python]
max_methods = 15
max_fields = 10
max_traits = 3
max_lines = 500
max_complexity = 150

# JavaScript-specific thresholds
[god_object_detection.javascript]
max_methods = 15
max_fields = 20         # JavaScript classes often have more properties
max_traits = 3
max_lines = 500
max_complexity = 150
</code></pre>
<p><strong>Note:</strong> Different languages have different defaults. Rust allows more methods since trait implementations add methods, while JavaScript classes should be smaller.</p>
<h3 id="context-aware-detection"><a class="header" href="#context-aware-detection">Context-Aware Detection</a></h3>
<p>Enable context-aware pattern detection to reduce false positives:</p>
<pre><code class="language-toml">[context]
enabled = false         # Opt-in (default: false)

# Custom context rules
[[context.rules]]
name = "allow_blocking_in_main"
pattern = "blocking_io"
action = "allow"
priority = 100
reason = "Main function can use blocking I/O"

[context.rules.context]
role = "main"

# Function pattern configuration
[context.function_patterns]
test_patterns = ["test_*", "bench_*"]
config_patterns = ["load_*_config", "parse_*_config"]
handler_patterns = ["handle_*", "*_handler"]
init_patterns = ["initialize_*", "setup_*"]
</code></pre>
<p>Context-aware detection adjusts severity based on where code appears (main functions, test code, configuration loaders, etc.).</p>
<h3 id="error-handling-detection"><a class="header" href="#error-handling-detection">Error Handling Detection</a></h3>
<p>Configure detection of error handling anti-patterns:</p>
<pre><code class="language-toml">[error_handling]
detect_async_errors = true          # Detect async error issues (default: true)
detect_context_loss = true          # Detect error context loss (default: true)
detect_propagation = true           # Analyze error propagation (default: true)
detect_panic_patterns = true        # Detect panic/unwrap usage (default: true)
detect_swallowing = true            # Detect swallowed errors (default: true)

# Custom error patterns
[[error_handling.custom_patterns]]
name = "custom_panic"
pattern = "my_panic_macro"
pattern_type = "macro_name"
severity = "high"
description = "Custom panic macro usage"
remediation = "Replace with Result-based error handling"

# Severity overrides
[[error_handling.severity_overrides]]
pattern = "unwrap"
context = "test"
severity = "low"        # Unwrap is acceptable in test code
</code></pre>
<h3 id="pure-mapping-pattern-detection"><a class="header" href="#pure-mapping-pattern-detection">Pure Mapping Pattern Detection</a></h3>
<p>Configure detection of pure mapping patterns to reduce false positives from exhaustive match expressions:</p>
<pre><code class="language-toml">[mapping_patterns]
enabled = true                      # Enable mapping pattern detection (default: true)
complexity_reduction = 0.30         # Reduce complexity by 30% (default: 0.30)
min_branches = 3                    # Minimum match arms to consider (default: 3)
</code></pre>
<p><strong>What are pure mapping patterns?</strong></p>
<p>Pure mapping patterns are exhaustive match expressions that transform input to output without side effects. These patterns have high cyclomatic complexity due to many branches, but are actually simple and maintainable because:</p>
<ul>
<li>Each branch is independent and straightforward</li>
<li>No mutation or side effects occur</li>
<li>The pattern is predictable and easy to understand</li>
<li>Adding new cases requires minimal changes</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn status_to_string(status: Status) -&gt; &amp;'static str {
    match status {
        Status::Success =&gt; "success",
        Status::Pending =&gt; "pending",
        Status::Failed =&gt; "failed",
        Status::Cancelled =&gt; "cancelled",
        // ... many more cases
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This function has high cyclomatic complexity (one branch per case), but is simple to maintain. Mapping pattern detection recognizes this and reduces the complexity score appropriately.</p>
<p><strong>Configuration options:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable mapping pattern detection</td></tr>
<tr><td><code>complexity_reduction</code></td><td>0.30</td><td>Percentage to reduce complexity (0.0-1.0)</td></tr>
<tr><td><code>min_branches</code></td><td>3</td><td>Minimum match arms to be considered a mapping pattern</td></tr>
</tbody></table>
</div>
<p><strong>Example configuration:</strong></p>
<pre><code class="language-toml"># Conservative reduction
[mapping_patterns]
complexity_reduction = 0.20         # Only 20% reduction

# Aggressive reduction for codebases with many mapping patterns
[mapping_patterns]
complexity_reduction = 0.50         # 50% reduction

# Disable if you want to see all match complexity
[mapping_patterns]
enabled = false
</code></pre>
<p><strong>When to adjust:</strong></p>
<ul>
<li><strong>Increase <code>complexity_reduction</code></strong> if you have many simple mapping functions being flagged as complex</li>
<li><strong>Decrease <code>complexity_reduction</code></strong> if you want more conservative adjustments</li>
<li><strong>Increase <code>min_branches</code></strong> to only apply reduction to very large match statements</li>
<li><strong>Disable entirely</strong> if you want raw complexity scores without adjustment</li>
</ul>
<h3 id="external-api-configuration"><a class="header" href="#external-api-configuration">External API Configuration</a></h3>
<p>Mark functions as public API for enhanced testing recommendations:</p>
<pre><code class="language-toml">[external_api]
detect_external_api = false         # Auto-detect public APIs (default: false)
api_functions = []                  # Explicitly mark API functions
api_files = []                      # Explicitly mark API files
</code></pre>
<p>When enabled, public API functions receive higher priority for test coverage.</p>
<h3 id="classification-configuration"><a class="header" href="#classification-configuration">Classification Configuration</a></h3>
<p>The <strong><code>[classification]</code></strong> section controls how Debtmap classifies functions by their semantic role (constructor, accessor, data flow, etc.). This classification drives role-based adjustments and reduces false positives.</p>
<pre><code class="language-toml">[classification]
# Constructor detection
[classification.constructors]
detect_constructors = true            # Enable constructor detection (default: true)
constructor_patterns = ["new", "create", "build", "from"]  # Common constructor names

# Accessor detection
[classification.accessors]
detect_accessors = true               # Enable accessor/getter detection (default: true)
accessor_patterns = ["get_*", "set_*", "is_*", "has_*"]   # Common accessor patterns

# Data flow detection
[classification.data_flow]
detect_data_flow = true               # Enable data flow analysis (default: true)
</code></pre>
<p><strong>Configuration Options:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Section</th><th>Option</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>constructors</code></td><td><code>detect_constructors</code></td><td>true</td><td>Identify constructor functions</td></tr>
<tr><td><code>constructors</code></td><td><code>constructor_patterns</code></td><td>[‚Äúnew‚Äù, ‚Äúcreate‚Äù, ‚Äúbuild‚Äù, ‚Äúfrom‚Äù]</td><td>Name patterns for constructors</td></tr>
<tr><td><code>accessors</code></td><td><code>detect_accessors</code></td><td>true</td><td>Identify accessor/getter functions</td></tr>
<tr><td><code>accessors</code></td><td><code>accessor_patterns</code></td><td>[‚Äúget_<em>‚Äù, ‚Äúset_</em>‚Äù, ‚Äúis_<em>‚Äù, ‚Äúhas_</em>‚Äù]</td><td>Name patterns for accessors</td></tr>
<tr><td><code>data_flow</code></td><td><code>detect_data_flow</code></td><td>true</td><td>Enable data flow analysis</td></tr>
</tbody></table>
</div>
<p><strong>Why Classification Matters:</strong></p>
<p>Classification helps Debtmap understand function intent and apply appropriate complexity adjustments:</p>
<ul>
<li><strong>Constructors</strong> typically have boilerplate initialization code with naturally higher complexity</li>
<li><strong>Accessors</strong> are simple getters/setters that shouldn‚Äôt be flagged as debt</li>
<li><strong>Data flow functions</strong> (mappers, filters) have predictable patterns that inflate metrics</li>
</ul>
<p>By detecting these patterns, Debtmap reduces false positives and focuses on genuine technical debt.</p>
<h3 id="additional-advanced-options"><a class="header" href="#additional-advanced-options">Additional Advanced Options</a></h3>
<p>Debtmap supports additional advanced configuration options:</p>
<h4 id="lines-of-code-configuration"><a class="header" href="#lines-of-code-configuration">Lines of Code Configuration</a></h4>
<p>The <strong><code>[loc]</code></strong> section controls how lines of code are counted for metrics and reporting:</p>
<pre><code class="language-toml">[loc]
include_tests = false         # Exclude test files from LOC counts (default: false)
include_generated = false     # Exclude generated files from LOC counts (default: false)
count_comments = false        # Include comment lines in LOC counts (default: false)
count_blank_lines = false     # Include blank lines in LOC counts (default: false)
</code></pre>
<p><strong>Configuration options:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>include_tests</code></td><td>false</td><td>Whether to include test files in LOC metrics</td></tr>
<tr><td><code>include_generated</code></td><td>false</td><td>Whether to include generated files in LOC metrics</td></tr>
<tr><td><code>count_comments</code></td><td>false</td><td>Whether to count comment lines as LOC</td></tr>
<tr><td><code>count_blank_lines</code></td><td>false</td><td>Whether to count blank lines as LOC</td></tr>
</tbody></table>
</div>
<p><strong>Example - Strict LOC counting:</strong></p>
<pre><code class="language-toml">[loc]
include_tests = false         # Focus on production code
include_generated = false     # Exclude auto-generated code
count_comments = false        # Only count executable code
count_blank_lines = false     # Exclude whitespace
</code></pre>
<h4 id="tier-configuration"><a class="header" href="#tier-configuration">Tier Configuration</a></h4>
<p>The <strong><code>[tiers]</code></strong> section configures tier threshold boundaries for prioritization:</p>
<pre><code class="language-toml">[tiers]
t2_complexity_threshold = 15      # Complexity threshold for Tier 2 (default: 15)
t2_dependency_threshold = 10      # Dependency threshold for Tier 2 (default: 10)
t3_complexity_threshold = 10      # Complexity threshold for Tier 3 (default: 10)
show_t4_in_main_report = false    # Show Tier 4 items in main report (default: false)
</code></pre>
<p><strong>Tier priority levels:</strong></p>
<ul>
<li><strong>Tier 1 (Critical)</strong>: Highest priority items</li>
<li><strong>Tier 2 (High)</strong>: Items above <code>t2_*</code> thresholds</li>
<li><strong>Tier 3 (Medium)</strong>: Items above <code>t3_*</code> thresholds</li>
<li><strong>Tier 4 (Low)</strong>: Items below all thresholds</li>
</ul>
<p><strong>Example - Stricter tier boundaries:</strong></p>
<pre><code class="language-toml">[tiers]
t2_complexity_threshold = 12      # Lower threshold = more items in high priority
t2_dependency_threshold = 8
t3_complexity_threshold = 8
show_t4_in_main_report = true     # Include low-priority items
</code></pre>
<h4 id="enhanced-complexity-thresholds"><a class="header" href="#enhanced-complexity-thresholds">Enhanced Complexity Thresholds</a></h4>
<p>The <strong><code>[complexity_thresholds]</code></strong> section provides more granular control over complexity detection:</p>
<p>This supplements the basic <code>[thresholds]</code> section with minimum total, cyclomatic, and cognitive complexity thresholds for flagging functions.</p>
<p>These options are advanced features with sensible defaults. Most users won‚Äôt need to configure them explicitly.</p>
<h4 id="orchestration-adjustment"><a class="header" href="#orchestration-adjustment">Orchestration Adjustment</a></h4>
<p>The <strong><code>[orchestration_adjustment]</code></strong> section configures complexity reduction for orchestrator functions that primarily delegate to other functions:</p>
<pre><code class="language-toml">[orchestration_adjustment]
enabled = true                        # Enable orchestration detection (default: true)
min_delegation_ratio = 0.6            # Minimum ratio of delegated calls (default: 0.6)
complexity_reduction = 0.25           # Reduce complexity by 25% (default: 0.25)
</code></pre>
<p><strong>Configuration Options:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable orchestration pattern detection</td></tr>
<tr><td><code>min_delegation_ratio</code></td><td>0.6</td><td>Minimum % of function that delegates to be considered orchestrator</td></tr>
<tr><td><code>complexity_reduction</code></td><td>0.25</td><td>Percentage to reduce complexity score (0.0-1.0)</td></tr>
</tbody></table>
</div>
<p>Orchestrator functions coordinate multiple operations but don‚Äôt contain complex logic themselves. This adjustment prevents them from being over-penalized.</p>
<h4 id="boilerplate-detection"><a class="header" href="#boilerplate-detection">Boilerplate Detection</a></h4>
<p>The <strong><code>[boilerplate_detection]</code></strong> section identifies and reduces penalties for boilerplate code patterns:</p>
<pre><code class="language-toml">[boilerplate_detection]
enabled = true                        # Enable boilerplate detection (default: true)
detect_constructors = true            # Detect constructor boilerplate (default: true)
detect_error_conversions = true       # Detect error conversion boilerplate (default: true)
complexity_reduction = 0.20           # Reduce complexity by 20% (default: 0.20)
</code></pre>
<p><strong>Configuration Options:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable boilerplate pattern detection</td></tr>
<tr><td><code>detect_constructors</code></td><td>true</td><td>Identify constructor initialization boilerplate</td></tr>
<tr><td><code>detect_error_conversions</code></td><td>true</td><td>Identify error type conversion boilerplate</td></tr>
<tr><td><code>complexity_reduction</code></td><td>0.20</td><td>Percentage to reduce complexity for boilerplate (0.0-1.0)</td></tr>
</tbody></table>
</div>
<p>Boilerplate code often inflates complexity metrics without representing true technical debt. This detection reduces false positives from necessary but repetitive code.</p>
<h4 id="functional-analysis"><a class="header" href="#functional-analysis">Functional Analysis</a></h4>
<p>The <strong><code>[functional_analysis]</code></strong> section configures detection of functional programming patterns:</p>
<pre><code class="language-toml">[functional_analysis]
enabled = true                        # Enable functional pattern detection (default: true)
detect_pure_functions = true          # Detect pure functions (default: true)
detect_higher_order = true            # Detect higher-order functions (default: true)
detect_immutable_patterns = true      # Detect immutable data patterns (default: true)
</code></pre>
<p><strong>Configuration Options:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>enabled</code></td><td>true</td><td>Enable functional programming analysis</td></tr>
<tr><td><code>detect_pure_functions</code></td><td>true</td><td>Identify functions without side effects</td></tr>
<tr><td><code>detect_higher_order</code></td><td>true</td><td>Identify functions that take/return functions</td></tr>
<tr><td><code>detect_immutable_patterns</code></td><td>true</td><td>Identify immutable data structure usage</td></tr>
</tbody></table>
</div>
<p>Functional patterns often lead to cleaner, more testable code. This analysis helps Debtmap recognize and appropriately score functional programming idioms.</p>
<h2 id="cli-integration"><a class="header" href="#cli-integration">CLI Integration</a></h2>
<p>CLI flags can override configuration file settings:</p>
<pre><code class="language-bash"># Override complexity threshold
debtmap analyze --threshold-complexity 15

# Provide coverage file
debtmap analyze --coverage-file coverage.json

# Enable context-aware detection
debtmap analyze --context

# Override output format
debtmap analyze --format json
</code></pre>
<h3 id="configuration-precedence"><a class="header" href="#configuration-precedence">Configuration Precedence</a></h3>
<p>Debtmap resolves configuration values in the following order (highest to lowest priority):</p>
<ol>
<li><strong>CLI flags</strong> - Command-line arguments (e.g., <code>--threshold-complexity 15</code>)</li>
<li><strong>Configuration file</strong> - Settings from <code>.debtmap.toml</code></li>
<li><strong>Built-in defaults</strong> - Debtmap‚Äôs sensible default values</li>
</ol>
<p>This allows you to set project-wide defaults in <code>.debtmap.toml</code> while customizing specific runs with CLI flags.</p>
<h2 id="configuration-validation"><a class="header" href="#configuration-validation">Configuration Validation</a></h2>
<h3 id="automatic-validation"><a class="header" href="#automatic-validation">Automatic Validation</a></h3>
<p>Debtmap automatically validates your configuration when loading:</p>
<ul>
<li><strong>Scoring weights</strong> must sum to 1.0 (¬±0.001 tolerance)</li>
<li><strong>Individual weights</strong> must be between 0.0 and 1.0</li>
<li><strong>Invalid configurations</strong> fall back to defaults with a warning</li>
</ul>
<h3 id="normalization"><a class="header" href="#normalization">Normalization</a></h3>
<p>If scoring weights don‚Äôt sum exactly to 1.0, Debtmap automatically normalizes them:</p>
<pre><code class="language-toml"># Input (sums to 0.80)
[scoring]
coverage = 0.40
complexity = 0.30
dependency = 0.10

# Automatically normalized to:
# coverage = 0.50
# complexity = 0.375
# dependency = 0.125
</code></pre>
<h3 id="debug-validation"><a class="header" href="#debug-validation">Debug Validation</a></h3>
<p>To verify which configuration file is being loaded, check debug logs:</p>
<pre><code class="language-bash">RUST_LOG=debug debtmap analyze
</code></pre>
<p>Look for log messages like:</p>
<pre><code>DEBUG debtmap::config: Loaded config from /path/to/.debtmap.toml
</code></pre>
<h2 id="complete-configuration-example"><a class="header" href="#complete-configuration-example">Complete Configuration Example</a></h2>
<p>Here‚Äôs a comprehensive configuration showing all major sections:</p>
<pre><code class="language-toml"># Scoring configuration
[scoring]
coverage = 0.50
complexity = 0.35
dependency = 0.15

# Basic thresholds
[thresholds]
complexity = 10
duplication = 50
max_file_length = 500
max_function_length = 50
minimum_debt_score = 2.0
minimum_cyclomatic_complexity = 3
minimum_cognitive_complexity = 5
minimum_risk_score = 2.0

# Validation thresholds for CI
[thresholds.validation]
max_average_complexity = 10.0
max_high_complexity_count = 100       # DEPRECATED: Use max_debt_density
max_debt_items = 2000                 # DEPRECATED: Use max_debt_density
max_total_debt_score = 10000
max_codebase_risk_score = 7.0
max_high_risk_functions = 50          # DEPRECATED: Use max_debt_density
min_coverage_percentage = 0.0
max_debt_density = 50.0

# Language configuration
[languages]
enabled = ["rust", "python", "javascript", "typescript"]

[languages.rust]
detect_dead_code = false
detect_complexity = true
detect_duplication = true

# Exclusion patterns
[ignore]
patterns = [
    "target/**",
    "node_modules/**",
    "tests/**/*",
    "**/*_test.rs",
]

# Display configuration
[display]
tiered = true
items_per_tier = 5

# Output configuration
[output]
default_format = "terminal"

# Entropy configuration
[entropy]
enabled = true
weight = 1.0
min_tokens = 20

# God object detection
[god_object_detection]
enabled = true

[god_object_detection.rust]
max_methods = 20
max_fields = 15

# Classification configuration
[classification.constructors]
detect_constructors = true
constructor_patterns = ["new", "create", "build", "from"]

[classification.accessors]
detect_accessors = true
accessor_patterns = ["get_*", "set_*", "is_*", "has_*"]

[classification.data_flow]
detect_data_flow = true

# Advanced analysis
[orchestration_adjustment]
enabled = true
min_delegation_ratio = 0.6
complexity_reduction = 0.25

[boilerplate_detection]
enabled = true
detect_constructors = true
detect_error_conversions = true
complexity_reduction = 0.20

[functional_analysis]
enabled = true
detect_pure_functions = true
detect_higher_order = true
detect_immutable_patterns = true
</code></pre>
<h2 id="configuration-best-practices"><a class="header" href="#configuration-best-practices">Configuration Best Practices</a></h2>
<h3 id="for-strict-quality-standards"><a class="header" href="#for-strict-quality-standards">For Strict Quality Standards</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.60         # Emphasize test coverage
complexity = 0.30
dependency = 0.10

[thresholds]
minimum_debt_score = 3.0        # Higher bar for flagging issues
max_function_length = 30        # Enforce smaller functions

[thresholds.validation]
max_average_complexity = 8.0    # Stricter complexity limits
max_debt_items = 500            # Stricter debt limits
min_coverage_percentage = 80.0  # Require 80% coverage
</code></pre>
<h3 id="for-legacy-codebases"><a class="header" href="#for-legacy-codebases">For Legacy Codebases</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.30         # Reduce coverage weight (legacy code often lacks tests)
complexity = 0.50       # Focus on complexity
dependency = 0.20

[thresholds]
minimum_debt_score = 5.0        # Only show highest priority items
minimum_cyclomatic_complexity = 10   # Filter out moderate complexity

[thresholds.validation]
max_debt_items = 10000          # Accommodate large debt
max_total_debt_score = 5000     # Higher limits for legacy code
</code></pre>
<h3 id="for-open-source-libraries"><a class="header" href="#for-open-source-libraries">For Open Source Libraries</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.55         # Prioritize test coverage (public API)
complexity = 0.30
dependency = 0.15

[external_api]
detect_external_api = true      # Flag untested public APIs

[thresholds.validation]
min_coverage_percentage = 90.0  # High coverage for public API
max_high_complexity_count = 20  # Keep complexity low
</code></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<h3 id="configuration-not-loading"><a class="header" href="#configuration-not-loading">Configuration Not Loading</a></h3>
<p><strong>Check file location:</strong></p>
<pre><code class="language-bash"># Ensure file is named .debtmap.toml (note the dot prefix)
ls -la .debtmap.toml

# Debtmap searches current directory + 10 parent directories
pwd
</code></pre>
<p><strong>Check file syntax:</strong></p>
<pre><code class="language-bash"># Verify TOML syntax is valid
debtmap analyze 2&gt;&amp;1 | grep -i "failed to parse"
</code></pre>
<h3 id="weights-dont-sum-to-10"><a class="header" href="#weights-dont-sum-to-10">Weights Don‚Äôt Sum to 1.0</a></h3>
<p><strong>Error message:</strong></p>
<pre><code>Warning: Invalid scoring weights: Active scoring weights must sum to 1.0, but sum to 0.800. Using defaults.
</code></pre>
<p><strong>Fix:</strong> Ensure coverage + complexity + dependency = 1.0</p>
<pre><code class="language-toml">[scoring]
coverage = 0.50
complexity = 0.35
dependency = 0.15    # Sum = 1.0 ‚úì
</code></pre>
<h3 id="no-results-shown"><a class="header" href="#no-results-shown">No Results Shown</a></h3>
<p><strong>Possible causes:</strong></p>
<ol>
<li>Minimum thresholds too high</li>
<li>All code excluded by ignore patterns</li>
<li>No supported languages in project</li>
</ol>
<p><strong>Solutions:</strong></p>
<pre><code class="language-toml"># Lower minimum thresholds
[thresholds]
minimum_debt_score = 1.0
minimum_cyclomatic_complexity = 1

# Check language configuration
[languages]
enabled = ["rust", "python", "javascript", "typescript"]

# Review ignore patterns
[ignore]
patterns = [
    # Make sure you're not excluding too much
]
</code></pre>
<h2 id="related-chapters"><a class="header" href="#related-chapters">Related Chapters</a></h2>
<ul>
<li><a href="./getting-started.html">Getting Started</a> - Initial setup and basic usage</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Understanding scoring and prioritization</li>
<li><a href="./output-formats.html">Output Formats</a> - Formatting and exporting results</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="threshold-configuration-1"><a class="header" href="#threshold-configuration-1">Threshold Configuration</a></h1>
<p>Debtmap uses configurable thresholds to determine when code complexity, duplication, or structural issues should be flagged as technical debt. This chapter explains how to configure thresholds to match your project‚Äôs quality standards.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>Thresholds control what gets flagged as technical debt. You can configure thresholds using:</p>
<ol>
<li><strong>Preset configurations</strong> - Quick start with strict, balanced, or lenient settings</li>
<li><strong>CLI flags</strong> - Override thresholds for a single analysis run</li>
<li><strong>Configuration file</strong> - Project-specific thresholds in <code>.debtmap.toml</code></li>
</ol>
<h2 id="threshold-presets"><a class="header" href="#threshold-presets">Threshold Presets</a></h2>
<p>Debtmap provides three preset threshold configurations to match different project needs:</p>
<h3 id="preset-comparison"><a class="header" href="#preset-comparison">Preset Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Threshold</th><th>Strict</th><th>Balanced (Default)</th><th>Lenient</th></tr></thead><tbody>
<tr><td>Cyclomatic Complexity</td><td>3</td><td>5</td><td>10</td></tr>
<tr><td>Cognitive Complexity</td><td>7</td><td>10</td><td>20</td></tr>
<tr><td>Total Complexity</td><td>5</td><td>8</td><td>15</td></tr>
<tr><td>Function Length (lines)</td><td>15</td><td>20</td><td>50</td></tr>
<tr><td>Match Arms</td><td>3</td><td>4</td><td>8</td></tr>
<tr><td>If-Else Chain</td><td>2</td><td>3</td><td>5</td></tr>
</tbody></table>
</div>
<h3 id="when-to-use-each-preset"><a class="header" href="#when-to-use-each-preset">When to Use Each Preset</a></h3>
<p><strong>Strict Preset</strong></p>
<ul>
<li>New projects aiming for high code quality standards</li>
<li>Libraries and reusable components</li>
<li>Critical systems requiring high reliability</li>
<li>Teams enforcing strict coding standards</li>
</ul>
<pre><code class="language-bash">debtmap analyze . --threshold-preset strict
</code></pre>
<p><strong>Balanced Preset (Default)</strong></p>
<ul>
<li>Typical production applications</li>
<li>Projects with moderate complexity tolerance</li>
<li>Recommended starting point for most projects</li>
<li>Good balance between catching issues and avoiding false positives</li>
</ul>
<pre><code class="language-bash">debtmap analyze .  # Uses balanced preset by default
</code></pre>
<p><strong>Lenient Preset</strong></p>
<ul>
<li>Legacy codebases during initial assessment</li>
<li>Complex domains (compilers, scientific computing)</li>
<li>Gradual debt reduction strategies</li>
<li>Temporary relaxation during major refactoring</li>
</ul>
<pre><code class="language-bash">debtmap analyze . --threshold-preset lenient
</code></pre>
<h2 id="understanding-complexity-thresholds"><a class="header" href="#understanding-complexity-thresholds">Understanding Complexity Thresholds</a></h2>
<p>Debtmap tracks multiple complexity metrics. A function must exceed <strong>ALL</strong> thresholds to be flagged:</p>
<h3 id="cyclomatic-complexity-1"><a class="header" href="#cyclomatic-complexity-1">Cyclomatic Complexity</a></h3>
<p>Counts decision points in code: <code>if</code>, <code>while</code>, <code>for</code>, <code>match</code>, <code>&amp;&amp;</code>, <code>||</code>, etc.</p>
<ul>
<li><strong>What it measures</strong>: Number of independent paths through code</li>
<li><strong>Why it matters</strong>: More paths = harder to test completely</li>
<li><strong>Default threshold</strong>: 5</li>
</ul>
<h3 id="cognitive-complexity-1"><a class="header" href="#cognitive-complexity-1">Cognitive Complexity</a></h3>
<p>Measures the mental effort required to understand code by weighing nested structures and breaks in linear flow.</p>
<ul>
<li><strong>What it measures</strong>: How hard code is to read and comprehend</li>
<li><strong>Why it matters</strong>: High cognitive load = maintenance burden</li>
<li><strong>Default threshold</strong>: 10</li>
</ul>
<h3 id="total-complexity"><a class="header" href="#total-complexity">Total Complexity</a></h3>
<p>Sum of cyclomatic and cognitive complexity.</p>
<ul>
<li><strong>What it measures</strong>: Combined complexity burden</li>
<li><strong>Why it matters</strong>: Catches functions high in either metric</li>
<li><strong>Default threshold</strong>: 8</li>
</ul>
<h3 id="function-length-1"><a class="header" href="#function-length-1">Function Length</a></h3>
<p>Number of lines of code in the function body.</p>
<ul>
<li><strong>What it measures</strong>: Physical size of function</li>
<li><strong>Why it matters</strong>: Long functions are hard to understand and test</li>
<li><strong>Default threshold</strong>: 20 lines</li>
</ul>
<h3 id="structural-complexity"><a class="header" href="#structural-complexity">Structural Complexity</a></h3>
<p>Additional metrics for specific patterns:</p>
<ul>
<li><strong>Match arms</strong>: Flags large match/switch statements (default: 4)</li>
<li><strong>If-else chains</strong>: Flags long conditional chains (default: 3)</li>
</ul>
<p><strong>Important</strong>: Functions are flagged when they meet ALL of these conditions simultaneously:</p>
<ul>
<li>Cyclomatic complexity &gt;= adjusted cyclomatic threshold</li>
<li>Cognitive complexity &gt;= adjusted cognitive threshold</li>
<li>Function length &gt;= minimum function length</li>
<li>Total complexity (cyclomatic + cognitive) &gt;= adjusted total threshold</li>
</ul>
<p>The thresholds are first adjusted by role-based multipliers, then all four checks must pass for the function to be flagged. This is a conjunction (AND) of individual threshold checks.</p>
<h3 id="threshold-validation"><a class="header" href="#threshold-validation">Threshold Validation</a></h3>
<p>All threshold configurations are validated to ensure they are positive (non-zero) values. The following validation rules apply:</p>
<ul>
<li><code>minimum_total_complexity</code> &gt; 0</li>
<li><code>minimum_cyclomatic_complexity</code> &gt; 0</li>
<li><code>minimum_cognitive_complexity</code> &gt; 0</li>
<li><code>minimum_match_arms</code> &gt; 0</li>
<li><code>minimum_if_else_chain</code> &gt; 0</li>
<li><code>minimum_function_length</code> &gt; 0</li>
<li>All role multipliers &gt; 0</li>
</ul>
<p>If any threshold is set to zero or a negative value, Debtmap will reject the configuration and use default values instead. This ensures that thresholds are always meaningful and prevent misconfiguration.</p>
<h2 id="role-based-multipliers"><a class="header" href="#role-based-multipliers">Role-Based Multipliers</a></h2>
<p>Debtmap automatically adjusts thresholds based on function role, recognizing that different types of functions have different complexity expectations:</p>
<div class="table-wrapper"><table><thead><tr><th>Function Role</th><th>Multiplier</th><th>Effect</th><th>Examples</th></tr></thead><tbody>
<tr><td>Entry Points</td><td>1.5x</td><td>More lenient</td><td><code>main()</code>, HTTP handlers, CLI commands</td></tr>
<tr><td>Core Logic</td><td>1.0x</td><td>Standard</td><td>Business logic, algorithms</td></tr>
<tr><td>Utility Functions</td><td>0.6x - 1.0x (preset-specific)</td><td>Stricter</td><td>Getters, setters, simple helpers</td></tr>
<tr><td>Test Functions</td><td>2.0x - 3.0x (preset-specific)</td><td>Most lenient</td><td>Unit tests, integration tests</td></tr>
<tr><td>Unknown Functions</td><td>1.0x (defaults to core logic)</td><td>Standard</td><td>Functions that don‚Äôt match any role pattern</td></tr>
</tbody></table>
</div>
<p><strong>Note</strong>: Some multipliers vary by preset:</p>
<ul>
<li><strong>Utility Functions</strong>: Strict=0.6x, Balanced=0.8x, Lenient=1.0x</li>
<li><strong>Test Functions</strong>: Strict=3.0x, Balanced=2.0x, Lenient=3.0x</li>
</ul>
<p><strong>How multipliers work:</strong></p>
<p>A higher multiplier makes thresholds more lenient by adjusting ALL thresholds. For example, an entry point function with the balanced preset would have these adjusted thresholds:</p>
<p><strong>Balanced Preset Entry Point (multiplier = 1.5x):</strong></p>
<ul>
<li>Cyclomatic threshold: 7.5 (5 √ó 1.5)</li>
<li>Cognitive threshold: 15 (10 √ó 1.5)</li>
<li>Total threshold: 12 (8 √ó 1.5)</li>
<li>Length threshold: 30 lines (20 √ó 1.5)</li>
</ul>
<p><strong>The function is flagged only if ALL conditions are met:</strong></p>
<ul>
<li>Cyclomatic complexity &gt;= 7.5 AND</li>
<li>Cognitive complexity &gt;= 15 AND</li>
<li>Function length &gt;= 30 lines AND</li>
<li>Total complexity (cyclomatic + cognitive) &gt;= 12</li>
</ul>
<p><strong>Comparison across roles (balanced preset):</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Role</th><th>Cyclomatic</th><th>Cognitive</th><th>Total</th><th>Length</th><th>Flagged When</th></tr></thead><tbody>
<tr><td>Entry Point (1.5x)</td><td>7.5</td><td>15</td><td>12</td><td>30</td><td>ALL conditions met</td></tr>
<tr><td>Core Logic (1.0x)</td><td>5</td><td>10</td><td>8</td><td>20</td><td>ALL conditions met</td></tr>
<tr><td>Utility (0.8x)</td><td>4</td><td>8</td><td>6.4</td><td>16</td><td>ALL conditions met</td></tr>
<tr><td>Test (2.0x)</td><td>10</td><td>20</td><td>16</td><td>40</td><td>ALL conditions met</td></tr>
</tbody></table>
</div>
<p>This allows test functions and entry points to be more complex without false positives, while keeping utility functions clean and simple.</p>
<h2 id="cli-threshold-flags"><a class="header" href="#cli-threshold-flags">CLI Threshold Flags</a></h2>
<p>Override thresholds for a single analysis run using command-line flags:</p>
<h3 id="preset-based-configuration-recommended"><a class="header" href="#preset-based-configuration-recommended">Preset-Based Configuration (Recommended)</a></h3>
<p>Use <code>--threshold-preset</code> to apply a predefined threshold configuration:</p>
<pre><code class="language-bash"># Use strict preset (cyclomatic=3, cognitive=7, total=5, length=15)
debtmap analyze . --threshold-preset strict

# Use balanced preset (default - cyclomatic=5, cognitive=10, total=8, length=20)
debtmap analyze . --threshold-preset balanced

# Use lenient preset (cyclomatic=10, cognitive=20, total=15, length=50)
debtmap analyze . --threshold-preset lenient
</code></pre>
<h3 id="individual-threshold-overrides"><a class="header" href="#individual-threshold-overrides">Individual Threshold Overrides</a></h3>
<p>You can also override specific thresholds:</p>
<pre><code class="language-bash"># Override cyclomatic complexity threshold (legacy flag, default: 10)
debtmap analyze . --threshold-complexity 15

# Override duplication threshold in lines (default: 50)
debtmap analyze . --threshold-duplication 30

# Combine multiple threshold flags
debtmap analyze . --threshold-complexity 15 --threshold-duplication 30
</code></pre>
<p><strong>Note</strong>:</p>
<ul>
<li><code>--threshold-preset</code> provides the most comprehensive threshold configuration (includes all complexity metrics and role multipliers)</li>
<li>Individual flags like <code>--threshold-complexity</code> are legacy flags with limited scope</li>
<li>For full control, use the <code>.debtmap.toml</code> configuration file</li>
<li>CLI flags override configuration file settings for that run only</li>
</ul>
<h2 id="configuration-file-1"><a class="header" href="#configuration-file-1">Configuration File</a></h2>
<p>For project-specific thresholds, create a <code>.debtmap.toml</code> file in your project root.</p>
<h3 id="complexity-thresholds-configuration"><a class="header" href="#complexity-thresholds-configuration">Complexity Thresholds Configuration</a></h3>
<p>The <code>[complexity_thresholds]</code> section in <code>.debtmap.toml</code> allows fine-grained control over function complexity detection:</p>
<pre><code class="language-toml">[complexity_thresholds]
# Core complexity metrics
minimum_total_complexity = 8        # Sum of cyclomatic + cognitive
minimum_cyclomatic_complexity = 5   # Decision points (if, match, etc.)
minimum_cognitive_complexity = 10   # Mental effort to understand code

# Structural complexity metrics
minimum_match_arms = 4              # Maximum match/switch arms
minimum_if_else_chain = 3           # Maximum if-else chain length
minimum_function_length = 20        # Minimum lines before flagging

# Role-based multipliers (applied to all thresholds above)
entry_point_multiplier = 1.5        # main(), handlers, CLI commands
core_logic_multiplier = 1.0         # Standard business logic
utility_multiplier = 0.8            # Getters, setters, helpers
test_function_multiplier = 2.0      # Unit tests, integration tests
</code></pre>
<p><strong>Note</strong>: The multipliers are applied to thresholds before comparison. For example, with <code>entry_point_multiplier = 1.5</code> and <code>minimum_cyclomatic_complexity = 5</code>, an entry point function would be flagged at cyclomatic complexity 7.5 (5 √ó 1.5).</p>
<h3 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h3>
<pre><code class="language-toml"># Complexity thresholds for flagging functions
[thresholds]
complexity = 15                # Cyclomatic complexity threshold
cognitive = 20                 # Cognitive complexity threshold
max_file_length = 500         # Maximum file length in lines

# Validation thresholds for CI/CD
[thresholds.validation]
max_average_complexity = 10.0      # Maximum average complexity across codebase
max_debt_density = 50.0           # Maximum debt items per 1000 LOC
max_codebase_risk_score = 7.0     # Maximum overall risk score
min_coverage_percentage = 0.0     # Minimum test coverage (0 = disabled)
max_total_debt_score = 10000      # Safety net for total debt score

# God object detection
[god_object]
enabled = true

# Rust-specific thresholds
[god_object.rust]
max_methods = 20        # Maximum methods before flagging as god object
max_fields = 15         # Maximum fields
max_traits = 5          # Maximum trait implementations
max_lines = 1000        # Maximum lines in impl block
max_complexity = 200    # Maximum total complexity

# Python-specific thresholds
[god_object.python]
max_methods = 15
max_fields = 10
max_traits = 3
max_lines = 500
max_complexity = 150

# JavaScript/TypeScript-specific thresholds
[god_object.javascript]
max_methods = 15
max_fields = 20
max_traits = 3
max_lines = 500
max_complexity = 150
</code></pre>
<h3 id="using-configuration-file"><a class="header" href="#using-configuration-file">Using Configuration File</a></h3>
<pre><code class="language-bash"># Initialize with default configuration
debtmap init

# Edit .debtmap.toml to customize thresholds
# Then run analysis (automatically uses config file)
debtmap analyze .

# Validate against thresholds in CI/CD
debtmap validate . --config .debtmap.toml
</code></pre>
<h2 id="god-object-thresholds"><a class="header" href="#god-object-thresholds">God Object Thresholds</a></h2>
<p>God objects are classes/structs with too many responsibilities. Debtmap uses language-specific thresholds to detect them:</p>
<h3 id="rust-thresholds"><a class="header" href="#rust-thresholds">Rust Thresholds</a></h3>
<pre><code class="language-toml">[god_object.rust]
max_methods = 20        # Methods in impl blocks
max_fields = 15         # Struct fields
max_traits = 5          # Trait implementations
max_lines = 1000        # Lines in impl blocks
max_complexity = 200    # Total complexity
</code></pre>
<h3 id="python-thresholds"><a class="header" href="#python-thresholds">Python Thresholds</a></h3>
<pre><code class="language-toml">[god_object.python]
max_methods = 15
max_fields = 10
max_traits = 3          # Base classes
max_lines = 500
max_complexity = 150
</code></pre>
<h3 id="javascripttypescript-thresholds"><a class="header" href="#javascripttypescript-thresholds">JavaScript/TypeScript Thresholds</a></h3>
<pre><code class="language-toml">[god_object.javascript]
max_methods = 15
max_fields = 20
max_traits = 3          # Extended classes
max_lines = 500
max_complexity = 150
</code></pre>
<p><strong>Why language-specific thresholds?</strong></p>
<p>Different languages have different idioms:</p>
<ul>
<li><strong>Rust</strong>: Encourages small traits and composition, so lower thresholds</li>
<li><strong>Python</strong>: Duck typing allows more fields, but fewer methods</li>
<li><strong>JavaScript</strong>: Prototype-based, typically has more properties</li>
</ul>
<h2 id="validation-thresholds-1"><a class="header" href="#validation-thresholds-1">Validation Thresholds</a></h2>
<p>Use validation thresholds in CI/CD pipelines to enforce quality gates:</p>
<h3 id="scale-independent-metrics-recommended"><a class="header" href="#scale-independent-metrics-recommended">Scale-Independent Metrics (Recommended)</a></h3>
<p>These metrics work for codebases of any size:</p>
<pre><code class="language-toml">[thresholds.validation]
# Average complexity per function (default: 10.0)
max_average_complexity = 10.0

# Debt items per 1000 lines of code (default: 50.0)
max_debt_density = 50.0

# Overall risk score 0-10 (default: 7.0)
max_codebase_risk_score = 7.0
</code></pre>
<h3 id="optional-metrics"><a class="header" href="#optional-metrics">Optional Metrics</a></h3>
<pre><code class="language-toml">[thresholds.validation]
# Minimum test coverage percentage (default: 0.0 = disabled)
min_coverage_percentage = 80.0

# Safety net for total debt score (default: 10000)
max_total_debt_score = 5000
</code></pre>
<h3 id="using-validation-in-cicd"><a class="header" href="#using-validation-in-cicd">Using Validation in CI/CD</a></h3>
<pre><code class="language-bash"># Run validation (exits with error if thresholds exceeded)
debtmap validate . --config .debtmap.toml

# Example CI/CD workflow
debtmap analyze . --output report.json
debtmap validate . --config .debtmap.toml || exit 1
</code></pre>
<p><strong>CI/CD Best Practices:</strong></p>
<ul>
<li>Start with lenient thresholds to establish baseline</li>
<li>Gradually tighten thresholds as you pay down debt</li>
<li>Use <code>max_debt_density</code> for stable quality metric</li>
<li>Track trends over time, not just point-in-time values</li>
</ul>
<h2 id="tuning-guidelines"><a class="header" href="#tuning-guidelines">Tuning Guidelines</a></h2>
<p>How to choose and adjust thresholds for your project:</p>
<h3 id="1-start-with-defaults"><a class="header" href="#1-start-with-defaults">1. Start with Defaults</a></h3>
<p>Begin with the balanced preset to understand your codebase:</p>
<pre><code class="language-bash">debtmap analyze .
</code></pre>
<p>Review the output to see what gets flagged and what doesn‚Äôt.</p>
<h3 id="2-run-baseline-analysis"><a class="header" href="#2-run-baseline-analysis">2. Run Baseline Analysis</a></h3>
<p>Understand your current state:</p>
<pre><code class="language-bash"># Analyze and save results
debtmap analyze . --output baseline.json

# Review high-priority items
debtmap analyze . --top 20
</code></pre>
<h3 id="3-adjust-based-on-project-type"><a class="header" href="#3-adjust-based-on-project-type">3. Adjust Based on Project Type</a></h3>
<p><strong>New Projects:</strong></p>
<ul>
<li>Use strict preset to enforce high quality from the start</li>
<li>Prevents accumulation of technical debt</li>
</ul>
<p><strong>Typical Projects:</strong></p>
<ul>
<li>Use balanced preset (recommended)</li>
<li>Good middle ground for most teams</li>
</ul>
<p><strong>Legacy Codebases:</strong></p>
<ul>
<li>Use lenient preset initially</li>
<li>Focus on worst offenders first</li>
<li>Gradually tighten thresholds as you refactor</li>
</ul>
<h3 id="4-fine-tune-in-configuration-file"><a class="header" href="#4-fine-tune-in-configuration-file">4. Fine-Tune in Configuration File</a></h3>
<p>Create <code>.debtmap.toml</code> and adjust specific thresholds:</p>
<pre><code class="language-bash"># Initialize config file
debtmap init

# Edit .debtmap.toml
# Adjust thresholds based on your baseline analysis
</code></pre>
<h3 id="5-validate-and-iterate"><a class="header" href="#5-validate-and-iterate">5. Validate and Iterate</a></h3>
<pre><code class="language-bash"># Test your thresholds
debtmap validate . --config .debtmap.toml

# Adjust if needed
# Iterate until you find the right balance
</code></pre>
<h3 id="troubleshooting-threshold-configuration"><a class="header" href="#troubleshooting-threshold-configuration">Troubleshooting Threshold Configuration</a></h3>
<p><strong>Too many false positives?</strong></p>
<ul>
<li>Increase thresholds or switch to lenient preset</li>
<li>Check if role multipliers are appropriate</li>
<li>Review god object thresholds for your language</li>
</ul>
<p><strong>Missing important issues?</strong></p>
<ul>
<li>Decrease thresholds or switch to strict preset</li>
<li>Verify <code>.debtmap.toml</code> is being loaded</li>
<li>Check for suppression patterns hiding issues</li>
</ul>
<p><strong>Different standards for tests?</strong></p>
<ul>
<li>Don‚Äôt worry - role multipliers automatically handle this</li>
<li>Test functions get 2-3x multiplier by default</li>
</ul>
<p><strong>Inconsistent results?</strong></p>
<ul>
<li>Ensure <code>.debtmap.toml</code> is in project root</li>
<li>CLI flags override config file - remove them for consistency</li>
<li>Use <code>--config</code> flag to specify config file explicitly</li>
</ul>
<h2 id="examples-1"><a class="header" href="#examples-1">Examples</a></h2>
<h3 id="example-1-quick-analysis-with-strict-preset"><a class="header" href="#example-1-quick-analysis-with-strict-preset">Example 1: Quick Analysis with Strict Preset</a></h3>
<pre><code class="language-bash"># Use strict thresholds for new project
debtmap analyze . --threshold-preset strict
</code></pre>
<h3 id="example-2-custom-cli-thresholds"><a class="header" href="#example-2-custom-cli-thresholds">Example 2: Custom CLI Thresholds</a></h3>
<pre><code class="language-bash"># Analyze with custom thresholds (no config file)
debtmap analyze . \
  --threshold-complexity 15 \
  --threshold-duplication 30
</code></pre>
<h3 id="example-3-project-specific-configuration"><a class="header" href="#example-3-project-specific-configuration">Example 3: Project-Specific Configuration</a></h3>
<pre><code class="language-bash"># Initialize configuration
debtmap init

# Creates .debtmap.toml - edit to customize
# Example: Increase complexity threshold to 15

# Run analysis with project config
debtmap analyze .
</code></pre>
<h3 id="example-4-cicd-validation"><a class="header" href="#example-4-cicd-validation">Example 4: CI/CD Validation</a></h3>
<pre><code class="language-bash"># Create strict validation configuration
cat &gt; .debtmap.toml &lt;&lt; EOF
[thresholds.validation]
max_average_complexity = 8.0
max_debt_density = 30.0
max_codebase_risk_score = 6.0
min_coverage_percentage = 75.0
EOF

# Run in CI/CD pipeline
debtmap analyze . --output report.json
debtmap validate . --config .debtmap.toml
</code></pre>
<h3 id="example-5-gradual-debt-reduction"><a class="header" href="#example-5-gradual-debt-reduction">Example 5: Gradual Debt Reduction</a></h3>
<pre><code class="language-bash"># Month 1: Start lenient
debtmap analyze . --threshold-preset lenient --output month1.json

# Month 2: Switch to balanced
debtmap analyze . --threshold-preset balanced --output month2.json

# Month 3: Tighten further
debtmap analyze . --threshold-preset strict --output month3.json

# Compare progress
debtmap analyze . --output current.json
# Review trend: month1.json -&gt; month2.json -&gt; month3.json -&gt; current.json
</code></pre>
<h2 id="decision-tree-choosing-your-preset"><a class="header" href="#decision-tree-choosing-your-preset">Decision Tree: Choosing Your Preset</a></h2>
<pre><code>Start here: What kind of project are you working on?
‚îÇ
‚îú‚îÄ New project or library
‚îÇ  ‚îî‚îÄ Use STRICT preset
‚îÇ     ‚îî‚îÄ Prevent debt accumulation from day one
‚îÇ
‚îú‚îÄ Existing production application
‚îÇ  ‚îî‚îÄ What's your goal?
‚îÇ     ‚îú‚îÄ Maintain current quality
‚îÇ     ‚îÇ  ‚îî‚îÄ Use BALANCED preset
‚îÇ     ‚îÇ     ‚îî‚îÄ Good default for most teams
‚îÇ     ‚îÇ
‚îÇ     ‚îî‚îÄ Reduce existing debt gradually
‚îÇ        ‚îî‚îÄ Start with LENIENT preset
‚îÇ           ‚îî‚îÄ Focus on worst issues first
‚îÇ           ‚îî‚îÄ Tighten thresholds over time
‚îÇ
‚îî‚îÄ Legacy codebase or complex domain
   ‚îî‚îÄ Use LENIENT preset
      ‚îî‚îÄ Avoid overwhelming with false positives
      ‚îî‚îÄ Create baseline and improve incrementally
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<ol>
<li><strong>Start with defaults</strong> - Don‚Äôt over-customize initially</li>
<li><strong>Track trends</strong> - Monitor debt over time, not just point values</li>
<li><strong>Be consistent</strong> - Use same thresholds across team</li>
<li><strong>Document choices</strong> - Comment your <code>.debtmap.toml</code> to explain custom thresholds</li>
<li><strong>Automate validation</strong> - Run <code>debtmap validate</code> in CI/CD</li>
<li><strong>Review regularly</strong> - Reassess thresholds quarterly</li>
<li><strong>Gradual tightening</strong> - Don‚Äôt make thresholds stricter too quickly</li>
<li><strong>Trust role multipliers</strong> - Let Debtmap handle different function types</li>
</ol>
<h2 id="related-topics"><a class="header" href="#related-topics">Related Topics</a></h2>
<ul>
<li><a href="getting-started.html">Getting Started</a> - Initial setup and first analysis</li>
<li><a href="cli-reference.html">CLI Reference</a> - Complete command-line flag documentation</li>
<li><a href="configuration.html">Configuration</a> - Full <code>.debtmap.toml</code> reference</li>
<li><a href="scoring-strategies.html">Scoring Strategies</a> - How thresholds affect debt scores</li>
<li><a href="god-object-detection.html">God Object Detection</a> - Deep dive into god object analysis</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="suppression-patterns"><a class="header" href="#suppression-patterns">Suppression Patterns</a></h1>
<p>Debtmap provides flexible suppression mechanisms to help you focus on the technical debt that matters most. You can suppress specific debt items inline with comments, or exclude entire files and functions through configuration.</p>
<h2 id="why-use-suppressions"><a class="header" href="#why-use-suppressions">Why Use Suppressions?</a></h2>
<p>Not all detected technical debt requires immediate action. Suppressions allow you to:</p>
<ul>
<li><strong>Focus on priorities</strong>: Hide known, accepted debt to see new issues clearly</li>
<li><strong>Handle false positives</strong>: Suppress patterns that don‚Äôt apply to your context</li>
<li><strong>Document decisions</strong>: Explain why certain debt is acceptable using reason annotations</li>
<li><strong>Exclude test code</strong>: Ignore complexity in test fixtures and setup functions</li>
</ul>
<h2 id="inline-comment-suppression"><a class="header" href="#inline-comment-suppression">Inline Comment Suppression</a></h2>
<p>Debtmap supports four inline comment formats that work with your language‚Äôs comment syntax:</p>
<h3 id="single-line-suppression"><a class="header" href="#single-line-suppression">Single-Line Suppression</a></h3>
<p>Suppress debt on the same line as the comment:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore
// TODO: Implement caching later - performance is acceptable for now
<span class="boring">}</span></code></pre></pre>
<pre><code class="language-python"># debtmap:ignore
# FIXME: Refactor this after the Q2 release
</code></pre>
<p>The suppression applies to debt detected on the same line as the comment.</p>
<h3 id="next-line-suppression"><a class="header" href="#next-line-suppression">Next-Line Suppression</a></h3>
<p>Suppress debt on the line immediately following the comment:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore-next-line
fn complex_algorithm() {
    // ...20 lines of complex code...
}
<span class="boring">}</span></code></pre></pre>
<pre><code class="language-typescript">// debtmap:ignore-next-line
function calculateMetrics(data: DataPoint[]): Metrics {
    // ...complex implementation...
}
</code></pre>
<p>This format is useful when you want the suppression comment to appear before the code it affects.</p>
<h3 id="block-suppression"><a class="header" href="#block-suppression">Block Suppression</a></h3>
<p>Suppress multiple lines of code between start and end markers:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore-start
fn setup_test_environment() {
    // TODO: Add more test cases
    // FIXME: Handle edge cases
    // Complex test setup code...
}
// debtmap:ignore-end
<span class="boring">}</span></code></pre></pre>
<pre><code class="language-python"># debtmap:ignore-start
def mock_api_responses():
    # TODO: Add more mock scenarios
    # Multiple lines of mock setup
    pass
# debtmap:ignore-end
</code></pre>
<p><strong>Important</strong>: Every <code>ignore-start</code> must have a matching <code>ignore-end</code>. Debtmap tracks unclosed blocks and can warn you about them.</p>
<h2 id="type-specific-suppression"><a class="header" href="#type-specific-suppression">Type-Specific Suppression</a></h2>
<p>You can suppress specific types of debt using bracket notation instead of suppressing everything:</p>
<h3 id="quick-reference-debt-type-suppression"><a class="header" href="#quick-reference-debt-type-suppression">Quick Reference: Debt Type Suppression</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Debt Type</th><th>Bracket Name(s)</th><th>Example</th><th>Notes</th></tr></thead><tbody>
<tr><td>TODO comments</td><td><code>[todo]</code></td><td><code>// debtmap:ignore[todo]</code></td><td>Also suppresses TestTodo</td></tr>
<tr><td>FIXME comments</td><td><code>[fixme]</code></td><td><code>// debtmap:ignore[fixme]</code></td><td></td></tr>
<tr><td>Code smells</td><td><code>[smell]</code> or <code>[codesmell]</code></td><td><code>// debtmap:ignore[smell]</code></td><td></td></tr>
<tr><td>High complexity</td><td><code>[complexity]</code></td><td><code>// debtmap:ignore[complexity]</code></td><td>Also suppresses TestComplexity</td></tr>
<tr><td>Code duplication</td><td><code>[duplication]</code> or <code>[duplicate]</code></td><td><code>// debtmap:ignore[duplication]</code></td><td>Also suppresses TestDuplication</td></tr>
<tr><td>Dependency issues</td><td><code>[dependency]</code></td><td><code>// debtmap:ignore[dependency]</code></td><td></td></tr>
<tr><td>Error swallowing</td><td>‚ùå Not supported</td><td><code>// debtmap:ignore</code></td><td>Use general suppression only</td></tr>
<tr><td>Resource management</td><td>‚ùå Not supported</td><td><code>// debtmap:ignore</code></td><td>Use general suppression only</td></tr>
<tr><td>Code organization</td><td>‚ùå Not supported</td><td><code>// debtmap:ignore</code></td><td>Use general suppression only</td></tr>
<tr><td>Test quality</td><td>‚ùå Not supported</td><td><code>// debtmap:ignore</code></td><td>Use general suppression only</td></tr>
<tr><td>All types</td><td><code>[*]</code></td><td><code>// debtmap:ignore[*]</code></td><td>Wildcard matches everything</td></tr>
</tbody></table>
</div>
<h3 id="suppress-specific-types"><a class="header" href="#suppress-specific-types">Suppress Specific Types</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore[todo]
// TODO: This TODO is ignored, but FIXMEs and complexity are still reported
<span class="boring">}</span></code></pre></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore[todo,fixme]
// TODO: Both TODOs and FIXMEs are ignored here
// FIXME: But complexity issues would still be detected
<span class="boring">}</span></code></pre></pre>
<h3 id="supported-debt-types"><a class="header" href="#supported-debt-types">Supported Debt Types</a></h3>
<p>You can suppress the following debt types by name in bracket notation:</p>
<p><strong>Currently Supported:</strong></p>
<ul>
<li><code>todo</code> - TODO comments (also detects test-specific TODOs)</li>
<li><code>fixme</code> - FIXME comments</li>
<li><code>smell</code> or <code>codesmell</code> - Code smell patterns</li>
<li><code>complexity</code> - High cognitive complexity (also detects test complexity)</li>
<li><code>duplication</code> or <code>duplicate</code> - Code duplication (also detects test duplication)</li>
<li><code>dependency</code> - Dependency issues</li>
<li><code>*</code> - All types (wildcard)</li>
</ul>
<p><strong>Auto-Detected Types</strong> (cannot be suppressed by name):</p>
<p>The following debt types are detected by code analysis rather than comment scanning. These types <strong>cannot</strong> be suppressed using bracket notation like <code>[error_swallowing]</code>. To suppress them, use the general <code>debtmap:ignore</code> marker without brackets:</p>
<ul>
<li><code>error_swallowing</code> - Error handling issues (empty catch blocks, ignored errors)</li>
<li><code>resource_management</code> - Resource cleanup issues (file handles, connections)</li>
<li><code>code_organization</code> - Structural issues (god objects, large classes)</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚úÖ Correct: General suppression without brackets
// debtmap:ignore -- Intentional empty catch for cleanup
match result {
    Err(_) =&gt; {} // Empty catch block
    Ok(v) =&gt; process(v)
}

// ‚ùå Wrong: Bracket notation not supported for auto-detected types
// debtmap:ignore[error_swallowing]
<span class="boring">}</span></code></pre></pre>
<p><strong>Test-Specific Debt Types:</strong></p>
<p>Test-specific variants like <code>TestComplexity</code>, <code>TestTodo</code>, <code>TestDuplication</code>, and <code>TestQuality</code> are suppressed through their base types:</p>
<ul>
<li><code>TestComplexity</code> ‚Üí suppressed with <code>[complexity]</code></li>
<li><code>TestTodo</code> ‚Üí suppressed with <code>[todo]</code></li>
<li><code>TestDuplication</code> ‚Üí suppressed with <code>[duplication]</code></li>
<li><code>TestQuality</code> ‚Üí suppressed with general <code>debtmap:ignore</code> (no bracket notation)</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    // Suppresses both Complexity and TestComplexity
    // debtmap:ignore[complexity] -- Complex test setup acceptable
    fn setup_test_environment() {
        // Complex test initialization
    }

    // debtmap:ignore[todo] -- Suppresses both Todo and TestTodo
    // TODO: Add more test cases
    fn test_feature() { }
}

## Wildcard Suppression

Use `[*]` to explicitly suppress all types (equivalent to no bracket notation):

```rust
// debtmap:ignore[*]
// Suppresses all debt types
<span class="boring">}</span></code></pre></pre>
<h3 id="type-specific-blocks"><a class="header" href="#type-specific-blocks">Type-Specific Blocks</a></h3>
<p>Block suppressions also support type filtering:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore-start[complexity]
fn intentionally_complex_for_performance() {
    // Complex nested logic is intentional here
    // Complexity warnings suppressed, but TODOs still detected
}
// debtmap:ignore-end
<span class="boring">}</span></code></pre></pre>
<h2 id="suppression-reasons"><a class="header" href="#suppression-reasons">Suppression Reasons</a></h2>
<p>Document why you‚Äôre suppressing debt using the <code>--</code> separator:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore -- Intentional for backward compatibility
// TODO: Remove this after all clients upgrade to v2.0
<span class="boring">}</span></code></pre></pre>
<pre><code class="language-python"># debtmap:ignore[complexity] -- Performance-critical hot path
def optimize_query(params):
    # Complex but necessary for performance
    pass
</code></pre>
<pre><code class="language-typescript">// debtmap:ignore-next-line -- Waiting on upstream library fix
function workaroundBug() {
    // FIXME: Remove when library v3.0 is released
}
</code></pre>
<p><strong>Best Practice</strong>: Always include reasons for suppressions. This helps future maintainers understand the context and know when suppressions can be removed.</p>
<h2 id="config-file-exclusions"><a class="header" href="#config-file-exclusions">Config File Exclusions</a></h2>
<p>For broader exclusions, use the <code>[ignore]</code> section in <code>.debtmap.toml</code>:</p>
<h3 id="file-pattern-exclusions"><a class="header" href="#file-pattern-exclusions">File Pattern Exclusions</a></h3>
<pre><code class="language-toml">[ignore]
patterns = [
    "target/**",              # Build artifacts
    "node_modules/**",        # Dependencies
    "**/*_test.rs",           # Test files with _test suffix
    "tests/**",               # All test directories
    "**/fixtures/**",         # Test fixtures
    "**/mocks/**",            # Mock implementations
    "**/*.min.js",            # Minified files
    "**/demo/**",             # Demo code
    "**/*.generated.rs",      # Generated files
    "vendor/**",              # Vendor code
    "third_party/**",         # Third-party code
]
</code></pre>
<h3 id="function-name-exclusions-planned"><a class="header" href="#function-name-exclusions-planned">Function Name Exclusions (Planned)</a></h3>
<blockquote>
<p><strong>Note:</strong> Function-level exclusions by name pattern are not yet implemented. This is a planned feature for a future release.</p>
</blockquote>
<p>When implemented, you will be able to exclude entire function families by name pattern:</p>
<pre><code class="language-toml"># Planned feature - not yet available
[ignore.functions]
patterns = [
    # Test setup functions
    "setup_test_*",
    "teardown_test_*",
    "create_test_*",
    "mock_*",

    # Generated code
    "derive_*",
    "__*",                    # Python dunder methods

    # CLI parsing (naturally complex)
    "parse_args",
    "parse_cli",
    "build_cli",

    # Serialization (naturally complex pattern matching)
    "serialize_*",
    "deserialize_*",
    "to_json",
    "from_json",
]
</code></pre>
<p><strong>Current workaround:</strong> Use inline suppression comments (<code>debtmap:ignore</code>) for specific functions, or use file pattern exclusions to exclude entire test files.</p>
<h2 id="glob-pattern-syntax"><a class="header" href="#glob-pattern-syntax">Glob Pattern Syntax</a></h2>
<p>File patterns use standard glob syntax:</p>
<div class="table-wrapper"><table><thead><tr><th>Pattern</th><th>Matches</th><th>Example</th></tr></thead><tbody>
<tr><td><code>*</code></td><td>Any characters within a path component</td><td><code>*.rs</code> matches <code>main.rs</code></td></tr>
<tr><td><code>**</code></td><td>Any directories (recursive)</td><td><code>tests/**</code> matches <code>tests/unit/foo.rs</code></td></tr>
<tr><td><code>?</code></td><td>Single character</td><td><code>test?.rs</code> matches <code>test1.rs</code></td></tr>
<tr><td><code>[abc]</code></td><td>Character class</td><td><code>test[123].rs</code> matches <code>test1.rs</code></td></tr>
<tr><td><code>[!abc]</code></td><td>Negated class</td><td><code>test[!0].rs</code> matches <code>test1.rs</code> but not <code>test0.rs</code></td></tr>
</tbody></table>
</div>
<h3 id="glob-pattern-examples"><a class="header" href="#glob-pattern-examples">Glob Pattern Examples</a></h3>
<pre><code class="language-toml">[ignore]
patterns = [
    "src/**/*_generated.rs",  # Generated files in any subdirectory
    "**/test_*.py",           # Python test files anywhere
    "legacy/**/[!i]*.js",     # Legacy JS files not starting with 'i'
    "**/*.min.js",            # Minified JavaScript
    "**/*.min.css",           # Minified CSS
]
</code></pre>
<blockquote>
<p><strong>Note:</strong> Brace expansion (e.g., <code>*.{js,css}</code>) is not supported. Use separate patterns for each file extension.</p>
</blockquote>
<h2 id="language-specific-comment-syntax"><a class="header" href="#language-specific-comment-syntax">Language-Specific Comment Syntax</a></h2>
<p>Debtmap automatically uses the correct comment syntax for each language:</p>
<div class="table-wrapper"><table><thead><tr><th>Language</th><th>Comment Prefix</th><th>Example</th></tr></thead><tbody>
<tr><td>Rust</td><td><code>//</code></td><td><code>// debtmap:ignore</code></td></tr>
<tr><td>JavaScript</td><td><code>//</code></td><td><code>// debtmap:ignore</code></td></tr>
<tr><td>TypeScript</td><td><code>//</code></td><td><code>// debtmap:ignore</code></td></tr>
<tr><td>Python</td><td><code>#</code></td><td><code># debtmap:ignore</code></td></tr>
</tbody></table>
</div>
<p>You don‚Äôt need to configure this‚ÄîDebtmap detects the language and uses the appropriate syntax.</p>
<h2 id="explicitly-specified-files"><a class="header" href="#explicitly-specified-files">Explicitly Specified Files</a></h2>
<p><strong>Important behavior</strong>: When you analyze a specific file directly, ignore patterns are bypassed:</p>
<pre><code class="language-bash"># Respects [ignore] patterns in .debtmap.toml
debtmap analyze .
debtmap analyze src/

# Bypasses ignore patterns - analyzes the file even if patterns would exclude it
debtmap analyze src/test_helper.rs
</code></pre>
<p>This ensures you can always analyze specific files when needed, even if they match an ignore pattern.</p>
<h2 id="suppression-statistics"><a class="header" href="#suppression-statistics">Suppression Statistics</a></h2>
<p>Debtmap internally tracks suppression usage during analysis:</p>
<ul>
<li><strong>Total suppressions</strong>: Count of active suppressions across all files</li>
<li><strong>Suppressions by type</strong>: How many of each debt type are suppressed</li>
<li><strong>Unclosed blocks</strong>: Detection of <code>ignore-start</code> without matching <code>ignore-end</code></li>
</ul>
<p><strong>Current Status</strong>: These statistics are tracked internally but not yet exposed through the CLI. Future releases may add a dedicated command to view suppression metrics.</p>
<p><strong>Auditing Suppressions Now</strong>: You can audit your suppressions using standard tools:</p>
<pre><code class="language-bash"># Find all suppressions in Rust code
rg "debtmap:ignore" --type rust

# Count suppressions by type
rg "debtmap:ignore\[" --type rust | grep -o "\[.*\]" | sort | uniq -c

# Find unclosed blocks
rg "debtmap:ignore-start" --type rust -A 100 | grep -v "debtmap:ignore-end"

# List files with suppressions
rg "debtmap:ignore" --files-with-matches
</code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="use-suppressions-sparingly"><a class="header" href="#use-suppressions-sparingly">Use Suppressions Sparingly</a></h3>
<p>Suppressions hide information, so use them intentionally:</p>
<p>‚úÖ <strong>Good use cases:</strong></p>
<ul>
<li>Test fixtures and mock data</li>
<li>Known technical debt with an accepted timeline</li>
<li>Intentional complexity for performance</li>
<li>False positives specific to your domain</li>
</ul>
<p>‚ùå <strong>Poor use cases:</strong></p>
<ul>
<li>Hiding all debt to make reports look clean</li>
<li>Suppressing instead of fixing simple issues</li>
<li>Using wildcards when specific types would work</li>
</ul>
<h3 id="always-include-reasons"><a class="header" href="#always-include-reasons">Always Include Reasons</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚úÖ Good: Clear reason and timeline
// debtmap:ignore[complexity] -- Hot path optimization, profiled and necessary
fn fast_algorithm() { }

// ‚ùå Bad: No context for future maintainers
// debtmap:ignore
fn fast_algorithm() { }
<span class="boring">}</span></code></pre></pre>
<h3 id="prefer-specific-over-broad"><a class="header" href="#prefer-specific-over-broad">Prefer Specific Over Broad</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚úÖ Good: Only suppress the specific debt type
// debtmap:ignore[todo] -- Remove after v2.0 migration
// TODO: Migrate to new API

// ‚ùå Bad: Suppresses everything, including real issues
// debtmap:ignore
// TODO: Migrate to new API
<span class="boring">}</span></code></pre></pre>
<h3 id="use-config-for-systematic-exclusions"><a class="header" href="#use-config-for-systematic-exclusions">Use Config for Systematic Exclusions</a></h3>
<p>For patterns that apply project-wide, use <code>.debtmap.toml</code> instead of inline comments:</p>
<pre><code class="language-toml"># ‚úÖ Good: One config applies to all test files
[ignore]
patterns = ["tests/**"]

# ‚ùå Bad: Repetitive inline suppressions in every test file
</code></pre>
<h3 id="review-suppressions-periodically"><a class="header" href="#review-suppressions-periodically">Review Suppressions Periodically</a></h3>
<p>Suppressions can become outdated:</p>
<ul>
<li>Remove suppressions when the reason no longer applies</li>
<li>Check if suppressed debt can now be fixed</li>
<li>Verify reasons are still accurate after refactoring</li>
</ul>
<p><strong>Solution:</strong> Periodically search for suppressions:</p>
<pre><code class="language-bash">rg "debtmap:ignore" --type rust
</code></pre>
<h3 id="ensure-blocks-are-closed"><a class="header" href="#ensure-blocks-are-closed">Ensure Blocks Are Closed</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚úÖ Good: Properly closed block
// debtmap:ignore-start
fn test_setup() { }
// debtmap:ignore-end

// ‚ùå Bad: Unclosed block affects all subsequent code
// debtmap:ignore-start
fn test_setup() { }
// (missing ignore-end)
<span class="boring">}</span></code></pre></pre>
<p>Debtmap detects unclosed blocks and can warn you about them.</p>
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="suppressing-test-code"><a class="header" href="#suppressing-test-code">Suppressing Test Code</a></h3>
<pre><code class="language-toml"># In .debtmap.toml
[ignore]
patterns = [
    "tests/**/*",
    "**/*_test.rs",
    "**/test_*.py",
    "**/fixtures/**",
]
</code></pre>
<p>For test functions within production files, use inline suppressions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    // debtmap:ignore-start -- Test code
    fn setup_test_environment() { }
    // debtmap:ignore-end
}
<span class="boring">}</span></code></pre></pre>
<h3 id="suppressing-generated-code"><a class="header" href="#suppressing-generated-code">Suppressing Generated Code</a></h3>
<pre><code class="language-toml">[ignore]
patterns = [
    "**/*_generated.*",
    "**/proto/**",
    "**/bindings/**",
]
</code></pre>
<h3 id="temporary-suppressions-with-timeline"><a class="header" href="#temporary-suppressions-with-timeline">Temporary Suppressions with Timeline</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore[complexity] -- TODO: Refactor during Q2 2025 sprint
fn legacy_payment_processor() {
    // Complex legacy code scheduled for refactoring
}
<span class="boring">}</span></code></pre></pre>
<h3 id="suppressing-false-positives"><a class="header" href="#suppressing-false-positives">Suppressing False Positives</a></h3>
<pre><code class="language-python"># debtmap:ignore[duplication] -- Similar but semantically different
def calculate_tax_us():
    # US tax calculation
    pass

# debtmap:ignore[duplication] -- Similar but semantically different
def calculate_tax_eu():
    # EU tax calculation with different rules
    pass
</code></pre>
<h3 id="conditional-suppression"><a class="header" href="#conditional-suppression">Conditional Suppression</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
// debtmap:ignore[complexity]
fn test_helper() {
    // Complex test setup is acceptable
}
<span class="boring">}</span></code></pre></pre>
<h3 id="suppression-with-detailed-justification"><a class="header" href="#suppression-with-detailed-justification">Suppression with Detailed Justification</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore[complexity] -- Required by specification XYZ-123
// This function implements the state machine defined in spec XYZ-123.
// Complexity is inherent to the specification and cannot be reduced
// without violating requirements.
fn state_machine() { ... }
<span class="boring">}</span></code></pre></pre>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<h3 id="suppression-not-working"><a class="header" href="#suppression-not-working">Suppression Not Working</a></h3>
<ol>
<li><strong>Check comment syntax</strong>: Ensure you‚Äôre using the correct comment prefix for your language (<code>//</code> for Rust/JS/TS, <code>#</code> for Python)</li>
<li><strong>Verify spelling</strong>: It‚Äôs <code>debtmap:ignore</code>, not <code>debtmap-ignore</code> or <code>debtmap_ignore</code></li>
<li><strong>Check line matching</strong>: For same-line suppressions, ensure the debt is on the same line as the comment</li>
<li><strong>Verify type names</strong>: Use <code>todo</code>, <code>fixme</code>, <code>complexity</code>, etc. (lowercase)</li>
</ol>
<p><strong>Common syntax errors:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Wrong: debtmap: ignore (space after colon)
// Right: debtmap:ignore

// Wrong: debtmap:ignore[Complexity] (capital C)
// Right: debtmap:ignore[complexity]
<span class="boring">}</span></code></pre></pre>
<p><strong>Check placement:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Wrong: comment after code
fn function() { } // debtmap:ignore

// Right: comment before code
// debtmap:ignore
fn function() { }
<span class="boring">}</span></code></pre></pre>
<h3 id="unclosed-block-warning"><a class="header" href="#unclosed-block-warning">Unclosed Block Warning</a></h3>
<p>If you see warnings about unclosed blocks:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Problem: Missing ignore-end
// debtmap:ignore-start
fn test_helper() { }
// (Should have debtmap:ignore-end here)

// Solution: Add the closing marker
// debtmap:ignore-start
fn test_helper() { }
// debtmap:ignore-end
<span class="boring">}</span></code></pre></pre>
<h3 id="file-still-being-analyzed"><a class="header" href="#file-still-being-analyzed">File Still Being Analyzed</a></h3>
<p>If a file in your ignore patterns is still being analyzed:</p>
<ol>
<li>Check if you‚Äôre analyzing the specific file directly (bypasses ignore patterns)</li>
<li>Verify the glob pattern matches the file path</li>
<li>Check for typos in the pattern</li>
<li>Test the pattern in isolation</li>
</ol>
<p><strong>Test pattern with find:</strong></p>
<pre><code class="language-bash">find . -path "tests/**/*" -type f
</code></pre>
<p><strong>Use double asterisk for subdirectories:</strong></p>
<pre><code class="language-toml"># Wrong: "tests/*" (only direct children)
# Right: "tests/**/*" (all descendants)
</code></pre>
<p><strong>Check relative paths:</strong></p>
<pre><code class="language-toml"># Patterns are relative to project root
patterns = [
    "src/legacy/**",  # ‚úì Correct
    "/src/legacy/**", # ‚úó Wrong (absolute path)
]
</code></pre>
<h3 id="function-suppression-not-working"><a class="header" href="#function-suppression-not-working">Function Suppression Not Working</a></h3>
<p>Function-level exclusions by name pattern are not yet implemented. To suppress specific functions:</p>
<ol>
<li>Use inline suppressions: <code>// debtmap:ignore</code> before the function</li>
<li>Use block suppressions: <code>// debtmap:ignore-start</code> ‚Ä¶ <code>// debtmap:ignore-end</code></li>
<li>Exclude entire files using <code>[ignore]</code> patterns if the functions are in dedicated files</li>
</ol>
<h2 id="related-topics-1"><a class="header" href="#related-topics-1">Related Topics</a></h2>
<ul>
<li><a href="configuration.html">Configuration</a> - Full <code>.debtmap.toml</code> reference</li>
<li><a href="cli-reference.html">CLI Reference</a> - Command-line analysis options</li>
<li><a href="analysis-guide.html">Analysis Guide</a> - Understanding debt detection</li>
<li><a href="output-formats.html">Output Formats</a> - Viewing suppressed items in reports</li>
</ul>
<h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<p>Suppressions help you focus on actionable technical debt:</p>
<ul>
<li><strong>Inline comments</strong>: <code>debtmap:ignore</code>, <code>ignore-next-line</code>, <code>ignore-start/end</code></li>
<li><strong>Type-specific</strong>: Use <code>[type1,type2]</code> to suppress selectively</li>
<li><strong>Reasons</strong>: Always use <code>-- reason</code> to document why</li>
<li><strong>Config patterns</strong>: Use <code>.debtmap.toml</code> for systematic file exclusions</li>
<li><strong>Best practices</strong>: Use sparingly, prefer specific over broad, review periodically</li>
</ul>
<p>With proper use of suppressions, your Debtmap reports show only the debt that matters to your team.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="output-formats-2"><a class="header" href="#output-formats-2">Output Formats</a></h1>
<p>Debtmap provides multiple output formats to suit different workflows, from interactive terminal reports to machine-readable JSON for CI/CD integration. This chapter covers all available formats and how to use them effectively.</p>
<h2 id="format-selection"><a class="header" href="#format-selection">Format Selection</a></h2>
<p>Select the output format using the <code>-f</code> or <code>--format</code> flag:</p>
<pre><code class="language-bash"># Terminal output (default) - human-readable with colors
debtmap analyze .

# JSON output - machine-readable for tooling
debtmap analyze . --format json

# Markdown output - documentation and reports
debtmap analyze . --format markdown
</code></pre>
<p>Available formats:</p>
<ul>
<li><strong>terminal</strong> (default): Interactive output with colors, emoji, and formatting</li>
<li><strong>json</strong>: Structured data for programmatic processing</li>
<li><strong>markdown</strong>: Reports suitable for documentation and PR comments</li>
</ul>
<blockquote>
<p><strong>Note:</strong> The codebase also includes an <code>Html</code> format variant in <code>src/core/types.rs</code> and <code>src/analysis/diagnostics/</code>, but this is only available internally for diagnostic reporting and is not exposed as a CLI option. For HTML output, convert markdown reports using tools like pandoc (see <a href="output-formats.html#rendering-to-htmlpdf">Rendering to HTML/PDF</a>).</p>
</blockquote>
<h3 id="writing-to-files"><a class="header" href="#writing-to-files">Writing to Files</a></h3>
<p>By default, output goes to stdout. Use <code>-o</code> or <code>--output</code> to write to a file:</p>
<pre><code class="language-bash"># Write JSON to file
debtmap analyze . --format json -o report.json

# Write markdown report
debtmap analyze . --format markdown -o DEBT_REPORT.md

# Terminal output to file (preserves colors)
debtmap analyze . -o analysis.txt
</code></pre>
<h2 id="terminal-output"><a class="header" href="#terminal-output">Terminal Output</a></h2>
<p>The terminal format provides an interactive, color-coded report designed for developer workflows. It‚Äôs the default format and optimized for readability.</p>
<h3 id="output-structure"><a class="header" href="#output-structure">Output Structure</a></h3>
<p>Terminal output is organized into five main sections:</p>
<ol>
<li><strong>Header</strong> - Analysis report title</li>
<li><strong>Codebase Summary</strong> - High-level metrics and debt score</li>
<li><strong>Complexity Hotspots</strong> - Top 5 most complex functions with refactoring guidance</li>
<li><strong>Technical Debt</strong> - High-priority debt items requiring attention</li>
<li><strong>Pass/Fail Status</strong> - Overall quality assessment</li>
</ol>
<h3 id="example-terminal-output"><a class="header" href="#example-terminal-output">Example Terminal Output</a></h3>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
           DEBTMAP ANALYSIS REPORT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä CODEBASE Summary
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Files analyzed:      42
  Total functions:     287
  Average complexity:  6.3
  Debt items:          15
  Total debt score:    156 (threshold: 100)

‚ö†Ô∏è  COMPLEXITY HOTSPOTS (Top 5)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  1. src/analyzers/rust.rs:245 parse_function() - Cyclomatic: 18, Cognitive: 24
     ACTION: Extract 3-5 pure functions using decompose-then-transform strategy
     PATTERNS: Decompose into logical units, then apply functional patterns
     BENEFIT: Pure functions are easily testable and composable

  2. src/debt/smells.rs:196 detect_data_clumps() - Cyclomatic: 15, Cognitive: 20
     ‚Üì Entropy: 0.32, Repetition: 85%, Effective: 0.6x
       High pattern repetition detected (85%)

üîß TECHNICAL DEBT (15 items)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  High Priority (5):
    - src/risk/scoring.rs:142 - TODO: Implement caching for score calculations
    - src/core/metrics.rs:89 - High complexity: cyclomatic=16
    - src/debt/patterns.rs:201 - Code duplication: 65 lines duplicated

‚úì Pass/Fail: PASS
</code></pre>
<h3 id="color-coding-and-symbols"><a class="header" href="#color-coding-and-symbols">Color Coding and Symbols</a></h3>
<p>The terminal output uses colors and symbols for quick visual scanning:</p>
<p><strong>Status Indicators:</strong></p>
<ul>
<li>‚úì Green: Passing, good, well-tested</li>
<li>‚ö†Ô∏è  Yellow: Warning, moderate complexity</li>
<li>‚úó Red: Failing, critical, high complexity</li>
<li>üìä Blue: Information, metrics</li>
<li>üîß Orange: Technical debt items</li>
<li>üéØ Cyan: Recommendations</li>
</ul>
<p><strong>Complexity Classification:</strong></p>
<ul>
<li><strong>LOW</strong> (0-5): Green - Simple, easy to maintain</li>
<li><strong>MODERATE</strong> (6-10): Yellow - Consider refactoring</li>
<li><strong>HIGH</strong> (11-15): Orange - Should refactor</li>
<li><strong>SEVERE</strong> (&gt;15): Red - Urgent refactoring needed</li>
</ul>
<blockquote>
<p><strong>Note:</strong> These levels match the <code>ComplexityLevel</code> enum in the implementation.</p>
</blockquote>
<p><strong>Debt Score Thresholds:</strong></p>
<p>The default debt threshold is <strong>100</strong>. Scores are colored based on this threshold:</p>
<ul>
<li><strong>Green (‚â§50)</strong>: Healthy - Below half threshold (score ‚â§ threshold/2)</li>
<li><strong>Yellow (51-100)</strong>: Attention needed - Between half and full threshold (threshold/2 &lt; score ‚â§ threshold)</li>
<li><strong>Red (&gt;100)</strong>: Action required - Exceeds threshold (score &gt; threshold)</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Boundary values use strict inequalities: 50 is Green, 100 is Yellow (not Red), 101+ is Red.</p>
</blockquote>
<h3 id="refactoring-guidance"><a class="header" href="#refactoring-guidance">Refactoring Guidance</a></h3>
<p>For complex functions (cyclomatic complexity &gt; 5), the terminal output provides actionable refactoring recommendations:</p>
<pre><code>ACTION: Extract 3-5 pure functions using decompose-then-transform strategy
PATTERNS: Decompose into logical units, then apply functional patterns
BENEFIT: Pure functions are easily testable and composable
</code></pre>
<p>Guidance levels:</p>
<ul>
<li><strong>Moderate</strong> (6-10): Extract 2-3 pure functions using direct functional transformation</li>
<li><strong>High</strong> (11-15): Extract 3-5 pure functions using decompose-then-transform strategy</li>
<li><strong>Severe</strong> (&gt;15): Extract 5+ pure functions into modules with functional core/imperative shell</li>
</ul>
<p>See the <a href="./analysis-guide.html">Analysis Guide</a> for metric explanations.</p>
<h3 id="plain-terminal-mode"><a class="header" href="#plain-terminal-mode">Plain Terminal Mode</a></h3>
<p>For environments without color support or when piping to tools, use <code>--plain</code>:</p>
<pre><code class="language-bash"># ASCII-only output, no colors
debtmap analyze . --plain
</code></pre>
<p>Plain mode:</p>
<ul>
<li>Removes ANSI color codes</li>
<li>Uses ASCII box-drawing characters</li>
<li>Machine-parseable structure</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Terminal output formatting is controlled internally via <code>FormattingConfig</code> (found in <code>src/formatting</code> and <code>src/io/writers/terminal.rs</code>), which manages color mode settings. The <code>--plain</code> flag and environment variables provide user-facing control over these settings:</p>
<ul>
<li><code>--plain</code> flag - Disables colors and fancy formatting</li>
<li><code>NO_COLOR=1</code> - Disables colors (per <a href="https://no-color.org">no-color.org</a> standard)</li>
<li><code>CLICOLOR=0</code> - Disables colors</li>
<li><code>CLICOLOR_FORCE=1</code> - Forces colors even when output is not a terminal</li>
</ul>
<p><code>FormattingConfig</code> is not directly exposed to CLI users but can be accessed when using debtmap as a library through <code>TerminalWriter::with_formatting</code>.</p>
</blockquote>
<h3 id="verbosity-levels"><a class="header" href="#verbosity-levels">Verbosity Levels</a></h3>
<p>Control detail level with <code>-v</code> flags (can be repeated):</p>
<pre><code class="language-bash"># Standard output
debtmap analyze .

# Level 1: Show main score factors
debtmap analyze . -v

# Level 2: Show detailed calculations
debtmap analyze . -vv

# Level 3: Show all debug information
debtmap analyze . -vvv
</code></pre>
<p><strong>Verbosity features:</strong></p>
<ul>
<li><code>-v</code>: Show main score factors (complexity, coverage, dependency breakdown)</li>
<li><code>-vv</code>: Show detailed calculations with formulas and intermediate values</li>
<li><code>-vvv</code>: Show all debug information including entropy metrics, role detection, and cache hits</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Verbosity flags affect terminal output only. JSON and markdown formats include all data regardless of verbosity level.</p>
</blockquote>
<p>Each level includes all information from the previous levels, progressively adding more detail to help understand how scores are calculated.</p>
<p><strong>Example Output Differences:</strong></p>
<p>Standard output shows basic metrics:</p>
<pre><code>Total debt score: 156 (threshold: 100)
</code></pre>
<p>Level 1 (<code>-v</code>) adds score breakdowns:</p>
<pre><code>Total debt score: 156 (threshold: 100)
  Complexity contribution: 85 (54%)
  Coverage gaps: 45 (29%)
  Dependency issues: 26 (17%)
</code></pre>
<p>Level 2 (<code>-vv</code>) adds detailed calculations:</p>
<pre><code>Total debt score: 156 (threshold: 100)
  Complexity contribution: 85 (54%)
    Formula: sum(cyclomatic_weight * severity_multiplier)
    High complexity functions: 5 √ó 12 = 60
    Medium complexity: 8 √ó 3 = 24
    Base penalty: 1
  Coverage gaps: 45 (29%)
    Uncovered complex functions: 3 √ó 15 = 45
</code></pre>
<p>Level 3 (<code>-vvv</code>) adds all internal details:</p>
<pre><code>Total debt score: 156 (threshold: 100)
  ... (all level 2 output) ...
  Debug info:
    Entropy metrics cached: 42/50 functions
    Function role detection: BusinessLogic=12, Utility=8, TestHelper=5
    Cache hit rate: 84%
</code></pre>
<h3 id="understanding-metrics-1"><a class="header" href="#understanding-metrics-1">Understanding Metrics</a></h3>
<p>To get detailed explanations of how metrics are calculated, use the <code>--explain-metrics</code> flag:</p>
<pre><code class="language-bash"># Get explanations of metric definitions and formulas
debtmap analyze . --explain-metrics
</code></pre>
<p>This flag provides:</p>
<ul>
<li><strong>Metric definitions</strong> - Detailed explanations of what each metric measures</li>
<li><strong>Calculation formulas</strong> - How scores are computed from raw data</li>
<li><strong>Measured vs estimated</strong> - Which metrics are exact and which are heuristic-based</li>
<li><strong>Interpretation guidance</strong> - How to understand and act on metric values</li>
</ul>
<p>The explanations appear inline with the analysis output, helping you understand:</p>
<ul>
<li>What cyclomatic and cognitive complexity measure</li>
<li>How debt scores are calculated</li>
<li>What entropy metrics indicate</li>
<li>How risk scores are determined</li>
</ul>
<p>This is particularly useful when:</p>
<ul>
<li>Learning how debtmap evaluates code quality</li>
<li>Understanding why certain functions have high scores</li>
<li>Explaining analysis results to team members</li>
<li>Tuning thresholds based on metric meanings</li>
</ul>
<h3 id="risk-analysis-output"><a class="header" href="#risk-analysis-output">Risk Analysis Output</a></h3>
<p>When coverage data is provided via <code>--lcov</code>, terminal output includes a dedicated risk analysis section:</p>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
           RISK ANALYSIS REPORT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìà RISK Summary
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Codebase Risk Score: 45.5 (MEDIUM)
Complexity-Coverage Correlation: -0.65

Risk Distribution:
  Critical: 2 functions
  High: 5 functions
  Medium: 10 functions
  Low: 15 functions
  Well Tested: 20 functions

üéØ CRITICAL RISKS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1. src/core/parser.rs:142 parse_complex_ast()
   Risk: 85.0 | Complexity: 15 | Coverage: 0%
   Recommendation: Add 5 unit tests (est: 2-3 hours)
   Impact: -40 risk reduction

üí° RECOMMENDATIONS (by ROI)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1. test_me() - ROI: 5.0x
   Current Risk: 75 | Reduction: 40 | Effort: Moderate
   Rationale: High risk function with low coverage
</code></pre>
<p><strong>Risk Level Classification:</strong></p>
<ul>
<li><strong>LOW</strong> (&lt;30): Green - score &lt; 30.0</li>
<li><strong>MEDIUM</strong> (30-59): Yellow - 30.0 ‚â§ score &lt; 60.0</li>
<li><strong>HIGH</strong> (‚â•60): Red - score ‚â• 60.0</li>
</ul>
<blockquote>
<p><strong>Note:</strong> 60 is the start of HIGH risk level.</p>
</blockquote>
<h2 id="json-output"><a class="header" href="#json-output">JSON Output</a></h2>
<p>JSON output provides complete analysis results in a machine-readable format, ideal for CI/CD pipelines, custom tooling, and programmatic analysis.</p>
<h3 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h3>
<pre><code class="language-bash"># Generate JSON output
debtmap analyze . --format json

# Save to file
debtmap analyze . --format json -o report.json

# Pretty-printed by default for readability
debtmap analyze . --format json | jq .
</code></pre>
<blockquote>
<p><strong>Note:</strong> JSON output is automatically pretty-printed for readability.</p>
</blockquote>
<h3 id="json-schema-structure"><a class="header" href="#json-schema-structure">JSON Schema Structure</a></h3>
<p>Debtmap outputs a structured JSON document with the following top-level fields:</p>
<pre><code class="language-json">{
  "project_path": "/path/to/project",
  "timestamp": "2025-01-09T12:00:00Z",
  "complexity": { ... },
  "technical_debt": { ... },
  "dependencies": { ... },
  "duplications": [ ... ]
}
</code></pre>
<h3 id="full-schema-example"><a class="header" href="#full-schema-example">Full Schema Example</a></h3>
<p>Here‚Äôs a complete annotated JSON output example:</p>
<pre><code class="language-json">{
  // Project metadata
  "project_path": "/Users/dev/myproject",
  "timestamp": "2025-01-09T15:30:00Z",

  // Complexity analysis results
  "complexity": {
    "metrics": [
      {
        "name": "calculate_risk_score",
        "file": "src/risk/scoring.rs",
        "line": 142,
        "cyclomatic": 12,
        "cognitive": 18,
        "nesting": 4,
        "length": 85,
        "is_test": false,
        "visibility": "pub",
        "is_trait_method": false,
        "in_test_module": false,
        "entropy_score": {
          "token_entropy": 0.65,
          "pattern_repetition": 0.30,
          "branch_similarity": 0.45,
          "effective_complexity": 0.85
        },
        "is_pure": false,
        "purity_confidence": 0.75,
        "detected_patterns": ["nested_loops", "complex_conditionals"],
        "upstream_callers": ["analyze_codebase", "generate_report"],
        "downstream_callees": ["get_metrics", "apply_weights"]
      }
    ],
    "summary": {
      "total_functions": 287,
      "average_complexity": 6.3,
      "max_complexity": 24,
      "high_complexity_count": 12
    }
  },

  // Technical debt items
  "technical_debt": {
    "items": [
      {
        "id": "debt_001",
        "debt_type": "Complexity",
        "priority": "High",
        "file": "src/analyzers/rust.rs",
        "line": 245,
        "column": 5,
        "message": "High cyclomatic complexity: 18",
        "context": "Function parse_function has excessive branching"
      },
      {
        "id": "debt_002",
        "debt_type": "Todo",
        "priority": "Medium",
        "file": "src/core/cache.rs",
        "line": 89,
        "column": null,
        "message": "TODO: Implement LRU eviction policy",
        "context": null
      }
    ],
    "by_type": {
      "Complexity": [ /* same structure as items */ ],
      "Todo": [ /* ... */ ],
      "Duplication": [ /* ... */ ]
    },
    "priorities": ["Low", "Medium", "High", "Critical"]
  },

  // Dependency analysis
  "dependencies": {
    "modules": [
      {
        "module": "risk::scoring",
        "dependencies": ["core::metrics", "debt::patterns"],
        "dependents": ["commands::analyze", "io::output"]
      }
    ],
    "circular": [
      {
        "cycle": ["module_a", "module_b", "module_c", "module_a"]
      }
    ]
  },

  // Code duplication blocks
  "duplications": [
    {
      "hash": "abc123def456",
      "lines": 15,
      "locations": [
        {
          "file": "src/parser/rust.rs",
          "start_line": 42,
          "end_line": 57
        },
        {
          "file": "src/parser/python.rs",
          "start_line": 89,
          "end_line": 104
        }
      ]
    }
  ]
}
</code></pre>
<h3 id="field-descriptions"><a class="header" href="#field-descriptions">Field Descriptions</a></h3>
<p><strong>FunctionMetrics Fields:</strong></p>
<ul>
<li>
<p><code>name</code>: Function name</p>
</li>
<li>
<p><code>file</code>: Path to source file</p>
</li>
<li>
<p><code>line</code>: Line number where function is defined</p>
</li>
<li>
<p><code>cyclomatic</code>: Cyclomatic complexity score</p>
</li>
<li>
<p><code>cognitive</code>: Cognitive complexity score</p>
</li>
<li>
<p><code>nesting</code>: Maximum nesting depth</p>
</li>
<li>
<p><code>length</code>: Lines of code in function</p>
</li>
<li>
<p><code>is_test</code>: Whether this is a test function</p>
</li>
<li>
<p><code>visibility</code>: Rust visibility modifier (pub, pub(crate), or null)</p>
</li>
<li>
<p><code>is_trait_method</code>: Whether this implements a trait</p>
</li>
<li>
<p><code>in_test_module</code>: Whether inside #[cfg(test)]</p>
</li>
<li>
<p><code>entropy_score</code>: Optional entropy analysis with structure:</p>
<pre><code class="language-json">{
  "token_entropy": 0.65,        // Token distribution entropy (0-1): measures variety of tokens
  "pattern_repetition": 0.30,   // Pattern repetition score (0-1): detects repeated code patterns
  "branch_similarity": 0.45,    // Branch similarity metric (0-1): compares similarity between branches
  "effective_complexity": 0.85  // Adjusted complexity multiplier: complexity adjusted for entropy
}
</code></pre>
<p><strong>EntropyScore Fields:</strong></p>
<ul>
<li><code>token_entropy</code>: Measures the variety and distribution of tokens in the function (0-1, higher = more variety)</li>
<li><code>pattern_repetition</code>: Detects repeated code patterns within the function (0-1, higher = more repetition)</li>
<li><code>branch_similarity</code>: Measures similarity between different code branches (0-1, higher = more similar)</li>
<li><code>effective_complexity</code>: The overall complexity multiplier adjusted for entropy effects</li>
</ul>
</li>
<li>
<p><code>is_pure</code>: Whether function is pure (no side effects)</p>
</li>
<li>
<p><code>purity_confidence</code>: Confidence level (0.0-1.0)</p>
</li>
<li>
<p><code>detected_patterns</code>: List of detected code patterns</p>
</li>
<li>
<p><code>upstream_callers</code>: Functions that call this one</p>
</li>
<li>
<p><code>downstream_callees</code>: Functions this one calls</p>
</li>
</ul>
<p><strong>DebtItem Fields:</strong></p>
<ul>
<li><code>id</code>: Unique identifier</li>
<li><code>debt_type</code>: Type of debt (see DebtType enum below)</li>
<li><code>priority</code>: Priority level (Low, Medium, High, Critical)</li>
<li><code>file</code>: Path to file containing debt</li>
<li><code>line</code>: Line number</li>
<li><code>column</code>: Optional column number</li>
<li><code>message</code>: Human-readable description</li>
<li><code>context</code>: Optional additional context</li>
</ul>
<p><strong>DebtType Enum:</strong></p>
<ul>
<li><code>Todo</code>: TODO markers</li>
<li><code>Fixme</code>: FIXME markers</li>
<li><code>CodeSmell</code>: Code smell patterns</li>
<li><code>Duplication</code>: Duplicated code</li>
<li><code>Complexity</code>: Excessive complexity</li>
<li><code>Dependency</code>: Dependency issues</li>
<li><code>ErrorSwallowing</code>: Suppressed errors</li>
<li><code>ResourceManagement</code>: Resource management issues</li>
<li><code>CodeOrganization</code>: Organizational problems</li>
<li><code>TestComplexity</code>: Complex test code</li>
<li><code>TestTodo</code>: TODOs in tests</li>
<li><code>TestDuplication</code>: Duplicated test code</li>
<li><code>TestQuality</code>: Test quality issues</li>
</ul>
<h3 id="json-format-variants"><a class="header" href="#json-format-variants">JSON Format Variants</a></h3>
<p>Debtmap supports two JSON output formats:</p>
<pre><code class="language-bash"># Legacy format (default) - backward compatible
debtmap analyze . --format json --output-format legacy

# Unified format - new consistent structure
debtmap analyze . --format json --output-format unified
</code></pre>
<blockquote>
<p><strong>Note:</strong> The <code>--output-format</code> flag only applies when using <code>--format json</code>. It has no effect with markdown or terminal formats.</p>
</blockquote>
<h4 id="format-comparison"><a class="header" href="#format-comparison">Format Comparison</a></h4>
<p><strong>Legacy format:</strong> Uses <code>{File: {...}}</code> and <code>{Function: {...}}</code> wrappers for backward compatibility with existing tooling.</p>
<p><strong>Unified format:</strong> Consistent structure with a <code>type</code> field, making parsing simpler and more predictable. Recommended for new integrations.</p>
<p><strong>When to use each format:</strong></p>
<ul>
<li>
<p><strong>Use legacy format if:</strong></p>
<ul>
<li>You have existing tooling that expects the old structure</li>
<li>You need backward compatibility with version 1.x parsers</li>
<li>You‚Äôre integrating with third-party tools expecting the legacy format</li>
</ul>
</li>
<li>
<p><strong>Use unified format for:</strong></p>
<ul>
<li>All new integrations and tooling</li>
<li>Cleaner, more predictable JSON parsing</li>
<li>Future-proof implementations</li>
<li>Simpler type discrimination in statically-typed languages</li>
</ul>
</li>
</ul>
<p><strong>Migration strategy:</strong></p>
<p>The legacy format will be maintained for backward compatibility, but unified is the recommended format going forward. If you‚Äôre starting a new integration, use unified format from the beginning. If migrating existing tooling:</p>
<ol>
<li>Test unified format with a subset of your codebase</li>
<li>Update parsers to handle the <code>type</code> field instead of key-based discrimination</li>
<li>Validate results match between legacy and unified formats</li>
<li>Switch to unified format once validation passes</li>
</ol>
<h4 id="structural-differences"><a class="header" href="#structural-differences">Structural Differences</a></h4>
<p><strong>Legacy format example:</strong></p>
<pre><code class="language-json">{
  "complexity": {
    "metrics": [
      {
        "File": {
          "path": "src/main.rs",
          "functions": 12,
          "average_complexity": 5.3
        }
      },
      {
        "Function": {
          "name": "calculate_score",
          "file": "src/scoring.rs",
          "line": 42,
          "cyclomatic": 8
        }
      }
    ]
  }
}
</code></pre>
<p><strong>Unified format example:</strong></p>
<pre><code class="language-json">{
  "complexity": {
    "metrics": [
      {
        "type": "File",
        "path": "src/main.rs",
        "functions": 12,
        "average_complexity": 5.3
      },
      {
        "type": "Function",
        "name": "calculate_score",
        "file": "src/scoring.rs",
        "line": 42,
        "cyclomatic": 8
      }
    ]
  }
}
</code></pre>
<p><strong>Key difference:</strong> Legacy uses <code>{File: {...}}</code> wrapper objects, while unified uses a flat structure with <code>"type": "File"</code> field. This makes unified format easier to parse in most programming languages.</p>
<h3 id="risk-insights-json"><a class="header" href="#risk-insights-json">Risk Insights JSON</a></h3>
<p>When coverage data is provided via <code>--lcov</code>, risk insights are included as part of the analysis output. The <code>write_risk_insights</code> method (found in <code>src/io/writers/json.rs</code>, <code>terminal.rs</code>, and <code>markdown/core.rs</code>) outputs risk analysis data in the following JSON structure:</p>
<pre><code class="language-json">{
  "items": [
    {
      "location": {
        "file": "src/risk/scoring.rs",
        "function": "calculate_priority",
        "line": 66
      },
      "debt_type": "TestGap",
      "unified_score": {
        "complexity_factor": 3.2,
        "coverage_factor": 10.0,
        "dependency_factor": 2.5,
        "role_multiplier": 1.2,
        "final_score": 9.4
      },
      "function_role": "BusinessLogic",
      "recommendation": {
        "action": "Add unit tests",
        "details": "Add 6 unit tests for full coverage",
        "effort_estimate": "2-3 hours"
      },
      "expected_impact": {
        "risk_reduction": 3.9,
        "complexity_reduction": 0,
        "coverage_improvement": 100
      },
      "upstream_dependencies": 0,
      "downstream_dependencies": 3,
      "nesting_depth": 1,
      "function_length": 13
    }
  ],
  "call_graph": {
    "total_functions": 1523,
    "entry_points": 12,
    "test_functions": 456,
    "max_depth": 8
  },
  "overall_coverage": 82.3,
  "total_impact": {
    "risk_reduction": 45.2,
    "complexity_reduction": 12.3,
    "coverage_improvement": 18.5
  }
}
</code></pre>
<h2 id="markdown-output"><a class="header" href="#markdown-output">Markdown Output</a></h2>
<p>Markdown format generates documentation-friendly reports suitable for README files, PR comments, and technical documentation.</p>
<h3 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h3>
<pre><code class="language-bash"># Generate markdown report
debtmap analyze . --format markdown

# Save to documentation
debtmap analyze . --format markdown -o docs/DEBT_REPORT.md
</code></pre>
<h3 id="markdown-structure"><a class="header" href="#markdown-structure">Markdown Structure</a></h3>
<p>Markdown output includes:</p>
<ol>
<li><strong>Executive Summary</strong> - High-level metrics and health dashboard</li>
<li><strong>Complexity Analysis</strong> - Detailed complexity breakdown by file</li>
<li><strong>Technical Debt</strong> - Categorized debt items with priorities</li>
<li><strong>Dependencies</strong> - Module dependencies and circular references</li>
<li><strong>Recommendations</strong> - Prioritized action items</li>
</ol>
<h3 id="example-markdown-output"><a class="header" href="#example-markdown-output">Example Markdown Output</a></h3>
<pre><code class="language-markdown"># Debtmap Analysis Report

**Generated:** 2025-01-09 15:30:00 UTC
**Project:** /Users/dev/myproject

## Executive Summary

- **Files Analyzed:** 42
- **Total Functions:** 287
- **Average Complexity:** 6.3
- **Total Debt Items:** 15
- **Debt Score:** 156/100 ‚ö†Ô∏è

### Health Dashboard

| Metric | Value | Status |
|--------|-------|--------|
| Complexity | 6.3 avg | ‚úÖ Good |
| Debt Score | 156 | ‚ö†Ô∏è Attention |
| High Priority Items | 5 | ‚ö†Ô∏è Action Needed |

## Complexity Analysis

### Top 5 Complex Functions

| Function | File | Cyclomatic | Cognitive | Priority |
|----------|------|-----------|-----------|----------|
| parse_function | src/analyzers/rust.rs:245 | 18 | 24 | High |
| detect_data_clumps | src/debt/smells.rs:196 | 15 | 20 | Medium |
| analyze_dependencies | src/core/deps.rs:89 | 14 | 18 | Medium |

### Refactoring Recommendations

**src/analyzers/rust.rs:245** - `parse_function()`
- **Complexity:** Cyclomatic: 18, Cognitive: 24
- **Action:** Extract 3-5 pure functions using decompose-then-transform strategy
- **Patterns:** Decompose into logical units, then apply functional patterns
- **Benefit:** Improved testability and maintainability

## Technical Debt

### High Priority (5 items)

- **src/risk/scoring.rs:142** - TODO: Implement caching for score calculations
- **src/core/metrics.rs:89** - High complexity: cyclomatic=16
- **src/debt/patterns.rs:201** - Code duplication: 65 lines duplicated

### Medium Priority (8 items)

...

## Dependencies

### Circular Dependencies

- `risk::scoring` ‚Üí `core::metrics` ‚Üí `risk::scoring`

## Recommendations

1. **Refactor parse_function** (High Priority)
   - Reduce complexity from 18 to &lt;10
   - Extract helper functions
   - Estimated effort: 4-6 hours

2. **Add tests for scoring module** (High Priority)
   - Current coverage: 35%
   - Target coverage: 80%
   - Estimated effort: 2-3 hours
</code></pre>
<h3 id="cli-vs-library-markdown-features"><a class="header" href="#cli-vs-library-markdown-features">CLI vs Library Markdown Features</a></h3>
<p><strong>CLI Markdown Output (<code>--format markdown</code>):</strong></p>
<p>When you use <code>debtmap analyze . --format markdown</code>, you get comprehensive reports that include:</p>
<ul>
<li>Executive summary with health dashboard</li>
<li>Complexity analysis with refactoring recommendations</li>
<li>Technical debt categorization by priority</li>
<li>Dependency analysis with circular reference detection</li>
<li>Actionable recommendations</li>
</ul>
<p>This uses the base <code>MarkdownWriter</code> implementation and provides everything needed for documentation and PR comments.</p>
<p><strong>Enhanced Library Features:</strong></p>
<p>If you‚Äôre using debtmap as a Rust library in your own tools, additional markdown capabilities are available:</p>
<ul>
<li><strong><code>EnhancedMarkdownWriter</code> trait</strong> (<code>src/io/writers/markdown/enhanced.rs</code>) - Provides advanced formatting and analysis features</li>
<li><strong>Enhanced markdown modules</strong> (<code>src/io/writers/enhanced_markdown/</code>) - Building blocks for custom visualizations including:
<ul>
<li>Priority-based debt rankings with unified scoring</li>
<li>Dead code detection and reporting</li>
<li>Call graph insights and dependency visualization</li>
<li>Testing recommendations with ROI analysis</li>
</ul>
</li>
</ul>
<p>To use enhanced features in your Rust code:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::io::writers::markdown::enhanced::EnhancedMarkdownWriter;
use debtmap::io::writers::enhanced_markdown::*;

// Create custom reports with enhanced features
let mut writer = create_enhanced_writer(output)?;
writer.write_priority_rankings(&amp;analysis)?;
writer.write_dead_code_analysis(&amp;call_graph)?;
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Note:</strong> Enhanced markdown features are only available through the library API, not via the CLI. The CLI <code>--format markdown</code> output is comprehensive for most use cases.</p>
</blockquote>
<h3 id="rendering-to-htmlpdf"><a class="header" href="#rendering-to-htmlpdf">Rendering to HTML/PDF</a></h3>
<p>Markdown reports can be converted to other formats:</p>
<pre><code class="language-bash"># Generate markdown
debtmap analyze . --format markdown -o report.md

# Convert to HTML with pandoc
pandoc report.md -o report.html --standalone --css style.css

# Convert to PDF
pandoc report.md -o report.pdf --pdf-engine=xelatex
</code></pre>
<h2 id="tool-integration"><a class="header" href="#tool-integration">Tool Integration</a></h2>
<h3 id="cicd-pipelines"><a class="header" href="#cicd-pipelines">CI/CD Pipelines</a></h3>
<p>Debtmap JSON output integrates seamlessly with CI/CD systems.</p>
<h4 id="github-actions"><a class="header" href="#github-actions">GitHub Actions</a></h4>
<pre><code class="language-yaml">name: Code Quality

on: [pull_request]

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install debtmap
        run: cargo install debtmap

      - name: Run analysis
        run: |
          debtmap analyze . \
            --format json \
            --output analysis.json \
            --lcov coverage/lcov.info

      - name: Check thresholds
        run: |
          DEBT_SCORE=$(jq '.technical_debt.items | length' analysis.json)
          if [ "$DEBT_SCORE" -gt 100 ]; then
            echo "‚ùå Debt score too high: $DEBT_SCORE"
            exit 1
          fi

      - name: Comment on PR
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const analysis = JSON.parse(fs.readFileSync('analysis.json'));
            const summary = `## Debtmap Analysis

            - **Debt Items:** ${analysis.technical_debt.items.length}
            - **Average Complexity:** ${analysis.complexity.summary.average_complexity}
            - **High Complexity Functions:** ${analysis.complexity.summary.high_complexity_count}
            `;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
</code></pre>
<h4 id="gitlab-ci"><a class="header" href="#gitlab-ci">GitLab CI</a></h4>
<pre><code class="language-yaml">code_quality:
  stage: test
  script:
    - cargo install debtmap
    - debtmap analyze . --format json --output gl-code-quality.json
    - |
      DEBT=$(jq '.technical_debt.items | length' gl-code-quality.json)
      if [ "$DEBT" -gt 50 ]; then
        echo "Debt threshold exceeded"
        exit 1
      fi
  artifacts:
    reports:
      codequality: gl-code-quality.json
</code></pre>
<h4 id="jenkins-pipeline"><a class="header" href="#jenkins-pipeline">Jenkins Pipeline</a></h4>
<pre><code class="language-groovy">pipeline {
    agent any

    stages {
        stage('Analyze') {
            steps {
                sh 'debtmap analyze . --format json -o report.json'

                script {
                    def json = readJSON file: 'report.json'
                    def debtScore = json.technical_debt.items.size()

                    if (debtScore &gt; 100) {
                        error("Debt score ${debtScore} exceeds threshold")
                    }
                }
            }
        }
    }

    post {
        always {
            archiveArtifacts artifacts: 'report.json'
        }
    }
}
</code></pre>
<h3 id="querying-json-with-jq"><a class="header" href="#querying-json-with-jq">Querying JSON with jq</a></h3>
<p>Common jq queries for analyzing debtmap output:</p>
<pre><code class="language-bash"># Get total debt items
jq '.technical_debt.items | length' report.json

# Get high-priority items only
jq '.technical_debt.items[] | select(.priority == "High")' report.json

# Get functions with complexity &gt; 10
jq '.complexity.metrics[] | select(.cyclomatic &gt; 10)' report.json

# Calculate average complexity
jq '.complexity.summary.average_complexity' report.json

# Get all TODO items
jq '.technical_debt.items[] | select(.debt_type == "Todo")' report.json

# Get top 5 complex functions
jq '.complexity.metrics | sort_by(-.cyclomatic) | .[0:5] | .[] | {name, file, cyclomatic}' report.json

# Get files with circular dependencies
jq '.dependencies.circular[] | .cycle' report.json

# Count debt items by type
jq '.technical_debt.items | group_by(.debt_type) | map({type: .[0].debt_type, count: length})' report.json

# Get functions with 0% coverage (when using --lcov)
jq '.complexity.metrics[] | select(.coverage == 0)' report.json

# Extract file paths with high debt
jq '.technical_debt.items[] | select(.priority == "High" or .priority == "Critical") | .file' report.json | sort -u
</code></pre>
<h3 id="filtering-and-transformation-examples"><a class="header" href="#filtering-and-transformation-examples">Filtering and Transformation Examples</a></h3>
<h4 id="python-script-to-parse-json"><a class="header" href="#python-script-to-parse-json">Python Script to Parse JSON</a></h4>
<pre><code class="language-python">#!/usr/bin/env python3
import json
import sys

def analyze_debtmap_output(json_file):
    with open(json_file) as f:
        data = json.load(f)

    # Get high-priority items
    high_priority = [
        item for item in data['technical_debt']['items']
        if item['priority'] in ['High', 'Critical']
    ]

    # Group by file
    by_file = {}
    for item in high_priority:
        file = item['file']
        if file not in by_file:
            by_file[file] = []
        by_file[file].append(item)

    # Print summary
    print(f"High-priority debt items: {len(high_priority)}")
    print(f"Files affected: {len(by_file)}")
    print("\nBy file:")
    for file, items in sorted(by_file.items(), key=lambda x: -len(x[1])):
        print(f"  {file}: {len(items)} items")

    return by_file

if __name__ == '__main__':
    analyze_debtmap_output(sys.argv[1])
</code></pre>
<h4 id="shell-script-for-threshold-checking"><a class="header" href="#shell-script-for-threshold-checking">Shell Script for Threshold Checking</a></h4>
<pre><code class="language-bash">#!/bin/bash
set -e

REPORT="$1"
DEBT_THRESHOLD=100
COMPLEXITY_THRESHOLD=10

# Check debt score
DEBT_SCORE=$(jq '.technical_debt.items | length' "$REPORT")
if [ "$DEBT_SCORE" -gt "$DEBT_THRESHOLD" ]; then
    echo "‚ùå Debt score $DEBT_SCORE exceeds threshold $DEBT_THRESHOLD"
    exit 1
fi

# Check average complexity
AVG_COMPLEXITY=$(jq '.complexity.summary.average_complexity' "$REPORT")
if (( $(echo "$AVG_COMPLEXITY &gt; $COMPLEXITY_THRESHOLD" | bc -l) )); then
    echo "‚ùå Average complexity $AVG_COMPLEXITY exceeds threshold $COMPLEXITY_THRESHOLD"
    exit 1
fi

echo "‚úÖ All quality checks passed"
echo "   Debt score: $DEBT_SCORE/$DEBT_THRESHOLD"
echo "   Avg complexity: $AVG_COMPLEXITY"
</code></pre>
<h3 id="editor-integration"><a class="header" href="#editor-integration">Editor Integration</a></h3>
<h4 id="vs-code-tasks"><a class="header" href="#vs-code-tasks">VS Code Tasks</a></h4>
<p>Create <code>.vscode/tasks.json</code>:</p>
<pre><code class="language-json">{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "Debtmap: Analyze",
      "type": "shell",
      "command": "debtmap",
      "args": [
        "analyze",
        ".",
        "--format",
        "terminal"
      ],
      "problemMatcher": [],
      "presentation": {
        "reveal": "always",
        "panel": "new"
      }
    },
    {
      "label": "Debtmap: Generate Report",
      "type": "shell",
      "command": "debtmap",
      "args": [
        "analyze",
        ".",
        "--format",
        "markdown",
        "-o",
        "DEBT_REPORT.md"
      ],
      "problemMatcher": []
    }
  ]
}
</code></pre>
<h4 id="problem-matcher-for-vs-code"><a class="header" href="#problem-matcher-for-vs-code">Problem Matcher for VS Code</a></h4>
<p>Parse debtmap output in VS Code‚Äôs Problems panel:</p>
<pre><code class="language-json">{
  "problemMatcher": {
    "owner": "debtmap",
    "fileLocation": "absolute",
    "pattern": {
      "regexp": "^(.+?):(\\d+):(\\d+)?\\s*-\\s*(.+)$",
      "file": 1,
      "line": 2,
      "column": 3,
      "message": 4
    }
  }
}
</code></pre>
<h3 id="webhook-integration"><a class="header" href="#webhook-integration">Webhook Integration</a></h3>
<p>Send debtmap results to webhooks for notifications:</p>
<pre><code class="language-bash">#!/bin/bash

# Run analysis
debtmap analyze . --format json -o report.json

# Send to Slack
DEBT_SCORE=$(jq '.technical_debt.items | length' report.json)
curl -X POST "$SLACK_WEBHOOK_URL" \
  -H 'Content-Type: application/json' \
  -d "{\"text\": \"Debtmap Analysis Complete\n‚Ä¢ Debt Score: $DEBT_SCORE\n‚Ä¢ High Priority: $(jq '[.technical_debt.items[] | select(.priority == "High")] | length' report.json)\"}"

# Send to custom webhook
curl -X POST "$CUSTOM_WEBHOOK_URL" \
  -H 'Content-Type: application/json' \
  -d @report.json
</code></pre>
<h2 id="output-filtering"><a class="header" href="#output-filtering">Output Filtering</a></h2>
<p>Debtmap provides several flags to filter and limit output:</p>
<blockquote>
<p><strong>Note:</strong> Filtering options (<code>--top</code>, <code>--tail</code>, <code>--summary</code>, <code>--filter</code>) apply to all output formats (terminal, JSON, and markdown). The filtered data is applied at the analysis level before formatting, ensuring consistent results across all output types.</p>
</blockquote>
<h3 id="limiting-results"><a class="header" href="#limiting-results">Limiting Results</a></h3>
<pre><code class="language-bash"># Show only top 10 priority items
debtmap analyze . --top 10

# Show bottom 5 lowest priority items
debtmap analyze . --tail 5
</code></pre>
<h3 id="priority-filtering"><a class="header" href="#priority-filtering">Priority Filtering</a></h3>
<pre><code class="language-bash"># Show only high and critical priority items
debtmap analyze . --min-priority high

# Filter by specific debt categories
debtmap analyze . --filter Architecture,Testing
</code></pre>
<p>Available categories:</p>
<ul>
<li><code>Architecture</code>: God objects, complexity hotspots, dead code</li>
<li><code>Testing</code>: Testing gaps, coverage issues</li>
<li><code>Performance</code>: Resource leaks, inefficient patterns</li>
<li><code>CodeQuality</code>: Code smells, maintainability</li>
</ul>
<h3 id="grouping-output"><a class="header" href="#grouping-output">Grouping Output</a></h3>
<pre><code class="language-bash"># Group results by debt category
debtmap analyze . --group-by-category

# Combine filters for focused analysis
debtmap analyze . --filter Architecture --min-priority high --top 5
</code></pre>
<h3 id="summary-mode"><a class="header" href="#summary-mode">Summary Mode</a></h3>
<pre><code class="language-bash"># Compact tiered priority display
debtmap analyze . --summary

# Combines well with filtering
debtmap analyze . --summary --min-priority medium
</code></pre>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="when-to-use-each-format"><a class="header" href="#when-to-use-each-format">When to Use Each Format</a></h3>
<p><strong>Use Terminal Format When:</strong></p>
<ul>
<li>Developing locally and reviewing code</li>
<li>Getting quick feedback on changes</li>
<li>Presenting results to team members</li>
<li>Exploring complexity hotspots interactively</li>
</ul>
<p><strong>Use JSON Format When:</strong></p>
<ul>
<li>Integrating with CI/CD pipelines</li>
<li>Building custom analysis tools</li>
<li>Tracking metrics over time</li>
<li>Programmatically processing results</li>
<li>Feeding into dashboards or monitoring systems</li>
</ul>
<p><strong>Use Markdown Format When:</strong></p>
<ul>
<li>Generating documentation</li>
<li>Creating PR comments</li>
<li>Sharing reports with stakeholders</li>
<li>Archiving analysis results</li>
<li>Producing executive summaries</li>
</ul>
<h3 id="quick-reference-table"><a class="header" href="#quick-reference-table">Quick Reference Table</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Best For</th><th>Machine Readable</th><th>Human Readable</th><th>File Extension</th></tr></thead><tbody>
<tr><td>Terminal</td><td>Development</td><td>No</td><td>Yes</td><td>.txt</td></tr>
<tr><td>JSON</td><td>Automation</td><td>Yes</td><td>No</td><td>.json</td></tr>
<tr><td>Markdown</td><td>Documentation</td><td>Partially</td><td>Yes</td><td>.md</td></tr>
</tbody></table>
</div>
<h3 id="combining-formats"><a class="header" href="#combining-formats">Combining Formats</a></h3>
<p>Use multiple formats for comprehensive workflows:</p>
<pre><code class="language-bash"># Generate terminal output for review
debtmap analyze .

# Generate JSON for automation
debtmap analyze . --format json -o ci-report.json

# Generate markdown for documentation
debtmap analyze . --format markdown -o docs/DEBT.md
</code></pre>
<h3 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h3>
<ul>
<li><strong>Terminal format</strong>: Fastest, minimal overhead</li>
<li><strong>JSON format</strong>: Fast serialization, efficient for large codebases</li>
<li><strong>Markdown format</strong>: Slightly slower due to formatting, but still performant</li>
</ul>
<p>For very large codebases (&gt;10,000 files), use <code>--top</code> or <code>--filter</code> to limit output size.</p>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h3>
<p><strong>Colors not showing in terminal:</strong></p>
<ul>
<li>Check if terminal supports ANSI colors</li>
<li>Use <code>--plain</code> flag for ASCII-only output</li>
<li>Some CI systems may not support color codes</li>
</ul>
<p><strong>JSON parsing errors:</strong></p>
<ul>
<li>Ensure output is complete (check for errors during analysis)</li>
<li>Validate JSON with <code>jq</code> or online validators</li>
<li>Check for special characters in file paths</li>
</ul>
<p><strong>Markdown rendering issues:</strong></p>
<ul>
<li>Some markdown renderers don‚Äôt support all features</li>
<li>Use standard markdown for maximum compatibility</li>
<li>Test with pandoc or GitHub/GitLab preview</li>
</ul>
<p><strong>File encoding problems:</strong></p>
<ul>
<li>Ensure UTF-8 encoding for all output files</li>
<li>Use <code>--plain</code> for pure ASCII output</li>
<li>Check locale settings (LC_ALL, LANG environment variables)</li>
</ul>
<h3 id="exit-codes"><a class="header" href="#exit-codes">Exit Codes</a></h3>
<p>Current behavior (as verified in <code>src/main.rs</code>):</p>
<ul>
<li><code>0</code>: Successful analysis completed without errors</li>
<li>Non-zero: Error during analysis (invalid path, parsing error, etc.)</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Threshold-based exit codes (where analysis succeeds but fails quality gates) are not currently implemented. The <code>analyze</code> command returns 0 on successful analysis regardless of debt scores or complexity thresholds.</p>
</blockquote>
<p>To enforce quality gates based on thresholds, use the <code>validate</code> command or parse JSON output:</p>
<pre><code class="language-bash"># Use validate command for threshold enforcement
debtmap validate . --config debtmap.toml

# Or parse JSON output for threshold checking
debtmap analyze . --format json -o report.json
DEBT_SCORE=$(jq '.technical_debt.items | length' report.json)
if [ "$DEBT_SCORE" -gt 100 ]; then
    echo "Debt threshold exceeded"
    exit 1
fi
</code></pre>
<h2 id="see-also-1"><a class="header" href="#see-also-1">See Also</a></h2>
<ul>
<li><a href="./getting-started.html">Getting Started</a> - Basic usage and examples</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Understanding metrics and scores</li>
<li><a href="./configuration.html">Configuration</a> - Customizing analysis behavior</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture"><a class="header" href="#architecture">Architecture</a></h1>
<p>This chapter explains how debtmap‚Äôs analysis pipeline works, from discovering files to producing prioritized technical debt recommendations.</p>
<h2 id="analysis-pipeline-overview"><a class="header" href="#analysis-pipeline-overview">Analysis Pipeline Overview</a></h2>
<p>Debtmap‚Äôs analysis follows a multi-stage pipeline that transforms source code into actionable recommendations:</p>
<pre><code class="language-mermaid">graph TD
    A[File Discovery] --&gt; B[Language Detection]
    B --&gt; C{Parser}
    C --&gt;|Rust| D[syn AST]
    C --&gt;|Python| E[rustpython AST]
    C --&gt;|JS/TS| F[tree-sitter AST]

    D --&gt; G[Metric Extraction]
    E --&gt; G
    F --&gt; G

    G --&gt; H[Complexity Calculation]
    G --&gt; I[Call Graph Construction]
    G --&gt; J[Pattern Detection]

    H --&gt; K[Entropy Analysis]
    K --&gt; L[Effective Complexity]

    I --&gt; M[Dependency Analysis]
    J --&gt; N[Debt Classification]

    O[LCOV Coverage] --&gt; P[Coverage Mapping]
    P --&gt; Q[Risk Scoring]

    L --&gt; Q
    M --&gt; Q
    N --&gt; Q

    Q --&gt; R[Tiered Prioritization]
    R --&gt; S[Output Formatting]
    S --&gt; T[Terminal/JSON/Markdown]
</code></pre>
<h2 id="key-components"><a class="header" href="#key-components">Key Components</a></h2>
<h3 id="1-file-discovery-and-language-detection"><a class="header" href="#1-file-discovery-and-language-detection">1. File Discovery and Language Detection</a></h3>
<p><strong>Purpose:</strong> Identify source files to analyze and determine their language.</p>
<p><strong>How it works:</strong></p>
<ul>
<li>Walks the project directory tree (respecting <code>.gitignore</code> and <code>.debtmapignore</code>)</li>
<li>Detects language based on file extension (<code>.rs</code>, <code>.py</code>, <code>.js</code>, <code>.ts</code>)</li>
<li>Filters out test files, build artifacts, and vendored dependencies</li>
<li>Groups files by language for parallel processing</li>
</ul>
<p><strong>Configuration:</strong></p>
<pre><code class="language-toml">[analysis]
exclude_patterns = ["**/tests/**", "**/target/**", "**/node_modules/**"]
include_patterns = ["src/**/*.rs", "lib/**/*.py"]
</code></pre>
<h3 id="2-parser-layer"><a class="header" href="#2-parser-layer">2. Parser Layer</a></h3>
<p><strong>Purpose:</strong> Convert source code into Abstract Syntax Trees (ASTs) for analysis.</p>
<p><strong>Language-Specific Parsers:</strong></p>
<p><strong>Rust (syn):</strong></p>
<ul>
<li>Uses the <code>syn</code> crate for full Rust syntax support</li>
<li>Extracts: functions, structs, impls, traits, macros</li>
<li>Handles: async/await, generic types, lifetime annotations</li>
<li>Performance: ~10-20ms per file</li>
</ul>
<p><strong>Python (rustpython):</strong></p>
<ul>
<li>Uses rustpython‚Äôs parser for Python 3.x syntax</li>
<li>Extracts: functions, classes, methods, decorators</li>
<li>Handles: comprehensions, async/await, type hints</li>
<li>Performance: ~5-15ms per file</li>
</ul>
<p><strong>JavaScript/TypeScript (tree-sitter):</strong></p>
<ul>
<li>Uses tree-sitter for JS/TS parsing</li>
<li>Extracts: functions, classes, arrow functions, hooks</li>
<li>Handles: JSX/TSX, decorators, generics</li>
<li>Performance: ~8-18ms per file</li>
</ul>
<p><strong>Error Handling:</strong></p>
<ul>
<li>Syntax errors logged but don‚Äôt stop analysis</li>
<li>Partial ASTs used when possible</li>
<li>Files with parse errors excluded from final report</li>
</ul>
<h3 id="3-metric-extraction"><a class="header" href="#3-metric-extraction">3. Metric Extraction</a></h3>
<p><strong>Purpose:</strong> Extract raw metrics from ASTs.</p>
<p><strong>Metrics Computed:</strong></p>
<p><strong>Function-Level:</strong></p>
<ul>
<li>Lines of code (LOC)</li>
<li>Cyclomatic complexity (branch count)</li>
<li>Nesting depth (max indentation level)</li>
<li>Parameter count</li>
<li>Return path count</li>
<li>Comment ratio</li>
</ul>
<p><strong>File-Level:</strong></p>
<ul>
<li>Total LOC</li>
<li>Number of functions/classes</li>
<li>Dependency count (imports)</li>
<li>Documentation coverage</li>
</ul>
<p><strong>Implementation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FunctionMetrics {
    pub name: String,
    pub location: Location,
    pub loc: u32,
    pub cyclomatic_complexity: u32,
    pub nesting_depth: u32,
    pub parameter_count: u32,
    pub return_paths: u32,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-complexity-calculation-and-entropy-analysis"><a class="header" href="#4-complexity-calculation-and-entropy-analysis">4. Complexity Calculation and Entropy Analysis</a></h3>
<p><strong>Purpose:</strong> Compute effective complexity using entropy-adjusted metrics.</p>
<p><strong>Traditional Cyclomatic Complexity:</strong></p>
<ul>
<li>Count decision points (if, match, loop, etc.)</li>
<li>Each branch adds +1 to complexity</li>
<li>Does not distinguish between repetitive and varied logic</li>
</ul>
<p><strong>Entropy-Based Adjustment:</strong></p>
<p>Debtmap calculates pattern entropy to adjust cyclomatic complexity:</p>
<ol>
<li><strong>Extract patterns</strong> - Identify branch structures (e.g., all if/return patterns)</li>
<li><strong>Calculate variety</strong> - Measure information entropy of patterns</li>
<li><strong>Adjust complexity</strong> - Reduce score for low-entropy (repetitive) code</li>
</ol>
<p><strong>Formula:</strong></p>
<pre><code>Entropy = -Œ£(p_i * log2(p_i))

where p_i = frequency of pattern i

Effective Complexity = Cyclomatic * (1 - (1 - Entropy/Max_Entropy) * 0.75)
</code></pre>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 20 similar if/return statements
// Cyclomatic: 20, Entropy: 0.3
// Effective: 20 * (1 - (1 - 0.3/4.32) * 0.75) ‚âà 5.5
<span class="boring">}</span></code></pre></pre>
<p>This approach reduces false positives from validation/configuration code while still flagging genuinely complex logic.</p>
<h3 id="5-call-graph-construction"><a class="header" href="#5-call-graph-construction">5. Call Graph Construction</a></h3>
<p><strong>Purpose:</strong> Understand function dependencies and identify critical paths.</p>
<p><strong>What‚Äôs Tracked:</strong></p>
<ul>
<li>Function calls within the same file</li>
<li>Cross-file calls (when possible to resolve)</li>
<li>Method calls on structs/classes</li>
<li>Trait/interface implementations</li>
</ul>
<p><strong>Analysis:</strong></p>
<ul>
<li><strong>Fan-in:</strong> How many functions call this function</li>
<li><strong>Fan-out:</strong> How many functions this function calls</li>
<li><strong>Depth:</strong> Distance from entry points (main, handlers)</li>
<li><strong>Cycles:</strong> Detect recursive calls</li>
</ul>
<p><strong>Usage:</strong></p>
<ul>
<li>Prioritize functions called from many untested paths</li>
<li>Identify central functions (high fan-in/fan-out)</li>
<li>Detect test coverage gaps in critical paths</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li>Dynamic dispatch not fully resolved</li>
<li>Cross-crate calls require additional analysis</li>
<li>Closures and function pointers approximated</li>
</ul>
<h3 id="6-pattern-detection-and-debt-classification"><a class="header" href="#6-pattern-detection-and-debt-classification">6. Pattern Detection and Debt Classification</a></h3>
<p><strong>Purpose:</strong> Identify specific technical debt patterns.</p>
<p><strong>Debt Categories:</strong></p>
<p><strong>Test Gaps:</strong></p>
<ul>
<li>Functions with 0% coverage and high complexity</li>
<li>Untested error paths</li>
<li>Missing edge case tests</li>
</ul>
<p><strong>Complexity Issues:</strong></p>
<ul>
<li>Functions exceeding thresholds (default: 10)</li>
<li>Deep nesting (3+ levels)</li>
<li>Long functions (200+ LOC)</li>
</ul>
<p><strong>Design Smells:</strong></p>
<ul>
<li>God functions (high fan-out)</li>
<li>Unused code (fan-in = 0)</li>
<li>Circular dependencies</li>
</ul>
<p><strong>Implementation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum DebtType {
    TestGap { missing_tests: u32 },
    HighComplexity { score: u32 },
    DeepNesting { depth: u32 },
    LongFunction { loc: u32 },
    TooManyParams { count: u32 },
}
<span class="boring">}</span></code></pre></pre>
<h3 id="7-coverage-integration"><a class="header" href="#7-coverage-integration">7. Coverage Integration</a></h3>
<p><strong>Purpose:</strong> Map test coverage data to complexity metrics for risk scoring.</p>
<p><strong>Coverage Data Flow:</strong></p>
<ol>
<li><strong>Read LCOV file</strong> - Parse coverage report from test runners</li>
<li><strong>Map to source</strong> - Match coverage lines to functions/branches</li>
<li><strong>Calculate coverage %</strong> - For each function, compute:
<ul>
<li>Line coverage: % of lines executed</li>
<li>Branch coverage: % of branches taken</li>
</ul>
</li>
<li><strong>Identify gaps</strong> - Find untested branches in complex functions</li>
</ol>
<p><strong>Coverage Scoring:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CoverageMetrics {
    pub lines_covered: u32,
    pub lines_total: u32,
    pub branches_covered: u32,
    pub branches_total: u32,
    pub coverage_percent: f64,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Special Cases:</strong></p>
<ul>
<li>Entry points (main, handlers) expect integration test coverage</li>
<li>Generated code excluded from coverage requirements</li>
<li>Test files themselves not analyzed for coverage</li>
</ul>
<h3 id="8-risk-scoring"><a class="header" href="#8-risk-scoring">8. Risk Scoring</a></h3>
<p><strong>Purpose:</strong> Combine complexity and coverage into a unified risk score.</p>
<p><strong>Risk Formula:</strong></p>
<pre><code>Risk Score = (Effective Complexity * Coverage Gap Weight) + (Call Graph Depth * Path Weight)

where:
- Effective Complexity: Entropy-adjusted cyclomatic complexity
- Coverage Gap Weight: 1.0 for 0% coverage, decreasing to 0.1 for 95%+
- Call Graph Depth: Distance from entry points
- Path Weight: Number of untested paths leading to this function
</code></pre>
<p><strong>Example Calculation:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn calculate_risk_score():
  Effective Complexity: 8.5
  Coverage: 30%
  Coverage Gap Weight: 0.7
  Call Graph Depth: 3
  Untested Paths: 2

  Risk = (8.5 * 0.7) + (3 * 2 * 0.3) = 5.95 + 1.8 = 7.75
<span class="boring">}</span></code></pre></pre>
<p><strong>Risk Tiers:</strong></p>
<ul>
<li><strong>Critical (8.0+):</strong> Immediate attention required</li>
<li><strong>High (5.0-7.9):</strong> Priority for next sprint</li>
<li><strong>Moderate (2.0-4.9):</strong> Address when refactoring nearby code</li>
<li><strong>Low (&lt;2.0):</strong> Monitor but no immediate action</li>
</ul>
<h3 id="9-tiered-prioritization"><a class="header" href="#9-tiered-prioritization">9. Tiered Prioritization</a></h3>
<p><strong>Purpose:</strong> Classify and rank technical debt items by urgency and impact.</p>
<p><strong>Prioritization Algorithm:</strong></p>
<ol>
<li><strong>Calculate base risk score</strong> (from Risk Scoring step)</li>
<li><strong>Apply context adjustments:</strong>
<ul>
<li>Entry points: -2.0 score (lower priority for unit tests)</li>
<li>Core business logic: +1.5 score (higher priority)</li>
<li>Frequently changed files: +1.0 score (git history analysis)</li>
<li>Critical paths: +0.5 score per untested caller</li>
</ul>
</li>
<li><strong>Classify into tiers:</strong>
<ul>
<li>Critical: score &gt;= 8.0</li>
<li>High: score &gt;= 5.0</li>
<li>Moderate: score &gt;= 2.0</li>
<li>Low: score &lt; 2.0</li>
</ul>
</li>
<li><strong>Sort within tiers by:</strong>
<ul>
<li>Impact (estimated risk reduction)</li>
<li>Effort (test count or refactoring size)</li>
<li>ROI (impact / effort)</li>
</ul>
</li>
</ol>
<p><strong>Output:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct PrioritizedDebtItem {
    pub rank: u32,
    pub score: f64,
    pub tier: Tier,
    pub location: Location,
    pub debt_type: DebtType,
    pub action: String,
    pub impact: f64,
    pub effort: Effort,
}
<span class="boring">}</span></code></pre></pre>
<p>See <a href="tiered-prioritization.html">Tiered Prioritization</a> for detailed explanation of the ranking algorithm.</p>
<h3 id="10-output-formatting"><a class="header" href="#10-output-formatting">10. Output Formatting</a></h3>
<p><strong>Purpose:</strong> Present analysis results in user-friendly formats.</p>
<p><strong>Output Formats:</strong></p>
<p><strong>Terminal (default):</strong></p>
<ul>
<li>Color-coded by tier (red=critical, yellow=high, etc.)</li>
<li>Hierarchical tree view with unicode box characters</li>
<li>Collapsible sections for detailed recommendations</li>
<li>Summary statistics at top</li>
</ul>
<p><strong>JSON:</strong></p>
<ul>
<li>Machine-readable for CI/CD integration</li>
<li>Full metadata for each debt item</li>
<li>Structured for programmatic consumption</li>
<li>Schema-versioned for compatibility</li>
</ul>
<p><strong>Markdown:</strong></p>
<ul>
<li>Rendered in GitHub/GitLab for PR comments</li>
<li>Embedded code blocks with syntax highlighting</li>
<li>Collapsible details sections</li>
<li>Linked to source code locations</li>
</ul>
<p><strong>GitHub PR Comments:</strong></p>
<ul>
<li>Automated comments on pull requests</li>
<li>Inline annotations at specific lines</li>
<li>Comparison with base branch (new vs existing debt)</li>
<li>Summary card with key metrics</li>
</ul>
<p>See <a href="output-formats.html">Output Formats</a> for examples and configuration options.</p>
<h2 id="data-flow-example"><a class="header" href="#data-flow-example">Data Flow Example</a></h2>
<p>Let‚Äôs trace a single function through the entire pipeline:</p>
<p><strong>Input: Source File</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// src/handlers.rs
pub fn process_request(req: Request) -&gt; Result&lt;Response&gt; {
    validate_auth(&amp;req)?;
    let data = parse_payload(&amp;req.body)?;
    let result = apply_business_logic(data)?;
    format_response(result)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Stage 1: Parsing</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>FunctionAst {
    name: "process_request",
    location: Location { file: "src/handlers.rs", line: 2 },
    calls: ["validate_auth", "parse_payload", "apply_business_logic", "format_response"],
    ...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Stage 2: Metric Extraction</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>FunctionMetrics {
    name: "process_request",
    cyclomatic_complexity: 4,  // 3 ?-operators + base
    nesting_depth: 1,
    loc: 5,
    ...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Stage 3: Entropy Analysis</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pattern: repetitive ?-operator error handling
Entropy: 0.4 (low variety)
Effective Complexity: 4 * 0.85 = 3.4
<span class="boring">}</span></code></pre></pre>
<p><strong>Stage 4: Call Graph</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>CallGraphNode {
    function: "process_request",
    fan_in: 3,  // called from 3 handlers
    fan_out: 4,  // calls 4 functions
    depth: 1,  // direct handler (entry point)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Stage 5: Coverage (from LCOV)</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>CoverageMetrics {
    lines_covered: 5,
    lines_total: 5,
    branches_covered: 3,
    branches_total: 4,  // Missing one error path
    coverage_percent: 75%,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Stage 6: Risk Scoring</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>Risk = (3.4 * 0.25) + (1 * 1 * 0.2) = 0.85 + 0.2 = 1.05
Tier: LOW (entry point with decent coverage)
<span class="boring">}</span></code></pre></pre>
<p><strong>Stage 7: Recommendation</strong></p>
<pre><code>#23 SCORE: 1.1 [LOW]
‚îú‚îÄ MINOR GAP: ./src/handlers.rs:2 process_request()
‚îú‚îÄ ACTION: Add 1 test for error path at line 3
‚îú‚îÄ IMPACT: -0.3 risk reduction
‚îî‚îÄ WHY: Entry point with 75% branch coverage, missing error case
</code></pre>
<h2 id="performance-characteristics-1"><a class="header" href="#performance-characteristics-1">Performance Characteristics</a></h2>
<p><strong>Analysis Speed:</strong></p>
<ul>
<li>Small project (&lt; 10k LOC): 1-3 seconds</li>
<li>Medium project (10-50k LOC): 5-15 seconds</li>
<li>Large project (50-200k LOC): 20-60 seconds</li>
<li>Very large project (200k+ LOC): 1-5 minutes</li>
</ul>
<p><strong>Parallelization:</strong></p>
<ul>
<li>File parsing: Parallel across all available cores</li>
<li>Metric extraction: Parallel per-file</li>
<li>Call graph construction: Sequential (requires cross-file state)</li>
<li>Risk scoring: Parallel per-function</li>
<li>Output formatting: Sequential</li>
</ul>
<p><strong>Memory Usage:</strong></p>
<ul>
<li>Approx 100-200 KB per file analyzed</li>
<li>Peak memory for large projects: 500 MB - 1 GB</li>
<li>Streaming mode available for very large codebases</li>
</ul>
<p><strong>Optimization Strategies:</strong></p>
<ul>
<li>Incremental analysis (cache previous results)</li>
<li>Skip unchanged files (git diff integration)</li>
<li>Parallel processing with rayon</li>
<li>Efficient AST traversal (visitor pattern)</li>
</ul>
<h2 id="extension-points"><a class="header" href="#extension-points">Extension Points</a></h2>
<p><strong>Custom Analyzers:</strong>
Implement the <code>Analyzer</code> trait to add language support:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Analyzer {
    fn parse(&amp;self, content: &amp;str) -&gt; Result&lt;Ast&gt;;
    fn extract_metrics(&amp;self, ast: &amp;Ast) -&gt; Vec&lt;FunctionMetrics&gt;;
    fn detect_patterns(&amp;self, ast: &amp;Ast) -&gt; Vec&lt;DebtPattern&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Custom Scoring:</strong>
Implement the <code>RiskScorer</code> trait to adjust scoring logic:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait RiskScorer {
    fn calculate_risk(&amp;self, metrics: &amp;FunctionMetrics, coverage: &amp;CoverageMetrics) -&gt; f64;
    fn classify_tier(&amp;self, score: f64) -&gt; Tier;
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Custom Output:</strong>
Implement the <code>OutputFormatter</code> trait for new formats:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait OutputFormatter {
    fn format(&amp;self, items: &amp;[PrioritizedDebtItem]) -&gt; Result&lt;String&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<ul>
<li><strong>Understand prioritization:</strong> See <a href="tiered-prioritization.html">Tiered Prioritization</a></li>
<li><strong>Learn scoring strategies:</strong> See <a href="scoring-strategies.html">Scoring Strategies</a></li>
<li><strong>Configure analysis:</strong> See <a href="configuration.html">Configuration</a></li>
<li><strong>View examples:</strong> See <a href="examples.html">Examples</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architectural-analysis"><a class="header" href="#architectural-analysis">Architectural Analysis</a></h1>
<p>Debtmap provides comprehensive architectural analysis capabilities based on Robert C. Martin‚Äôs software engineering principles. These tools help identify structural issues, coupling problems, and architectural anti-patterns in your codebase.</p>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>Architectural analysis examines module-level relationships and dependencies to identify:</p>
<ul>
<li><strong>Circular Dependencies</strong> - Modules that create dependency cycles</li>
<li><strong>Coupling Metrics</strong> - Afferent and efferent coupling measurements</li>
<li><strong>Bidirectional Dependencies</strong> - Inappropriate intimacy between modules</li>
<li><strong>Stable Dependencies Principle Violations</strong> - Unstable modules being depended upon</li>
<li><strong>Zone of Pain</strong> - Rigid, concrete implementations heavily depended upon</li>
<li><strong>Zone of Uselessness</strong> - Overly abstract, unstable modules</li>
<li><strong>Code Duplication</strong> - Identical or similar code blocks across files</li>
</ul>
<p>These analyses help you maintain clean architecture and identify refactoring opportunities.</p>
<h2 id="circular-dependency-detection"><a class="header" href="#circular-dependency-detection">Circular Dependency Detection</a></h2>
<p>Circular dependencies occur when modules form a dependency cycle (A depends on B, B depends on C, C depends on A). These violations break architectural boundaries and make code harder to understand, test, and maintain.</p>
<h3 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h3>
<p>Debtmap builds a <strong>dependency graph</strong> from module imports and uses <strong>depth-first search (DFS)</strong> with recursion stack tracking to detect cycles:</p>
<ol>
<li>Parse all files to extract import/module dependencies</li>
<li>Build a directed graph where nodes are modules and edges are dependencies</li>
<li>Run DFS from each unvisited module</li>
<li>Track visited nodes and recursion stack</li>
<li>When a node is reached that‚Äôs already in the recursion stack, a cycle is detected</li>
</ol>
<p><strong>Implementation:</strong> <code>src/debt/circular.rs:44-66</code> (detect_circular_dependencies)</p>
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Module A (src/auth.rs)
use crate::user::User;
use crate::session::validate_session;

// Module B (src/user.rs)
use crate::session::Session;

// Module C (src/session.rs)
use crate::auth::authenticate; // Creates cycle: auth ‚Üí session ‚Üí auth
<span class="boring">}</span></code></pre></pre>
<p><strong>Debtmap detects:</strong></p>
<pre><code>Circular dependency detected: auth ‚Üí session ‚Üí auth
</code></pre>
<h3 id="refactoring-recommendations"><a class="header" href="#refactoring-recommendations">Refactoring Recommendations</a></h3>
<p>To break circular dependencies:</p>
<ol>
<li><strong>Extract Interface</strong> - Create a trait that both modules depend on</li>
<li><strong>Dependency Inversion</strong> - Introduce an abstraction layer</li>
<li><strong>Move Shared Code</strong> - Extract common functionality to a new module</li>
<li><strong>Remove Dependency</strong> - Inline or duplicate small amounts of code</li>
</ol>
<h2 id="coupling-metrics"><a class="header" href="#coupling-metrics">Coupling Metrics</a></h2>
<p>Coupling metrics measure how interconnected modules are. Debtmap calculates two primary metrics:</p>
<h3 id="afferent-coupling-ca"><a class="header" href="#afferent-coupling-ca">Afferent Coupling (Ca)</a></h3>
<p><strong>Afferent coupling</strong> is the number of modules that depend on this module. High afferent coupling means many modules rely on this code.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CouplingMetrics {
    pub module: String,
    pub afferent_coupling: usize, // Number depending on this module
    pub efferent_coupling: usize, // Number this module depends on
    pub instability: f64,         // Calculated from Ca and Ce
    pub abstractness: f64,        // Ratio of abstract types
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Implementation:</strong> <code>src/debt/coupling.rs:6-30</code></p>
<h3 id="efferent-coupling-ce"><a class="header" href="#efferent-coupling-ce">Efferent Coupling (Ce)</a></h3>
<p><strong>Efferent coupling</strong> is the number of modules this module depends on. High efferent coupling means this module has many dependencies.</p>
<h3 id="example-coupling-analysis"><a class="header" href="#example-coupling-analysis">Example Coupling Analysis</a></h3>
<pre><code>Module: api_handler
  Afferent coupling (Ca): 8  // 8 modules depend on api_handler
  Efferent coupling (Ce): 3  // api_handler depends on 3 modules
  Instability: 0.27          // Relatively stable
</code></pre>
<p>High afferent or efferent coupling (typically &gt;5) indicates potential maintainability issues.</p>
<h2 id="instability-metric"><a class="header" href="#instability-metric">Instability Metric</a></h2>
<p>The <strong>instability metric</strong> measures how resistant a module is to change. It‚Äôs calculated as:</p>
<pre><code>I = Ce / (Ca + Ce)
</code></pre>
<p><strong>Interpretation:</strong></p>
<ul>
<li><strong>I = 0.0</strong> - Maximally stable (no dependencies, many dependents)</li>
<li><strong>I = 1.0</strong> - Maximally unstable (many dependencies, no dependents)</li>
</ul>
<p><strong>Implementation:</strong> <code>src/debt/coupling.rs:16-24</code> (calculate_instability)</p>
<h3 id="stability-guidelines"><a class="header" href="#stability-guidelines">Stability Guidelines</a></h3>
<ul>
<li><strong>Stable modules (I &lt; 0.3)</strong> - Hard to change but depended upon; should contain stable abstractions</li>
<li><strong>Balanced modules (0.3 ‚â§ I ‚â§ 0.7)</strong> - Normal modules with both dependencies and dependents</li>
<li><strong>Unstable modules (I &gt; 0.7)</strong> - Change frequently; should have few or no dependents</li>
</ul>
<h3 id="example-1"><a class="header" href="#example-1">Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Stable module (I = 0.1)
// core/types.rs - defines fundamental types, depended on by 20 modules
pub struct User { ... }
pub struct Session { ... }

// Unstable module (I = 0.9)
// handlers/admin_dashboard.rs - depends on 10 modules, no dependents
use crate::auth::*;
use crate::database::*;
use crate::templates::*;
// ... 7 more imports
<span class="boring">}</span></code></pre></pre>
<h2 id="stable-dependencies-principle"><a class="header" href="#stable-dependencies-principle">Stable Dependencies Principle</a></h2>
<p>The <strong>Stable Dependencies Principle (SDP)</strong> states: <em>Depend in the direction of stability</em>. Modules should depend on modules that are more stable than themselves.</p>
<h3 id="sdp-violations"><a class="header" href="#sdp-violations">SDP Violations</a></h3>
<p>Debtmap flags violations when a module has:</p>
<ul>
<li><strong>Instability &gt; 0.8</strong> (very unstable)</li>
<li><strong>Afferent coupling &gt; 2</strong> (multiple modules depend on it)</li>
</ul>
<p>This means an unstable, frequently changing module is being depended upon by multiple other modules - a recipe for maintenance problems.</p>
<p><strong>Implementation:</strong> <code>src/debt/coupling.rs:69-76</code></p>
<h3 id="example-violation"><a class="header" href="#example-violation">Example Violation</a></h3>
<pre><code>Module 'temp_utils' violates Stable Dependencies Principle
(instability: 0.85, depended on by 5 modules)

Problem: This module changes frequently but is heavily depended upon.
Solution: Extract stable interface or reduce dependencies on this module.
</code></pre>
<h3 id="fixing-sdp-violations"><a class="header" href="#fixing-sdp-violations">Fixing SDP Violations</a></h3>
<ol>
<li><strong>Increase stability</strong> - Reduce the module‚Äôs dependencies</li>
<li><strong>Reduce afferent coupling</strong> - Extract interface, use dependency injection</li>
<li><strong>Split module</strong> - Separate stable and unstable parts</li>
</ol>
<h2 id="bidirectional-dependencies"><a class="header" href="#bidirectional-dependencies">Bidirectional Dependencies</a></h2>
<p>Bidirectional dependencies (also called <strong>inappropriate intimacy</strong>) occur when two modules depend on each other:</p>
<pre><code>Module A depends on Module B
Module B depends on Module A
</code></pre>
<p>This creates tight coupling and makes both modules harder to change, test, or reuse independently.</p>
<p><strong>Implementation:</strong> <code>src/debt/coupling.rs:98-117</code> (detect_inappropriate_intimacy)</p>
<h3 id="example-2"><a class="header" href="#example-2">Example</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// order.rs
use crate::customer::Customer;

pub struct Order {
    customer: Customer,
}

// customer.rs
use crate::order::Order; // Bidirectional dependency!

pub struct Customer {
    orders: Vec&lt;Order&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Debtmap detects:</strong></p>
<pre><code>Inappropriate intimacy detected between 'order' and 'customer'
</code></pre>
<h3 id="refactoring-recommendations-1"><a class="header" href="#refactoring-recommendations-1">Refactoring Recommendations</a></h3>
<ol>
<li><strong>Create Mediator</strong> - Introduce a third module to manage the relationship</li>
<li><strong>Break into Separate Modules</strong> - Split concerns more clearly</li>
<li><strong>Use Events</strong> - Replace direct dependencies with event-driven communication</li>
<li><strong>Dependency Inversion</strong> - Introduce interfaces/traits both depend on</li>
</ol>
<h2 id="zone-of-pain-detection"><a class="header" href="#zone-of-pain-detection">Zone of Pain Detection</a></h2>
<p>The <strong>zone of pain</strong> contains modules with:</p>
<ul>
<li><strong>Low abstractness (&lt; 0.2)</strong> - Concrete implementations, no abstractions</li>
<li><strong>Low instability (&lt; 0.2)</strong> - Stable, hard to change</li>
<li><strong>High afferent coupling (&gt; 3)</strong> - Many modules depend on them</li>
</ul>
<p>These modules are rigid concrete implementations that are heavily used but hard to change - causing pain when modifications are needed.</p>
<p><strong>Implementation:</strong> <code>src/debt/coupling.rs:125-138</code></p>
<h3 id="example-3"><a class="header" href="#example-3">Example</a></h3>
<pre><code>Module 'database_client' is in the zone of pain (rigid and hard to change)
  Abstractness: 0.1  (all concrete implementation)
  Instability: 0.15  (very stable, many dependents)
  Afferent coupling: 12 (12 modules depend on it)

Problem: This concrete database client is used everywhere.
Any change to its implementation requires updating many modules.
</code></pre>
<h3 id="refactoring-recommendations-2"><a class="header" href="#refactoring-recommendations-2">Refactoring Recommendations</a></h3>
<ol>
<li><strong>Extract Interfaces</strong> - Create a <code>DatabaseClient</code> trait</li>
<li><strong>Introduce Abstractions</strong> - Define abstract operations others depend on</li>
<li><strong>Break into Smaller Modules</strong> - Separate concerns to reduce coupling</li>
<li><strong>Use Dependency Injection</strong> - Pass implementations via interfaces</li>
</ol>
<h2 id="zone-of-uselessness-detection"><a class="header" href="#zone-of-uselessness-detection">Zone of Uselessness Detection</a></h2>
<p>The <strong>zone of uselessness</strong> contains modules with:</p>
<ul>
<li><strong>High abstractness (&gt; 0.8)</strong> - Mostly abstract, few concrete implementations</li>
<li><strong>High instability (&gt; 0.8)</strong> - Frequently changing</li>
</ul>
<p>These modules are overly abstract and unstable, providing little stable value to the system.</p>
<p><strong>Implementation:</strong> <code>src/debt/coupling.rs:141-153</code></p>
<h3 id="example-4"><a class="header" href="#example-4">Example</a></h3>
<pre><code>Module 'base_processor' is in the zone of uselessness
(too abstract and unstable)
  Abstractness: 0.9  (mostly traits and interfaces)
  Instability: 0.85  (changes frequently)

Problem: This module defines many abstractions but provides little
concrete value. It changes often, breaking implementations.
</code></pre>
<h3 id="refactoring-recommendations-3"><a class="header" href="#refactoring-recommendations-3">Refactoring Recommendations</a></h3>
<ol>
<li><strong>Add Concrete Implementations</strong> - Make the module useful by implementing functionality</li>
<li><strong>Remove if Unused</strong> - Delete if no real value is provided</li>
<li><strong>Stabilize Interfaces</strong> - Stop changing abstractions frequently</li>
<li><strong>Merge with Implementations</strong> - Combine abstract and concrete code</li>
</ol>
<h2 id="distance-from-main-sequence"><a class="header" href="#distance-from-main-sequence">Distance from Main Sequence</a></h2>
<p>The <strong>main sequence</strong> represents the ideal balance between abstractness and instability. Modules should lie on the line:</p>
<pre><code>A + I = 1
</code></pre>
<p>Where:</p>
<ul>
<li><strong>A</strong> = Abstractness (ratio of abstract types to total types)</li>
<li><strong>I</strong> = Instability (Ce / (Ca + Ce))</li>
</ul>
<p><strong>Distance</strong> from the main sequence:</p>
<pre><code>D = |A + I - 1|
</code></pre>
<p><strong>Implementation:</strong> <code>src/debt/coupling.rs:119-123</code></p>
<h3 id="interpretation"><a class="header" href="#interpretation">Interpretation</a></h3>
<ul>
<li><strong>D ‚âà 0.0</strong> - Module is on the main sequence (ideal)</li>
<li><strong>D &gt; 0.5</strong> - Module is far from ideal
<ul>
<li>High D with low A and I ‚Üí Zone of Pain</li>
<li>High D with high A and I ‚Üí Zone of Uselessness</li>
</ul>
</li>
</ul>
<h3 id="visual-representation"><a class="header" href="#visual-representation">Visual Representation</a></h3>
<pre><code>Abstractness
    1.0 ‚î§        Zone of Uselessness
        ‚îÇ      ‚ï±
        ‚îÇ    ‚ï±
    0.5 ‚î§  ‚ï± Main Sequence
        ‚îÇ‚ï±
        ‚ï±
    0.0 ‚î§‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        0.0    0.5              1.0
                 Instability

        Zone of Pain
</code></pre>
<h2 id="code-duplication-detection"><a class="header" href="#code-duplication-detection">Code Duplication Detection</a></h2>
<p>Debtmap detects code duplication using <strong>hash-based chunk comparison</strong>:</p>
<ol>
<li><strong>Extract chunks</strong> - Split files into fixed-size chunks (default: 50 lines)</li>
<li><strong>Normalize</strong> - Remove whitespace and comments</li>
<li><strong>Calculate hash</strong> - Compute SHA-256 hash for each normalized chunk</li>
<li><strong>Match duplicates</strong> - Find chunks with identical hashes</li>
<li><strong>Merge adjacent</strong> - Consolidate consecutive duplicate blocks</li>
</ol>
<p><strong>Note:</strong> The minimum chunk size is configurable via the <code>--threshold-duplication</code> flag (default: 50 lines).</p>
<p><strong>Implementation:</strong> <code>src/debt/duplication.rs:6-44</code> (detect_duplication)</p>
<h3 id="algorithm-details"><a class="header" href="#algorithm-details">Algorithm Details</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn detect_duplication(
    files: Vec&lt;(PathBuf, String)&gt;,
    min_lines: usize,           // Default: 50
    _similarity_threshold: f64, // Currently unused (exact matching)
) -&gt; Vec&lt;DuplicationBlock&gt;
<span class="boring">}</span></code></pre></pre>
<p>The algorithm:</p>
<ol>
<li>Extracts overlapping chunks from each file</li>
<li>Normalizes by trimming whitespace and removing comments</li>
<li>Calculates SHA-256 hash for each normalized chunk</li>
<li>Groups chunks by hash</li>
<li>Returns groups with 2+ locations (duplicates found)</li>
</ol>
<h3 id="example-output-1"><a class="header" href="#example-output-1">Example Output</a></h3>
<pre><code>Code duplication detected:
  Hash: a3f2b9c1...
  Lines: 50
  Locations:
    - src/handlers/user.rs:120-169
    - src/handlers/admin.rs:85-134
    - src/handlers/guest.rs:200-249

Recommendation: Extract common validation logic to shared module
</code></pre>
<h2 id="duplication-configuration"><a class="header" href="#duplication-configuration">Duplication Configuration</a></h2>
<p>Configure duplication detection in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml"># Minimum lines for duplication detection
threshold_duplication = 50  # Default value

# Smaller values catch more duplications but increase noise
# threshold_duplication = 30  # More sensitive

# Larger values only catch major duplications
# threshold_duplication = 100  # Less noise
</code></pre>
<p><strong>Configuration reference:</strong> <code>src/cli.rs:69</code> (threshold_duplication flag definition)</p>
<p><strong>Implementation:</strong> <code>src/debt/duplication.rs:6-10</code></p>
<h3 id="current-limitations"><a class="header" href="#current-limitations">Current Limitations</a></h3>
<ul>
<li><strong>Exact matching only</strong> - Currently uses hash-based exact matching</li>
<li><strong>similarity_threshold parameter</strong> - Defined but not implemented yet</li>
<li><strong>Future enhancement</strong> - Fuzzy matching for near-duplicates</li>
</ul>
<h2 id="refactoring-recommendations-4"><a class="header" href="#refactoring-recommendations-4">Refactoring Recommendations</a></h2>
<p>Debtmap provides specific refactoring recommendations for each architectural issue:</p>
<h3 id="for-circular-dependencies"><a class="header" href="#for-circular-dependencies">For Circular Dependencies</a></h3>
<ol>
<li><strong>Extract Interface</strong> - Create shared abstraction both modules use</li>
<li><strong>Dependency Inversion</strong> - Introduce interfaces to reverse dependency direction</li>
<li><strong>Move Shared Code</strong> - Extract to new module both can depend on</li>
<li><strong>Event-Driven</strong> - Replace direct calls with event publishing/subscribing</li>
</ol>
<h3 id="for-high-coupling"><a class="header" href="#for-high-coupling">For High Coupling</a></h3>
<ol>
<li><strong>Facade Pattern</strong> - Provide simplified interface hiding complex dependencies</li>
<li><strong>Reduce Dependencies</strong> - Remove unnecessary imports and calls</li>
<li><strong>Dependency Injection</strong> - Pass dependencies via constructors/parameters</li>
<li><strong>Interface Segregation</strong> - Split large interfaces into focused ones</li>
</ol>
<h3 id="for-zone-of-pain"><a class="header" href="#for-zone-of-pain">For Zone of Pain</a></h3>
<ol>
<li><strong>Introduce Abstractions</strong> - Extract traits/interfaces for flexibility</li>
<li><strong>Adapter Pattern</strong> - Wrap concrete implementations with adapters</li>
<li><strong>Strategy Pattern</strong> - Make algorithms pluggable via interfaces</li>
</ol>
<h3 id="for-zone-of-uselessness"><a class="header" href="#for-zone-of-uselessness">For Zone of Uselessness</a></h3>
<ol>
<li><strong>Add Concrete Implementations</strong> - Provide useful functionality</li>
<li><strong>Remove Unused Code</strong> - Delete if providing no value</li>
<li><strong>Stabilize Interfaces</strong> - Stop changing abstractions frequently</li>
</ol>
<h3 id="for-bidirectional-dependencies"><a class="header" href="#for-bidirectional-dependencies">For Bidirectional Dependencies</a></h3>
<ol>
<li><strong>Create Mediator</strong> - Third module manages relationship</li>
<li><strong>Break into Separate Modules</strong> - Clearer separation of concerns</li>
<li><strong>Observer Pattern</strong> - One-way communication via observers</li>
</ol>
<h3 id="for-code-duplication"><a class="header" href="#for-code-duplication">For Code Duplication</a></h3>
<ol>
<li><strong>Extract Common Code</strong> - Create shared function/module</li>
<li><strong>Use Inheritance/Composition</strong> - Share via traits or composition</li>
<li><strong>Parameterize Differences</strong> - Extract variable parts as parameters</li>
<li><strong>Template Method</strong> - Define algorithm structure, vary specific steps</li>
</ol>
<h2 id="examples-and-use-cases"><a class="header" href="#examples-and-use-cases">Examples and Use Cases</a></h2>
<h3 id="running-architectural-analysis"><a class="header" href="#running-architectural-analysis">Running Architectural Analysis</a></h3>
<pre><code class="language-bash"># Architectural analysis runs automatically with standard analysis
debtmap analyze .

# Duplication detection with custom chunk size
debtmap analyze . --threshold-duplication 30

# Note: Circular dependencies, coupling metrics, and SDP violations
# are analyzed automatically. There are no separate flags to enable
# or disable specific architectural checks.
</code></pre>
<h3 id="example-circular-dependency"><a class="header" href="#example-circular-dependency">Example: Circular Dependency</a></h3>
<p><strong>Before:</strong></p>
<pre><code>src/auth.rs ‚Üí src/session.rs ‚Üí src/user.rs ‚Üí src/auth.rs

Circular dependency detected: auth ‚Üí session ‚Üí user ‚Üí auth
</code></pre>
<p><strong>After refactoring:</strong></p>
<pre><code>src/auth.rs ‚Üí src/auth_interface.rs ‚Üê src/session.rs
                      ‚Üë
              src/user.rs

No circular dependencies found.
</code></pre>
<h3 id="example-coupling-metrics-table"><a class="header" href="#example-coupling-metrics-table">Example: Coupling Metrics Table</a></h3>
<pre><code>Module Analysis Results:

Module              Ca    Ce    Instability  Issues
-------------------------------------------------
core/types          15     0       0.00      None
api/handlers         2     8       0.80      High Ce
database/client      8     2       0.20      None
utils/temp          5    12       0.71      SDP violation
auth/session        3     3       0.50      None
</code></pre>
<h3 id="example-zone-of-pain"><a class="header" href="#example-zone-of-pain">Example: Zone of Pain</a></h3>
<p><strong>Module:</strong> <code>legacy_db_client</code></p>
<pre><code>Metrics:
  Abstractness: 0.05 (all concrete code)
  Instability: 0.12 (depended on by 25 modules)
  Afferent coupling: 25
  Distance from main sequence: 0.83

Status: Zone of Pain - rigid and hard to change

Refactoring steps:
1. Extract interface DatabaseClient trait
2. Create adapter wrapping legacy implementation
3. Gradually migrate dependents to use trait
4. Introduce alternative implementations
</code></pre>
<h2 id="interpreting-results-1"><a class="header" href="#interpreting-results-1">Interpreting Results</a></h2>
<h3 id="prioritization"><a class="header" href="#prioritization">Prioritization</a></h3>
<p>Address architectural issues in this order:</p>
<ol>
<li>
<p><strong>Circular Dependencies</strong> (Highest Priority)</p>
<ul>
<li>Break architectural boundaries</li>
<li>Make testing impossible</li>
<li>Cause build issues</li>
</ul>
</li>
<li>
<p><strong>Bidirectional Dependencies</strong> (High Priority)</p>
<ul>
<li>Create tight coupling</li>
<li>Prevent independent testing</li>
<li>Block modular changes</li>
</ul>
</li>
<li>
<p><strong>Zone of Pain Issues</strong> (Medium-High Priority)</p>
<ul>
<li>Indicate rigid architecture</li>
<li>Block future changes</li>
<li>High risk for bugs</li>
</ul>
</li>
<li>
<p><strong>SDP Violations</strong> (Medium Priority)</p>
<ul>
<li>Cause ripple effects</li>
<li>Increase maintenance cost</li>
<li>Unstable foundation</li>
</ul>
</li>
<li>
<p><strong>High Coupling</strong> (Medium Priority)</p>
<ul>
<li>Maintainability risk</li>
<li>Testing difficulty</li>
<li>Change amplification</li>
</ul>
</li>
<li>
<p><strong>Code Duplication</strong> (Lower Priority)</p>
<ul>
<li>Maintenance burden</li>
<li>Bug multiplication</li>
<li>Inconsistency risk</li>
</ul>
</li>
</ol>
<h3 id="decision-flowchart"><a class="header" href="#decision-flowchart">Decision Flowchart</a></h3>
<pre><code>Is there a circular dependency?
‚îú‚îÄ YES ‚Üí Break immediately (extract interface, DI)
‚îî‚îÄ NO  ‚Üí Continue

Is there bidirectional dependency?
‚îú‚îÄ YES ‚Üí Refactor (mediator, event-driven)
‚îî‚îÄ NO  ‚Üí Continue

Is module in zone of pain?
‚îú‚îÄ YES ‚Üí Introduce abstractions
‚îî‚îÄ NO  ‚Üí Continue

Is SDP violated?
‚îú‚îÄ YES ‚Üí Stabilize or reduce afferent coupling
‚îî‚îÄ NO  ‚Üí Continue

Is coupling &gt; threshold?
‚îú‚îÄ YES ‚Üí Reduce dependencies
‚îî‚îÄ NO  ‚Üí Continue

Is there significant duplication?
‚îú‚îÄ YES ‚Üí Extract common code
‚îî‚îÄ NO  ‚Üí Architecture is good!
</code></pre>
<h2 id="integration-with-debt-categories"><a class="header" href="#integration-with-debt-categories">Integration with Debt Categories</a></h2>
<p>Architectural analysis results are integrated with debtmap‚Äôs debt categorization system:</p>
<h3 id="debt-type-mapping"><a class="header" href="#debt-type-mapping">Debt Type Mapping</a></h3>
<ul>
<li><strong>CircularDependency</strong> - Circular dependency cycles detected</li>
<li><strong>HighCoupling</strong> - Modules exceeding coupling threshold</li>
<li><strong>Duplication</strong> - Duplicated code blocks found</li>
<li><strong>ArchitecturalViolation</strong> - SDP violations, zone issues</li>
</ul>
<p><strong>Reference:</strong> See <code>src/core/mod.rs</code> for debt type definitions</p>
<h3 id="tiered-prioritization-1"><a class="header" href="#tiered-prioritization-1">Tiered Prioritization</a></h3>
<p>Architectural issues are assigned priority tiers:</p>
<ul>
<li><strong>Tier 1 (Critical)</strong> - Circular dependencies, bidirectional dependencies</li>
<li><strong>Tier 2 (High)</strong> - Zone of pain, SDP violations</li>
<li><strong>Tier 3 (Medium)</strong> - High coupling, large duplications</li>
<li><strong>Tier 4 (Low)</strong> - Small duplications, minor coupling issues</li>
</ul>
<p><strong>Reference:</strong> See <a href="tiered-prioritization.html">Tiered Prioritization</a> for complete priority assignment logic</p>
<h2 id="cohesion-analysis"><a class="header" href="#cohesion-analysis">Cohesion Analysis</a></h2>
<p><strong>Note:</strong> Module cohesion analysis is currently a simplified placeholder implementation.</p>
<p><strong>Current status:</strong> <code>src/debt/coupling.rs:82-95</code> (analyze_module_cohesion)</p>
<p>The function exists but provides basic cohesion calculation. Full cohesion analysis (measuring how well module elements belong together) is planned for a future release.</p>
<h3 id="future-enhancement"><a class="header" href="#future-enhancement">Future Enhancement</a></h3>
<p>Full cohesion analysis would measure:</p>
<ul>
<li>Functional cohesion (functions operating on related data)</li>
<li>Sequential cohesion (output of one function feeds another)</li>
<li>Communicational cohesion (functions operating on same data structures)</li>
</ul>
<h2 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h2>
<h3 id="configurable-parameters"><a class="header" href="#configurable-parameters">Configurable Parameters</a></h3>
<p>Configure duplication detection in <code>.debtmap.toml</code> or via CLI:</p>
<pre><code class="language-toml"># Minimum lines for duplication detection
threshold_duplication = 50  # Default value
</code></pre>
<p>Or via command line:</p>
<pre><code class="language-bash">debtmap analyze . --threshold-duplication 50
</code></pre>
<p><strong>Configuration reference:</strong> <code>src/cli.rs:69</code> (threshold_duplication flag definition)</p>
<h3 id="hardcoded-thresholds"><a class="header" href="#hardcoded-thresholds">Hardcoded Thresholds</a></h3>
<p><strong>Note:</strong> Most architectural thresholds are currently hardcoded in the implementation and cannot be configured:</p>
<ul>
<li><strong>Coupling threshold:</strong> 5 (modules with &gt;5 dependencies are flagged)</li>
<li><strong>Instability threshold:</strong> 0.8 (for SDP violations)</li>
<li><strong>SDP afferent threshold:</strong> 2 (minimum dependents for SDP violations)</li>
<li><strong>Zone of pain thresholds:</strong>
<ul>
<li>Abstractness &lt; 0.2</li>
<li>Instability &lt; 0.2</li>
<li>Afferent coupling &gt; 3</li>
</ul>
</li>
<li><strong>Zone of uselessness thresholds:</strong>
<ul>
<li>Abstractness &gt; 0.8</li>
<li>Instability &gt; 0.8</li>
</ul>
</li>
</ul>
<p><strong>Source:</strong> <code>src/debt/coupling.rs:70-76</code> (hardcoded threshold definitions)</p>
<p>See <a href="configuration.html">Configuration</a> for complete options.</p>
<h2 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h2>
<h3 id="no-circular-dependencies-detected-but-build-fails"><a class="header" href="#no-circular-dependencies-detected-but-build-fails">‚ÄúNo circular dependencies detected but build fails‚Äù</a></h3>
<p><strong>Cause:</strong> Circular dependencies at the package/crate level, not module level.</p>
<p><strong>Solution:</strong> Use <code>cargo tree</code> to analyze package-level dependencies.</p>
<h3 id="too-many-coupling-warnings"><a class="header" href="#too-many-coupling-warnings">‚ÄúToo many coupling warnings‚Äù</a></h3>
<p><strong>Cause:</strong> Default threshold may be too strict for your codebase.</p>
<p><strong>Solution:</strong> Adjust <code>coupling_threshold</code> in <code>.debtmap.toml</code> to match your architecture.</p>
<h3 id="duplication-detected-in-generated-code"><a class="header" href="#duplication-detected-in-generated-code">‚ÄúDuplication detected in generated code‚Äù</a></h3>
<p><strong>Cause:</strong> Code generation tools create similar patterns.</p>
<p><strong>Solution:</strong> Use suppression patterns to exclude generated files. See <a href="suppression-patterns.html">Suppression Patterns</a>.</p>
<h3 id="zone-of-pain-false-positives"><a class="header" href="#zone-of-pain-false-positives">‚ÄúZone of pain false positives‚Äù</a></h3>
<p><strong>Cause:</strong> Utility modules are intentionally stable and concrete.</p>
<p><strong>Solution:</strong> This is often correct - utility modules should be stable. Consider whether the module should be more abstract.</p>
<h2 id="further-reading"><a class="header" href="#further-reading">Further Reading</a></h2>
<h3 id="robert-c-martins-principles"><a class="header" href="#robert-c-martins-principles">Robert C. Martin‚Äôs Principles</a></h3>
<p>The architectural metrics in debtmap are based on:</p>
<ul>
<li><strong>Clean Architecture</strong> by Robert C. Martin</li>
<li><strong>Agile Software Development: Principles, Patterns, and Practices</strong> by Robert C. Martin</li>
<li>Stable Dependencies Principle (SDP)</li>
<li>Stable Abstractions Principle (SAP)</li>
<li>Main Sequence distance metric</li>
</ul>
<h3 id="related-topics-2"><a class="header" href="#related-topics-2">Related Topics</a></h3>
<ul>
<li><a href="analysis-guide.html">Analysis Guide</a> - Complete analysis workflow</li>
<li><a href="configuration.html">Configuration</a> - Configuration options</li>
<li><a href="entropy-analysis.html">Entropy Analysis</a> - Complexity vs. entropy</li>
<li><a href="scoring-strategies.html">Scoring Strategies</a> - How debt is scored</li>
<li><a href="tiered-prioritization.html">Tiered Prioritization</a> - Priority assignment</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="boilerplate-vs-complexity"><a class="header" href="#boilerplate-vs-complexity">Boilerplate vs Complexity</a></h1>
<h2 id="overview-4"><a class="header" href="#overview-4">Overview</a></h2>
<p>Debtmap distinguishes between <strong>boilerplate code</strong> (necessary but mechanical patterns) and <strong>true complexity</strong> (business logic requiring cognitive effort). This distinction is critical for:</p>
<ul>
<li>Avoiding false positives in complexity analysis</li>
<li>Focusing refactoring efforts on actual problems</li>
<li>Understanding which high-complexity code is acceptable</li>
<li>Providing actionable recommendations</li>
</ul>
<p>This chapter explains how Debtmap identifies boilerplate patterns, why they differ from complexity, and how to interpret the analysis results.</p>
<h2 id="the-distinction"><a class="header" href="#the-distinction">The Distinction</a></h2>
<h3 id="what-is-boilerplate"><a class="header" href="#what-is-boilerplate">What is Boilerplate?</a></h3>
<p>Boilerplate code consists of repetitive, mechanical patterns that are:</p>
<ol>
<li><strong>Required by language/framework</strong> - Type conversions, trait implementations, builder patterns</li>
<li><strong>Structurally necessary</strong> - Match arms for enums, error propagation, validation chains</li>
<li><strong>Low cognitive load</strong> - Pattern-based code that developers scan rather than deeply analyze</li>
<li><strong>Not actual complexity</strong> - High cyclomatic complexity but mechanistic structure</li>
</ol>
<p><strong>Examples:</strong></p>
<ul>
<li><code>From</code> trait implementations converting between types</li>
<li><code>Display</code> formatting with exhaustive enum match arms</li>
<li>Builder pattern setters with validation</li>
<li>Error conversion implementations</li>
<li>Serialization/deserialization code</li>
</ul>
<h3 id="what-is-true-complexity"><a class="header" href="#what-is-true-complexity">What is True Complexity?</a></h3>
<p>True complexity consists of business logic that requires:</p>
<ol>
<li><strong>Domain understanding</strong> - Knowledge of problem space and requirements</li>
<li><strong>Cognitive effort</strong> - Careful analysis to understand behavior</li>
<li><strong>Algorithmic decisions</strong> - Non-obvious control flow or data transformations</li>
<li><strong>Maintainability risk</strong> - Changes may introduce subtle bugs</li>
</ol>
<p><strong>Examples:</strong></p>
<ul>
<li>Graph traversal algorithms</li>
<li>Complex business rules with multiple conditions</li>
<li>State machine implementations with non-trivial transitions</li>
<li>Performance-critical optimizations</li>
<li>Error recovery with fallback strategies</li>
</ul>
<h2 id="real-example-ripgreps-defsrs"><a class="header" href="#real-example-ripgreps-defsrs">Real Example: ripgrep‚Äôs defs.rs</a></h2>
<p>The ripgrep codebase provides an excellent real-world example of boilerplate vs complexity.</p>
<h3 id="file-cratesprintersrcdefsrs"><a class="header" href="#file-cratesprintersrcdefsrs">File: <code>crates/printer/src/defs.rs</code></a></h3>
<p>This file contains type conversion implementations with high cyclomatic complexity scores but minimal actual complexity:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl From&lt;HyperlinkFormat&gt; for ColorHyperlink {
    fn from(format: HyperlinkFormat) -&gt; ColorHyperlink {
        match format {
            HyperlinkFormat::Default =&gt; ColorHyperlink::default(),
            HyperlinkFormat::Grep =&gt; ColorHyperlink::grep(),
            HyperlinkFormat::GrepPlus =&gt; ColorHyperlink::grep_plus(),
            HyperlinkFormat::Ripgrep =&gt; ColorHyperlink::ripgrep(),
            HyperlinkFormat::FileNone =&gt; ColorHyperlink::file_none(),
            // ... 10+ more variants
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Analysis:</strong></p>
<ul>
<li><strong>Cyclomatic Complexity</strong>: 15+ (one branch per enum variant)</li>
<li><strong>Cognitive Complexity</strong>: Low (simple delegation pattern)</li>
<li><strong>Boilerplate Confidence</strong>: 95% (trait implementation with mechanical structure)</li>
</ul>
<h3 id="why-this-matters"><a class="header" href="#why-this-matters">Why This Matters</a></h3>
<p>Without boilerplate detection, this file would be flagged as:</p>
<ul>
<li>High complexity debt</li>
<li>Requiring refactoring</li>
<li>Priority for review</li>
</ul>
<p>With boilerplate detection, it‚Äôs correctly classified as:</p>
<ul>
<li>Necessary type conversion code</li>
<li>Low maintenance risk</li>
<li>Can be safely skipped in debt prioritization</li>
</ul>
<h2 id="detection-methodology"><a class="header" href="#detection-methodology">Detection Methodology</a></h2>
<p>Debtmap uses a multi-phase analysis pipeline to detect boilerplate:</p>
<h3 id="phase-1-trait-analysis"><a class="header" href="#phase-1-trait-analysis">Phase 1: Trait Analysis</a></h3>
<p>Identifies trait implementations known to produce boilerplate:</p>
<p><strong>High-confidence boilerplate traits:</strong></p>
<ul>
<li><code>From</code>, <code>Into</code> - Type conversions</li>
<li><code>Display</code>, <code>Debug</code> - Formatting</li>
<li><code>Default</code> - Default value construction</li>
<li><code>Clone</code>, <code>Copy</code> - Value semantics</li>
<li><code>Eq</code>, <code>PartialEq</code>, <code>Ord</code>, <code>PartialOrd</code> - Comparisons</li>
<li><code>Hash</code> - Hashing implementations</li>
</ul>
<p><strong>Medium-confidence boilerplate traits:</strong></p>
<ul>
<li><code>Serialize</code>, <code>Deserialize</code> - Serialization</li>
<li><code>AsRef</code>, <code>AsMut</code>, <code>Deref</code>, <code>DerefMut</code> - Reference conversions</li>
<li>Custom builder traits</li>
</ul>
<p>See <code>src/debt/boilerplate/boilerplate_traits.rs:10-58</code> for complete trait categorization.</p>
<h3 id="phase-2-pattern-analysis"><a class="header" href="#phase-2-pattern-analysis">Phase 2: Pattern Analysis</a></h3>
<p>Analyzes code structure for boilerplate patterns:</p>
<p><strong>Pattern 1: Simple Delegation</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn operation(&amp;self) -&gt; Result&lt;T&gt; {
    self.inner.operation()  // Single delegation call
}
<span class="boring">}</span></code></pre></pre>
<p>Score: 90% confidence</p>
<p><strong>Pattern 2: Trivial Match Arms</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>match variant {
    A =&gt; handler_a(),
    B =&gt; handler_b(),
    C =&gt; handler_c(),
}
<span class="boring">}</span></code></pre></pre>
<p>Each arm calls a single function with no additional logic.
Score: 85% confidence</p>
<p><strong>Pattern 3: Validation Chains</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn validate(&amp;self) -&gt; Result&lt;()&gt; {
    check_condition_1()?;
    check_condition_2()?;
    check_condition_3()?;
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p>Sequential validation with early returns.
Score: 75% confidence</p>
<p><strong>Pattern 4: Builder Setters</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn with_field(mut self, value: T) -&gt; Self {
    self.field = value;
    self
}
<span class="boring">}</span></code></pre></pre>
<p>Simple field assignment with fluent return.
Score: 95% confidence</p>
<p>See <code>src/debt/boilerplate/pattern_detector.rs:18-82</code> for pattern detection logic.</p>
<h3 id="phase-3-macro-analysis"><a class="header" href="#phase-3-macro-analysis">Phase 3: Macro Analysis</a></h3>
<p>Detects macro-generated code and provides recommendations:</p>
<p><strong>Derivable Traits:</strong>
Debtmap suggests using <code>#[derive(...)]</code> when it detects manual implementations of:</p>
<ul>
<li><code>Clone</code>, <code>Copy</code>, <code>Debug</code>, <code>Default</code></li>
<li><code>Eq</code>, <code>PartialEq</code>, <code>Ord</code>, <code>PartialOrd</code></li>
<li><code>Hash</code></li>
</ul>
<p><strong>Custom Macros:</strong>
Recommends creating custom derive macros for:</p>
<ul>
<li>Repeated builder pattern implementations</li>
<li>Repeated conversion trait implementations</li>
<li>Repeated validation logic</li>
</ul>
<p><strong>Existing Crates:</strong>
Suggests established crates for common patterns:</p>
<ul>
<li><code>derive_more</code> - Extended derive macros</li>
<li><code>thiserror</code> - Error type boilerplate</li>
<li><code>typed-builder</code> - Builder pattern macros</li>
<li><code>delegate</code> - Delegation patterns</li>
</ul>
<p>See <code>src/debt/boilerplate/macro_recommender.rs:9-136</code> for macro recommendation logic.</p>
<h2 id="common-boilerplate-patterns"><a class="header" href="#common-boilerplate-patterns">Common Boilerplate Patterns</a></h2>
<h3 id="type-conversions"><a class="header" href="#type-conversions">Type Conversions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High complexity (15+), but boilerplate
impl From&lt;ConfigFormat&gt; for Config {
    fn from(format: ConfigFormat) -&gt; Config {
        match format {
            ConfigFormat::Json =&gt; Config::json(),
            ConfigFormat::Yaml =&gt; Config::yaml(),
            ConfigFormat::Toml =&gt; Config::toml(),
            // ... many variants
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Boilerplate Confidence</strong>: 90%+
<strong>Recommendation</strong>: Consider using a macro if pattern repeats</p>
<h3 id="error-propagation"><a class="header" href="#error-propagation">Error Propagation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High nesting, but boilerplate pattern
fn complex_operation(&amp;self) -&gt; Result&lt;Output&gt; {
    let step1 = self.step_one()
        .context("Step one failed")?;
    let step2 = self.step_two(&amp;step1)
        .context("Step two failed")?;
    let step3 = self.step_three(&amp;step2)
        .context("Step three failed")?;
    Ok(Output::new(step3))
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Boilerplate Confidence</strong>: 75%
<strong>Recommendation</strong>: Acceptable pattern for error handling</p>
<h3 id="builder-patterns"><a class="header" href="#builder-patterns">Builder Patterns</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Many methods, but all boilerplate
impl ConfigBuilder {
    pub fn with_timeout(mut self, timeout: Duration) -&gt; Self {
        self.timeout = Some(timeout);
        self
    }

    pub fn with_retries(mut self, retries: u32) -&gt; Self {
        self.retries = Some(retries);
        self
    }

    // ... 20+ more setters
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Boilerplate Confidence</strong>: 95%
<strong>Recommendation</strong>: Use <code>typed-builder</code> or similar crate</p>
<h3 id="display-formatting"><a class="header" href="#display-formatting">Display Formatting</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High complexity due to match, but boilerplate
impl Display for Status {
    fn fmt(&amp;self, f: &amp;mut Formatter) -&gt; fmt::Result {
        match self {
            Status::Pending =&gt; write!(f, "pending"),
            Status::Running =&gt; write!(f, "running"),
            Status::Success =&gt; write!(f, "success"),
            Status::Failed(err) =&gt; write!(f, "failed: {}", err),
            // ... many variants
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Boilerplate Confidence</strong>: 90%
<strong>Recommendation</strong>: Consider using <code>strum</code> or <code>derive_more</code></p>
<h2 id="decision-table"><a class="header" href="#decision-table">Decision Table</a></h2>
<p>Use this table to interpret boilerplate confidence scores:</p>
<div class="table-wrapper"><table><thead><tr><th>Confidence</th><th>Interpretation</th><th>Action</th></tr></thead><tbody>
<tr><td>90-100%</td><td>Definite boilerplate</td><td>Exclude from complexity prioritization; consider macro optimization</td></tr>
<tr><td>70-89%</td><td>Probable boilerplate</td><td>Review pattern; likely acceptable; low refactoring priority</td></tr>
<tr><td>50-69%</td><td>Mixed boilerplate/logic</td><td>Investigate; may contain hidden complexity; medium priority</td></tr>
<tr><td>30-49%</td><td>Mostly real complexity</td><td>Standard complexity analysis; normal refactoring priority</td></tr>
<tr><td>0-29%</td><td>True complexity</td><td>High priority; focus refactoring efforts here</td></tr>
</tbody></table>
</div>
<h3 id="example-classifications"><a class="header" href="#example-classifications">Example Classifications</a></h3>
<p><strong>Boilerplate (90%+ confidence):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simple trait delegation - skip in debt analysis
impl AsRef&lt;str&gt; for CustomString {
    fn as_ref(&amp;self) -&gt; &amp;str {
        &amp;self.inner
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Mixed (50-70% confidence):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Match with some logic - review case by case
fn process_event(&amp;mut self, event: Event) -&gt; Result&lt;()&gt; {
    match event {
        Event::Simple =&gt; self.handle_simple(),  // Boilerplate
        Event::Complex(data) =&gt; {                // Real logic
            if data.priority &gt; 10 {
                self.handle_urgent(data)?;
            } else {
                self.queue_normal(data)?;
            }
            self.update_metrics()?;
            Ok(())
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>True Complexity (0-30% confidence):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Business logic requiring domain knowledge
fn calculate_optimal_strategy(&amp;self, market: &amp;Market) -&gt; Strategy {
    let volatility = market.calculate_volatility();
    let trend = market.detect_trend();

    if volatility &gt; self.risk_threshold {
        if trend.is_bullish() &amp;&amp; self.can_hedge() {
            Strategy::hedged_long(self.calculate_position_size())
        } else {
            Strategy::defensive()
        }
    } else {
        Strategy::momentum_based(trend, self.confidence_level())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="integration-with-complexity-analysis"><a class="header" href="#integration-with-complexity-analysis">Integration with Complexity Analysis</a></h2>
<h3 id="boilerplate-scoring"><a class="header" href="#boilerplate-scoring">Boilerplate Scoring</a></h3>
<p>Debtmap calculates a <code>BoilerplateScore</code> for each function:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BoilerplateScore {
    pub confidence: f64,              // 0.0-1.0 (0% to 100%)
    pub primary_pattern: Pattern,     // Strongest detected pattern
    pub contributing_patterns: Vec&lt;Pattern&gt;,
    pub macro_recommendation: Option&lt;MacroRecommendation&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="complexity-adjustment"><a class="header" href="#complexity-adjustment">Complexity Adjustment</a></h3>
<p>High-confidence boilerplate reduces effective complexity:</p>
<pre><code>effective_complexity = raw_complexity √ó (1.0 - boilerplate_confidence)
</code></pre>
<p><strong>Example:</strong></p>
<ul>
<li>Raw cyclomatic complexity: 15</li>
<li>Boilerplate confidence: 0.90 (90%)</li>
<li>Effective complexity: 15 √ó (1.0 - 0.90) = 1.5</li>
</ul>
<p>This prevents boilerplate from dominating debt prioritization.</p>
<h3 id="output-display"><a class="header" href="#output-display">Output Display</a></h3>
<p>Debtmap annotates boilerplate functions in analysis output:</p>
<pre><code>src/types/conversions.rs:
  ‚îú‚îÄ from (complexity: 15, boilerplate: 92%)
  ‚îÇ    Pattern: Trait Implementation (From)
  ‚îÇ    Recommendation: Consider #[derive(From)] via derive_more
  ‚îÇ    Priority: Low (boilerplate)

  ‚îú‚îÄ process_request (complexity: 12, boilerplate: 15%)
  ‚îÇ    Priority: High (true complexity)
</code></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="when-to-accept-boilerplate"><a class="header" href="#when-to-accept-boilerplate">When to Accept Boilerplate</a></h3>
<p><strong>Accept</strong> high-complexity boilerplate when:</p>
<ol>
<li><strong>Required by language</strong> - Trait implementations, type conversions</li>
<li><strong>Pattern is clear</strong> - Developers can scan quickly without deep analysis</li>
<li><strong>Covered by tests</strong> - Mechanical patterns verified by unit tests</li>
<li><strong>No simpler alternative</strong> - Refactoring would reduce clarity</li>
</ol>
<p><strong>Example:</strong> Exhaustive match arms for enum variants with simple delegation.</p>
<h3 id="when-to-refactor-boilerplate"><a class="header" href="#when-to-refactor-boilerplate">When to Refactor Boilerplate</a></h3>
<p><strong>Refactor</strong> boilerplate when:</p>
<ol>
<li><strong>Pattern repeats extensively</strong> - 10+ similar implementations</li>
<li><strong>Macro alternative exists</strong> - Can use derive or custom macro</li>
<li><strong>Maintenance burden</strong> - Changes require updating many copies</li>
<li><strong>Error-prone</strong> - Manual pattern increases bug risk</li>
</ol>
<p><strong>Example:</strong> 50+ builder setters that could use <code>typed-builder</code> crate.</p>
<h3 id="configuring-thresholds"><a class="header" href="#configuring-thresholds">Configuring Thresholds</a></h3>
<p>Adjust boilerplate sensitivity in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[boilerplate_detection]
enabled = true
min_confidence_to_exclude = 0.85  # Only exclude 85%+ confidence
trait_delegation_threshold = 0.90  # Trait impl confidence
pattern_match_threshold = 0.75     # Match pattern confidence
</code></pre>
<p><strong>Strict mode</strong> (minimize false negatives):</p>
<pre><code class="language-toml">min_confidence_to_exclude = 0.95  # Very high bar for exclusion
</code></pre>
<p><strong>Lenient mode</strong> (minimize false positives):</p>
<pre><code class="language-toml">min_confidence_to_exclude = 0.70  # More aggressive exclusion
</code></pre>
<h2 id="validation-and-testing"><a class="header" href="#validation-and-testing">Validation and Testing</a></h2>
<h3 id="integration-test-example"><a class="header" href="#integration-test-example">Integration Test Example</a></h3>
<p>Debtmap‚Äôs test suite includes real-world boilerplate validation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_ripgrep_defs_boilerplate() {
    let code = r#"
        impl From&lt;HyperlinkFormat&gt; for ColorHyperlink {
            fn from(format: HyperlinkFormat) -&gt; ColorHyperlink {
                match format {
                    HyperlinkFormat::Default =&gt; ColorHyperlink::default(),
                    // ... 15 variants
                }
            }
        }
    "#;

    let result = analyze_boilerplate(code);
    assert!(result.confidence &gt;= 0.85, "Should detect trait boilerplate");
    assert_eq!(result.primary_pattern, Pattern::TraitImplementation);
}
<span class="boring">}</span></code></pre></pre>
<p>See <code>tests/boilerplate_integration_test.rs</code> for complete test cases.</p>
<h3 id="performance-overhead"><a class="header" href="#performance-overhead">Performance Overhead</a></h3>
<p>Boilerplate detection adds minimal overhead:</p>
<p><strong>Measurement:</strong> &lt;5% increase in analysis time
<strong>Reason:</strong> Single-pass AST analysis with cached pattern matching
<strong>Optimization:</strong> Trait analysis uses fast HashMap lookups</p>
<p>See <code>tests/boilerplate_performance_test.rs</code> for benchmark details.</p>
<h2 id="troubleshooting-7"><a class="header" href="#troubleshooting-7">Troubleshooting</a></h2>
<h3 id="why-is-my-code-marked-as-boilerplate"><a class="header" href="#why-is-my-code-marked-as-boilerplate">‚ÄúWhy is my code marked as boilerplate?‚Äù</a></h3>
<p><strong>Check:</strong></p>
<ol>
<li>Is it a trait implementation? (From, Display, etc.)</li>
<li>Does it follow a mechanical pattern?</li>
<li>Are all branches simple delegations?</li>
</ol>
<p><strong>If incorrectly classified:</strong></p>
<ul>
<li>Adjust <code>min_confidence_to_exclude</code> threshold</li>
<li>Report false positive if confidence is very high</li>
</ul>
<h3 id="my-boilerplate-isnt-detected"><a class="header" href="#my-boilerplate-isnt-detected">‚ÄúMy boilerplate isn‚Äôt detected‚Äù</a></h3>
<p><strong>Common causes:</strong></p>
<ol>
<li>Custom logic mixed with boilerplate pattern</li>
<li>Non-standard trait names</li>
<li>Complex match arm logic</li>
</ol>
<p><strong>Solutions:</strong></p>
<ul>
<li>Extract pure boilerplate into separate functions</li>
<li>Use standard traits when possible</li>
<li>Check confidence score - may be detected with lower confidence</li>
</ul>
<h3 id="boilerplate-detection-seems-too-aggressive"><a class="header" href="#boilerplate-detection-seems-too-aggressive">‚ÄúBoilerplate detection seems too aggressive‚Äù</a></h3>
<p><strong>Adjust configuration:</strong></p>
<pre><code class="language-toml">[boilerplate_detection]
min_confidence_to_exclude = 0.95  # Raise threshold
trait_delegation_threshold = 0.95
</code></pre>
<h2 id="related-documentation-1"><a class="header" href="#related-documentation-1">Related Documentation</a></h2>
<ul>
<li><a href="./metrics-reference.html">Complexity Metrics</a> - Understanding cyclomatic complexity</li>
<li><a href="./configuration.html">Configuration</a> - Complete <code>.debtmap.toml</code> reference</li>
<li><a href="./tiered-prioritization.html">Tiered Prioritization</a> - How boilerplate affects debt ranking</li>
</ul>
<h2 id="summary-2"><a class="header" href="#summary-2">Summary</a></h2>
<p>Boilerplate detection is a critical feature that:</p>
<ul>
<li>Distinguishes mechanical patterns from true complexity</li>
<li>Reduces false positives in debt analysis</li>
<li>Provides actionable macro recommendations</li>
<li>Integrates seamlessly with complexity scoring</li>
<li>Helps teams focus on real maintainability issues</li>
</ul>
<p>By identifying boilerplate with 85%+ confidence, Debtmap ensures that high-complexity scores reflect actual cognitive burden rather than necessary but mechanical code patterns.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cache-management-1"><a class="header" href="#cache-management-1">Cache Management</a></h1>
<p>Debtmap includes a comprehensive caching system designed to significantly speed up repeated analyses, particularly beneficial for large codebases and CI/CD pipelines. The cache stores parsed ASTs, call graphs, analysis results, and file metrics to avoid redundant computation.</p>
<h2 id="cache-location-and-configuration"><a class="header" href="#cache-location-and-configuration">Cache Location and Configuration</a></h2>
<p>Debtmap uses a platform-specific, XDG-compliant cache directory structure by default. The cache location is determined by the following priority order:</p>
<ol>
<li><strong><code>DEBTMAP_CACHE_DIR</code></strong> environment variable (if set)</li>
<li><strong><code>XDG_CACHE_HOME/debtmap</code></strong> (if XDG_CACHE_HOME is set)</li>
<li><strong>Platform-specific defaults:</strong>
<ul>
<li>macOS: <code>~/Library/Caches/debtmap</code></li>
<li>Linux: <code>~/.cache/debtmap</code></li>
<li>Windows: <code>%LOCALAPPDATA%\debtmap</code></li>
</ul>
</li>
<li><strong>Fallback:</strong> System temporary directory</li>
</ol>
<h3 id="cache-strategy"><a class="header" href="#cache-strategy">Cache Strategy</a></h3>
<p>Debtmap supports two cache storage strategies:</p>
<ul>
<li><strong>Shared (default)</strong>: Stores cache in XDG-compliant shared directory (maps to <code>CacheStrategy::Shared</code> in code)</li>
<li><strong>Custom</strong>: Stores cache in user-specified location via <code>DEBTMAP_CACHE_DIR</code> (maps to <code>CacheStrategy::Custom</code> in code)</li>
</ul>
<h3 id="project-identification"><a class="header" href="#project-identification">Project Identification</a></h3>
<p>To ensure cache isolation between different projects, debtmap generates a unique project ID using:</p>
<ol>
<li><strong>Git remote URL hash</strong> (preferred): SHA256 hash (first 16 characters) of the git remote origin URL</li>
<li><strong>Absolute path hash</strong> (fallback): SHA256 hash (first 16 characters) of the project‚Äôs absolute path</li>
</ol>
<p>This ensures that different projects never share cached data, even when analyzed from the same machine.</p>
<h2 id="cache-directory-structure"><a class="header" href="#cache-directory-structure">Cache Directory Structure</a></h2>
<p>The cache directory contains several subdirectories, each serving a specific purpose:</p>
<pre><code>debtmap/
‚îî‚îÄ‚îÄ projects/
    ‚îî‚îÄ‚îÄ &lt;project-id&gt;/
        ‚îú‚îÄ‚îÄ call_graphs/     # Call graph computation results
        ‚îú‚îÄ‚îÄ analysis/        # Analysis results and metrics
        ‚îú‚îÄ‚îÄ metadata/        # Cache indices and metadata
        ‚îú‚îÄ‚îÄ temp/            # Temporary files created during analysis operations
        ‚îî‚îÄ‚îÄ file_metrics/    # File-level complexity scores
</code></pre>
<h2 id="environment-variables-1"><a class="header" href="#environment-variables-1">Environment Variables</a></h2>
<p>Debtmap provides extensive cache configuration through environment variables:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Default</th><th>Example</th></tr></thead><tbody>
<tr><td><code>DEBTMAP_CACHE_DIR</code></td><td>Custom cache directory path</td><td>Platform-specific</td><td><code>/tmp/my-cache</code></td></tr>
<tr><td><code>DEBTMAP_CACHE_AUTO_PRUNE</code></td><td>Enable automatic cache pruning</td><td><code>true</code></td><td><code>true</code> or <code>false</code></td></tr>
<tr><td><code>DEBTMAP_CACHE_MAX_SIZE</code></td><td>Maximum cache size in bytes</td><td><code>1073741824</code> (1GB)</td><td><code>524288000</code> (500MB)</td></tr>
<tr><td><code>DEBTMAP_CACHE_MAX_AGE_DAYS</code></td><td>Maximum age for cache entries</td><td><code>30</code></td><td><code>7</code></td></tr>
<tr><td><code>DEBTMAP_CACHE_MAX_ENTRIES</code></td><td>Maximum number of cache entries</td><td><code>10000</code></td><td><code>5000</code></td></tr>
<tr><td><code>DEBTMAP_CACHE_PRUNE_PERCENTAGE</code></td><td>Percentage to remove when pruning (0.0-1.0)</td><td><code>0.25</code> (25%)</td><td><code>0.3</code> (30%)</td></tr>
<tr><td><code>DEBTMAP_CACHE_STRATEGY</code></td><td>Pruning strategy (lru, lfu, fifo, age). Note: ‚Äòage_based‚Äô is accepted as an alias for ‚Äòage‚Äô</td><td><code>lru</code></td><td><code>lfu</code></td></tr>
<tr><td><code>DEBTMAP_CACHE_SYNC_PRUNE</code></td><td>Use synchronous pruning (blocks)</td><td><code>false</code></td><td><code>true</code></td></tr>
<tr><td><code>DEBTMAP_CACHE_SCOPE</code></td><td>Branch-specific cache scope</td><td>None</td><td><code>feature-branch</code></td></tr>
</tbody></table>
</div>
<h3 id="configuration-examples"><a class="header" href="#configuration-examples">Configuration Examples</a></h3>
<pre><code class="language-bash"># Use a custom cache location
export DEBTMAP_CACHE_DIR=/mnt/fast-ssd/debtmap-cache

# Configure cache limits for CI environment
export DEBTMAP_CACHE_MAX_SIZE=524288000  # 500MB
export DEBTMAP_CACHE_MAX_AGE_DAYS=7      # 1 week
export DEBTMAP_CACHE_STRATEGY=lru

# Disable auto-pruning (manual control)
export DEBTMAP_CACHE_AUTO_PRUNE=false

# Branch-specific caching
# Creates isolated cache namespaces for different branches, useful when
# switching between branches with different code states
export DEBTMAP_CACHE_SCOPE="$(git branch --show-current)"
</code></pre>
<h2 id="command-line-options-1"><a class="header" href="#command-line-options-1">Command Line Options</a></h2>
<p>Debtmap provides several CLI flags for cache management:</p>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--no-cache</code></td><td>Disable caching for this run (caching is enabled by default)</td></tr>
<tr><td><code>--clear-cache</code></td><td>Clear cache before running analysis</td></tr>
<tr><td><code>--force-cache-rebuild</code></td><td>Force cache rebuild (same as <code>--clear-cache</code>)</td></tr>
<tr><td><code>--cache-stats</code></td><td>Show cache statistics and location</td></tr>
<tr><td><code>--migrate-cache</code></td><td>Migrate cache from local to shared location</td></tr>
<tr><td><code>--cache-location &lt;path&gt;</code></td><td>Specify custom cache directory path for this run (sets DEBTMAP_CACHE_DIR)</td></tr>
</tbody></table>
</div>
<h3 id="cli-examples"><a class="header" href="#cli-examples">CLI Examples</a></h3>
<pre><code class="language-bash"># Run analysis without using cache
debtmap --no-cache

# Clear cache and rebuild from scratch
debtmap --clear-cache

# View cache statistics
debtmap --cache-stats

# Use custom cache location for this run
debtmap --cache-location /tmp/temp-cache

# Migrate existing cache to shared location
debtmap --migrate-cache
</code></pre>
<h2 id="automatic-pruning-strategies"><a class="header" href="#automatic-pruning-strategies">Automatic Pruning Strategies</a></h2>
<p>Debtmap automatically prunes the cache when configured limits are exceeded. Four pruning strategies are available:</p>
<h3 id="lru-least-recently-used---default"><a class="header" href="#lru-least-recently-used---default">LRU (Least Recently Used) - Default</a></h3>
<p>Removes entries that haven‚Äôt been accessed recently. Best for general-purpose usage where recently analyzed code is more likely to be analyzed again.</p>
<p><strong>When to use:</strong> Default choice for most development workflows and CI pipelines.</p>
<pre><code class="language-bash">export DEBTMAP_CACHE_STRATEGY=lru
</code></pre>
<h3 id="lfu-least-frequently-used"><a class="header" href="#lfu-least-frequently-used">LFU (Least Frequently Used)</a></h3>
<p>Removes entries with the lowest access count. Best when certain files are analyzed repeatedly while others are analyzed infrequently.</p>
<p><strong>When to use:</strong> Projects with stable core modules that are analyzed frequently and peripheral code that changes rarely.</p>
<pre><code class="language-bash">export DEBTMAP_CACHE_STRATEGY=lfu
</code></pre>
<h3 id="fifo-first-in-first-out"><a class="header" href="#fifo-first-in-first-out">FIFO (First In First Out)</a></h3>
<p>Removes the oldest entries by creation time. Simpler strategy that doesn‚Äôt consider access patterns.</p>
<p><strong>When to use:</strong> When you want predictable cache behavior or are testing cache performance.</p>
<pre><code class="language-bash">export DEBTMAP_CACHE_STRATEGY=fifo
</code></pre>
<h3 id="age-based-only"><a class="header" href="#age-based-only">Age-Based Only</a></h3>
<p>Only removes entries older than <code>DEBTMAP_CACHE_MAX_AGE_DAYS</code>. Does not prune based on size or entry count limits - this means the cache can grow unbounded if all entries are recent.</p>
<p><strong>When to use:</strong> When disk space is not a concern but you want to ensure cache freshness. Note that this strategy ignores size and count thresholds entirely.</p>
<pre><code class="language-bash">export DEBTMAP_CACHE_STRATEGY=age
</code></pre>
<h2 id="default-configuration"><a class="header" href="#default-configuration">Default Configuration</a></h2>
<p>When no environment variables are set, debtmap uses the following defaults:</p>
<ul>
<li><strong>Max size:</strong> 1GB (1,073,741,824 bytes)</li>
<li><strong>Max age:</strong> 30 days</li>
<li><strong>Max entries:</strong> 10,000 entries</li>
<li><strong>Prune percentage:</strong> 25% (removes 25% of entries when limit is hit)</li>
<li><strong>Strategy:</strong> LRU (Least Recently Used)</li>
<li><strong>Auto-prune:</strong> Enabled</li>
</ul>
<h3 id="pruning-triggers"><a class="header" href="#pruning-triggers">Pruning Triggers</a></h3>
<p>Automatic pruning is triggered when:</p>
<ol>
<li><strong>Cache size exceeds max_size_bytes</strong> - Immediate pruning</li>
<li><strong>Entry count exceeds max_entries</strong> - Immediate pruning</li>
<li><strong>Entries older than max_age_days exist</strong> - Periodic pruning (checked daily)</li>
</ol>
<p>When pruning is triggered, debtmap removes enough entries to bring the cache below the configured limits, plus an additional buffer (based on prune_percentage) to avoid frequent pruning.</p>
<h2 id="performance-optimization-1"><a class="header" href="#performance-optimization-1">Performance Optimization</a></h2>
<h3 id="cache-benefits"><a class="header" href="#cache-benefits">Cache Benefits</a></h3>
<p>The cache system provides significant performance improvements by storing various analysis components:</p>
<ul>
<li><strong>Call graphs</strong> (stored in <code>call_graphs/</code>): Reuse expensive call graph computation</li>
<li><strong>Analysis results</strong> (stored in <code>analysis/</code>): Skip redundant metric calculations</li>
<li><strong>File metrics</strong> (stored in <code>file_metrics/</code>): Cache file-level complexity scores</li>
<li><strong>Metadata</strong> (stored in <code>metadata/</code>): Cache indices and project metadata</li>
</ul>
<p><strong>Performance impact:</strong> Cache hits can reduce analysis time by 50-90% for large codebases, depending on the number of changed files.</p>
<h3 id="best-practices-for-ci-environments"><a class="header" href="#best-practices-for-ci-environments">Best Practices for CI Environments</a></h3>
<pre><code class="language-bash"># Example CI configuration for fast builds
export DEBTMAP_CACHE_DIR=/ci-cache/debtmap
export DEBTMAP_CACHE_MAX_SIZE=2147483648  # 2GB for CI
export DEBTMAP_CACHE_MAX_AGE_DAYS=14      # 2 weeks
export DEBTMAP_CACHE_STRATEGY=lru

# Run analysis with cache
debtmap --cache-stats  # Show cache hit rate
</code></pre>
<h3 id="background-vs-synchronous-pruning"><a class="header" href="#background-vs-synchronous-pruning">Background vs Synchronous Pruning</a></h3>
<p>By default, cache pruning runs in a background thread, allowing analysis to continue without waiting for cleanup. This is optimal for development and CI environments.</p>
<p>For testing or when you need deterministic behavior, use synchronous pruning:</p>
<pre><code class="language-bash">export DEBTMAP_CACHE_SYNC_PRUNE=true
</code></pre>
<p><strong>Synchronous pruning:</strong> Blocks during cleanup, ensuring cache is pruned before analysis continues. Used automatically in test environments.</p>
<p><strong>Background pruning (default):</strong> Spawns a separate thread for non-blocking cleanup. Analysis proceeds immediately while cleanup happens in parallel.</p>
<h2 id="troubleshooting-cache-issues"><a class="header" href="#troubleshooting-cache-issues">Troubleshooting Cache Issues</a></h2>
<h3 id="cache-taking-too-much-disk-space"><a class="header" href="#cache-taking-too-much-disk-space">Cache Taking Too Much Disk Space</a></h3>
<p><strong>Problem:</strong> Cache directory is consuming excessive disk space.</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Option 1: Reduce max cache size
export DEBTMAP_CACHE_MAX_SIZE=524288000  # 500MB

# Option 2: Clear cache manually
debtmap --clear-cache

# Option 3: Reduce max age
export DEBTMAP_CACHE_MAX_AGE_DAYS=7

# Option 4: Inspect current cache usage
debtmap --cache-stats
</code></pre>
<h3 id="stale-cache-causing-incorrect-results"><a class="header" href="#stale-cache-causing-incorrect-results">Stale Cache Causing Incorrect Results</a></h3>
<p><strong>Problem:</strong> Cache contains outdated data, causing analysis to report incorrect results.</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Force cache rebuild
debtmap --force-cache-rebuild

# Or disable cache for this run
debtmap --no-cache
</code></pre>
<h3 id="permission-errors"><a class="header" href="#permission-errors">Permission Errors</a></h3>
<p><strong>Problem:</strong> Cannot write to cache directory.</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Use a custom cache location with proper permissions
export DEBTMAP_CACHE_DIR=$HOME/.local/cache/debtmap

# Or check permissions on the default cache directory
ls -la $(debtmap --cache-stats | grep "Cache location")
</code></pre>
<h3 id="inspecting-cache-statistics"><a class="header" href="#inspecting-cache-statistics">Inspecting Cache Statistics</a></h3>
<p>Use <code>--cache-stats</code> to inspect cache health:</p>
<pre><code class="language-bash">debtmap --cache-stats
</code></pre>
<p>This displays:</p>
<ul>
<li>Cache location path</li>
<li>Total cache size</li>
<li>Number of cached entries</li>
<li>Cache hit rate (if available)</li>
<li>Last pruning timestamp</li>
</ul>
<h3 id="debug-cache-issues"><a class="header" href="#debug-cache-issues">Debug Cache Issues</a></h3>
<p>To debug cache-related issues, check:</p>
<ol>
<li>
<p><strong>Cache directory exists and is writable:</strong></p>
<pre><code class="language-bash">ls -la ~/.cache/debtmap  # Linux
ls -la ~/Library/Caches/debtmap  # macOS
</code></pre>
</li>
<li>
<p><strong>Environment variables are set correctly:</strong></p>
<pre><code class="language-bash">env | grep DEBTMAP_CACHE
</code></pre>
</li>
<li>
<p><strong>Project ID generation:</strong>
Cache keys are based on project ID. Verify your project has a stable git remote or path.</p>
</li>
<li>
<p><strong>File timestamps:</strong>
Cache invalidation relies on file modification times. Ensure your build system doesn‚Äôt modify timestamps unexpectedly.</p>
</li>
</ol>
<h2 id="cache-migration"><a class="header" href="#cache-migration">Cache Migration</a></h2>
<p>If you previously used a local cache strategy and want to migrate to the shared XDG-compliant location:</p>
<pre><code class="language-bash">debtmap --migrate-cache
</code></pre>
<p>This command:</p>
<ol>
<li>Identifies the old cache location</li>
<li>Creates the new shared cache directory</li>
<li>Copies cache data preserving metadata</li>
<li>Verifies the migration was successful</li>
</ol>
<p>After migration, you can safely delete the old cache directory.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="context-providers"><a class="header" href="#context-providers">Context Providers</a></h1>
<p>Context providers enhance debtmap‚Äôs risk analysis by incorporating additional factors beyond complexity and test coverage. They analyze critical execution paths, dependency relationships, and version control history to provide a more comprehensive understanding of technical risk.</p>
<h2 id="overview-5"><a class="header" href="#overview-5">Overview</a></h2>
<p>Context providers implement the <code>ContextProvider</code> trait, which gathers risk-relevant information about functions and modules. Each provider analyzes a specific dimension of risk:</p>
<ul>
<li><strong>Critical Path Provider</strong>: Identifies functions on critical execution paths</li>
<li><strong>Dependency Provider</strong>: Analyzes call graph relationships and blast radius</li>
<li><strong>Git History Provider</strong>: Integrates version control history for change patterns</li>
</ul>
<p>Context providers help debtmap understand:</p>
<ul>
<li>Which code paths are most critical</li>
<li>How functions depend on each other</li>
<li>Which code changes most frequently</li>
<li>Where bugs are likely to occur</li>
</ul>
<p>This context-aware analysis improves prioritization accuracy and reduces false positives.</p>
<p>The <code>ContextAggregator</code> combines context from multiple enabled providers and adjusts risk scores using the formula:</p>
<pre><code>contextual_risk = base_risk √ó (1.0 + context_contribution)
</code></pre>
<p>Where <code>context_contribution</code> is the weighted sum of all provider contributions:</p>
<pre><code>context_contribution = Œ£(provider.contribution √ó provider.weight)
</code></pre>
<h2 id="critical-path-provider"><a class="header" href="#critical-path-provider">Critical Path Provider</a></h2>
<p>The Critical Path provider identifies functions that lie on critical execution paths through your application. Functions on these paths have elevated risk because failures directly impact user-facing functionality.</p>
<h3 id="entry-point-detection"><a class="header" href="#entry-point-detection">Entry Point Detection</a></h3>
<p>The provider automatically detects entry points based on function names and file paths. These weights determine the base criticality of execution paths:</p>
<div class="table-wrapper"><table><thead><tr><th>Entry Type</th><th>Weight</th><th>Detection Pattern</th><th>User-Facing</th></tr></thead><tbody>
<tr><td>Main</td><td>10.0</td><td>Function named <code>main</code></td><td>Yes</td></tr>
<tr><td>API Endpoint</td><td>8.0</td><td><code>handle_*</code>, <code>*_handler</code>, <code>get_*</code>, <code>post_*</code> in <code>api/</code>, <code>handler/</code>, <code>route/</code> paths</td><td>Yes</td></tr>
<tr><td>CLI Command</td><td>7.0</td><td><code>cmd_*</code>, <code>command_*</code>, <code>*_command</code> in <code>cli/</code>, <code>command/</code> paths</td><td>Yes</td></tr>
<tr><td>Web Handler</td><td>7.0</td><td>Functions with <code>route</code>, <code>handler</code> in <code>web/</code>, <code>http/</code> paths</td><td>Yes</td></tr>
<tr><td>Event Handler</td><td>5.0</td><td><code>on_*</code>, <code>*_listener</code>, contains <code>event</code></td><td>No</td></tr>
<tr><td>Test Entry</td><td>2.0</td><td><code>test_*</code>, in <code>test/</code> paths</td><td>No</td></tr>
</tbody></table>
</div>
<p><strong>What it detects:</strong></p>
<ul>
<li>Entry points (main functions, CLI handlers, API endpoints)</li>
<li>Error handling paths</li>
<li>Data processing pipelines</li>
<li>Resource initialization</li>
</ul>
<h3 id="path-weighting"><a class="header" href="#path-weighting">Path Weighting</a></h3>
<p>Functions on critical paths receive contribution scores based on:</p>
<ul>
<li><strong>Path weight</strong>: The maximum entry point weight leading to the function</li>
<li><strong>User-facing flag</strong>: Doubles contribution for user-facing paths</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Example: Function on main entry path (weight 10.0, user-facing)
contribution = (10.0 / 10.0) √ó 2.0 = 2.0

// Example: Function on event handler path (weight 5.0, non-user-facing)
contribution = (5.0 / 10.0) √ó 1.0 = 0.5
<span class="boring">}</span></code></pre></pre>
<p><strong>Impact on scoring:</strong></p>
<ul>
<li>Functions on critical paths get higher priority</li>
<li>Entry point multiplier: 1.5x</li>
<li>Business logic multiplier: 1.2x</li>
</ul>
<h3 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h3>
<ul>
<li><strong>API prioritization</strong>: Identify critical endpoints that need careful review</li>
<li><strong>Refactoring safety</strong>: Avoid breaking user-facing execution paths</li>
<li><strong>Test coverage</strong>: Ensure critical paths have adequate test coverage</li>
</ul>
<h3 id="enable"><a class="header" href="#enable">Enable</a></h3>
<pre><code class="language-bash">debtmap analyze . --context-providers critical_path
</code></pre>
<p><strong>Configuration:</strong></p>
<pre><code class="language-toml">[analysis]
context_providers = ["critical_path"]

# Note: Provider-specific TOML sections below are planned features.
# Currently, providers use hard-coded defaults. Use CLI flags for now.

[context.critical_path]
# Multiplier for entry points (default: 1.5)
entry_point_multiplier = 1.5

# Multiplier for business logic (default: 1.2)
business_logic_multiplier = 1.2
</code></pre>
<h2 id="dependency-provider"><a class="header" href="#dependency-provider">Dependency Provider</a></h2>
<p>The Dependency provider analyzes call graph relationships to identify functions with high architectural impact. It calculates how changes propagate through the dependency graph and determines the blast radius of modifications.</p>
<h3 id="dependency-chain-analysis"><a class="header" href="#dependency-chain-analysis">Dependency Chain Analysis</a></h3>
<p>The provider builds a dependency graph where:</p>
<ul>
<li><strong>Modules</strong> contain functions and have intrinsic risk scores</li>
<li><strong>Edges</strong> represent dependencies with coupling strength (0.0-1.0)</li>
<li><strong>Risk propagation</strong> flows through dependencies using iterative refinement</li>
</ul>
<p><strong>What it detects:</strong></p>
<ul>
<li>Upstream dependencies (functions this function calls)</li>
<li>Downstream dependencies (functions that call this function)</li>
<li>Transitive dependencies through the call graph</li>
<li>Dependency criticality</li>
</ul>
<h3 id="blast-radius-calculation"><a class="header" href="#blast-radius-calculation">Blast Radius Calculation</a></h3>
<p>The blast radius represents how many modules would be affected by changes to a function. It counts unique modules reachable through transitive dependencies by traversing the dependency graph edges.</p>
<div class="table-wrapper"><table><thead><tr><th>Blast Radius</th><th>Contribution</th><th>Impact Level</th></tr></thead><tbody>
<tr><td>&gt; 10 modules</td><td>1.5</td><td>Critical dependency affecting many modules</td></tr>
<tr><td>6-10 modules</td><td>1.0</td><td>Important dependency with moderate impact</td></tr>
<tr><td>3-5 modules</td><td>0.5</td><td>Limited dependency impact</td></tr>
<tr><td>‚â§ 2 modules</td><td>0.2</td><td>Minimal or isolated component</td></tr>
</tbody></table>
</div>
<h3 id="risk-propagation-formula"><a class="header" href="#risk-propagation-formula">Risk Propagation Formula</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>propagated_risk = base_risk √ó criticality_factor + dependency_risk

where:
  criticality_factor = 1.0 + min(0.5, dependents.len() √ó 0.1)
  dependency_risk = Œ£(dependency.risk √ó coupling_strength √ó 0.3)
<span class="boring">}</span></code></pre></pre>
<p><strong>Note</strong>: The constants (0.5, 0.1, 0.3) are currently hard-coded based on empirical analysis. Future versions may make these configurable.</p>
<p><strong>Impact on scoring:</strong></p>
<pre><code>dependency_factor = normalized_to_0_10(upstream + downstream)

Ranges:
- Entry points: 8-10 (critical path)
- Business logic: 6-8 (core functionality)
- Data access: 5-7 (important but stable)
- Utilities: 3-5 (lower priority)
- Test helpers: 1-3 (lowest priority)
</code></pre>
<h3 id="use-cases-1"><a class="header" href="#use-cases-1">Use Cases</a></h3>
<ul>
<li><strong>Architectural refactoring</strong>: Identify high-impact modules to refactor carefully</li>
<li><strong>Change impact analysis</strong>: Understand downstream effects of modifications</li>
<li><strong>Module decoupling</strong>: Find tightly coupled modules with high blast radius</li>
</ul>
<h3 id="enable-1"><a class="header" href="#enable-1">Enable</a></h3>
<pre><code class="language-bash">debtmap analyze . --context-providers dependency
</code></pre>
<p><strong>Configuration:</strong></p>
<pre><code class="language-toml">[analysis]
context_providers = ["dependency"]

# Note: Provider-specific TOML sections below are planned features.
# Currently, providers use hard-coded defaults. Use CLI flags for now.

[context.dependency]
# Include transitive dependencies (default: true)
include_transitive = true

# Maximum depth for transitive analysis (default: 5)
max_depth = 5
</code></pre>
<h2 id="git-history-provider"><a class="header" href="#git-history-provider">Git History Provider</a></h2>
<p>The Git History provider integrates version control data to detect change-prone code and bug patterns. Files with frequent changes and bug fixes indicate higher maintenance risk.</p>
<h3 id="metrics-collected"><a class="header" href="#metrics-collected">Metrics Collected</a></h3>
<p>The provider analyzes Git history to calculate:</p>
<ul>
<li><strong>Change frequency</strong>: Commits per month (recent activity indicator)</li>
<li><strong>Bug density</strong>: Ratio of bug fix commits to total commits</li>
<li><strong>Age</strong>: Days since first commit (maturity indicator)</li>
<li><strong>Author count</strong>: Number of unique contributors (complexity indicator)</li>
<li><strong>Total commits</strong>: Total number of commits to the file</li>
<li><strong>Last modified</strong>: Timestamp of the most recent commit</li>
<li><strong>Stability score</strong>: Weighted combination of churn, bug fixes, and age (0.0-1.0)</li>
</ul>
<p><strong>What it analyzes:</strong></p>
<ul>
<li>Commit frequency per file/function</li>
<li>Bug fix patterns (commits with ‚Äúfix‚Äù in message)</li>
<li>Code churn (lines added/removed)</li>
<li>Recent activity</li>
</ul>
<h3 id="risk-classification"><a class="header" href="#risk-classification">Risk Classification</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Conditions</th><th>Contribution</th><th>Explanation</th></tr></thead><tbody>
<tr><td>Very unstable</td><td>freq &gt; 5.0 AND bug_density &gt; 0.3</td><td>2.0</td><td>High churn with many bug fixes</td></tr>
<tr><td>Moderately unstable</td><td>freq &gt; 2.0 OR bug_density &gt; 0.2</td><td>1.0</td><td>Frequent changes or bug-prone</td></tr>
<tr><td>Slightly unstable</td><td>freq &gt; 1.0 OR bug_density &gt; 0.1</td><td>0.5</td><td>Some instability</td></tr>
<tr><td>Stable</td><td>freq ‚â§ 1.0 AND bug_density ‚â§ 0.1</td><td>0.1</td><td>Low change rate, few bugs</td></tr>
</tbody></table>
</div>
<h3 id="bug-fix-detection"><a class="header" href="#bug-fix-detection">Bug Fix Detection</a></h3>
<p>The provider identifies bug fixes by searching commit messages for patterns:</p>
<pre><code class="language-bash">git log --grep=fix --grep=bug --grep=Fix --grep=Bug -- &lt;file&gt;
</code></pre>
<h3 id="stability-score"><a class="header" href="#stability-score">Stability Score</a></h3>
<p>Stability is calculated using weighted factors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>stability = (churn_factor √ó 0.4) + (bug_factor √ó 0.4) + (age_factor √ó 0.2)

where:
  churn_factor = 1.0 / (1.0 + monthly_churn)
  bug_factor = 1.0 - (bug_fixes / total_commits)
  age_factor = min(1.0, age_days / 365.0)
<span class="boring">}</span></code></pre></pre>
<p><strong>Impact on scoring:</strong></p>
<ul>
<li>High-churn functions get higher priority</li>
<li>Recently fixed bugs indicate risk areas</li>
<li>Stable code (no recent changes) gets lower priority</li>
</ul>
<h3 id="use-cases-2"><a class="header" href="#use-cases-2">Use Cases</a></h3>
<ul>
<li><strong>Find change-prone code</strong>: Identify files that change frequently and need attention</li>
<li><strong>Detect bug hotspots</strong>: Locate areas with high bug fix rates</li>
<li><strong>Prioritize refactoring</strong>: Target unstable code for improvement</li>
<li><strong>Team collaboration patterns</strong>: Files touched by many authors may need better documentation</li>
</ul>
<h3 id="enable-2"><a class="header" href="#enable-2">Enable</a></h3>
<pre><code class="language-bash">debtmap analyze . --context-providers git_history
</code></pre>
<p><strong>Configuration:</strong></p>
<pre><code class="language-toml">[analysis]
context_providers = ["git_history"]

# Note: Provider-specific TOML sections below are planned features.
# Currently, providers use hard-coded defaults. Use CLI flags for now.

[context.git_history]
# Commits to analyze (default: 100)
max_commits = 100

# Time range in days (default: 90)
time_range_days = 90

# Minimum commits to consider "high churn" (default: 10)
high_churn_threshold = 10
</code></pre>
<h3 id="troubleshooting-8"><a class="header" href="#troubleshooting-8">Troubleshooting</a></h3>
<p><strong>Git repository not found</strong>: The provider requires a Git repository. If analysis fails:</p>
<pre><code class="language-bash"># Verify you're in a git repository
git rev-parse --git-dir

# If not a git repo, initialize one or disable git_history provider
# Option 1: Enable context but exclude git_history
debtmap analyze --context --disable-context git_history

# Option 2: Use only specific providers
debtmap analyze --context-providers critical_path,dependency
</code></pre>
<p><strong>Performance issues</strong>: Git history analysis can be slow for large repositories:</p>
<pre><code class="language-bash"># Use only lightweight providers
debtmap analyze --context-providers critical_path,dependency
</code></pre>
<h2 id="enabling-context-providers"><a class="header" href="#enabling-context-providers">Enabling Context Providers</a></h2>
<p>Context-aware analysis is disabled by default. Enable it using CLI flags:</p>
<h3 id="enable-all-providers"><a class="header" href="#enable-all-providers">Enable All Providers</a></h3>
<pre><code class="language-bash"># Enable all available context providers
debtmap analyze --context
# or
debtmap analyze --enable-context
</code></pre>
<h3 id="enable-specific-providers"><a class="header" href="#enable-specific-providers">Enable Specific Providers</a></h3>
<pre><code class="language-bash"># Enable only critical_path and dependency
debtmap analyze --context-providers critical_path,dependency

# Enable only git_history
debtmap analyze --context-providers git_history

# Enable all three explicitly
debtmap analyze --context-providers critical_path,dependency,git_history
</code></pre>
<h3 id="disable-specific-providers"><a class="header" href="#disable-specific-providers">Disable Specific Providers</a></h3>
<pre><code class="language-bash"># Enable context but disable git_history (useful for non-git repos)
debtmap analyze --context --disable-context git_history

# Enable context but disable dependency analysis
debtmap analyze --context --disable-context dependency
</code></pre>
<h3 id="enabling-multiple-providers"><a class="header" href="#enabling-multiple-providers">Enabling Multiple Providers</a></h3>
<p>Combine providers for comprehensive analysis:</p>
<pre><code class="language-bash">debtmap analyze . --context-providers critical_path,dependency,git_history
</code></pre>
<p>Or via config:</p>
<pre><code class="language-toml">[analysis]
context_providers = ["critical_path", "dependency", "git_history"]
</code></pre>
<h2 id="provider-weights"><a class="header" href="#provider-weights">Provider Weights</a></h2>
<p>Each provider has a weight that determines its influence on the final risk score:</p>
<div class="table-wrapper"><table><thead><tr><th>Provider</th><th>Weight</th><th>Rationale</th></tr></thead><tbody>
<tr><td>critical_path</td><td>1.5</td><td>Critical paths have high impact on users</td></tr>
<tr><td>dependency_risk</td><td>1.2</td><td>Architectural dependencies affect many modules</td></tr>
<tr><td>git_history</td><td>1.0</td><td>Historical patterns indicate future risk</td></tr>
</tbody></table>
</div>
<p>The total context contribution is calculated as:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>total_contribution = Œ£(contribution_i √ó weight_i)

Example with all providers:
  critical_path: 2.0 √ó 1.5 = 3.0
  dependency:    1.0 √ó 1.2 = 1.2
  git_history:   0.5 √ó 1.0 = 0.5
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  total_contribution = 4.7

contextual_risk = base_risk √ó (1.0 + 4.7) = base_risk √ó 5.7
<span class="boring">}</span></code></pre></pre>
<h2 id="how-context-affects-scoring"><a class="header" href="#how-context-affects-scoring">How Context Affects Scoring</a></h2>
<h3 id="base-scoring-no-context"><a class="header" href="#base-scoring-no-context">Base Scoring (No Context)</a></h3>
<pre><code>Base Score = (Complexity √ó 0.40) + (Coverage √ó 0.40) + (Dependency √ó 0.20)
</code></pre>
<h3 id="with-context-providers"><a class="header" href="#with-context-providers">With Context Providers</a></h3>
<pre><code>Context-Adjusted Score = Base Score √ó Role Multiplier √ó Churn Multiplier

Role Multiplier (from critical path &amp; dependency analysis):
- Entry points: 1.5x
- Business logic: 1.2x
- Data access: 1.0x
- Infrastructure: 0.8x
- Utilities: 0.5x
- Test code: 0.1x

Churn Multiplier (from git history):
- High churn (10+ commits/month): 1.3x
- Medium churn (5-10 commits/month): 1.1x
- Low churn (1-5 commits/month): 1.0x
- Stable (0 commits/6 months): 0.8x
</code></pre>
<h2 id="context-details-structure"><a class="header" href="#context-details-structure">Context Details Structure</a></h2>
<p>When using <code>--format json</code>, context information is included in the output. The <code>ContextDetails</code> enum contains provider-specific data:</p>
<h3 id="criticalpath"><a class="header" href="#criticalpath">CriticalPath</a></h3>
<pre><code class="language-json">{
  "provider": "critical_path",
  "weight": 1.5,
  "contribution": 2.0,
  "details": {
    "CriticalPath": {
      "entry_points": ["main (Main)", "handle_request (ApiEndpoint)"],
      "path_weight": 10.0,
      "is_user_facing": true
    }
  }
}
</code></pre>
<h3 id="dependencychain"><a class="header" href="#dependencychain">DependencyChain</a></h3>
<pre><code class="language-json">{
  "provider": "dependency_risk",
  "weight": 1.2,
  "contribution": 1.5,
  "details": {
    "DependencyChain": {
      "depth": 3,
      "propagated_risk": 8.5,
      "dependents": ["module_a", "module_b", "module_c"],
      "blast_radius": 12
    }
  }
}
</code></pre>
<h3 id="historical"><a class="header" href="#historical">Historical</a></h3>
<pre><code class="language-json">{
  "provider": "git_history",
  "weight": 1.0,
  "contribution": 1.0,
  "details": {
    "Historical": {
      "change_frequency": 3.5,
      "bug_density": 0.25,
      "age_days": 180,
      "author_count": 5
    }
  }
}
</code></pre>
<h2 id="practical-examples-1"><a class="header" href="#practical-examples-1">Practical Examples</a></h2>
<h3 id="example-1-entry-point-vs-utility"><a class="header" href="#example-1-entry-point-vs-utility">Example 1: Entry Point vs Utility</a></h3>
<p><strong>Without context providers:</strong></p>
<pre><code>Function: main() - Entry point
Complexity: 8
Coverage: 50%
Score: 6.0 [MEDIUM]

Function: format_string() - Utility
Complexity: 8
Coverage: 50%
Score: 6.0 [MEDIUM]
</code></pre>
<p>Both functions have the same score.</p>
<p><strong>With context providers:</strong></p>
<pre><code>Function: main() - Entry point
Complexity: 8
Coverage: 50%
Base Score: 6.0
Role Multiplier: 1.5x (entry point)
Final Score: 9.0 [CRITICAL]

Function: format_string() - Utility
Complexity: 8
Coverage: 50%
Base Score: 6.0
Role Multiplier: 0.5x (utility)
Final Score: 3.0 [LOW]
</code></pre>
<p>Entry point is prioritized over utility.</p>
<h3 id="example-2-high-churn-function"><a class="header" href="#example-2-high-churn-function">Example 2: High-Churn Function</a></h3>
<p><strong>Without git history:</strong></p>
<pre><code>Function: process_payment()
Complexity: 12
Coverage: 60%
Score: 7.5 [HIGH]
</code></pre>
<p><strong>With git history:</strong></p>
<pre><code>Function: process_payment()
Complexity: 12
Coverage: 60%
Base Score: 7.5
Churn: 15 commits in last month (bug fixes)
Churn Multiplier: 1.3x
Final Score: 9.75 [CRITICAL]
</code></pre>
<p>High-churn function is elevated to critical.</p>
<h3 id="example-3-stable-well-tested-code"><a class="header" href="#example-3-stable-well-tested-code">Example 3: Stable Well-Tested Code</a></h3>
<p><strong>Without context:</strong></p>
<pre><code>Function: legacy_parser()
Complexity: 15
Coverage: 95%
Score: 3.5 [LOW]
</code></pre>
<p><strong>With context:</strong></p>
<pre><code>Function: legacy_parser()
Complexity: 15
Coverage: 95%
Base Score: 3.5
Churn: 0 commits in last 2 years
Churn Multiplier: 0.8x
Role: Data access (stable)
Role Multiplier: 1.0x
Final Score: 2.8 [LOW]
</code></pre>
<p>Stable, well-tested code gets even lower priority.</p>
<h3 id="example-4-api-endpoint-prioritization"><a class="header" href="#example-4-api-endpoint-prioritization">Example 4: API Endpoint Prioritization</a></h3>
<p>Analyze a web service to identify critical API endpoints:</p>
<pre><code class="language-bash">debtmap analyze --context-providers critical_path --format json
</code></pre>
<p>Functions on API endpoint paths will receive elevated risk scores. Use this to prioritize code review and testing for user-facing functionality.</p>
<h3 id="example-5-finding-change-prone-code"><a class="header" href="#example-5-finding-change-prone-code">Example 5: Finding Change-Prone Code</a></h3>
<p>Identify files with high change frequency and bug fixes:</p>
<pre><code class="language-bash">debtmap analyze --context-providers git_history --top 20
</code></pre>
<p>This highlights unstable areas of the codebase that may benefit from refactoring or increased test coverage.</p>
<h3 id="example-6-architectural-impact-analysis"><a class="header" href="#example-6-architectural-impact-analysis">Example 6: Architectural Impact Analysis</a></h3>
<p>Find high-impact modules with large blast radius:</p>
<pre><code class="language-bash">debtmap analyze --context-providers dependency --format json | \
  jq '.[] | select(.blast_radius &gt; 10)'
</code></pre>
<p>Use this to identify architectural choke points that require careful change management.</p>
<h3 id="example-7-comprehensive-risk-assessment"><a class="header" href="#example-7-comprehensive-risk-assessment">Example 7: Comprehensive Risk Assessment</a></h3>
<p>Combine all providers for holistic risk analysis:</p>
<pre><code class="language-bash">debtmap analyze --context -v
</code></pre>
<p>The verbose output shows how each provider contributes to the final risk score:</p>
<pre><code>function: process_payment
  base_risk: 5.0
  critical_path: +3.0 (on main path, user-facing)
  dependency: +1.2 (12 dependent modules)
  git_history: +1.0 (3.5 changes/month, 0.25 bug density)
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  contextual_risk: 26.0
</code></pre>
<h2 id="configuration-3"><a class="header" href="#configuration-3">Configuration</a></h2>
<p>Configure context providers in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[analysis]
# Enable context-aware analysis (default: false)
enable_context = true

# Specify which providers to use
context_providers = ["critical_path", "dependency", "git_history"]

# Disable specific providers (use CLI flag --disable-context instead)
# disable_context = ["git_history"]  # Not yet implemented in config

# Note: The provider-specific TOML sections below are planned features.
# Currently, all provider settings use hard-coded defaults from the implementation.
# Use CLI flags (--context, --context-providers, --disable-context) to control providers.
# See the CLI examples throughout this chapter for working configurations.

[context.git_history]
# Commits to analyze (default: 100) - PLANNED
max_commits = 100

# Time range in days (default: 90) - PLANNED
time_range_days = 90

# Minimum commits to consider "high churn" (default: 10) - PLANNED
high_churn_threshold = 10

[context.critical_path]
# Multiplier for entry points (default: 1.5) - PLANNED
entry_point_multiplier = 1.5

# Multiplier for business logic (default: 1.2) - PLANNED
business_logic_multiplier = 1.2

[context.dependency]
# Include transitive dependencies (default: true) - PLANNED
include_transitive = true

# Maximum depth for transitive analysis (default: 5) - PLANNED
max_depth = 5
</code></pre>
<h2 id="performance-considerations-1"><a class="header" href="#performance-considerations-1">Performance Considerations</a></h2>
<p>Context providers add computational overhead to analysis:</p>
<p><strong>Impact on analysis time:</strong></p>
<ul>
<li>Critical path: +10-15% (fast - call graph traversal)</li>
<li>Dependency: +20-30% (moderate - iterative risk propagation)</li>
<li>Git history: +30-50% (slow for large repos - multiple git commands per file)</li>
</ul>
<p><strong>Combined overhead:</strong> ~60-80% increase in analysis time</p>
<h3 id="optimization-tips"><a class="header" href="#optimization-tips">Optimization Tips</a></h3>
<ol>
<li><strong>Start minimal</strong>: Use <code>--context-providers critical_path,dependency</code> initially</li>
<li><strong>Add git_history selectively</strong>: Enable for critical modules only</li>
<li><strong>Use caching</strong>: The <code>ContextAggregator</code> caches results by <code>file:function</code> key</li>
<li><strong>Profile with verbose flags</strong>: Use <code>-vvv</code> to see provider execution times</li>
</ol>
<h3 id="for-large-projects"><a class="header" href="#for-large-projects">For Large Projects</a></h3>
<pre><code class="language-bash"># Disable git history for faster analysis
debtmap analyze . --disable-context git_history

# Or disable all context
debtmap analyze . --no-context-aware
</code></pre>
<h3 id="for-cicd"><a class="header" href="#for-cicd">For CI/CD</a></h3>
<pre><code class="language-bash"># Full analysis with context (run nightly)
debtmap analyze . --context-providers critical_path,dependency,git_history

# Fast analysis without context (run on every commit)
debtmap analyze . --no-context-aware
</code></pre>
<h3 id="when-to-use-each-provider"><a class="header" href="#when-to-use-each-provider">When to Use Each Provider</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Scenario</th><th>Recommended Providers</th></tr></thead><tbody>
<tr><td>API service refactoring</td><td><code>critical_path</code></td></tr>
<tr><td>Legacy codebase analysis</td><td><code>git_history</code></td></tr>
<tr><td>Microservice boundaries</td><td><code>dependency</code></td></tr>
<tr><td>Pre-release risk review</td><td>All providers (<code>--context</code>)</td></tr>
<tr><td>CI/CD integration</td><td><code>critical_path,dependency</code> (faster)</td></tr>
</tbody></table>
</div>
<h2 id="troubleshooting-9"><a class="header" href="#troubleshooting-9">Troubleshooting</a></h2>
<h3 id="git-history-analysis-slow"><a class="header" href="#git-history-analysis-slow">Git History Analysis Slow</a></h3>
<p><strong>Issue:</strong> Analysis takes much longer with git history enabled</p>
<p><strong>Solutions:</strong></p>
<p><strong>Reduce commit history:</strong></p>
<pre><code class="language-toml">[context.git_history]
max_commits = 50
time_range_days = 30
</code></pre>
<p><strong>Use shallow clone in CI:</strong></p>
<pre><code class="language-bash">git clone --depth 50 repo.git
debtmap analyze . --context-providers critical_path,dependency
</code></pre>
<h3 id="incorrect-role-classification"><a class="header" href="#incorrect-role-classification">Incorrect Role Classification</a></h3>
<p><strong>Issue:</strong> Function classified as wrong role (e.g., utility instead of business logic)</p>
<p><strong>Possible causes:</strong></p>
<ol>
<li>Function naming doesn‚Äôt match patterns</li>
<li>Call graph analysis incomplete</li>
<li>Function is misplaced in codebase</li>
</ol>
<p><strong>Solutions:</strong></p>
<p><strong>Check with verbose output:</strong></p>
<pre><code class="language-bash">debtmap analyze . -vv | grep "Role classification"
</code></pre>
<p><strong>Manually verify call graph:</strong></p>
<pre><code class="language-bash">debtmap analyze . --show-call-graph
</code></pre>
<h3 id="context-providers-not-available"><a class="header" href="#context-providers-not-available">Context Providers Not Available</a></h3>
<p><strong>Issue:</strong> <code>--context-providers</code> flag not recognized</p>
<p><strong>Solution:</strong> Ensure you‚Äôre using a recent version:</p>
<pre><code class="language-bash">debtmap --version
# Should be 0.2.0 or later
</code></pre>
<p>Update debtmap:</p>
<pre><code class="language-bash">cargo install debtmap --force
</code></pre>
<h3 id="common-issues-1"><a class="header" href="#common-issues-1">Common Issues</a></h3>
<p><strong>Issue</strong>: Context providers not affecting scores</p>
<p><strong>Solution</strong>: Ensure providers are enabled with <code>--context</code> or <code>--context-providers</code></p>
<pre><code class="language-bash"># Wrong: context flag missing
debtmap analyze

# Correct: context enabled
debtmap analyze --context
</code></pre>
<hr />
<p><strong>Issue</strong>: Git history provider fails with ‚ÄúNot a git repository‚Äù</p>
<p><strong>Solution</strong>: Disable git_history if not using version control</p>
<pre><code class="language-bash">debtmap analyze --context --disable-context git_history
</code></pre>
<hr />
<p><strong>Issue</strong>: Dependency analysis errors</p>
<p><strong>Solution</strong>: Check for circular dependencies or disable dependency provider</p>
<pre><code class="language-bash">debtmap analyze --context --disable-context dependency
</code></pre>
<hr />
<p><strong>Issue</strong>: Slow analysis with all providers</p>
<p><strong>Solution</strong>: Use selective providers or increase verbosity to identify bottlenecks</p>
<pre><code class="language-bash"># Faster: skip git_history
debtmap analyze --context-providers critical_path,dependency

# Debug: see provider execution times
debtmap analyze --context -vvv
</code></pre>
<hr />
<p>For more troubleshooting guidance, see the <a href="troubleshooting.html">Troubleshooting</a> chapter.</p>
<h2 id="advanced-usage"><a class="header" href="#advanced-usage">Advanced Usage</a></h2>
<h3 id="interpreting-context-contribution"><a class="header" href="#interpreting-context-contribution">Interpreting Context Contribution</a></h3>
<p>Enable verbose output to see detailed context contributions:</p>
<pre><code class="language-bash">debtmap analyze --context -v
</code></pre>
<p>Each function shows:</p>
<ul>
<li>Base risk score from complexity/coverage</li>
<li>Individual provider contributions</li>
<li>Total contextual risk score</li>
<li>Provider-specific explanations</li>
</ul>
<h3 id="architecture-exploration"><a class="header" href="#architecture-exploration">Architecture Exploration</a></h3>
<p>The <code>ContextAggregator</code> caches context by <code>file:function</code> key to avoid redundant analysis during a single run. The cache is in-memory per <code>ContextAggregator</code> instance and is cleared when a new instance is created or when analyzing a different codebase. This enables efficient re-analysis within the same run:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut aggregator = ContextAggregator::new()
    .with_provider(Box::new(CriticalPathProvider::new(analyzer)))
    .with_provider(Box::new(DependencyRiskProvider::new(graph)))
    .with_provider(Box::new(GitHistoryProvider::new(repo_root)?));

let context = aggregator.analyze(&amp;target);
let contribution = context.total_contribution();
<span class="boring">}</span></code></pre></pre>
<h3 id="custom-provider-implementation"><a class="header" href="#custom-provider-implementation">Custom Provider Implementation</a></h3>
<p>Advanced users can implement custom context providers by implementing the <code>ContextProvider</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait ContextProvider: Send + Sync {
    fn name(&amp;self) -&gt; &amp;str;
    fn gather(&amp;self, target: &amp;AnalysisTarget) -&gt; Result&lt;Context&gt;;
    fn weight(&amp;self) -&gt; f64;
    fn explain(&amp;self, context: &amp;Context) -&gt; String;
}
<span class="boring">}</span></code></pre></pre>
<p>See <a href="https://github.com/your-repo/debtmap/blob/main/src/risk/context/mod.rs">src/risk/context/mod.rs</a> for implementation examples.</p>
<h2 id="future-enhancements"><a class="header" href="#future-enhancements">Future Enhancements</a></h2>
<h3 id="business-context-provider-planned"><a class="header" href="#business-context-provider-planned">Business Context Provider (Planned)</a></h3>
<p>A Business context provider is defined but not yet implemented. It will support:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>Business {
    priority: Priority,      // Critical, High, Medium, Low
    impact: Impact,          // Revenue, UserExperience, Security, Compliance
    annotations: Vec&lt;String&gt; // Custom business metadata
}
<span class="boring">}</span></code></pre></pre>
<p>This will allow manual prioritization based on business requirements through code annotations or configuration files.</p>
<h2 id="best-practices-5"><a class="header" href="#best-practices-5">Best Practices</a></h2>
<ol>
<li><strong>Use all providers for comprehensive analysis</strong> - Especially for production code</li>
<li><strong>Disable git history in CI</strong> - Use shallow clones or disable for speed</li>
<li><strong>Verify role classifications</strong> - Use <code>-vv</code> to see how functions are classified</li>
<li><strong>Tune multipliers for your project</strong> - Adjust in config based on architecture</li>
<li><strong>Combine with coverage data</strong> - Context providers enhance coverage-based risk analysis</li>
</ol>
<h2 id="summary-3"><a class="header" href="#summary-3">Summary</a></h2>
<p>Context providers transform debtmap from a static complexity analyzer into a comprehensive risk assessment tool. By combining:</p>
<ul>
<li><strong>Critical path analysis</strong> for user impact</li>
<li><strong>Dependency analysis</strong> for architectural risk</li>
<li><strong>Git history analysis</strong> for maintenance patterns</li>
</ul>
<p>You gain actionable insights for prioritizing technical debt and refactoring efforts. Start with <code>--context</code> to enable all providers, then refine based on your project‚Äôs needs.</p>
<h2 id="see-also-2"><a class="header" href="#see-also-2">See Also</a></h2>
<ul>
<li><a href="analysis-guide.html">Analysis Guide</a> - Core analysis concepts</li>
<li><a href="analysis-guide.html#risk-assessment">Risk Assessment</a> - Risk scoring methodology</li>
<li><a href="configuration.html">Configuration</a> - Complete configuration reference</li>
<li><a href="parallel-processing.html">Parallel Processing</a> - Performance optimization</li>
<li><a href="troubleshooting.html">Troubleshooting</a> - Common issues and solutions</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="coverage-gap-analysis"><a class="header" href="#coverage-gap-analysis">Coverage Gap Analysis</a></h1>
<p>Debtmap provides precise line-level coverage gap reporting to help you understand exactly which lines of code lack test coverage, rather than relying on misleading function-level percentages.</p>
<h2 id="understanding-coverage-gaps"><a class="header" href="#understanding-coverage-gaps">Understanding Coverage Gaps</a></h2>
<p>A <strong>coverage gap</strong> represents the portion of a function that is not executed during tests. Traditional tools report this as a simple percentage (e.g., ‚Äú50% covered‚Äù), but this can be misleading:</p>
<ul>
<li>A 100-line function with 1 uncovered line shows ‚Äú99% covered‚Äù - sounds great!</li>
<li>A 10-line function with 1 uncovered line shows ‚Äú90% covered‚Äù - sounds worse, but is actually better</li>
</ul>
<p>Debtmap improves on this by:</p>
<ol>
<li>Reporting the actual number of uncovered lines</li>
<li>Showing which specific lines are uncovered</li>
<li>Calculating the gap as a percentage of instrumented lines (not total lines)</li>
<li>Providing visual severity indicators based on gap size</li>
</ol>
<h2 id="precise-vs-estimated-gaps"><a class="header" href="#precise-vs-estimated-gaps">Precise vs Estimated Gaps</a></h2>
<p>Debtmap uses different precision levels depending on available coverage data:</p>
<h3 id="precise-gaps-line-level-data-available"><a class="header" href="#precise-gaps-line-level-data-available">Precise Gaps (Line-Level Data Available)</a></h3>
<p>When LCOV coverage data is available, debtmap provides exact line-level reporting:</p>
<pre><code>Business logic - 1 line uncovered (11% gap) - line 52
Complex calculation - 4 lines uncovered (20% gap) - lines 10-12, 15
</code></pre>
<p><strong>Benefits:</strong></p>
<ul>
<li>Exact line numbers for uncovered code</li>
<li>Accurate gap percentage based on instrumented lines</li>
<li>Compact line range formatting (e.g., ‚Äú10-12, 15, 20-21‚Äù)</li>
<li>Distinguishes between code that can‚Äôt be instrumented vs uncovered code</li>
</ul>
<p><strong>How it works:</strong></p>
<ul>
<li>Debtmap reads LCOV coverage data from your test runs</li>
<li>Matches functions by file path and name</li>
<li>Extracts precise uncovered line numbers</li>
<li>Calculates percentage as: <code>(uncovered_lines / instrumented_lines) * 100</code></li>
</ul>
<h3 id="estimated-gaps-function-level-data-only"><a class="header" href="#estimated-gaps-function-level-data-only">Estimated Gaps (Function-Level Data Only)</a></h3>
<p>When only function-level coverage percentages are available:</p>
<pre><code>Data processing - ~50% gap (estimated, ~25 lines)
Helper function - ~100% gap (estimated, 15 lines)
Utility - ~3% gap (mostly covered)
</code></pre>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Estimates uncovered line count from percentage</li>
<li>Uses tilde (~) prefix to indicate estimation</li>
<li>Special cases:
<ul>
<li>‚â•99% gap ‚Üí ‚Äú~100% gap‚Äù</li>
<li>&lt;5% gap ‚Üí ‚Äúmostly covered‚Äù</li>
<li>Otherwise ‚Üí ‚Äú~X% gap (estimated, ~Y lines)‚Äù</li>
</ul>
</li>
</ul>
<p><strong>How it works:</strong></p>
<ul>
<li>Falls back when LCOV data unavailable or function not found</li>
<li>Calculates: <code>estimated_uncovered = total_lines * (gap_percentage / 100)</code></li>
<li>Useful for quick overview but less actionable than precise gaps</li>
</ul>
<h3 id="unknown-coverage"><a class="header" href="#unknown-coverage">Unknown Coverage</a></h3>
<p>When no coverage data is available:</p>
<pre><code>Untested module - Coverage data unavailable (42 lines)
</code></pre>
<p>This typically occurs when:</p>
<ul>
<li>No coverage collection has been run</li>
<li>File not included in coverage report</li>
<li>Coverage data file path mismatch</li>
</ul>
<h2 id="gap-severity-indicators"><a class="header" href="#gap-severity-indicators">Gap Severity Indicators</a></h2>
<p>Debtmap uses visual indicators to quickly identify the severity of coverage gaps:</p>
<div class="table-wrapper"><table><thead><tr><th>Indicator</th><th>Range</th><th>Severity</th><th>Meaning</th></tr></thead><tbody>
<tr><td>üü°</td><td>1-25%</td><td>LOW</td><td>Minor gaps, mostly covered</td></tr>
<tr><td>üü†</td><td>26-50%</td><td>MODERATE</td><td>Significant gaps, needs attention</td></tr>
<tr><td>üî¥</td><td>51-75%</td><td>HIGH</td><td>Major gaps, high priority</td></tr>
<tr><td>üî¥üî¥</td><td>76-100%</td><td>CRITICAL</td><td>Severe gaps, critical priority</td></tr>
</tbody></table>
</div>
<p>These indicators appear in debtmap‚Äôs priority output to help you quickly identify which functions need testing most urgently.</p>
<h3 id="severity-calculation"><a class="header" href="#severity-calculation">Severity Calculation</a></h3>
<p>Gap severity is based on the percentage of uncovered code:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn get_severity(gap_percentage: f64) -&gt; &amp;'static str {
    match gap_percentage {
        p if p &lt;= 25.0 =&gt; "üü° LOW",
        p if p &lt;= 50.0 =&gt; "üü† MODERATE",
        p if p &lt;= 75.0 =&gt; "üî¥ HIGH",
        _ =&gt; "üî¥üî¥ CRITICAL"
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This works for both precise and estimated gaps, ensuring consistent severity classification across your codebase.</p>
<h2 id="example-output-2"><a class="header" href="#example-output-2">Example Output</a></h2>
<h3 id="high-verbosity-mode"><a class="header" href="#high-verbosity-mode">High Verbosity Mode</a></h3>
<pre><code>Priority 1: Authentication Logic (CRITICAL)
  File: src/auth/login.rs:45
  Coverage Gap: 2 lines uncovered (89% gap) üî¥üî¥ - lines 67, 89
  Complexity: Cyclomatic 8, Cognitive 12
  Impact: High-risk business logic with critical coverage gaps

Priority 2: Data Validation (HIGH)
  File: src/validation/rules.rs:120
  Coverage Gap: 15 lines uncovered (65% gap) üî¥ - lines 145-152, 167-173
  Complexity: Cyclomatic 5, Cognitive 8
  Impact: Complex validation logic needs comprehensive testing

Priority 3: Helper Function (MODERATE)
  File: src/utils/helpers.rs:30
  Coverage Gap: ~45% gap (estimated, ~12 lines) üü†
  Complexity: Cyclomatic 3, Cognitive 4
  Impact: Moderate complexity with estimated coverage gaps
</code></pre>
<h3 id="standard-mode"><a class="header" href="#standard-mode">Standard Mode</a></h3>
<pre><code>1. Authentication Logic (src/auth/login.rs:45)
   Gap: 2 lines uncovered (89%) üî¥üî¥ [lines 67, 89]

2. Data Validation (src/validation/rules.rs:120)
   Gap: 15 lines uncovered (65%) üî¥ [lines 145-152, 167-173]

3. Helper Function (src/utils/helpers.rs:30)
   Gap: ~45% (estimated) üü†
</code></pre>
<h2 id="integration-with-coverage-tools"><a class="header" href="#integration-with-coverage-tools">Integration with Coverage Tools</a></h2>
<h3 id="generating-lcov-data"><a class="header" href="#generating-lcov-data">Generating LCOV Data</a></h3>
<p>For precise gap reporting, generate LCOV coverage data with your test framework:</p>
<p><strong>Rust (using cargo-tarpaulin):</strong></p>
<pre><code class="language-bash">cargo tarpaulin --out Lcov --output-dir ./coverage
</code></pre>
<p><strong>Python (using pytest-cov):</strong></p>
<pre><code class="language-bash">pytest --cov=mypackage --cov-report=lcov:coverage/lcov.info
</code></pre>
<p><strong>JavaScript (using Jest):</strong></p>
<pre><code class="language-bash">jest --coverage --coverageReporters=lcov
</code></pre>
<h3 id="configuring-debtmap"><a class="header" href="#configuring-debtmap">Configuring Debtmap</a></h3>
<p>Point debtmap to your coverage data:</p>
<pre><code class="language-bash">debtmap analyze --coverage-path ./coverage/lcov.info
</code></pre>
<p>Or in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[coverage]
lcov_path = "./coverage/lcov.info"
</code></pre>
<h2 id="best-practices-6"><a class="header" href="#best-practices-6">Best Practices</a></h2>
<h3 id="1-use-precise-gaps-when-possible"><a class="header" href="#1-use-precise-gaps-when-possible">1. Use Precise Gaps When Possible</a></h3>
<p>Always generate LCOV data for actionable coverage insights:</p>
<ul>
<li>Precise line numbers help you quickly locate untested code</li>
<li>Accurate percentages prevent over/under-estimating gaps</li>
<li>Line ranges show if gaps are concentrated or scattered</li>
</ul>
<h3 id="2-focus-on-high-severity-gaps-first"><a class="header" href="#2-focus-on-high-severity-gaps-first">2. Focus on High Severity Gaps First</a></h3>
<p>Prioritize based on severity indicators:</p>
<ol>
<li>üî¥üî¥ CRITICAL (76-100%) - Address immediately</li>
<li>üî¥ HIGH (51-75%) - Schedule for next sprint</li>
<li>üü† MODERATE (26-50%) - Address when convenient</li>
<li>üü° LOW (1-25%) - Acceptable for some code</li>
</ol>
<h3 id="3-consider-context"><a class="header" href="#3-consider-context">3. Consider Context</a></h3>
<p>Gap severity should be weighted by:</p>
<ul>
<li><strong>Function role</strong>: Business logic vs utilities</li>
<li><strong>Complexity</strong>: High complexity + high gap = top priority</li>
<li><strong>Change frequency</strong>: Frequently changed code needs better coverage</li>
<li><strong>Risk</strong>: Security, data integrity, financial calculations</li>
</ul>
<h3 id="4-track-progress-over-time"><a class="header" href="#4-track-progress-over-time">4. Track Progress Over Time</a></h3>
<p>Run debtmap regularly to track coverage improvements:</p>
<pre><code class="language-bash"># Weekly coverage check
debtmap analyze --coverage-path ./coverage/lcov.info &gt; weekly-gaps.txt
</code></pre>
<p>Compare reports to see gap reduction progress.</p>
<h2 id="troubleshooting-10"><a class="header" href="#troubleshooting-10">Troubleshooting</a></h2>
<h3 id="coverage-data-unavailable-for-all-functions"><a class="header" href="#coverage-data-unavailable-for-all-functions">‚ÄúCoverage data unavailable‚Äù for all functions</a></h3>
<p><strong>Cause</strong>: Debtmap can‚Äôt find or parse LCOV file</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify <code>--coverage-path</code> points to valid LCOV file</li>
<li>Ensure LCOV file was generated recently</li>
<li>Check file permissions (readable by debtmap)</li>
<li>Validate LCOV format: <code>head -20 ./coverage/lcov.info</code></li>
</ul>
<h3 id="line-numbers-dont-match-source-code"><a class="header" href="#line-numbers-dont-match-source-code">Line numbers don‚Äôt match source code</a></h3>
<p><strong>Cause</strong>: Source code changed since coverage was generated</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Re-run tests with coverage collection</li>
<li>Ensure clean build before coverage run</li>
<li>Commit code before running coverage</li>
</ul>
<h3 id="estimated-gaps-for-functions-with-lcov-data"><a class="header" href="#estimated-gaps-for-functions-with-lcov-data">Estimated gaps for functions with LCOV data</a></h3>
<p><strong>Cause</strong>: Function name or path mismatch</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check function names match exactly (case-sensitive)</li>
<li>Verify file paths are consistent (relative vs absolute)</li>
<li>Enable debug logging: <code>debtmap analyze --log-level debug</code></li>
</ul>
<h3 id="missing-functions-in-coverage-report"><a class="header" href="#missing-functions-in-coverage-report">Missing functions in coverage report</a></h3>
<p><strong>Cause</strong>: Functions not instrumented or filtered out</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check coverage tool configuration</li>
<li>Ensure test execution reaches those functions</li>
<li>Verify functions aren‚Äôt in excluded paths</li>
</ul>
<h2 id="related-topics-3"><a class="header" href="#related-topics-3">Related Topics</a></h2>
<ul>
<li><a href="coverage-integration.html">Coverage Integration</a> - Detailed coverage tool setup</li>
<li><a href="tiered-prioritization.html">Tiered Prioritization</a> - How coverage gaps affect priority</li>
<li><a href="scoring-strategies.html">Scoring Strategies</a> - Coverage weight in debt scoring</li>
<li><a href="metrics-reference.html">Metrics Reference</a> - All coverage-related metrics</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="coverage-integration-1"><a class="header" href="#coverage-integration-1">Coverage Integration</a></h1>
<p>Coverage integration is one of Debtmap‚Äôs most powerful capabilities, enabling <strong>risk-based prioritization</strong> by correlating complexity metrics with test coverage. This helps you identify truly risky code‚Äîfunctions that are both complex and untested‚Äîrather than just highlighting complex but well-tested functions.</p>
<h2 id="why-coverage-matters"><a class="header" href="#why-coverage-matters">Why Coverage Matters</a></h2>
<p>Without coverage data, complexity analysis shows you <em>what‚Äôs complex</em>, but not <em>what‚Äôs risky</em>. A complex function with 100% test coverage poses far less risk than a simple function with 0% coverage on a critical path.</p>
<p>Coverage integration transforms Debtmap from a complexity analyzer into a <strong>risk assessment tool</strong>:</p>
<ul>
<li><strong>Prioritize testing efforts</strong>: Focus on high-complexity functions with low coverage</li>
<li><strong>Validate refactoring safety</strong>: See which complex code is already protected by tests</li>
<li><strong>Risk-based sprint planning</strong>: Surface truly risky code ahead of well-tested complexity</li>
<li><strong>Quantify risk reduction</strong>: Measure how coverage improvements reduce project risk</li>
</ul>
<h2 id="lcov-format-the-universal-standard"><a class="header" href="#lcov-format-the-universal-standard">LCOV Format: The Universal Standard</a></h2>
<p>Debtmap uses the <strong>LCOV format</strong> for coverage data. LCOV is a language-agnostic standard supported by virtually all coverage tools across all major languages.</p>
<h3 id="why-lcov"><a class="header" href="#why-lcov">Why LCOV?</a></h3>
<ul>
<li><strong>Universal compatibility</strong>: Works with Rust, Python, JavaScript, TypeScript, Go, and more</li>
<li><strong>Tool independence</strong>: Not tied to any specific test framework</li>
<li><strong>Simple text format</strong>: Easy to inspect and debug</li>
<li><strong>Widely supported</strong>: Generated by most modern coverage tools</li>
</ul>
<h3 id="lcov-file-structure"><a class="header" href="#lcov-file-structure">LCOV File Structure</a></h3>
<p>An LCOV file contains line-by-line coverage information:</p>
<pre><code class="language-lcov">SF:src/analyzer.rs
FN:42,calculate_complexity
FNDA:15,calculate_complexity
DA:42,15
DA:43,15
DA:44,12
DA:45,0
LH:3
LF:4
end_of_record
</code></pre>
<ul>
<li><code>SF:</code> - Source file path</li>
<li><code>FN:</code> - Function name and starting line</li>
<li><code>FNDA:</code> - Function execution count</li>
<li><code>DA:</code> - Line execution data (line number, hit count)</li>
<li><code>LH:</code> - Lines hit</li>
<li><code>LF:</code> - Lines found (total)</li>
</ul>
<h2 id="generating-coverage-data-1"><a class="header" href="#generating-coverage-data-1">Generating Coverage Data</a></h2>
<h3 id="rust-cargo-tarpaulin"><a class="header" href="#rust-cargo-tarpaulin">Rust: cargo-tarpaulin</a></h3>
<p><strong>Installation:</strong></p>
<pre><code class="language-bash">cargo install cargo-tarpaulin
</code></pre>
<p><strong>Generate LCOV:</strong></p>
<pre><code class="language-bash">cargo tarpaulin --out lcov --output-dir target/coverage
</code></pre>
<p><strong>Analyze with Debtmap:</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<p><strong>Common Issues:</strong></p>
<ul>
<li>Ensure tests compile before running tarpaulin</li>
<li>Use <code>--ignore-tests</code> if tests themselves show up in coverage</li>
<li>Check paths match your project structure (relative to project root)</li>
</ul>
<h3 id="javascripttypescript-jest"><a class="header" href="#javascripttypescript-jest">JavaScript/TypeScript: Jest</a></h3>
<p><strong>Configuration (package.json or jest.config.js):</strong></p>
<pre><code class="language-json">{
  "jest": {
    "coverageReporters": ["lcov", "text"]
  }
}
</code></pre>
<p><strong>Generate Coverage:</strong></p>
<pre><code class="language-bash">npm test -- --coverage
</code></pre>
<p><strong>Analyze with Debtmap:</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage/lcov.info
</code></pre>
<h3 id="python-pytest-cov"><a class="header" href="#python-pytest-cov">Python: pytest-cov</a></h3>
<p><strong>Installation:</strong></p>
<pre><code class="language-bash">pip install pytest-cov
</code></pre>
<p><strong>Generate LCOV:</strong></p>
<pre><code class="language-bash">pytest --cov=src --cov-report=lcov
</code></pre>
<p><strong>Analyze with Debtmap:</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.lcov
</code></pre>
<h3 id="go-go-test-with-gocover-cobertura"><a class="header" href="#go-go-test-with-gocover-cobertura">Go: go test with gocover-cobertura</a></h3>
<p><strong>Generate Coverage:</strong></p>
<pre><code class="language-bash">go test -coverprofile=coverage.out ./...
gocover-cobertura &lt; coverage.out &gt; coverage.xml
# Convert to LCOV using lcov tools
</code></pre>
<p><strong>Note</strong>: Go‚Äôs native coverage format requires conversion. Most CI systems support LCOV conversion plugins.</p>
<h2 id="how-coverage-affects-scoring"><a class="header" href="#how-coverage-affects-scoring">How Coverage Affects Scoring</a></h2>
<p>Coverage data fundamentally changes how Debtmap calculates debt scores. The scoring system operates in <strong>two different modes</strong> depending on whether coverage data is available.</p>
<h3 id="scoring-modes"><a class="header" href="#scoring-modes">Scoring Modes</a></h3>
<p><strong>Mode 1: With Coverage Data (Dampening Multiplier)</strong></p>
<p>When you provide an LCOV file with <code>--lcov</code>, coverage acts as a <strong>dampening multiplier</strong> that reduces scores for well-tested code:</p>
<pre><code>Base Score = (Complexity Factor √ó 0.50) + (Dependency Factor √ó 0.25)
Coverage Multiplier = 1.0 - coverage_percentage
Final Score = Base Score √ó Coverage Multiplier
</code></pre>
<p>This is the <strong>current implementation</strong> as of spec 122. Coverage dampens the base score rather than contributing as an additive component.</p>
<p><strong>Mode 2: Without Coverage Data (Weighted Sum)</strong></p>
<p>When no coverage data is available, Debtmap falls back to a weighted sum model:</p>
<pre><code>Final Score = (Coverage √ó 0.50) + (Complexity √ó 0.35) + (Dependency √ó 0.15)
</code></pre>
<p>In this mode, coverage is assumed to be 0% (worst case), giving it a weight of 50% in the total score. See <code>src/priority/scoring/calculation.rs:119-129</code> for the implementation.</p>
<h3 id="coverage-dampening-multiplier"><a class="header" href="#coverage-dampening-multiplier">Coverage Dampening Multiplier</a></h3>
<p>When coverage data is provided, it acts as a <strong>multiplier</strong> that dampens the base score:</p>
<pre><code>Coverage Multiplier = 1.0 - coverage_percentage
Final Score = Base Score √ó Coverage Multiplier
</code></pre>
<p><strong>Examples:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Base Score</th><th>Coverage</th><th>Multiplier</th><th>Final Score</th><th>Priority</th></tr></thead><tbody>
<tr><td>8.5</td><td>100%</td><td>0.0</td><td>0.0</td><td>Minimal (well-tested)</td></tr>
<tr><td>8.5</td><td>50%</td><td>0.5</td><td>4.25</td><td>Medium</td></tr>
<tr><td>8.5</td><td>0%</td><td>1.0</td><td>8.5</td><td>High (untested)</td></tr>
</tbody></table>
</div>
<p><strong>Key Insight</strong>: Complex but well-tested code automatically drops in priority, while untested complex code rises to the top.</p>
<p><strong>Special Cases:</strong></p>
<ul>
<li><strong>Test functions</strong>: Coverage multiplier = 0.0 (tests get near-zero scores regardless of complexity)</li>
<li><strong>Entry points</strong>: Handled through semantic classification (FunctionRole) system with role multipliers, not coverage-specific weighting</li>
</ul>
<p><strong>Invariant</strong>: Total debt score with coverage ‚â§ total debt score without coverage.</p>
<p><strong>Implementation</strong>: See <code>src/priority/scoring/calculation.rs:68-82</code> for the coverage dampening calculation.</p>
<h2 id="transitive-coverage-propagation"><a class="header" href="#transitive-coverage-propagation">Transitive Coverage Propagation</a></h2>
<p>Debtmap doesn‚Äôt just look at <em>direct</em> coverage‚Äîit propagates coverage through the <strong>call graph</strong> using transitive analysis.</p>
<h3 id="how-it-works-1"><a class="header" href="#how-it-works-1">How It Works</a></h3>
<p>A function‚Äôs effective coverage considers:</p>
<ol>
<li><strong>Direct coverage</strong>: Lines executed by tests</li>
<li><strong>Caller coverage</strong>: Coverage of functions that call this function</li>
</ol>
<pre><code>Transitive Coverage = Direct Coverage + Œ£(Caller Coverage √ó Weight)
</code></pre>
<h3 id="algorithm-parameters"><a class="header" href="#algorithm-parameters">Algorithm Parameters</a></h3>
<p>The transitive coverage propagation uses carefully tuned parameters to balance accuracy and performance:</p>
<ul>
<li><strong>Well-Tested Threshold</strong>: 80% - Only functions with ‚â•80% direct coverage contribute to indirect coverage, ensuring high confidence</li>
<li><strong>Distance Discount</strong>: 70% per hop - Each level of indirection reduces contribution by 30%, reflecting decreased confidence</li>
<li><strong>Maximum Distance</strong>: 3 hops - Limits recursion depth to prevent exponential complexity (after 3 hops, contribution drops to ~34%)</li>
</ul>
<p>These parameters ensure that indirect coverage signals are meaningful while preventing false confidence from distant call relationships. See <code>src/priority/coverage_propagation.rs:38-46</code> for the implementation.</p>
<h3 id="why-it-matters"><a class="header" href="#why-it-matters">Why It Matters</a></h3>
<p>A function with 0% direct coverage might have high transitive coverage if it‚Äôs only called by well-tested functions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// direct_coverage = 0%
// But called only by `process_request` (100% coverage)
// ‚Üí transitive_coverage = 85%
fn validate_input(data: &amp;str) -&gt; bool {
    data.len() &gt; 0
}

// direct_coverage = 100%
fn process_request(input: String) -&gt; Result&lt;()&gt; {
    if !validate_input(&amp;input) {
        return Err("Invalid");
    }
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Effect</strong>: <code>validate_input</code> has reduced urgency because it‚Äôs only reachable through well-tested code paths.</p>
<h2 id="performance-characteristics-2"><a class="header" href="#performance-characteristics-2">Performance Characteristics</a></h2>
<p>Coverage integration is highly optimized for large codebases:</p>
<ul>
<li><strong>Index Build</strong>: O(n), ~20-30ms for 5,000 functions</li>
<li><strong>Exact Lookup</strong>: O(1), ~0.5Œºs per lookup</li>
<li><strong>Fallback Lookup</strong>: O(files) iteration with O(1) per-file lookup, ~5-8Œºs when exact match fails. Uses suffix matching and normalized path equality strategies</li>
<li><strong>Memory Usage</strong>: ~200 bytes per record (~2MB for 5,000 functions)</li>
<li><strong>Thread Safety</strong>: Lock-free parallel access via <code>Arc&lt;CoverageIndex&gt;</code></li>
<li><strong>Analysis Overhead</strong>: ~2.5x baseline (target: ‚â§3x)</li>
</ul>
<p><strong>Result</strong>: Coverage integration adds minimal overhead even on projects with thousands of functions.</p>
<p><strong>Implementation</strong>: See <code>src/risk/coverage_index.rs:13-38</code> for the CoverageIndex struct and performance documentation.</p>
<h2 id="cli-options-reference"><a class="header" href="#cli-options-reference">CLI Options Reference</a></h2>
<h3 id="primary-coverage-options"><a class="header" href="#primary-coverage-options">Primary Coverage Options</a></h3>
<pre><code class="language-bash"># Provide LCOV coverage file
debtmap analyze . --coverage-file path/to/lcov.info

# Shorthand alias
debtmap analyze . --lcov path/to/lcov.info
</code></pre>
<h3 id="context-providers-1"><a class="header" href="#context-providers-1">Context Providers</a></h3>
<p>Coverage can be combined with other context providers for nuanced risk assessment:</p>
<pre><code class="language-bash"># Enable all context providers (includes coverage propagation)
debtmap analyze . --lcov coverage.info --enable-context

# Specify specific providers
debtmap analyze . --lcov coverage.info \
  --context-providers critical_path,dependency,git_history

# Disable specific providers
debtmap analyze . --lcov coverage.info \
  --disable-context git_history
</code></pre>
<p><strong>Available Context Providers</strong>:</p>
<ul>
<li><code>critical_path</code>: Identifies functions on critical execution paths</li>
<li><code>dependency</code>: Analyzes dependency relationships and impact</li>
<li><code>git_history</code>: Uses change frequency from version control</li>
</ul>
<p>See <a href="scoring-strategies.html">Scoring Strategies</a> for details on how these combine.</p>
<h3 id="validate-command-support"><a class="header" href="#validate-command-support">Validate Command Support</a></h3>
<p>The <code>validate</code> command also supports coverage integration for risk-based quality gates:</p>
<pre><code class="language-bash"># Fail CI builds if untested complex code exceeds thresholds
debtmap validate . --lcov coverage.info --max-debt-density 50
</code></pre>
<p>See <a href="cli-reference.html">CLI Reference</a> for complete validation options.</p>
<h2 id="troubleshooting-coverage-integration"><a class="header" href="#troubleshooting-coverage-integration">Troubleshooting Coverage Integration</a></h2>
<h3 id="coverage-not-correlating-with-functions"><a class="header" href="#coverage-not-correlating-with-functions">Coverage Not Correlating with Functions</a></h3>
<p><strong>Symptoms</strong>:</p>
<ul>
<li>Debtmap shows 0% coverage for all functions</li>
<li>Warning: ‚ÄúNo coverage data correlated with analyzed functions‚Äù</li>
</ul>
<p><strong>Solutions</strong>:</p>
<ol>
<li><strong>Verify LCOV Format</strong>:</li>
</ol>
<pre><code class="language-bash">head coverage.info
# Should show: SF:, FN:, DA: lines
</code></pre>
<ol start="2">
<li><strong>Check Path Matching</strong>:
Coverage file paths must be relative to project root:</li>
</ol>
<pre><code class="language-bash"># Good: SF:src/analyzer.rs
# Bad:  SF:/home/user/project/src/analyzer.rs
</code></pre>
<ol start="3">
<li><strong>Enable Verbose Logging</strong>:</li>
</ol>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.info -vv
</code></pre>
<p>This shows coverage lookup details for each function.</p>
<ol start="4">
<li><strong>Verify Coverage Tool Output</strong>:</li>
</ol>
<pre><code class="language-bash"># Ensure your coverage tool generated line data (DA: records)
grep "^DA:" coverage.info | head
</code></pre>
<h3 id="functions-still-show-up-despite-100-coverage"><a class="header" href="#functions-still-show-up-despite-100-coverage">Functions Still Show Up Despite 100% Coverage</a></h3>
<p><strong>This is expected behavior</strong> when:</p>
<ul>
<li>Function has high complexity (cyclomatic &gt; 10)</li>
<li>Function has other debt issues (duplication, nesting, etc.)</li>
<li>You‚Äôre viewing function-level output (coverage dampens but doesn‚Äôt eliminate)</li>
</ul>
<p><strong>Coverage reduces priority but doesn‚Äôt hide issues</strong>. Use filters to focus:</p>
<pre><code class="language-bash"># Show only critical and high priority items
debtmap analyze . --lcov coverage.info --min-priority high

# Show top 10 most urgent items
debtmap analyze . --lcov coverage.info --top 10
</code></pre>
<h3 id="coverage-file-path-issues"><a class="header" href="#coverage-file-path-issues">Coverage File Path Issues</a></h3>
<p><strong>Problem</strong>: Can‚Äôt find coverage file</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use absolute path
debtmap analyze . --lcov /absolute/path/to/coverage.info

# Or ensure relative path is from project root
debtmap analyze . --lcov ./target/coverage/lcov.info
</code></pre>
<h3 id="lcov-format-errors"><a class="header" href="#lcov-format-errors">LCOV Format Errors</a></h3>
<p><strong>Problem</strong>: ‚ÄúInvalid LCOV format‚Äù error</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Non-LCOV format (Cobertura XML, JaCoCo, etc.)</li>
<li>Corrupted file</li>
<li>Wrong file encoding</li>
</ul>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify your coverage tool is configured for LCOV output</li>
<li>Check for binary/encoding issues: <code>file coverage.info</code></li>
<li>Regenerate coverage with explicit LCOV format flag</li>
</ul>
<p>See <a href="troubleshooting.html">Troubleshooting</a> for more debugging tips.</p>
<h2 id="best-practices-7"><a class="header" href="#best-practices-7">Best Practices</a></h2>
<h3 id="analysis-workflow"><a class="header" href="#analysis-workflow">Analysis Workflow</a></h3>
<ol>
<li>
<p><strong>Generate Coverage Before Analysis</strong>:</p>
<pre><code class="language-bash"># Rust example
cargo tarpaulin --out lcov --output-dir target/coverage
debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
</li>
<li>
<p><strong>Use Coverage for Sprint Planning</strong>:</p>
<pre><code class="language-bash"># Focus on untested complex code
debtmap analyze . --lcov coverage.info --top 20
</code></pre>
</li>
<li>
<p><strong>Combine with Tiered Prioritization</strong>:
Coverage automatically feeds into <a href="tiered-prioritization.html">Tiered Prioritization</a>:</p>
<ul>
<li><strong>Tier 1</strong>: Architectural issues (less affected by coverage)</li>
<li><strong>Tier 2</strong>: Complex untested code (coverage &lt; 50%, complexity &gt; 15)</li>
<li><strong>Tier 3</strong>: Testing gaps (coverage &lt; 80%, complexity 10-15)</li>
</ul>
</li>
<li>
<p><strong>Validate Refactoring Impact</strong>:</p>
<pre><code class="language-bash"># Before refactoring
debtmap analyze . --lcov coverage-before.info -o before.json

# After refactoring
debtmap analyze . --lcov coverage-after.info -o after.json

# Compare
debtmap compare --before before.json --after after.json
</code></pre>
</li>
</ol>
<h3 id="testing-strategy"><a class="header" href="#testing-strategy">Testing Strategy</a></h3>
<p><strong>Prioritize testing based on risk</strong>:</p>
<ol>
<li>
<p><strong>High Complexity + Low Coverage = Highest Priority</strong>:</p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.info \
  --filter Risk --min-priority high
</code></pre>
</li>
<li>
<p><strong>Focus on Business Logic</strong>:
Entry points and infrastructure code have natural coverage patterns. Focus unit tests on business logic functions.</p>
</li>
<li>
<p><strong>Use Dependency Analysis</strong>:</p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.info \
  --context-providers dependency -vv
</code></pre>
<p>Tests high-dependency functions first‚Äîthey have the most impact.</p>
</li>
<li>
<p><strong>Don‚Äôt Over-Test Entry Points</strong>:
Entry points (main, handlers) are better tested with integration tests, not unit tests. Debtmap applies role multipliers through its semantic classification system (FunctionRole) to adjust scoring for different function types. See <code>src/priority/unified_scorer.rs:149</code> and <code>src/priority/scoring/classification.rs</code> for the classification system.</p>
</li>
</ol>
<h3 id="configuration-4"><a class="header" href="#configuration-4">Configuration</a></h3>
<p>In <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[scoring]
# Default weights for scoring WITHOUT coverage data
# When coverage data IS provided, it acts as a dampening multiplier instead
coverage = 0.50  # Default: 50% (only used when no LCOV provided)
complexity = 0.35  # Default: 35%
dependency = 0.15  # Default: 15%

[thresholds]
# Set minimum risk score to filter low-priority items
minimum_risk_score = 15.0

# Skip simple functions even if uncovered
minimum_cyclomatic_complexity = 5
</code></pre>
<p><strong>Important</strong>: These weights are from the deprecated additive scoring model. The current implementation (spec 122) calculates a base score from complexity (50%) and dependency (25%) factors, then applies coverage as a dampening multiplier: <code>Final Score = Base Score √ó (1.0 - coverage_pct)</code>. These weights only apply when coverage data is <strong>not</strong> available. See <code>src/priority/scoring/calculation.rs:68-82</code> and <code>src/config.rs:122-132</code> for the implementation.</p>
<p>See <a href="configuration.html">Configuration</a> for complete options.</p>
<h3 id="ci-integration"><a class="header" href="#ci-integration">CI Integration</a></h3>
<p><strong>Example GitHub Actions Workflow</strong>:</p>
<pre><code class="language-yaml">- name: Generate Coverage
  run: cargo tarpaulin --out lcov --output-dir target/coverage

- name: Analyze with Debtmap
  run: |
    debtmap analyze . \
      --lcov target/coverage/lcov.info \
      --format json \
      --output debtmap-report.json

- name: Validate Quality Gates
  run: |
    debtmap validate . \
      --lcov target/coverage/lcov.info \
      --max-debt-density 50
</code></pre>
<p><strong>Quality Gate Strategy</strong>:</p>
<ul>
<li>Fail builds on new critical debt (Tier 1 architectural issues)</li>
<li>Warn on new high-priority untested code (Tier 2)</li>
<li>Track coverage trends over time with <code>compare</code> command</li>
</ul>
<h2 id="complete-language-examples"><a class="header" href="#complete-language-examples">Complete Language Examples</a></h2>
<h3 id="rust-end-to-end"><a class="header" href="#rust-end-to-end">Rust End-to-End</a></h3>
<pre><code class="language-bash"># 1. Generate coverage
cargo tarpaulin --out lcov --output-dir target/coverage

# 2. Verify LCOV output
head target/coverage/lcov.info

# 3. Run Debtmap with coverage
debtmap analyze . --lcov target/coverage/lcov.info

# 4. Interpret results (look for [UNTESTED] markers on high-complexity functions)
</code></pre>
<h3 id="javascripttypescript-end-to-end"><a class="header" href="#javascripttypescript-end-to-end">JavaScript/TypeScript End-to-End</a></h3>
<pre><code class="language-bash"># 1. Configure Jest for LCOV (in package.json or jest.config.js)
# "coverageReporters": ["lcov", "text"]

# 2. Generate coverage
npm test -- --coverage

# 3. Verify LCOV output
head coverage/lcov.info

# 4. Run Debtmap
debtmap analyze . --lcov coverage/lcov.info --languages javascript,typescript
</code></pre>
<h3 id="python-end-to-end"><a class="header" href="#python-end-to-end">Python End-to-End</a></h3>
<pre><code class="language-bash"># 1. Install pytest-cov
pip install pytest-cov

# 2. Generate LCOV coverage
pytest --cov=src --cov-report=lcov

# 3. Verify output
head coverage.lcov

# 4. Run Debtmap
debtmap analyze . --lcov coverage.lcov --languages python
</code></pre>
<h3 id="go-end-to-end"><a class="header" href="#go-end-to-end">Go End-to-End</a></h3>
<pre><code class="language-bash"># 1. Generate native coverage
go test -coverprofile=coverage.out ./...

# 2. Convert to LCOV (requires gocover-cobertura or similar)
# Note: This step is tool-dependent

# 3. Run Debtmap
debtmap analyze . --lcov coverage.lcov --languages go
</code></pre>
<h2 id="faq"><a class="header" href="#faq">FAQ</a></h2>
<h3 id="why-does-my-100-covered-function-still-show-up"><a class="header" href="#why-does-my-100-covered-function-still-show-up">Why does my 100% covered function still show up?</a></h3>
<p>Coverage dampens debt scores but doesn‚Äôt eliminate debt. A function with cyclomatic complexity 25 and 100% coverage still represents technical debt‚Äîit‚Äôs just lower priority than untested complex code.</p>
<p><strong>Use filters to focus on high-priority items</strong>:</p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.info --top 10
</code></pre>
<h3 id="whats-the-difference-between-direct-and-transitive-coverage"><a class="header" href="#whats-the-difference-between-direct-and-transitive-coverage">What‚Äôs the difference between direct and transitive coverage?</a></h3>
<ul>
<li><strong>Direct coverage</strong>: Lines executed directly by tests</li>
<li><strong>Transitive coverage</strong>: Coverage considering call graph (functions called by well-tested code)</li>
</ul>
<p>Transitive coverage reduces urgency for functions only reachable through well-tested paths.</p>
<h3 id="should-i-test-everything-to-100-coverage"><a class="header" href="#should-i-test-everything-to-100-coverage">Should I test everything to 100% coverage?</a></h3>
<p><strong>No.</strong> Use Debtmap‚Äôs risk scores to prioritize:</p>
<ol>
<li>Test high-complexity, low-coverage functions first</li>
<li>Entry points are better tested with integration tests</li>
<li>Simple utility functions (complexity &lt; 5) may not need dedicated unit tests</li>
</ol>
<p>Debtmap helps you achieve <strong>optimal coverage</strong>, not maximal coverage.</p>
<h3 id="how-do-i-debug-coverage-correlation-issues"><a class="header" href="#how-do-i-debug-coverage-correlation-issues">How do I debug coverage correlation issues?</a></h3>
<p>Use verbose logging:</p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.info -vv
</code></pre>
<p>This shows:</p>
<ul>
<li>Coverage file parsing details</li>
<li>Function-to-coverage correlation attempts</li>
<li>Path matching diagnostics</li>
</ul>
<h3 id="can-i-use-coverage-with-validate-command"><a class="header" href="#can-i-use-coverage-with-validate-command">Can I use coverage with validate command?</a></h3>
<p>Yes! The <code>validate</code> command supports <code>--lcov</code> for risk-based quality gates:</p>
<pre><code class="language-bash">debtmap validate . --lcov coverage.info --max-debt-density 50
</code></pre>
<p>See <a href="cli-reference.html#validate-command">CLI Reference</a> for details.</p>
<h2 id="further-reading-1"><a class="header" href="#further-reading-1">Further Reading</a></h2>
<ul>
<li><a href="scoring-strategies.html">Scoring Strategies</a> - Deep dive into how coverage affects unified scoring</li>
<li><a href="tiered-prioritization.html">Tiered Prioritization</a> - How coverage fits into tiered priority levels</li>
<li><a href="cli-reference.html">CLI Reference</a> - Complete coverage option documentation</li>
<li><a href="configuration.html">Configuration</a> - Customizing coverage scoring weights</li>
<li><a href="troubleshooting.html">Troubleshooting</a> - More debugging tips for coverage issues</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dead-code-analysis"><a class="header" href="#dead-code-analysis">Dead Code Analysis</a></h1>
<p>Debtmap‚Äôs Python dead code detection system uses advanced static analysis to identify unused functions with high accuracy and low false positive rates. The analyzer integrates multiple detection systems to provide confidence-scored results that help you make informed decisions about code removal.</p>
<h2 id="overview-6"><a class="header" href="#overview-6">Overview</a></h2>
<p>The dead code analyzer combines several detection techniques:</p>
<ul>
<li><strong>Static call graph analysis</strong> - Tracks which functions call each other across your codebase</li>
<li><strong>Framework pattern detection</strong> - Recognizes entry points from Flask, Django, FastAPI, Click, pytest, and more</li>
<li><strong>Test detection</strong> - Identifies test functions and test files to avoid false positives</li>
<li><strong>Callback tracking</strong> - Detects functions registered as callbacks or event handlers</li>
<li><strong>Import analysis</strong> - Tracks which functions are imported and exported by other modules</li>
<li><strong>Coverage integration</strong> - Uses test coverage data when available to identify live code</li>
<li><strong>Public API detection</strong> - Uses heuristics to identify external API functions</li>
</ul>
<p>This multi-layered approach achieves a target false positive rate of less than 10%, compared to 30-40% for naive call graph analysis.</p>
<h2 id="confidence-scoring"><a class="header" href="#confidence-scoring">Confidence Scoring</a></h2>
<p>Every analysis result includes a confidence score to help you prioritize code removal:</p>
<h3 id="high-confidence-08-10"><a class="header" href="#high-confidence-08-10">High Confidence (0.8-1.0)</a></h3>
<p><strong>Safe to remove</strong> - These functions are very likely dead code.</p>
<p>Characteristics:</p>
<ul>
<li>No static callers found in the codebase</li>
<li>Not a framework entry point (route, command, view, etc.)</li>
<li>Not a test function or in a test file</li>
<li>Not registered as a callback or event handler</li>
<li>Not exported in <code>__all__</code> or used in public API patterns</li>
<li>Often private functions (starting with <code>_</code>)</li>
</ul>
<p>Example output:</p>
<pre><code>Function: _old_helper
Confidence: High (0.95)
Suggestion: High confidence this function is dead code and can be safely removed.
</code></pre>
<h3 id="medium-confidence-05-08"><a class="header" href="#medium-confidence-05-08">Medium Confidence (0.5-0.8)</a></h3>
<p><strong>Review recommended</strong> - These functions might be dead code but require manual verification.</p>
<p>Characteristics:</p>
<ul>
<li>No static callers but function is public</li>
<li>In a test file but not called by any tests</li>
<li>Might be used dynamically (via <code>getattr</code>, plugins, etc.)</li>
<li>Public API that might be used by external code</li>
</ul>
<p>Example output:</p>
<pre><code>Function: legacy_api_method
Confidence: Medium (0.65)
Suggestion: Medium confidence this function is dead code. Manual verification recommended.
Risks:
  - Function is public and may be used by external code.
</code></pre>
<h3 id="low-confidence-00-05"><a class="header" href="#low-confidence-00-05">Low Confidence (0.0-0.5)</a></h3>
<p><strong>Likely in use</strong> - These functions are probably not dead code.</p>
<p>Characteristics:</p>
<ul>
<li>Has static callers in the codebase</li>
<li>Framework entry point (Flask route, Django view, Click command)</li>
<li>Test function (starts with <code>test_</code>, in test file)</li>
<li>Callback target or event handler</li>
<li>Magic method (<code>__init__</code>, <code>__str__</code>, etc.)</li>
<li>Property accessor or descriptor</li>
</ul>
<p>Example output:</p>
<pre><code>Function: index
Confidence: Low (0.15)
Result: LIVE
Reasons:
  - Framework entry point (Flask route)
  - Function is public
</code></pre>
<h2 id="public-api-detection"><a class="header" href="#public-api-detection">Public API Detection</a></h2>
<p>Debtmap uses advanced heuristics to identify functions that are likely part of your project‚Äôs external API (introduced in Spec 113). This prevents false positives when analyzing library code.</p>
<h3 id="detection-heuristics"><a class="header" href="#detection-heuristics">Detection Heuristics</a></h3>
<p>The public API detector considers:</p>
<ol>
<li><strong>Public visibility</strong> - Function doesn‚Äôt start with <code>_</code></li>
<li><strong>File location patterns</strong> - Functions in <code>api/</code>, <code>public/</code>, or top-level <code>__init__.py</code> files</li>
<li><strong>Naming conventions</strong> - Functions following API naming patterns</li>
<li><strong>Export declarations</strong> - Functions listed in <code>__all__</code></li>
<li><strong>Explicit configuration</strong> - Functions marked as API in <code>.debtmap.toml</code></li>
</ol>
<h3 id="configuration-5"><a class="header" href="#configuration-5">Configuration</a></h3>
<p>Configure public API detection in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[external_api]
# Enable/disable automatic public API detection (default: true)
detect_external_api = true

# Explicitly mark specific functions as external APIs
api_functions = [
    "calculate_score",           # Just function name
    "mylib.api::process_data",   # Module-qualified name
    "public_handler",            # Any function matching this name
]

# Mark entire files as containing external APIs (supports glob patterns)
api_files = [
    "src/api/**/*.py",           # All Python files in api directory recursively
    "src/lib.rs",                # Rust library entry point (all public functions)
    "src/public_interface.py",   # Specific Python file
    "**/__init__.py",            # All __init__.py files in any directory
    "**/public_*.py",            # Any file starting with 'public_'
    "myapp/api.py",              # Specific API module
]
</code></pre>
<p>Functions identified as public APIs receive lower dead code confidence scores, even if they have no internal callers.</p>
<h2 id="framework-support"><a class="header" href="#framework-support">Framework Support</a></h2>
<p>The analyzer recognizes entry points from popular Python frameworks to avoid false positives:</p>
<h3 id="web-frameworks"><a class="header" href="#web-frameworks">Web Frameworks</a></h3>
<ul>
<li><strong>Flask</strong>: <code>@app.route</code>, <code>@app.before_request</code>, <code>@app.after_request</code>, <code>@app.errorhandler</code></li>
<li><strong>Django</strong>: View functions, admin actions, signal handlers, middleware methods</li>
<li><strong>FastAPI</strong>: <code>@app.get</code>, <code>@app.post</code>, <code>@app.put</code>, <code>@app.delete</code>, route decorators</li>
</ul>
<h3 id="cli-frameworks"><a class="header" href="#cli-frameworks">CLI Frameworks</a></h3>
<ul>
<li><strong>Click</strong>: <code>@click.command</code>, <code>@click.group</code>, subcommand handlers</li>
<li><strong>argparse</strong>: Functions registered as subcommand handlers</li>
</ul>
<h3 id="testing-frameworks"><a class="header" href="#testing-frameworks">Testing Frameworks</a></h3>
<ul>
<li><strong>pytest</strong>: Functions starting with <code>test_</code>, <code>@pytest.fixture</code>, parametrized tests</li>
<li><strong>unittest</strong>: <code>TestCase</code> methods, <code>setUp</code>, <code>tearDown</code>, <code>setUpClass</code>, <code>tearDownClass</code></li>
</ul>
<h3 id="event-systems"><a class="header" href="#event-systems">Event Systems</a></h3>
<ul>
<li><strong>Qt/PyQt</strong>: Signal connections, slot decorators (<code>@pyqtSlot</code>)</li>
<li><strong>Tkinter</strong>: Event bindings, button command callbacks, widget event handlers</li>
</ul>
<h3 id="framework-detection-matrix"><a class="header" href="#framework-detection-matrix">Framework Detection Matrix</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Framework</th><th>Pattern</th><th>Decorator/Keyword</th><th>Detection Method</th><th>Example</th></tr></thead><tbody>
<tr><td><strong>Flask</strong></td><td>Routes</td><td><code>@app.route</code></td><td>Decorator analysis</td><td><code>@app.route('/')</code></td></tr>
<tr><td>Flask</td><td>Before request</td><td><code>@app.before_request</code></td><td>Decorator analysis</td><td>Handler hooks</td></tr>
<tr><td>Flask</td><td>Error handlers</td><td><code>@app.errorhandler</code></td><td>Decorator analysis</td><td>Custom error pages</td></tr>
<tr><td><strong>Django</strong></td><td>Views</td><td>Function-based views</td><td>Module structure</td><td><code>def my_view(request):</code></td></tr>
<tr><td>Django</td><td>Admin actions</td><td><code>@admin.action</code></td><td>Decorator analysis</td><td>Admin panel actions</td></tr>
<tr><td>Django</td><td>Signals</td><td><code>@receiver</code></td><td>Decorator analysis</td><td>Signal handlers</td></tr>
<tr><td><strong>FastAPI</strong></td><td>Routes</td><td><code>@app.get</code>, <code>@app.post</code></td><td>Decorator analysis</td><td>REST endpoints</td></tr>
<tr><td>FastAPI</td><td>Dependencies</td><td><code>Depends()</code></td><td>Call graph analysis</td><td>Dependency injection</td></tr>
<tr><td><strong>Click</strong></td><td>Commands</td><td><code>@click.command</code></td><td>Decorator analysis</td><td>CLI commands</td></tr>
<tr><td>Click</td><td>Groups</td><td><code>@click.group</code></td><td>Decorator analysis</td><td>Command groups</td></tr>
<tr><td><strong>pytest</strong></td><td>Tests</td><td><code>test_*</code> prefix</td><td>Naming convention</td><td><code>def test_foo():</code></td></tr>
<tr><td>pytest</td><td>Fixtures</td><td><code>@pytest.fixture</code></td><td>Decorator analysis</td><td>Test fixtures</td></tr>
<tr><td><strong>unittest</strong></td><td>Tests</td><td><code>TestCase</code> methods</td><td>Class hierarchy</td><td><code>class TestFoo(TestCase):</code></td></tr>
<tr><td>unittest</td><td>Setup/Teardown</td><td><code>setUp</code>, <code>tearDown</code></td><td>Method naming</td><td>Lifecycle methods</td></tr>
<tr><td><strong>Qt/PyQt</strong></td><td>Slots</td><td><code>@pyqtSlot</code></td><td>Decorator analysis</td><td>Signal handlers</td></tr>
<tr><td>Qt</td><td>Connections</td><td><code>.connect()</code> calls</td><td>Call graph analysis</td><td>Event wiring</td></tr>
<tr><td><strong>Tkinter</strong></td><td>Callbacks</td><td><code>command=func</code></td><td>Assignment tracking</td><td>Button callbacks</td></tr>
</tbody></table>
</div>
<p>See <a href="context-providers.html">Framework Patterns documentation</a> for comprehensive framework support details and language-specific patterns.</p>
<h2 id="confidence-thresholds"><a class="header" href="#confidence-thresholds">Confidence Thresholds</a></h2>
<p>You can customize confidence thresholds based on your project‚Äôs tolerance for false positives vs. false negatives:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::analysis::python_dead_code_enhanced::AnalysisConfig;

let config = AnalysisConfig {
    high_confidence_threshold: 0.8,      // Default: 0.8
    medium_confidence_threshold: 0.5,    // Default: 0.5
    respect_suppression_comments: true,  // Default: true
    include_private_api: true,           // Default: true
    enable_public_api_detection: true,   // Default: true (Spec 113)
    ..Default::default()
};
<span class="boring">}</span></code></pre></pre>
<p><strong>Tuning recommendations:</strong></p>
<ul>
<li><strong>Conservative projects</strong> (libraries, public APIs): Raise thresholds to 0.9/0.7 to reduce false positives</li>
<li><strong>Aggressive cleanup</strong> (internal tools): Lower thresholds to 0.7/0.4 to catch more dead code</li>
<li><strong>Balanced approach</strong> (most projects): Use defaults of 0.8/0.5</li>
</ul>
<h2 id="suppressing-false-positives-1"><a class="header" href="#suppressing-false-positives-1">Suppressing False Positives</a></h2>
<p>Mark functions as intentionally unused with suppression comments:</p>
<pre><code class="language-python"># debtmap: not-dead
def future_api_endpoint():
    """Will be activated in v2.0"""
    pass

def compatibility_shim():  # noqa: dead-code
    """Kept for backwards compatibility"""
    pass
</code></pre>
<h3 id="supported-comment-formats"><a class="header" href="#supported-comment-formats">Supported Comment Formats</a></h3>
<p>All of these formats are recognized:</p>
<ul>
<li><code># debtmap: not-dead</code> (recommended)</li>
<li><code># debtmap:not-dead</code></li>
<li><code># noqa: dead-code</code></li>
<li><code># noqa:dead-code</code></li>
</ul>
<h3 id="comment-placement"><a class="header" href="#comment-placement">Comment Placement</a></h3>
<p>Suppression comments can appear:</p>
<ul>
<li>
<p><strong>Above the function</strong> (most common):</p>
<pre><code class="language-python"># debtmap: not-dead
def my_function():
    pass
</code></pre>
</li>
<li>
<p><strong>Same line as function definition</strong>:</p>
<pre><code class="language-python">def my_function():  # debtmap: not-dead
    pass
</code></pre>
</li>
<li>
<p><strong>Below the function definition</strong> (less common):</p>
<pre><code class="language-python">def my_function():
# debtmap: not-dead
    pass
</code></pre>
</li>
</ul>
<h2 id="coverage-integration-2"><a class="header" href="#coverage-integration-2">Coverage Integration</a></h2>
<p>When test coverage data is available, the analyzer uses it to dramatically improve accuracy by marking covered functions as live:</p>
<h3 id="generating-coverage-data-2"><a class="header" href="#generating-coverage-data-2">Generating Coverage Data</a></h3>
<pre><code class="language-bash"># With pytest and pytest-cov
pytest --cov=myapp --cov-report=json

# With coverage.py directly
coverage run -m pytest
coverage json

# Debtmap automatically detects and uses coverage.json
debtmap analyze myapp/
</code></pre>
<h3 id="how-it-works-2"><a class="header" href="#how-it-works-2">How It Works</a></h3>
<p>Functions that appear in coverage data are considered live, even if:</p>
<ul>
<li>No static callers are found</li>
<li>They‚Äôre private functions</li>
<li>They‚Äôre not framework entry points</li>
</ul>
<p>This catches functions called:</p>
<ul>
<li>Dynamically via <code>getattr()</code> or <code>exec()</code></li>
<li>Through plugin systems</li>
<li>By external libraries or C extensions</li>
</ul>
<h3 id="programmatic-coverage-usage"><a class="header" href="#programmatic-coverage-usage">Programmatic Coverage Usage</a></h3>
<p>In Rust code, you can provide coverage data programmatically:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::analysis::python_dead_code_enhanced::{EnhancedDeadCodeAnalyzer, CoverageData};

// Load coverage from coverage.json file
let coverage = CoverageData::from_coverage_json("coverage.json")?;

// Create analyzer with coverage data
let analyzer = EnhancedDeadCodeAnalyzer::new()
    .with_coverage(coverage);

// Analyze functions - covered functions will have higher "live" confidence
let result = analyzer.analyze_function(&amp;func, &amp;call_graph);
<span class="boring">}</span></code></pre></pre>
<h3 id="accuracy-improvement"><a class="header" href="#accuracy-improvement">Accuracy Improvement</a></h3>
<p>Coverage integration typically provides:</p>
<ul>
<li><strong>60-70% reduction</strong> in false positives for complex codebases</li>
<li><strong>Near-zero false positives</strong> for functions with test coverage</li>
<li><strong>Confidence in removal</strong> for uncovered code</li>
<li><strong>Detection of dynamic calls</strong> that static analysis misses</li>
</ul>
<p><strong>Coverage data format</strong>: Debtmap uses the standard <code>coverage.json</code> format produced by <code>coverage.py</code> and <code>pytest-cov</code>. The file should be in your project root and contain executed line numbers for each source file.</p>
<h2 id="configuration-reference"><a class="header" href="#configuration-reference">Configuration Reference</a></h2>
<h3 id="toml-configuration"><a class="header" href="#toml-configuration">TOML Configuration</a></h3>
<p>Complete dead code analysis configuration in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml"># Language-specific dead code detection
[languages.python]
detect_dead_code = true           # Enable Python dead code analysis (default: true)

# External API detection (Spec 113)
[external_api]
detect_external_api = true        # Enable automatic public API detection (default: true)

api_functions = [
    "public_function_name",       # Function name only
    "module::qualified_name",     # Module-qualified format
]

api_files = [
    "src/api/**/*.py",            # Glob patterns supported
    "src/public_interface.py",    # Exact file paths
    "**/__init__.py",             # All package entry points
]
</code></pre>
<h3 id="programmatic-configuration-rust-api"><a class="header" href="#programmatic-configuration-rust-api">Programmatic Configuration (Rust API)</a></h3>
<p>Confidence thresholds and analysis behavior are configured programmatically:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::analysis::python_dead_code_enhanced::AnalysisConfig;

let config = AnalysisConfig {
    // Confidence thresholds
    high_confidence_threshold: 0.8,       // Default: 0.8 (80%)
    medium_confidence_threshold: 0.5,     // Default: 0.5 (50%)

    // Analysis options
    respect_suppression_comments: true,   // Honor # debtmap: not-dead (default: true)
    include_private_api: true,            // Analyze private functions (default: true)
    enable_public_api_detection: true,    // Use public API heuristics (default: true)

    // Public API detector configuration (optional)
    public_api_config: None,              // Use default PublicApiConfig
};

let analyzer = EnhancedDeadCodeAnalyzer::new()
    .with_config(config);
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-tuning-by-project-type"><a class="header" href="#configuration-tuning-by-project-type">Configuration Tuning by Project Type</a></h3>
<p><strong>Libraries and Public APIs</strong> (conservative):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>AnalysisConfig {
    high_confidence_threshold: 0.9,       // Very strict
    medium_confidence_threshold: 0.7,
    enable_public_api_detection: true,    // Critical for libraries
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Internal Applications</strong> (aggressive):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>AnalysisConfig {
    high_confidence_threshold: 0.7,       // More lenient
    medium_confidence_threshold: 0.4,
    include_private_api: true,            // Analyze everything
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Balanced Approach</strong> (recommended default):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>AnalysisConfig::default()  // Uses 0.8/0.5 thresholds
<span class="boring">}</span></code></pre></pre>
<h2 id="understanding-results"><a class="header" href="#understanding-results">Understanding Results</a></h2>
<h3 id="interpreting-output"><a class="header" href="#interpreting-output">Interpreting Output</a></h3>
<p>When you run dead code analysis, you‚Äôll see results like:</p>
<pre><code>Dead code analysis for 'calculate_total':
  Result: LIVE
  Confidence: Low (0.2)

  Reasons it's LIVE:
    - HasStaticCallers (called by 3 functions)
    - PublicApi

  Suggestion:
    Function appears to be in use or is a framework/test entry point.
</code></pre>
<h3 id="decision-guide"><a class="header" href="#decision-guide">Decision Guide</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Result</th><th>Confidence</th><th>Action</th></tr></thead><tbody>
<tr><td><code>is_dead: true</code></td><td>High (0.8-1.0)</td><td><strong>Safe to remove</strong> - Very likely unused</td></tr>
<tr><td><code>is_dead: true</code></td><td>Medium (0.5-0.8)</td><td><strong>Review manually</strong> - Might be dead, verify first</td></tr>
<tr><td><code>is_dead: true</code></td><td>Low (0.0-0.5)</td><td><strong>Keep</strong> - Likely used dynamically</td></tr>
<tr><td><code>is_dead: false</code></td><td>Any</td><td><strong>Keep</strong> - Function is in use</td></tr>
</tbody></table>
</div>
<h3 id="decision-tree-for-confidence-interpretation"><a class="header" href="#decision-tree-for-confidence-interpretation">Decision Tree for Confidence Interpretation</a></h3>
<p>Use this decision tree to determine what action to take:</p>
<pre><code>Is the function flagged as dead?
‚îÇ
‚îú‚îÄ NO ‚Üí Keep the function (it's in use)
‚îÇ
‚îî‚îÄ YES ‚Üí What is the confidence level?
    ‚îÇ
    ‚îú‚îÄ HIGH (0.8-1.0)
    ‚îÇ   ‚îú‚îÄ Is it a public API function? ‚Üí Review, add suppression comment if keeping
    ‚îÇ   ‚îî‚îÄ Is it private (_prefix)? ‚Üí **SAFE TO REMOVE**
    ‚îÇ
    ‚îú‚îÄ MEDIUM (0.5-0.8)
    ‚îÇ   ‚îú‚îÄ Check git history: recently added? ‚Üí Keep for now, review in next sprint
    ‚îÇ   ‚îú‚îÄ Has coverage data been generated? ‚Üí Run with coverage first
    ‚îÇ   ‚îú‚îÄ Is it used dynamically (getattr, plugins)? ‚Üí Add suppression comment
    ‚îÇ   ‚îî‚îÄ No clear reason to keep? ‚Üí **REVIEW MANUALLY, likely safe to remove**
    ‚îÇ
    ‚îî‚îÄ LOW (0.0-0.5)
        ‚îú‚îÄ Review "Reasons it's LIVE" ‚Üí If reasons are valid, keep it
        ‚îú‚îÄ Function is public and might be external API? ‚Üí Keep it
        ‚îî‚îÄ Truly unused but marked live incorrectly? ‚Üí Report issue or use suppression
</code></pre>
<h3 id="confidence-level-quick-reference"><a class="header" href="#confidence-level-quick-reference">Confidence Level Quick Reference</a></h3>
<p><strong>When to act without review:</strong></p>
<ul>
<li><code>is_dead: true</code> + <code>confidence: HIGH</code> + <code>private function (_prefix)</code> ‚Üí <strong>Remove immediately</strong></li>
<li><code>is_dead: true</code> + <code>confidence: HIGH</code> + <code>in test file</code> + <code>not test function</code> ‚Üí <strong>Remove immediately</strong></li>
</ul>
<p><strong>When to review before acting:</strong></p>
<ul>
<li><code>is_dead: true</code> + <code>confidence: MEDIUM</code> ‚Üí <strong>Manual review required</strong></li>
<li><code>is_dead: true</code> + <code>confidence: HIGH</code> + <code>public function</code> ‚Üí <strong>Check git history, verify external usage</strong></li>
</ul>
<p><strong>When to keep:</strong></p>
<ul>
<li><code>is_dead: false</code> ‚Üí <strong>Always keep (function is live)</strong></li>
<li><code>is_dead: true</code> + <code>confidence: LOW</code> ‚Üí <strong>Keep (too uncertain to remove)</strong></li>
</ul>
<h3 id="cli-filtering-by-confidence"><a class="header" href="#cli-filtering-by-confidence">CLI Filtering by Confidence</a></h3>
<pre><code class="language-bash"># Show only high confidence dead code
debtmap analyze --min-confidence=0.8

# Show high and medium confidence
debtmap analyze --min-confidence=0.5

# Show all results (including low confidence)
debtmap analyze --min-confidence=0.0
</code></pre>
<p>See <a href="cli-reference.html">CLI Reference</a> for complete command options.</p>
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="false-positives-and-how-to-handle-them"><a class="header" href="#false-positives-and-how-to-handle-them">False Positives (and How to Handle Them)</a></h3>
<p><strong>Public API methods</strong></p>
<pre><code class="language-python">class Calculator:
    def add(self, a, b):  # Might be used by external code
        return a + b
</code></pre>
<p><em>Solution</em>: Add to <code>api_functions</code> in <code>.debtmap.toml</code> or use suppression comment</p>
<p><strong>Dynamic imports</strong></p>
<pre><code class="language-python"># Module loaded dynamically via importlib
def handle_command(cmd):  # Called via getattr()
    pass
</code></pre>
<p><em>Solution</em>: Add <code># debtmap: not-dead</code> suppression comment</p>
<p><strong>Plugin registration</strong></p>
<pre><code class="language-python">@registry.register
def handler():  # Registered at import time
    pass
</code></pre>
<p><em>Solution</em>: Should be detected by callback tracker; if not, add suppression comment</p>
<h3 id="true-positives-safe-to-remove"><a class="header" href="#true-positives-safe-to-remove">True Positives (Safe to Remove)</a></h3>
<p><strong>Old implementations</strong></p>
<pre><code class="language-python">def _old_calculate(x):  # Replaced but not removed
    return x * 2
</code></pre>
<p><em>Action</em>: Safe to remove (high confidence)</p>
<p><strong>Unused helper functions</strong></p>
<pre><code class="language-python">def _format_date(date):  # Was used but caller was removed
    return date.strftime("%Y-%m-%d")
</code></pre>
<p><em>Action</em>: Safe to remove (high confidence)</p>
<p><strong>Commented-out code alternatives</strong></p>
<pre><code class="language-python">def process_v1(data):  # Old version, v2 is now used
    pass
</code></pre>
<p><em>Action</em>: Safe to remove (high confidence)</p>
<h2 id="best-practices-8"><a class="header" href="#best-practices-8">Best Practices</a></h2>
<h3 id="workflow-recommendations"><a class="header" href="#workflow-recommendations">Workflow Recommendations</a></h3>
<ol>
<li>
<p><strong>Start with high confidence items</strong> - Remove functions with 0.8+ confidence first to build trust in the tool</p>
</li>
<li>
<p><strong>Run with coverage data</strong> - Generate <code>coverage.json</code> to dramatically improve accuracy:</p>
<pre><code class="language-bash">pytest --cov=myapp --cov-report=json
debtmap analyze myapp/
</code></pre>
</li>
<li>
<p><strong>Review medium confidence items</strong> - These often find real dead code but need manual verification</p>
</li>
<li>
<p><strong>Use suppression comments liberally</strong> - Better to mark something as intentionally unused than to have noise in results</p>
</li>
<li>
<p><strong>Check git history</strong> - Before removing, verify the function wasn‚Äôt recently added:</p>
<pre><code class="language-bash">git log -p -- path/to/file.py | grep -A5 "def function_name"
</code></pre>
</li>
<li>
<p><strong>Remove incrementally</strong> - Remove a few functions, run tests, commit. Don‚Äôt remove everything at once:</p>
<pre><code class="language-bash"># Remove 3-5 high confidence functions
pytest  # Verify tests still pass
git commit -m "Remove dead code: _old_helper, _unused_formatter"
</code></pre>
</li>
<li>
<p><strong>Look for patterns</strong> - If multiple related functions are flagged, they might all be part of an abandoned feature</p>
</li>
</ol>
<h3 id="cicd-integration-2"><a class="header" href="#cicd-integration-2">CI/CD Integration</a></h3>
<p>Prevent dead code from accumulating by integrating into your CI pipeline:</p>
<pre><code class="language-bash"># .github/workflows/dead-code.yml
- name: Check for dead code
  run: |
    debtmap analyze --min-confidence=0.8 --format=json &gt; dead-code.json
    # Fail if high-confidence dead code is found
    if [ $(jq '.dead_code | length' dead-code.json) -gt 0 ]; then
      echo "High-confidence dead code detected!"
      jq '.dead_code[] | "\(.file):\(.line) - \(.function)"' dead-code.json
      exit 1
    fi
</code></pre>
<h2 id="limitations-1"><a class="header" href="#limitations-1">Limitations</a></h2>
<h3 id="what-the-analyzer-can-detect"><a class="header" href="#what-the-analyzer-can-detect">What the Analyzer CAN Detect</a></h3>
<ul>
<li>‚úÖ Static function calls across modules</li>
<li>‚úÖ Framework entry points via decorators</li>
<li>‚úÖ Test functions in test files</li>
<li>‚úÖ Callback registrations and event handlers</li>
<li>‚úÖ Functions in <code>__all__</code> exports</li>
<li>‚úÖ Property decorators and descriptors</li>
<li>‚úÖ Magic methods (<code>__init__</code>, <code>__str__</code>, etc.)</li>
<li>‚úÖ Functions covered by test coverage data</li>
</ul>
<h3 id="what-the-analyzer-cannot-detect"><a class="header" href="#what-the-analyzer-cannot-detect">What the Analyzer CANNOT Detect</a></h3>
<ul>
<li>‚ùå <code>eval()</code> or <code>exec()</code> usage - arbitrary code execution</li>
<li>‚ùå <code>getattr()</code> with dynamic string names - runtime attribute lookup</li>
<li>‚ùå Reflection-based calls - <code>inspect</code> module usage</li>
<li>‚ùå Functions called from C extensions</li>
<li>‚ùå Plugin systems using string-based loading - dynamic imports</li>
</ul>
<h3 id="mitigation-strategies"><a class="header" href="#mitigation-strategies">Mitigation Strategies</a></h3>
<p>For functions the analyzer cannot detect, use suppression comments:</p>
<pre><code class="language-python"># Called dynamically via getattr in plugin system
# debtmap: not-dead
def handle_dynamic_command():
    pass

# Loaded via string-based plugin system
# debtmap: not-dead
def plugin_entrypoint():
    pass
</code></pre>
<h2 id="troubleshooting-11"><a class="header" href="#troubleshooting-11">Troubleshooting</a></h2>
<h3 id="function-marked-as-dead-but-its-actually-used"><a class="header" href="#function-marked-as-dead-but-its-actually-used">‚ÄúFunction marked as dead but it‚Äôs actually used‚Äù</a></h3>
<p><strong>Possible causes and solutions:</strong></p>
<ol>
<li>
<p><strong>Dynamic call via <code>getattr()</code> or <code>exec()</code></strong></p>
<ul>
<li><em>Solution</em>: Add <code># debtmap: not-dead</code> suppression comment</li>
<li><em>Example</em>: Plugin systems, command dispatchers</li>
</ul>
</li>
<li>
<p><strong>Called from external code or C extension</strong></p>
<ul>
<li><em>Solution</em>: Add function to <code>api_functions</code> in <code>.debtmap.toml</code></li>
<li><em>Example</em>: Public library APIs</li>
</ul>
</li>
<li>
<p><strong>Framework pattern not recognized</strong></p>
<ul>
<li><em>Solution</em>: Report issue on GitHub with framework details</li>
<li><em>Workaround</em>: Add suppression comment</li>
</ul>
</li>
<li>
<p><strong>Callback registration not detected</strong></p>
<ul>
<li><em>Solution</em>: Check if decorator is supported; add suppression if not</li>
<li><em>Example</em>: Custom registration decorators</li>
</ul>
</li>
</ol>
<h3 id="too-many-false-positives-in-my-codebase"><a class="header" href="#too-many-false-positives-in-my-codebase">‚ÄúToo many false positives in my codebase‚Äù</a></h3>
<p><strong>Solutions to try (in order):</strong></p>
<ol>
<li>
<p><strong>Run with coverage data</strong> - Biggest impact on accuracy:</p>
<pre><code class="language-bash">pytest --cov=myapp --cov-report=json
debtmap analyze myapp/
</code></pre>
</li>
<li>
<p><strong>Configure public API detection</strong> - Mark your external APIs:</p>
<pre><code class="language-toml">[external_api]
api_files = ["src/api/**/*.py", "src/public/**/*.py"]
</code></pre>
</li>
<li>
<p><strong>Add framework patterns</strong> - Report unrecognized frameworks on GitHub</p>
</li>
<li>
<p><strong>Add suppression comments</strong> - Mark intentionally unused functions</p>
</li>
<li>
<p><strong>Adjust confidence thresholds</strong> - Raise to 0.9/0.7 for conservative analysis</p>
</li>
</ol>
<h3 id="low-confidence-on-obviously-dead-code"><a class="header" href="#low-confidence-on-obviously-dead-code">‚ÄúLow confidence on obviously dead code‚Äù</a></h3>
<p>This is working as intended - the analyzer is <strong>conservative</strong> to avoid false positives.</p>
<p><strong>What to do:</strong></p>
<ol>
<li><strong>Review the ‚ÄúReasons it‚Äôs LIVE‚Äù</strong> - Understand why confidence is low</li>
<li><strong>Check if function is truly unused</strong> - Verify no dynamic calls</li>
<li><strong>Run with coverage</strong> - Coverage data will increase confidence for truly dead code</li>
<li><strong>Accept medium/low confidence</strong> - Manual review is valuable for complex cases</li>
</ol>
<h2 id="examples-2"><a class="header" href="#examples-2">Examples</a></h2>
<h3 id="example-1-flask-application"><a class="header" href="#example-1-flask-application">Example 1: Flask Application</a></h3>
<pre><code class="language-python">from flask import Flask
app = Flask(__name__)

@app.route('/')
def index():  # ‚úÖ LIVE - Framework entry point
    return helper()

def helper():  # ‚úÖ LIVE - Called by index()
    return format_response("Hello")

def format_response(msg):  # ‚úÖ LIVE - Called by helper()
    return f"&lt;html&gt;{msg}&lt;/html&gt;"

def _old_route():  # ‚ùå DEAD - No callers, not a route (High: 0.95)
    return "Unused"
</code></pre>
<p><strong>Analysis results:</strong></p>
<ul>
<li><code>index</code>: LIVE (Low: 0.15) - Flask route decorator detected</li>
<li><code>helper</code>: LIVE (Low: 0.25) - Has static caller (index)</li>
<li><code>format_response</code>: LIVE (Low: 0.30) - Has static caller (helper)</li>
<li><code>_old_route</code>: DEAD (High: 0.95) - No callers, private function</li>
</ul>
<h3 id="example-2-test-file"><a class="header" href="#example-2-test-file">Example 2: Test File</a></h3>
<pre><code class="language-python">import pytest

def test_addition():  # ‚úÖ LIVE - Test function
    assert add(1, 2) == 3

def add(a, b):  # ‚úÖ LIVE - Called by test
    return a + b

@pytest.fixture
def sample_data():  # ‚úÖ LIVE - pytest fixture
    return [1, 2, 3]

def _unused_helper():  # ‚ùå DEAD - No callers (High: 0.90)
    return 42

def _old_test_helper():  # ‚ùå DEAD - Was used, now orphaned (High: 0.92)
    return "test data"
</code></pre>
<p><strong>Analysis results:</strong></p>
<ul>
<li><code>test_addition</code>: LIVE (Low: 0.10) - Test function pattern</li>
<li><code>add</code>: LIVE (Low: 0.20) - Called by test</li>
<li><code>sample_data</code>: LIVE (Low: 0.15) - pytest fixture decorator</li>
<li><code>_unused_helper</code>: DEAD (High: 0.90) - No callers in test file</li>
<li><code>_old_test_helper</code>: DEAD (High: 0.92) - Orphaned helper</li>
</ul>
<h3 id="example-3-public-api-with-configuration"><a class="header" href="#example-3-public-api-with-configuration">Example 3: Public API with Configuration</a></h3>
<pre><code class="language-python"># src/api/calculator.py

__all__ = ['calculate', 'format_result']

def calculate(x):  # ‚úÖ LIVE - Exported in __all__
    return _internal_multiply(x, 2)

def format_result(x):  # ‚úÖ LIVE - Exported in __all__
    return f"Result: {x}"

def _internal_multiply(a, b):  # ‚úÖ LIVE - Called by calculate
    return a * b

def _internal_helper():  # ‚ùå DEAD - Not exported, no callers (High: 0.88)
    return None

# Public API but not in __all__
def legacy_api():  # ‚ö†Ô∏è MEDIUM - Public but no callers (Medium: 0.65)
    """Kept for backwards compatibility"""
    pass
</code></pre>
<p><strong>.debtmap.toml configuration:</strong></p>
<pre><code class="language-toml">[external_api]
api_files = ["src/api/**/*.py"]

# Explicitly mark legacy API
api_functions = ["legacy_api"]
</code></pre>
<p><strong>Analysis results:</strong></p>
<ul>
<li><code>calculate</code>: LIVE (Low: 0.20) - In <code>__all__</code>, has callers</li>
<li><code>format_result</code>: LIVE (Low: 0.25) - In <code>__all__</code></li>
<li><code>_internal_multiply</code>: LIVE (Low: 0.30) - Called by calculate</li>
<li><code>_internal_helper</code>: DEAD (High: 0.88) - Private, no callers</li>
<li><code>legacy_api</code>: LIVE (Low: 0.35) - Marked as API in config</li>
</ul>
<h2 id="getting-help-1"><a class="header" href="#getting-help-1">Getting Help</a></h2>
<ul>
<li><strong>Documentation</strong>: See <a href="troubleshooting.html">Troubleshooting Guide</a> for common issues</li>
<li><strong>Report issues</strong>: https://github.com/anthropics/debtmap/issues</li>
<li><strong>Examples</strong>: Check the <a href="examples.html">Examples chapter</a> for more scenarios</li>
<li><strong>Related topics</strong>:
<ul>
<li><a href="coverage-integration.html">Coverage Integration</a> - Detailed coverage setup</li>
<li><a href="suppression-patterns.html">Suppression Patterns</a> - Advanced suppression techniques</li>
<li><a href="configuration.html">Configuration</a> - Complete configuration reference</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-pattern-detection"><a class="header" href="#design-pattern-detection">Design Pattern Detection</a></h1>
<p>Debtmap automatically detects common design patterns in your codebase to provide better architectural insights and reduce false positives in complexity analysis. When recognized design patterns are detected, Debtmap applies appropriate complexity adjustments to avoid penalizing idiomatic code.</p>
<h2 id="overview-7"><a class="header" href="#overview-7">Overview</a></h2>
<p>Debtmap detects 7 design patterns across Python, JavaScript, TypeScript, and Rust:</p>
<div class="table-wrapper"><table><thead><tr><th>Pattern</th><th>Primary Language</th><th>Detection Confidence</th></tr></thead><tbody>
<tr><td>Observer</td><td>Python, Rust</td><td>High (0.8-0.9)</td></tr>
<tr><td>Singleton</td><td>Python</td><td>High (0.85-0.95)</td></tr>
<tr><td>Factory</td><td>Python</td><td>Medium-High (0.7-0.85)</td></tr>
<tr><td>Strategy</td><td>Python</td><td>Medium (0.7-0.8)</td></tr>
<tr><td>Callback</td><td>Python, JavaScript</td><td>High (0.8-0.9)</td></tr>
<tr><td>Template Method</td><td>Python</td><td>Medium (0.7-0.8)</td></tr>
<tr><td>Dependency Injection</td><td>Python</td><td>Medium (0.65-0.75)</td></tr>
</tbody></table>
</div>
<p>Pattern detection serves multiple purposes:</p>
<ul>
<li><strong>Reduces false positives</strong>: Avoids flagging idiomatic pattern implementations as overly complex</li>
<li><strong>Documents architecture</strong>: Automatically identifies architectural patterns in your codebase</li>
<li><strong>Validates consistency</strong>: Helps ensure patterns are used correctly and completely</li>
<li><strong>Guides refactoring</strong>: Identifies incomplete pattern implementations</li>
</ul>
<h2 id="pattern-detection-details"><a class="header" href="#pattern-detection-details">Pattern Detection Details</a></h2>
<h3 id="observer-pattern"><a class="header" href="#observer-pattern">Observer Pattern</a></h3>
<p>The Observer pattern is detected in Python and Rust by identifying abstract base classes with concrete implementations.</p>
<p><strong>Detection Criteria (Python)</strong>:</p>
<ul>
<li>Abstract base class with <code>ABC</code>, <code>Protocol</code>, or <code>Interface</code> markers</li>
<li>Abstract methods decorated with <code>@abstractmethod</code></li>
<li>Concrete implementations inheriting from the interface</li>
<li>Methods prefixed with <code>on_</code>, <code>handle_</code>, or <code>notify_</code></li>
<li>Registration methods like <code>add_observer</code>, <code>register</code>, or <code>subscribe</code></li>
<li>Notification methods like <code>notify</code>, <code>notify_all</code>, <code>trigger</code>, <code>emit</code></li>
</ul>
<p><strong>Detection Criteria (Rust)</strong>:</p>
<ul>
<li>Trait definitions with callback-style methods</li>
<li>Multiple implementations of the same trait</li>
<li>Trait registry tracking for cross-module detection</li>
</ul>
<p><strong>Example (Python)</strong>:</p>
<pre><code class="language-python">from abc import ABC, abstractmethod

class EventObserver(ABC):
    @abstractmethod
    def on_event(self, data):
        """Handle event notification"""
        pass

class LoggingObserver(EventObserver):
    def on_event(self, data):
        print(f"Event occurred: {data}")

class EmailObserver(EventObserver):
    def on_event(self, data):
        send_email(f"Alert: {data}")

class EventManager:
    def __init__(self):
        self.observers = []

    def add_observer(self, observer: EventObserver):
        self.observers.append(observer)

    def notify_all(self, data):
        for observer in self.observers:
            observer.on_event(data)
</code></pre>
<p><strong>Confidence</strong>: High (0.8-0.9) when abstract base class, implementations, and registration/notification methods are present. Lower confidence (0.5-0.7) for partial implementations.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml">[patterns.observer]
interface_markers = ["ABC", "Protocol", "Interface"]
registration_methods = ["add_observer", "register", "subscribe"]
method_prefixes = ["on_", "handle_", "notify_"]
</code></pre>
<h3 id="singleton-pattern"><a class="header" href="#singleton-pattern">Singleton Pattern</a></h3>
<p>Singleton pattern detection identifies three common Python implementations: module-level singletons, <code>__new__</code> override, and decorator-based patterns.</p>
<p><strong>Detection Criteria</strong>:</p>
<ul>
<li>Module-level variable assignments (e.g., <code>instance = MyClass()</code>)</li>
<li>Classes overriding <code>__new__</code> to enforce single instance</li>
<li>Classes decorated with <code>@singleton</code> or similar decorators</li>
<li>Presence of instance caching logic</li>
</ul>
<p><strong>Example (Module-level)</strong>:</p>
<pre><code class="language-python"># config.py
class Config:
    def __init__(self):
        self.settings = {}

    def load(self, path):
        # Load configuration
        pass

# Single instance created at module level
config = Config()
</code></pre>
<p><strong>Example (<code>__new__</code> override)</strong>:</p>
<pre><code class="language-python">class DatabaseConnection:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.initialized = True
            self.connect()
</code></pre>
<p><strong>Example (Decorator-based)</strong>:</p>
<pre><code class="language-python">def singleton(cls):
    instances = {}
    def get_instance(*args, **kwargs):
        if cls not in instances:
            instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    return get_instance

@singleton
class Logger:
    def __init__(self):
        self.log_file = open('app.log', 'a')
</code></pre>
<p><strong>Confidence</strong>: Very High (0.9-0.95) for <code>__new__</code> override and decorator patterns. High (0.85) for module-level singletons with clear naming.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml">[patterns.singleton]
# No user-configurable options currently
# Detection is based on implementation patterns
</code></pre>
<h3 id="factory-pattern"><a class="header" href="#factory-pattern">Factory Pattern</a></h3>
<p>Factory pattern detection identifies factory functions, factory classes, and factory registries based on naming conventions and structural patterns.</p>
<p><strong>Detection Criteria</strong>:</p>
<ul>
<li>Functions with names containing <code>create_</code>, <code>make_</code>, <code>build_</code>, or <code>_factory</code></li>
<li>Factory registry patterns (dictionaries mapping types to constructors)</li>
<li>Functions that return instances of different types based on parameters</li>
<li>Classes with factory methods</li>
</ul>
<p><strong>Example (Factory Function)</strong>:</p>
<pre><code class="language-python">def create_logger(log_type: str):
    if log_type == "file":
        return FileLogger()
    elif log_type == "console":
        return ConsoleLogger()
    elif log_type == "network":
        return NetworkLogger()
    else:
        raise ValueError(f"Unknown logger type: {log_type}")
</code></pre>
<p><strong>Example (Registry-based Factory)</strong>:</p>
<pre><code class="language-python"># Parser registry
PARSERS = {
    'json': JSONParser,
    'xml': XMLParser,
    'yaml': YAMLParser,
}

def create_parser(format: str):
    parser_class = PARSERS.get(format)
    if parser_class is None:
        raise ValueError(f"No parser for format: {format}")
    return parser_class()
</code></pre>
<p><strong>Example (Factory Method)</strong>:</p>
<pre><code class="language-python">class DocumentFactory:
    @staticmethod
    def create_document(doc_type: str):
        if doc_type == "pdf":
            return PDFDocument()
        elif doc_type == "word":
            return WordDocument()
        else:
            return PlainTextDocument()
</code></pre>
<p><strong>Confidence</strong>: Medium-High (0.75-0.85) for functions with factory naming patterns. Lower confidence (0.6-0.7) for registry patterns without factory names.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml">[patterns.factory]
function_patterns = ["create_", "make_", "build_", "_factory"]
min_implementations = 2  # Minimum branches/types to consider it a factory
</code></pre>
<h3 id="strategy-pattern"><a class="header" href="#strategy-pattern">Strategy Pattern</a></h3>
<p>Strategy pattern detection identifies interfaces with multiple implementations representing interchangeable algorithms.</p>
<p><strong>Detection Criteria</strong>:</p>
<ul>
<li>Abstract base class or Protocol defining strategy interface</li>
<li>Multiple concrete implementations</li>
<li>Strategy interface typically has 1-2 core methods</li>
<li>Used via composition (strategy object passed to context)</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-python">from abc import ABC, abstractmethod

class CompressionStrategy(ABC):
    @abstractmethod
    def compress(self, data: bytes) -&gt; bytes:
        pass

class ZipCompression(CompressionStrategy):
    def compress(self, data: bytes) -&gt; bytes:
        return zlib.compress(data)

class GzipCompression(CompressionStrategy):
    def compress(self, data: bytes) -&gt; bytes:
        return gzip.compress(data)

class LzmaCompression(CompressionStrategy):
    def compress(self, data: bytes) -&gt; bytes:
        return lzma.compress(data)

class FileCompressor:
    def __init__(self, strategy: CompressionStrategy):
        self.strategy = strategy

    def compress_file(self, path):
        data = read_file(path)
        return self.strategy.compress(data)
</code></pre>
<p><strong>Confidence</strong>: Medium (0.7-0.8) based on interface structure and implementation count.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml">[patterns.strategy]
min_implementations = 2  # Minimum concrete strategies
</code></pre>
<h3 id="callback-pattern"><a class="header" href="#callback-pattern">Callback Pattern</a></h3>
<p>Callback pattern detection identifies decorator-based callbacks commonly used in web frameworks and event handlers.</p>
<p><strong>Detection Criteria</strong>:</p>
<ul>
<li>Decorators with patterns like <code>@route</code>, <code>@handler</code>, <code>@app.</code>, <code>@on</code>, <code>@callback</code></li>
<li>Framework-specific decorators (Flask routes, FastAPI endpoints, event handlers)</li>
<li>Functions registered as callbacks for events or hooks</li>
</ul>
<p><strong>Example (Flask Routes)</strong>:</p>
<pre><code class="language-python">from flask import Flask

app = Flask(__name__)

@app.route('/api/users')
def get_users():
    return {"users": []}

@app.route('/api/users/&lt;id&gt;')
def get_user(id):
    return {"user": find_user(id)}
</code></pre>
<p><strong>Example (Event Handler)</strong>:</p>
<pre><code class="language-python">class EventBus:
    def __init__(self):
        self.handlers = {}

    def on(self, event_name):
        def decorator(func):
            self.handlers[event_name] = func
            return func
        return decorator

bus = EventBus()

@bus.on('user.created')
def handle_user_created(user):
    send_welcome_email(user)

@bus.on('order.placed')
def handle_order_placed(order):
    process_payment(order)
</code></pre>
<p><strong>Confidence</strong>: High (0.8-0.9) for framework decorator patterns. Medium (0.6-0.7) for custom callback implementations.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml">[patterns.callback]
decorator_patterns = [
    "route", "handler", "app.", "on", "callback",
    "post", "get", "put", "delete", "patch"
]
</code></pre>
<h3 id="template-method-pattern"><a class="header" href="#template-method-pattern">Template Method Pattern</a></h3>
<p>Template method pattern detection identifies base classes with template methods that call abstract hook methods.</p>
<p><strong>Detection Criteria</strong>:</p>
<ul>
<li>Base class with concrete methods (template methods)</li>
<li>Abstract methods intended to be overridden (hook methods)</li>
<li>Template method calls hook methods in a defined sequence</li>
<li>Subclasses override hook methods but not template method</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-python">from abc import ABC, abstractmethod

class DataProcessor(ABC):
    def process(self, data):
        """Template method defining the algorithm skeleton"""
        raw = self.load_data(data)
        validated = self.validate(raw)
        transformed = self.transform(validated)
        self.save(transformed)

    @abstractmethod
    def load_data(self, source):
        """Hook: Load data from source"""
        pass

    @abstractmethod
    def validate(self, data):
        """Hook: Validate data"""
        pass

    def transform(self, data):
        """Hook: Transform data (optional override)"""
        return data

    @abstractmethod
    def save(self, data):
        """Hook: Save processed data"""
        pass

class CSVProcessor(DataProcessor):
    def load_data(self, source):
        return read_csv(source)

    def validate(self, data):
        return [row for row in data if row]

    def save(self, data):
        write_csv('output.csv', data)
</code></pre>
<p><strong>Confidence</strong>: Medium (0.7-0.8) based on combination of abstract and concrete methods in base class.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml">[patterns.template_method]
# Detection based on abstract method patterns
# No user-configurable options currently
</code></pre>
<h3 id="dependency-injection-pattern"><a class="header" href="#dependency-injection-pattern">Dependency Injection Pattern</a></h3>
<p>Dependency injection pattern detection identifies classes that receive dependencies through constructors or setters rather than creating them internally.</p>
<p><strong>Detection Criteria</strong>:</p>
<ul>
<li>Constructor parameters accepting interface/protocol types</li>
<li>Setter methods for injecting dependencies</li>
<li>Optional dependencies with default values</li>
<li>Absence of hard-coded object instantiation inside the class</li>
</ul>
<p><strong>Example (Constructor Injection)</strong>:</p>
<pre><code class="language-python">class UserService:
    def __init__(self,
                 user_repository: UserRepository,
                 email_service: EmailService,
                 logger: Logger):
        self.user_repo = user_repository
        self.email_service = email_service
        self.logger = logger

    def create_user(self, username, email):
        user = self.user_repo.create(username, email)
        self.email_service.send_welcome(email)
        self.logger.info(f"Created user: {username}")
        return user
</code></pre>
<p><strong>Example (Setter Injection)</strong>:</p>
<pre><code class="language-python">class ReportGenerator:
    def __init__(self):
        self.data_source = None
        self.formatter = None

    def set_data_source(self, source):
        self.data_source = source

    def set_formatter(self, formatter):
        self.formatter = formatter

    def generate(self):
        data = self.data_source.fetch()
        return self.formatter.format(data)
</code></pre>
<p><strong>Confidence</strong>: Medium (0.65-0.75) based on constructor signatures and absence of direct instantiation.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml">[patterns.dependency_injection]
# Detection based on constructor patterns
# No user-configurable options currently
</code></pre>
<h2 id="internal-pattern-detection"><a class="header" href="#internal-pattern-detection">Internal Pattern Detection</a></h2>
<p>Debtmap also detects certain patterns internally for analysis purposes, but these are not exposed as user-facing design pattern detection features. These internal patterns help improve the accuracy of other analyses like god object detection and complexity calculations.</p>
<h3 id="builder-pattern-internal-use-only"><a class="header" href="#builder-pattern-internal-use-only">Builder Pattern (Internal Use Only)</a></h3>
<p>The Builder pattern is detected internally during <strong>god object detection</strong> to avoid false positives. Classes that follow the builder pattern are given adjusted scores in god object analysis since builder classes naturally have many methods and fields.</p>
<p><strong>Note</strong>: Builder pattern detection is <strong>not available</strong> via the <code>--patterns</code> CLI flag. It‚Äôs used only internally for scoring adjustments.</p>
<p><strong>Internal Detection Criteria</strong>:</p>
<ul>
<li>Struct with builder suffix or builder-related naming</li>
<li>Methods returning <code>Self</code> for chaining</li>
<li>Final <code>build()</code> method returning the constructed type</li>
<li>Type-state pattern usage (optional)</li>
</ul>
<p><strong>Example</strong> (Internal Detection):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct HttpClientBuilder {
    base_url: Option&lt;String&gt;,
    timeout: Duration,
    headers: HashMap&lt;String, String&gt;,
}

impl HttpClientBuilder {
    pub fn new() -&gt; Self { /* ... */ }

    // Chaining methods detected internally
    pub fn base_url(mut self, url: impl Into&lt;String&gt;) -&gt; Self { /* ... */ }
    pub fn timeout(mut self, timeout: Duration) -&gt; Self { /* ... */ }
    pub fn header(mut self, key: String, value: String) -&gt; Self { /* ... */ }

    pub fn build(self) -&gt; Result&lt;HttpClient&gt; { /* ... */ }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Why Internal Only</strong>: Builder patterns are a legitimate design choice for complex object construction. Debtmap detects them to prevent flagging builder classes as god objects, but doesn‚Äôt report them as design patterns since they don‚Äôt require complexity adjustments like other patterns.</p>
<p><strong>Source</strong>: <code>src/organization/builder_pattern.rs</code> - Used for god object detection score adjustment</p>
<h3 id="visitor-pattern-internal-use-only"><a class="header" href="#visitor-pattern-internal-use-only">Visitor Pattern (Internal Use Only)</a></h3>
<p>The Visitor pattern is detected internally for <strong>complexity analysis normalization</strong>. When exhaustive pattern matching is detected (typical of visitor patterns), Debtmap applies logarithmic complexity scaling instead of linear scaling to avoid penalizing idiomatic exhaustive match expressions.</p>
<p><strong>Note</strong>: Visitor pattern detection is <strong>not available</strong> via the <code>--patterns</code> CLI flag. It‚Äôs used only internally for complexity scaling adjustments.</p>
<p><strong>Internal Detection Criteria</strong>:</p>
<ul>
<li>Trait with visit methods for different types</li>
<li>Implementations providing behavior for each visited type</li>
<li>Exhaustive pattern matching across enum variants</li>
<li>Used primarily for AST traversal or data structure processing</li>
</ul>
<p><strong>Example</strong> (Internal Detection):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Visitor {
    fn visit_function(&amp;mut self, func: &amp;Function);
    fn visit_class(&amp;mut self, class: &amp;Class);
    fn visit_module(&amp;mut self, module: &amp;Module);
}

impl Visitor for ComplexityVisitor {
    fn visit_function(&amp;mut self, func: &amp;Function) {
        // Exhaustive matching detected for complexity scaling
        match &amp;func.body {
            FunctionBody::Simple =&gt; { /* ... */ }
            FunctionBody::Complex(statements) =&gt; { /* ... */ }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Why Internal Only</strong>: Visitor patterns often involve exhaustive pattern matching which can appear complex by traditional metrics. Debtmap detects these patterns to apply logarithmic scaling (<code>log2(match_arms) * avg_complexity</code>) instead of linear, preventing false positives in complexity analysis. This is a complexity adjustment mechanism, not a user-visible pattern detection feature.</p>
<p><strong>Source</strong>: <code>src/complexity/visitor_detector.rs</code> - Used for complexity analysis, not pattern reporting</p>
<h2 id="configuration-6"><a class="header" href="#configuration-6">Configuration</a></h2>
<h3 id="cli-options"><a class="header" href="#cli-options">CLI Options</a></h3>
<p>Enable or configure pattern detection using command-line flags:</p>
<pre><code class="language-bash"># Disable all pattern detection
debtmap analyze --no-pattern-detection

# Enable only specific patterns (all 7 available patterns shown)
debtmap analyze --patterns observer,singleton,factory,strategy,callback,template_method,dependency_injection

# Enable a subset of patterns
debtmap analyze --patterns observer,singleton,factory

# Set confidence threshold (0.0-1.0)
debtmap analyze --pattern-threshold 0.8

# Show warnings for uncertain pattern detections
debtmap analyze --show-pattern-warnings
</code></pre>
<p><strong>Available Patterns for <code>--patterns</code> Flag</strong>:</p>
<ul>
<li><code>observer</code> - Observer pattern detection</li>
<li><code>singleton</code> - Singleton pattern detection</li>
<li><code>factory</code> - Factory pattern detection</li>
<li><code>strategy</code> - Strategy pattern detection</li>
<li><code>callback</code> - Callback pattern detection</li>
<li><code>template_method</code> - Template method pattern detection</li>
<li><code>dependency_injection</code> - Dependency injection detection</li>
</ul>
<p><strong>Note</strong>: Builder and Visitor patterns are detected internally but are <strong>not available</strong> via the <code>--patterns</code> flag. See <a href="design-patterns.html#internal-pattern-detection">Internal Pattern Detection</a> for details.</p>
<h3 id="configuration-file-2"><a class="header" href="#configuration-file-2">Configuration File</a></h3>
<p>Configure pattern detection in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[patterns]
# Enable/disable pattern recognition globally
enabled = true

# Minimum confidence threshold for pattern detection (0.0 - 1.0)
confidence_threshold = 0.7

# Observer pattern configuration
[patterns.observer]
interface_markers = ["ABC", "Protocol", "Interface"]
registration_methods = ["add_observer", "register", "subscribe"]
method_prefixes = ["on_", "handle_", "notify_"]

# Singleton pattern configuration
[patterns.singleton]
# Detection is automatic based on implementation patterns

# Factory pattern configuration
[patterns.factory]
function_patterns = ["create_", "make_", "build_", "_factory"]
min_implementations = 2

# Strategy pattern configuration
[patterns.strategy]
min_implementations = 2

# Callback pattern configuration
[patterns.callback]
decorator_patterns = [
    "route", "handler", "app.", "on", "callback",
    "post", "get", "put", "delete", "patch"
]

# Template method pattern configuration
[patterns.template_method]
# Detection is automatic based on abstract methods

# Custom pattern rules (see next section)
[[patterns.custom_rules]]
name = "Repository Pattern"
method_pattern = "^(find|save|update|delete)_"
confidence = 0.75
</code></pre>
<h3 id="custom-pattern-rules"><a class="header" href="#custom-pattern-rules">Custom Pattern Rules</a></h3>
<p>Define project-specific patterns using custom rules:</p>
<pre><code class="language-toml">[[patterns.custom_rules]]
name = "Repository Pattern"
description = "Data access layer pattern"
method_pattern = "^(find|save|update|delete|get)_.*"
class_pattern = ".*Repository$"
confidence = 0.75

[[patterns.custom_rules]]
name = "Service Layer"
description = "Business logic service pattern"
class_pattern = ".*Service$"
method_pattern = "^(execute|process|handle)_"
confidence = 0.7

[[patterns.custom_rules]]
name = "Command Pattern"
description = "Command objects with execute method"
class_pattern = ".*Command$"
method_pattern = "^execute$"
confidence = 0.8
</code></pre>
<p>Custom rule fields:</p>
<ul>
<li><code>name</code>: Pattern name for reporting</li>
<li><code>description</code>: Optional description</li>
<li><code>method_pattern</code>: Regular expression for method names</li>
<li><code>class_pattern</code>: Regular expression for class names</li>
<li><code>decorator_pattern</code>: Regular expression for decorator names</li>
<li><code>confidence</code>: Confidence score (0.0-1.0) when pattern matches</li>
</ul>
<h2 id="confidence-scoring-1"><a class="header" href="#confidence-scoring-1">Confidence Scoring</a></h2>
<p>Pattern detection uses a confidence scoring system (0.0-1.0) to indicate match quality:</p>
<ul>
<li><strong>0.9-1.0</strong>: Very High - Strong structural match with all key elements present</li>
<li><strong>0.8-0.9</strong>: High - Clear pattern with most elements present</li>
<li><strong>0.7-0.8</strong>: Medium-High - Pattern present with some uncertainty</li>
<li><strong>0.6-0.7</strong>: Medium - Possible pattern with limited evidence</li>
<li><strong>0.5-0.6</strong>: Low - Weak match, may be false positive</li>
</ul>
<p><strong>Default Threshold</strong>: 0.7 - Only patterns with 70% or higher confidence are reported by default.</p>
<p><strong>Adjusting Thresholds</strong>:</p>
<pre><code class="language-bash"># More strict (fewer patterns, higher confidence)
debtmap analyze --pattern-threshold 0.85

# More lenient (more patterns, lower confidence)
debtmap analyze --pattern-threshold 0.6 --show-pattern-warnings
</code></pre>
<p><strong>How Confidence is Calculated</strong>:</p>
<p>Each pattern detector calculates confidence based on:</p>
<ol>
<li><strong>Structural completeness</strong>: Are all expected elements present?</li>
<li><strong>Naming conventions</strong>: Do names match expected patterns?</li>
<li><strong>Implementation count</strong>: Are there enough implementations to confirm the pattern?</li>
<li><strong>Cross-validation</strong>: Do different detection heuristics agree?</li>
</ol>
<p>Example confidence calculation for Observer pattern:</p>
<ul>
<li>Base class with <code>ABC</code> marker: +0.3</li>
<li>Abstract methods present: +0.2</li>
<li>Concrete implementations found: +0.2</li>
<li>Registration methods detected: +0.15</li>
<li>Notification methods detected: +0.15</li>
<li><strong>Total</strong>: 0.8 (High confidence)</li>
</ul>
<h2 id="cross-file-pattern-detection"><a class="header" href="#cross-file-pattern-detection">Cross-File Pattern Detection</a></h2>
<p>Debtmap can detect patterns that span multiple files, particularly for the Observer pattern where interfaces and implementations may be in separate modules.</p>
<p><strong>How Cross-File Detection Works</strong>:</p>
<ol>
<li><strong>Import Tracking</strong>: Debtmap tracks imports to understand module dependencies</li>
<li><strong>Interface Registry</strong>: Abstract base classes are registered globally</li>
<li><strong>Implementation Matching</strong>: Implementations in other files are matched to registered interfaces</li>
<li><strong>Cross-Module Context</strong>: A shared context links related files</li>
</ol>
<p><strong>Example</strong>:</p>
<pre><code class="language-python"># interfaces/observer.py
from abc import ABC, abstractmethod

class EventObserver(ABC):
    @abstractmethod
    def on_event(self, data):
        pass

# observers/logging_observer.py
from interfaces.observer import EventObserver

class LoggingObserver(EventObserver):
    def on_event(self, data):
        log(data)

# observers/email_observer.py
from interfaces.observer import EventObserver

class EmailObserver(EventObserver):
    def on_event(self, data):
        send_email(data)
</code></pre>
<p>Debtmap detects this as a single Observer pattern with cross-file implementations.</p>
<p><strong>Limitations</strong>:</p>
<ul>
<li>Only works for explicitly imported interfaces</li>
<li>Requires static import analysis (dynamic imports may not be tracked)</li>
<li>Most effective within a single project (not across external dependencies)</li>
</ul>
<h2 id="rust-specific-pattern-detection"><a class="header" href="#rust-specific-pattern-detection">Rust-Specific Pattern Detection</a></h2>
<h3 id="trait-based-patterns"><a class="header" href="#trait-based-patterns">Trait-Based Patterns</a></h3>
<p>Rust pattern detection leverages the trait system for identifying patterns:</p>
<p><strong>Trait Registry</strong>: Tracks trait definitions and implementations across modules</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Trait registered for pattern detection
pub trait EventHandler {
    fn handle(&amp;self, event: &amp;Event);
}

// Multiple implementations tracked
impl EventHandler for LogHandler { /* ... */ }
impl EventHandler for MetricsHandler { /* ... */ }
impl EventHandler for AlertHandler { /* ... */ }
<span class="boring">}</span></code></pre></pre>
<p><strong>Observer Pattern via Traits</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Observable {
    fn subscribe(&amp;mut self, observer: Box&lt;dyn Observer&gt;);
    fn notify(&amp;self, event: &amp;Event);
}

pub trait Observer {
    fn on_event(&amp;self, event: &amp;Event);
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Differences from Python Detection</strong>:</p>
<ul>
<li>Traits are more explicit than Python‚Äôs ABC</li>
<li>Type system ensures implementation correctness</li>
<li>No runtime reflection needed for detection</li>
<li>Pattern matching exhaustiveness helps identify Visitor pattern</li>
</ul>
<h2 id="integration-with-complexity-analysis-1"><a class="header" href="#integration-with-complexity-analysis-1">Integration with Complexity Analysis</a></h2>
<p>Pattern detection directly affects complexity scoring through <strong>pattern-based adjustments</strong>:</p>
<h3 id="role-multipliers-1"><a class="header" href="#role-multipliers-1">Role Multipliers</a></h3>
<p>Functions identified as part of design patterns receive adjusted complexity scores:</p>
<div class="table-wrapper"><table><thead><tr><th>Role</th><th>Multiplier</th><th>Reasoning</th></tr></thead><tbody>
<tr><td>Pattern Implementation</td><td>0.6</td><td>Boilerplate pattern code is less concerning</td></tr>
<tr><td>Factory Method</td><td>0.7</td><td>Expected to have branching logic</td></tr>
<tr><td>Observer Notification</td><td>0.5</td><td>Simple iteration over observers</td></tr>
<tr><td>Template Method</td><td>0.8</td><td>Framework method with expected complexity</td></tr>
</tbody></table>
</div>
<h3 id="pattern-dampening"><a class="header" href="#pattern-dampening">Pattern Dampening</a></h3>
<p>Recognized patterns reduce effective complexity:</p>
<pre><code>effective_complexity = base_complexity * pattern_multiplier
</code></pre>
<p>Example:</p>
<ul>
<li>Observer implementation method with cognitive complexity 15</li>
<li>Pattern multiplier: 0.6</li>
<li>Effective complexity: 15 * 0.6 = 9</li>
</ul>
<h3 id="visitor-pattern-special-case"><a class="header" href="#visitor-pattern-special-case">Visitor Pattern Special Case</a></h3>
<p>Debtmap internally detects visitor-like patterns (exhaustive matching) and applies <strong>logarithmic scaling</strong> instead of linear complexity:</p>
<pre><code>visitor_complexity = log2(match_arms) * average_arm_complexity
</code></pre>
<p>This prevents exhaustive pattern matching from being flagged as overly complex. Note that this is an internal complexity adjustment mechanism, not a user-visible design pattern detection feature. See <a href="design-patterns.html#visitor-pattern-internal-use-only">Visitor Pattern (Internal Use Only)</a> for more details.</p>
<p><strong>See Also</strong>:</p>
<ul>
<li><a href="./entropy-analysis.html">Entropy Analysis</a> - Pattern dampening in entropy calculations</li>
<li><a href="./scoring-strategies.html">Scoring Strategies</a> - Role multipliers and complexity adjustments</li>
<li><a href="./configuration.html">Configuration</a> - Configuring pattern detection in <code>.debtmap.toml</code></li>
</ul>
<h2 id="practical-examples-2"><a class="header" href="#practical-examples-2">Practical Examples</a></h2>
<h3 id="example-1-analyzing-a-web-framework"><a class="header" href="#example-1-analyzing-a-web-framework">Example 1: Analyzing a Web Framework</a></h3>
<p>Analyzing a Flask application with callback patterns:</p>
<pre><code class="language-bash">debtmap analyze --patterns callback --show-pattern-warnings myapp/
</code></pre>
<p>Output excerpt:</p>
<pre><code>Design Patterns Detected:
  Callback Pattern (15 instances, confidence: 0.85-0.92)
    - @app.route decorators: 12
    - @app.before_request decorators: 2
    - @app.errorhandler decorators: 1

Complexity Adjustments:
  - Route handlers: -40% complexity (pattern boilerplate)
  - Error handlers: -50% complexity (expected pattern)
</code></pre>
<h3 id="example-2-detecting-observer-pattern"><a class="header" href="#example-2-detecting-observer-pattern">Example 2: Detecting Observer Pattern</a></h3>
<p>Analyzing a codebase with event-driven architecture:</p>
<pre><code class="language-bash">debtmap analyze --patterns observer --pattern-threshold 0.75
</code></pre>
<p>Code:</p>
<pre><code class="language-python"># event_system.py
from abc import ABC, abstractmethod

class EventListener(ABC):
    @abstractmethod
    def on_user_login(self, user):
        pass

class AuditLogger(EventListener):
    def on_user_login(self, user):
        audit_log.write(f"User {user.id} logged in")

class SessionManager(EventListener):
    def on_user_login(self, user):
        create_session(user)

class EventDispatcher:
    def __init__(self):
        self.listeners = []

    def add_listener(self, listener):
        self.listeners.append(listener)

    def notify_login(self, user):
        for listener in self.listeners:
            listener.on_user_login(user)
</code></pre>
<p>Output:</p>
<pre><code>Design Patterns:
  Observer Pattern (confidence: 0.88)
    Interface: EventListener (event_system.py:4)
    Implementations:
      - AuditLogger (event_system.py:9)
      - SessionManager (event_system.py:13)
    Registration: add_listener (event_system.py:21)
    Notification: notify_login (event_system.py:24)
</code></pre>
<h3 id="example-3-custom-repository-pattern"><a class="header" href="#example-3-custom-repository-pattern">Example 3: Custom Repository Pattern</a></h3>
<p>Defining and detecting a custom Repository pattern:</p>
<p><code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[[patterns.custom_rules]]
name = "Repository Pattern"
description = "Data access layer"
class_pattern = ".*Repository$"
method_pattern = "^(find|get|save|update|delete)_"
confidence = 0.75
</code></pre>
<p>Code:</p>
<pre><code class="language-python">class UserRepository:
    def find_by_id(self, user_id):
        return db.query(User).get(user_id)

    def find_by_email(self, email):
        return db.query(User).filter_by(email=email).first()

    def save(self, user):
        db.session.add(user)
        db.session.commit()

    def delete_by_id(self, user_id):
        user = self.find_by_id(user_id)
        db.session.delete(user)
        db.session.commit()
</code></pre>
<p>Analysis:</p>
<pre><code class="language-bash">debtmap analyze --show-pattern-warnings
</code></pre>
<p>Output:</p>
<pre><code>Custom Patterns Detected:
  Repository Pattern (confidence: 0.75)
    - UserRepository (models.py:10)
      Methods: find_by_id, find_by_email, save, delete_by_id
</code></pre>
<h2 id="use-cases-3"><a class="header" href="#use-cases-3">Use Cases</a></h2>
<h3 id="1-false-positive-reduction"><a class="header" href="#1-false-positive-reduction">1. False Positive Reduction</a></h3>
<p><strong>Problem</strong>: Complex factory functions flagged as too complex
<strong>Solution</strong>: Enable factory pattern detection to apply appropriate complexity adjustments</p>
<pre><code class="language-bash">debtmap analyze --patterns factory --pattern-threshold 0.7
</code></pre>
<h3 id="2-architecture-documentation"><a class="header" href="#2-architecture-documentation">2. Architecture Documentation</a></h3>
<p><strong>Problem</strong>: Undocumented design patterns in legacy codebase
<strong>Solution</strong>: Run pattern detection to automatically identify architectural patterns</p>
<pre><code class="language-bash">debtmap analyze --patterns all --show-pattern-warnings &gt; architecture-report.txt
</code></pre>
<h3 id="3-pattern-consistency-validation"><a class="header" href="#3-pattern-consistency-validation">3. Pattern Consistency Validation</a></h3>
<p><strong>Problem</strong>: Inconsistent Observer implementations across the codebase
<strong>Solution</strong>: Use pattern detection to identify all Observer instances and compare their structure</p>
<pre><code class="language-bash">debtmap analyze --patterns observer --output-format json &gt; observers.json
</code></pre>
<h3 id="4-refactoring-guidance"><a class="header" href="#4-refactoring-guidance">4. Refactoring Guidance</a></h3>
<p><strong>Problem</strong>: Code smells that might be incomplete pattern implementations
<strong>Solution</strong>: Detect partial patterns with lower confidence thresholds</p>
<pre><code class="language-bash">debtmap analyze --pattern-threshold 0.5 --show-pattern-warnings
</code></pre>
<h2 id="troubleshooting-12"><a class="header" href="#troubleshooting-12">Troubleshooting</a></h2>
<h3 id="pattern-not-detected"><a class="header" href="#pattern-not-detected">Pattern Not Detected</a></h3>
<p><strong>Symptoms</strong>: Expected pattern not appearing in output</p>
<p><strong>Possible Causes</strong>:</p>
<ol>
<li>Confidence below threshold
<ul>
<li>Solution: Lower <code>--pattern-threshold</code> or use <code>--show-pattern-warnings</code></li>
</ul>
</li>
<li>Pattern disabled
<ul>
<li>Solution: Check <code>--patterns</code> flag and <code>.debtmap.toml</code> config</li>
</ul>
</li>
<li>Implementation doesn‚Äôt match detection criteria
<ul>
<li>Solution: Review pattern-specific criteria above or add custom rule</li>
</ul>
</li>
</ol>
<h3 id="builder-or-visitor-pattern-not-available-via-cli"><a class="header" href="#builder-or-visitor-pattern-not-available-via-cli">Builder or Visitor Pattern Not Available via CLI</a></h3>
<p><strong>Symptoms</strong>: Using <code>--patterns builder</code> or <code>--patterns visitor</code> has no effect</p>
<p><strong>Explanation</strong>: Builder and Visitor patterns are detected <strong>internally only</strong> and are not available as user-facing pattern detection features:</p>
<ul>
<li><strong>Builder</strong>: Used internally during god object detection to adjust scores for builder classes</li>
<li><strong>Visitor</strong>: Used internally for complexity analysis to apply logarithmic scaling to exhaustive match expressions</li>
</ul>
<p><strong>Solution</strong>: These patterns are detected automatically when needed for internal analyses. They don‚Äôt require manual enablement and won‚Äôt appear in pattern detection output. See <a href="design-patterns.html#internal-pattern-detection">Internal Pattern Detection</a> for details.</p>
<p><strong>Available user-facing patterns</strong>: <code>observer</code>, <code>singleton</code>, <code>factory</code>, <code>strategy</code>, <code>callback</code>, <code>template_method</code>, <code>dependency_injection</code></p>
<h3 id="false-positive-detection"><a class="header" href="#false-positive-detection">False Positive Detection</a></h3>
<p><strong>Symptoms</strong>: Pattern detected incorrectly</p>
<p><strong>Possible Causes</strong>:</p>
<ol>
<li>Naming collision (e.g., <code>create_</code> function that isn‚Äôt a factory)
<ul>
<li>Solution: Increase <code>--pattern-threshold</code> to require stronger evidence</li>
</ul>
</li>
<li>Coincidental structural match
<ul>
<li>Solution: Add exclusion rules in configuration (if supported)</li>
</ul>
</li>
</ol>
<h3 id="incomplete-cross-file-detection"><a class="header" href="#incomplete-cross-file-detection">Incomplete Cross-File Detection</a></h3>
<p><strong>Symptoms</strong>: Pattern implementations in other files not linked to interface</p>
<p><strong>Possible Causes</strong>:</p>
<ol>
<li>Dynamic imports not tracked
<ul>
<li>Solution: Use static imports where possible</li>
</ul>
</li>
<li>Interface not explicitly imported
<ul>
<li>Solution: Add explicit import even if not type-checking</li>
</ul>
</li>
</ol>
<h2 id="best-practices-9"><a class="header" href="#best-practices-9">Best Practices</a></h2>
<ol>
<li><strong>Start with defaults</strong>: The default 0.7 threshold works well for most projects</li>
<li><strong>Use <code>--show-pattern-warnings</code></strong> during initial analysis to see borderline detections</li>
<li><strong>Configure per-pattern</strong>: Adjust detection criteria for patterns most relevant to your project</li>
<li><strong>Define custom rules</strong>: Add project-specific patterns to reduce false positives</li>
<li><strong>Combine with complexity analysis</strong>: Use pattern detection to understand complexity adjustments</li>
<li><strong>Review low-confidence detections</strong>: They may indicate incomplete implementations worth refactoring</li>
</ol>
<h2 id="summary-4"><a class="header" href="#summary-4">Summary</a></h2>
<p>Debtmap‚Äôs design pattern detection provides:</p>
<ul>
<li><strong>7 user-facing patterns</strong> covering common OOP and functional patterns (Observer, Singleton, Factory, Strategy, Callback, Template Method, Dependency Injection)</li>
<li><strong>2 internal patterns</strong> (Builder, Visitor) used for god object detection and complexity normalization</li>
<li><strong>Configurable confidence thresholds</strong> for precision vs. recall tradeoff</li>
<li><strong>Custom pattern rules</strong> for project-specific patterns</li>
<li><strong>Cross-file detection</strong> for patterns spanning multiple modules</li>
<li><strong>Rust trait support</strong> for idiomatic Rust pattern detection</li>
<li><strong>Complexity integration</strong> to reduce false positives in analysis</li>
</ul>
<p>Pattern detection improves the accuracy of technical debt analysis by recognizing idiomatic code patterns and applying appropriate complexity adjustments. Internal pattern detection helps prevent false positives in god object and complexity analyses without exposing implementation details to users.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="entropy-analysis"><a class="header" href="#entropy-analysis">Entropy Analysis</a></h1>
<p>Entropy analysis is Debtmap‚Äôs unique approach to distinguishing genuinely complex code from repetitive pattern-based code. This reduces false positives by 60-75% compared to traditional cyclomatic complexity metrics.</p>
<h2 id="overview-8"><a class="header" href="#overview-8">Overview</a></h2>
<p>Traditional static analysis tools flag code as ‚Äúcomplex‚Äù based purely on cyclomatic complexity or lines of code. However, not all complexity is equal:</p>
<ul>
<li><strong>Repetitive patterns</strong> (validation functions, dispatchers) have high cyclomatic complexity but low cognitive load</li>
<li><strong>Diverse logic</strong> (state machines, business rules) may have moderate cyclomatic complexity but high cognitive load</li>
</ul>
<p>Entropy analysis uses information theory to distinguish between these cases.</p>
<h2 id="how-it-works-3"><a class="header" href="#how-it-works-3">How It Works</a></h2>
<p>Debtmap‚Äôs entropy analysis is <strong>language-agnostic</strong>, working across Rust, Python, JavaScript, and TypeScript codebases using a universal token classification approach. This ensures consistent complexity assessment regardless of the programming language used.</p>
<h3 id="shannon-entropy"><a class="header" href="#shannon-entropy">Shannon Entropy</a></h3>
<p>Shannon entropy measures the variety and unpredictability of code patterns:</p>
<pre><code>H(X) = -Œ£ p(x) √ó log‚ÇÇ(p(x))
</code></pre>
<p>Where:</p>
<ul>
<li><code>p(x)</code> = probability of each token type</li>
<li>High entropy (0.8-1.0) = many different patterns</li>
<li>Low entropy (0.0-0.3) = repetitive patterns</li>
</ul>
<h3 id="token-classification"><a class="header" href="#token-classification">Token Classification</a></h3>
<p>Debtmap can classify tokens by importance to give more weight to semantically significant tokens in entropy calculations. This is controlled by the <code>use_classification</code> configuration option.</p>
<p><strong>When enabled</strong> (disabled by default for backward compatibility), tokens are weighted by importance:</p>
<p><strong>High importance (weight: 1.0):</strong></p>
<ul>
<li>Control flow keywords (<code>if</code>, <code>match</code>, <code>for</code>, <code>while</code>)</li>
<li>Error handling (<code>try</code>, <code>catch</code>, <code>?</code>, <code>unwrap</code>)</li>
<li>Async keywords (<code>async</code>, <code>await</code>)</li>
</ul>
<p><strong>Medium importance (weight: 0.7):</strong></p>
<ul>
<li>Function calls</li>
<li>Method invocations</li>
<li>Operators</li>
</ul>
<p><strong>Low importance (weight: 0.3):</strong></p>
<ul>
<li>Identifiers (variable names)</li>
<li>Literals (strings, numbers)</li>
<li>Punctuation</li>
</ul>
<p><strong>When disabled</strong> (<code>use_classification = false</code>), all tokens are treated equally, which may be useful for debugging or when you want unweighted entropy scores.</p>
<h3 id="pattern-repetition-detection"><a class="header" href="#pattern-repetition-detection">Pattern Repetition Detection</a></h3>
<p>Detects repetitive structures in the AST:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Low pattern repetition (0.2) - all branches identical
if a.is_none() { return Err(...) }
if b.is_none() { return Err(...) }
if c.is_none() { return Err(...) }

// High pattern repetition (0.9) - diverse branches
match state {
    Active =&gt; transition_to_standby(),
    Standby =&gt; transition_to_active(),
    Maintenance =&gt; schedule_restart(),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="branch-similarity-analysis"><a class="header" href="#branch-similarity-analysis">Branch Similarity Analysis</a></h3>
<p>Analyzes similarity between conditional branches:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// High branch similarity (0.9) - branches are nearly identical
if condition_a {
    log("A happened");
    process_a();
}
if condition_b {
    log("B happened");
    process_b();
}

// Low branch similarity (0.2) - branches are very different
if needs_auth {
    authenticate_user()?;
    load_profile()?;
} else {
    show_guest_ui();
}
<span class="boring">}</span></code></pre></pre>
<h3 id="effective-complexity-adjustment"><a class="header" href="#effective-complexity-adjustment">Effective Complexity Adjustment</a></h3>
<p>Debtmap uses a multi-factor dampening approach that analyzes three dimensions of code repetitiveness:</p>
<ol>
<li><strong>Pattern Repetition</strong> - Detects repetitive AST structures</li>
<li><strong>Token Entropy</strong> - Measures variety in token usage</li>
<li><strong>Branch Similarity</strong> - Compares similarity between conditional branches</li>
</ol>
<p>These factors are combined multiplicatively with a minimum floor of 0.7 (preserving at least 70% of original complexity):</p>
<pre><code>dampening_factor = (repetition_factor √ó entropy_factor √ó branch_factor).max(0.7)
effective_complexity = raw_complexity √ó dampening_factor
</code></pre>
<h4 id="historical-note-spec-68"><a class="header" href="#historical-note-spec-68">Historical Note: Spec 68</a></h4>
<p><strong>Spec 68: Graduated Entropy Dampening</strong> was the original simple algorithm that only considered entropy &lt; 0.2:</p>
<pre><code>dampening_factor = 0.5 + 0.5 √ó (entropy / 0.2)  [when entropy &lt; 0.2]
</code></pre>
<p>The current implementation uses a more sophisticated <strong>graduated dampening</strong> approach that considers all three factors (repetition, entropy, branch similarity) with separate thresholds and ranges for each. The test suite references Spec 68 to verify backward compatibility with the original behavior.</p>
<h4 id="when-dampening-applies"><a class="header" href="#when-dampening-applies">When Dampening Applies</a></h4>
<p>Dampening is applied based on multiple thresholds:</p>
<ul>
<li><strong>Pattern Repetition</strong>: Values approaching 1.0 trigger dampening (high repetition detected)</li>
<li><strong>Token Entropy</strong>: Values below 0.4 trigger graduated dampening (low variety)</li>
<li><strong>Branch Similarity</strong>: Values above 0.8 trigger dampening (similar branches)</li>
</ul>
<h4 id="graduated-dampening-formula"><a class="header" href="#graduated-dampening-formula">Graduated Dampening Formula</a></h4>
<p>Each factor is dampened individually using a graduated calculation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simplified version - actual implementation in src/complexity/entropy.rs:185-195
fn calculate_dampening_factor(
    repetition: f64,     // 0.0-1.0
    entropy: f64,        // 0.0-1.0
    branch_similarity: f64  // 0.0-1.0
) -&gt; f64 {
    let repetition_factor = graduated_dampening(repetition, threshold=1.0, max_reduction=0.20);
    let entropy_factor = graduated_dampening(entropy, threshold=0.4, max_reduction=0.15);
    let branch_factor = graduated_dampening(branch_similarity, threshold=0.8, max_reduction=0.25);

    (repetition_factor * entropy_factor * branch_factor).max(0.7)  // Never reduce below 70%
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Key Parameters</strong> (hardcoded in implementation):</p>
<ul>
<li><strong>Repetition</strong>: Threshold 1.0, max 20% reduction</li>
<li><strong>Entropy</strong>: Threshold 0.4, max 15% reduction</li>
<li><strong>Branch Similarity</strong>: Threshold 0.8, max 25% reduction</li>
<li><strong>Combined Floor</strong>: Minimum 70% of original complexity preserved</li>
</ul>
<h4 id="example-repetitive-validation-function"><a class="header" href="#example-repetitive-validation-function">Example: Repetitive Validation Function</a></h4>
<pre><code>Raw Complexity: 20
Pattern Repetition: 0.95 (very high)
Token Entropy: 0.3 (low variety)
Branch Similarity: 0.9 (very similar branches)

repetition_factor ‚âà 0.85 (15% reduction)
entropy_factor ‚âà 0.90 (10% reduction)
branch_factor ‚âà 0.80 (20% reduction)

dampening_factor = (0.85 √ó 0.90 √ó 0.80) = 0.612
dampening_factor = max(0.612, 0.7) = 0.7  // Floor applied

Effective Complexity = 20 √ó 0.7 = 14

Result: 30% reduction (maximum allowed)
</code></pre>
<h4 id="example-diverse-state-machine"><a class="header" href="#example-diverse-state-machine">Example: Diverse State Machine</a></h4>
<pre><code>Raw Complexity: 20
Pattern Repetition: 0.2 (low - not repetitive)
Token Entropy: 0.8 (high variety)
Branch Similarity: 0.3 (diverse branches)

repetition_factor ‚âà 1.0 (no reduction)
entropy_factor ‚âà 1.0 (no reduction)
branch_factor ‚âà 1.0 (no reduction)

dampening_factor = (1.0 √ó 1.0 √ó 1.0) = 1.0

Effective Complexity = 20 √ó 1.0 = 20

Result: 0% reduction (complexity preserved)
</code></pre>
<h2 id="real-world-examples"><a class="header" href="#real-world-examples">Real-World Examples</a></h2>
<h3 id="example-1-validation-function"><a class="header" href="#example-1-validation-function">Example 1: Validation Function</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn validate_config(config: &amp;Config) -&gt; Result&lt;()&gt; {
    if config.output_dir.is_none() {
        return Err(anyhow!("output_dir required"));
    }
    if config.max_workers.is_none() {
        return Err(anyhow!("max_workers required"));
    }
    if config.timeout_secs.is_none() {
        return Err(anyhow!("timeout_secs required"));
    }
    // ... 17 more similar checks
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Traditional analysis:</strong></p>
<ul>
<li>Cyclomatic Complexity: 20</li>
<li>Assessment: CRITICAL</li>
</ul>
<p><strong>Entropy analysis:</strong></p>
<ul>
<li>Shannon Entropy: 0.3 (low variety)</li>
<li>Pattern Repetition: 0.9 (highly repetitive)</li>
<li>Branch Similarity: 0.95 (nearly identical)</li>
<li>Effective Complexity: 5</li>
<li>Assessment: LOW PRIORITY</li>
</ul>
<h3 id="example-2-state-machine-logic"><a class="header" href="#example-2-state-machine-logic">Example 2: State Machine Logic</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn reconcile_state(current: &amp;State, desired: &amp;State) -&gt; Vec&lt;Action&gt; {
    let mut actions = vec![];

    match (current.mode, desired.mode) {
        (Mode::Active, Mode::Standby) =&gt; {
            if current.has_active_connections() {
                actions.push(Action::DrainConnections);
                actions.push(Action::WaitForDrain);
            }
            actions.push(Action::TransitionToStandby);
        }
        (Mode::Standby, Mode::Active) =&gt; {
            if desired.requires_warmup() {
                actions.push(Action::Warmup);
            }
            actions.push(Action::TransitionToActive);
        }
        // ... more diverse state transitions
        _ =&gt; {}
    }

    actions
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Traditional analysis:</strong></p>
<ul>
<li>Cyclomatic Complexity: 8</li>
<li>Assessment: MODERATE</li>
</ul>
<p><strong>Entropy analysis:</strong></p>
<ul>
<li>Shannon Entropy: 0.85 (high variety)</li>
<li>Pattern Repetition: 0.2 (not repetitive)</li>
<li>Branch Similarity: 0.3 (diverse branches)</li>
<li>Effective Complexity: 9</li>
<li>Assessment: HIGH PRIORITY</li>
</ul>
<h2 id="configuration-7"><a class="header" href="#configuration-7">Configuration</a></h2>
<p>Configure entropy analysis in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[entropy]
# Enable entropy analysis (default: true)
enabled = true

# Weight of entropy in overall complexity scoring (0.0-1.0, default: 1.0)
# Note: This affects scoring, not dampening thresholds
weight = 1.0

# Minimum tokens required for entropy calculation (default: 20)
min_tokens = 20

# Pattern similarity threshold for repetition detection (0.0-1.0, default: 0.7)
pattern_threshold = 0.7

# Enable advanced token classification (default: false for backward compatibility)
# When true, weights tokens by semantic importance (control flow &gt; operators &gt; identifiers)
use_classification = false

# Branch similarity threshold (0.0-1.0, default: 0.8)
# Branches with similarity above this threshold contribute to dampening
branch_threshold = 0.8

# Maximum reduction limits (these are configurable)
max_repetition_reduction = 0.20  # Max 20% reduction from pattern repetition
max_entropy_reduction = 0.15     # Max 15% reduction from low token entropy
max_branch_reduction = 0.25      # Max 25% reduction from branch similarity
max_combined_reduction = 0.30    # Overall cap at 30% reduction (minimum 70% preserved)
</code></pre>
<p><strong>Important Notes:</strong></p>
<ol>
<li>
<p><strong>Graduated dampening thresholds are hardcoded</strong> in the implementation (<code>src/complexity/entropy.rs:185-195</code>):</p>
<ul>
<li>Entropy threshold: 0.4 (not configurable via <code>entropy_threshold</code>)</li>
<li>Branch threshold: 0.8 (configured via <code>branch_threshold</code>)</li>
<li>Repetition threshold: 1.0 (via <code>pattern_threshold</code>)</li>
</ul>
</li>
<li>
<p><strong>The <code>weight</code> parameter</strong> affects how entropy scores contribute to overall complexity scoring, but does not change the dampening thresholds or reductions.</p>
</li>
<li>
<p><strong>Token classification</strong> defaults to <code>false</code> (disabled) for backward compatibility, even though it provides more accurate entropy analysis when enabled.</p>
</li>
</ol>
<h3 id="tuning-for-your-project"><a class="header" href="#tuning-for-your-project">Tuning for Your Project</a></h3>
<p><strong>Enable token classification for better accuracy:</strong></p>
<pre><code class="language-toml">[entropy]
enabled = true
use_classification = true  # Weight control flow keywords more heavily
</code></pre>
<p><strong>Strict mode (fewer reductions, flag more code):</strong></p>
<pre><code class="language-toml">[entropy]
enabled = true
max_repetition_reduction = 0.10  # Reduce from default 0.20
max_entropy_reduction = 0.08     # Reduce from default 0.15
max_branch_reduction = 0.12      # Reduce from default 0.25
max_combined_reduction = 0.20    # Reduce from default 0.30 (preserve 80%)
</code></pre>
<p><strong>Lenient mode (more aggressive reduction):</strong></p>
<pre><code class="language-toml">[entropy]
enabled = true
max_repetition_reduction = 0.30  # Increase from default 0.20
max_entropy_reduction = 0.25     # Increase from default 0.15
max_branch_reduction = 0.35      # Increase from default 0.25
max_combined_reduction = 0.50    # Increase from default 0.30 (preserve 50%)
</code></pre>
<p><strong>Disable entropy dampening entirely:</strong></p>
<pre><code class="language-toml">[entropy]
enabled = false
</code></pre>
<p>Or via CLI (disables entropy-based complexity adjustments):</p>
<pre><code class="language-bash"># Disables semantic analysis features including entropy dampening
debtmap analyze . --semantic-off
</code></pre>
<p><strong>Note</strong>: The <code>--semantic-off</code> flag disables all semantic analysis features, including entropy-based complexity adjustments. This is useful when you want raw cyclomatic complexity without any dampening.</p>
<h2 id="understanding-the-impact"><a class="header" href="#understanding-the-impact">Understanding the Impact</a></h2>
<h3 id="measuring-false-positive-reduction"><a class="header" href="#measuring-false-positive-reduction">Measuring False Positive Reduction</a></h3>
<p>Run analysis with and without entropy:</p>
<pre><code class="language-bash"># Without entropy
debtmap analyze . --semantic-off --top 20 &gt; without_entropy.txt

# With entropy (default)
debtmap analyze . --top 20 &gt; with_entropy.txt

# Compare
diff without_entropy.txt with_entropy.txt
</code></pre>
<p><strong>Expected results:</strong></p>
<ul>
<li>60-75% reduction in flagged validation functions</li>
<li>40-50% reduction in flagged dispatcher functions</li>
<li>20-30% reduction in flagged configuration parsers</li>
<li>No reduction in genuinely complex state machines or business logic</li>
</ul>
<h3 id="verifying-correctness"><a class="header" href="#verifying-correctness">Verifying Correctness</a></h3>
<p>Entropy analysis should:</p>
<ul>
<li><strong>Reduce</strong> flags on repetitive code (validators, dispatchers)</li>
<li><strong>Preserve</strong> flags on genuinely complex code (state machines, business logic)</li>
</ul>
<p>If entropy analysis incorrectly reduces flags on genuinely complex code, adjust configuration:</p>
<pre><code class="language-toml">[entropy]
max_combined_reduction = 0.20  # Reduce from default 0.30 (preserve 80%)
max_repetition_reduction = 0.10  # Reduce individual factors
max_entropy_reduction = 0.08
max_branch_reduction = 0.12
</code></pre>
<h2 id="best-practices-10"><a class="header" href="#best-practices-10">Best Practices</a></h2>
<ol>
<li><strong>Use default settings</strong> - They work well for most projects</li>
<li><strong>Verify results</strong> - Spot-check top-priority items to ensure correctness</li>
<li><strong>Tune conservatively</strong> - Start with default settings, adjust if needed</li>
<li><strong>Disable for debugging</strong> - Use <code>--semantic-off</code> if entropy seems incorrect</li>
<li><strong>Report issues</strong> - If entropy incorrectly flags code, report it</li>
</ol>
<h2 id="limitations-2"><a class="header" href="#limitations-2">Limitations</a></h2>
<p>Entropy analysis works best for:</p>
<ul>
<li>Functions with cyclomatic complexity 10-50</li>
<li>Code with clear repetitive patterns</li>
<li>Validation, dispatch, and configuration functions</li>
</ul>
<p>Entropy analysis is less effective for:</p>
<ul>
<li>Very simple functions (complexity &lt; 5)</li>
<li>Very complex functions (complexity &gt; 100)</li>
<li>Obfuscated or generated code</li>
</ul>
<h2 id="comparison-with-other-approaches"><a class="header" href="#comparison-with-other-approaches">Comparison with Other Approaches</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Approach</th><th>False Positive Rate</th><th>Complexity</th><th>Speed</th></tr></thead><tbody>
<tr><td>Raw Cyclomatic Complexity</td><td>High (many false positives)</td><td>Low</td><td>Fast</td></tr>
<tr><td>Cognitive Complexity</td><td>Medium</td><td>Medium</td><td>Medium</td></tr>
<tr><td>Entropy Analysis (Debtmap)</td><td>Low</td><td>High</td><td>Fast</td></tr>
<tr><td>Manual Code Review</td><td>Very Low</td><td>Very High</td><td>Very Slow</td></tr>
</tbody></table>
</div>
<p>Debtmap‚Äôs entropy analysis provides the best balance of accuracy and speed.</p>
<h2 id="see-also-3"><a class="header" href="#see-also-3">See Also</a></h2>
<ul>
<li><a href="why-debtmap.html">Why Debtmap?</a> - Real-world examples of entropy analysis</li>
<li><a href="analysis-guide.html">Analysis Guide</a> - General analysis concepts</li>
<li><a href="configuration.html">Configuration</a> - Complete configuration reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="error-handling-analysis"><a class="header" href="#error-handling-analysis">Error Handling Analysis</a></h1>
<p>Debtmap provides comprehensive error handling analysis across all supported languages (Rust, Python, JavaScript, TypeScript), detecting anti-patterns that lead to silent failures, production panics, and difficult-to-debug issues.</p>
<h2 id="overview-9"><a class="header" href="#overview-9">Overview</a></h2>
<p>Error handling issues are classified as <strong>ErrorSwallowing</strong> debt with <strong>Major severity</strong> (weight 4), reflecting their significant impact on code reliability and debuggability. Debtmap detects:</p>
<ul>
<li><strong>Error swallowing</strong>: Exception handlers that silently catch errors without logging or re-raising</li>
<li><strong>Panic patterns</strong>: Rust code that can panic in production (unwrap, expect, panic!)</li>
<li><strong>Error propagation issues</strong>: Missing error context in Result chains</li>
<li><strong>Async error handling</strong>: Unhandled promise rejections, dropped futures, missing await</li>
<li><strong>Python-specific patterns</strong>: Bare except clauses, silent exception handling</li>
</ul>
<p>All error handling patterns are filtered intelligently - code detected in test modules (e.g., <code>#[cfg(test)]</code>, <code>test_</code> prefixes) receives lower priority or is excluded entirely.</p>
<h2 id="rust-error-handling-analysis"><a class="header" href="#rust-error-handling-analysis">Rust Error Handling Analysis</a></h2>
<h3 id="panic-pattern-detection"><a class="header" href="#panic-pattern-detection">Panic Pattern Detection</a></h3>
<p>Debtmap identifies Rust code that can panic at runtime instead of returning <code>Result</code>:</p>
<p><strong>Detected patterns:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚ùå CRITICAL: Direct panic in production code
fn process_data(value: Option&lt;i32&gt;) -&gt; i32 {
    panic!("not implemented");  // Detected: PanicInNonTest
}

// ‚ùå HIGH: Unwrap on Result
fn read_config(path: &amp;Path) -&gt; Config {
    let content = fs::read_to_string(path).unwrap();  // Detected: UnwrapOnResult
    parse_config(&amp;content)
}

// ‚ùå HIGH: Unwrap on Option
fn get_user(id: u32) -&gt; User {
    users.get(&amp;id).unwrap()  // Detected: UnwrapOnOption
}

// ‚ùå MEDIUM: Expect with generic message
fn parse_value(s: &amp;str) -&gt; i32 {
    s.parse().expect("parse failed")  // Detected: ExpectWithGenericMessage
}

// ‚ùå MEDIUM: TODO in production
fn calculate_tax(amount: f64) -&gt; f64 {
    todo!("implement tax calculation")  // Detected: TodoInProduction
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Recommended alternatives:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚úÖ GOOD: Propagate errors with ?
fn read_config(path: &amp;Path) -&gt; Result&lt;Config&gt; {
    let content = fs::read_to_string(path)?;
    parse_config(&amp;content)
}

// ‚úÖ GOOD: Handle Option explicitly
fn get_user(id: u32) -&gt; Result&lt;User&gt; {
    users.get(&amp;id)
        .ok_or_else(|| anyhow!("User {} not found", id))
}

// ‚úÖ GOOD: Add meaningful context
fn parse_value(s: &amp;str) -&gt; Result&lt;i32&gt; {
    s.parse()
        .with_context(|| format!("Failed to parse '{}' as integer", s))
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Test code exceptions:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    #[test]
    fn test_parsing() {
        let result = "42".parse::&lt;i32&gt;().unwrap();  // ‚úÖ OK in tests (LOW priority)
        assert_eq!(result, 42);
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Debtmap detects <code>#[cfg(test)]</code> attributes and test function contexts, automatically assigning <strong>Low priority</strong> to panic patterns in test code.</p>
<h3 id="error-propagation-analysis"><a class="header" href="#error-propagation-analysis">Error Propagation Analysis</a></h3>
<p>Debtmap detects missing error context in Result chains:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚ùå Missing context - which file failed? What was the error?
fn load_multiple_configs(paths: &amp;[PathBuf]) -&gt; Result&lt;Vec&lt;Config&gt;&gt; {
    paths.iter()
        .map(|p| fs::read_to_string(p))  // Error loses file path information
        .collect::&lt;Result&lt;Vec&lt;_&gt;&gt;&gt;()?
        .into_iter()
        .map(|c| parse_config(&amp;c))  // Error loses which config failed
        .collect()
}

// ‚úÖ GOOD: Preserve context through the chain
fn load_multiple_configs(paths: &amp;[PathBuf]) -&gt; Result&lt;Vec&lt;Config&gt;&gt; {
    paths.iter()
        .map(|p| {
            fs::read_to_string(p)
                .with_context(|| format!("Failed to read config from {}", p.display()))
        })
        .collect::&lt;Result&lt;Vec&lt;_&gt;&gt;&gt;()?
        .into_iter()
        .enumerate()
        .map(|(i, content)| {
            parse_config(&amp;content)
                .with_context(|| format!("Failed to parse config #{}", i))
        })
        .collect()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Best practices:</strong></p>
<ul>
<li>Use <code>.context()</code> or <code>.with_context()</code> from <code>anyhow</code> or <code>thiserror</code></li>
<li>Include relevant values in error messages (file paths, indices, input values)</li>
<li>Maintain error context at each transformation in the chain</li>
</ul>
<h3 id="error-swallowing-in-rust"><a class="header" href="#error-swallowing-in-rust">Error Swallowing in Rust</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚ùå Silent error swallowing
fn try_parse(s: &amp;str) -&gt; Option&lt;i32&gt; {
    match s.parse::&lt;i32&gt;() {
        Ok(v) =&gt; Some(v),
        Err(_) =&gt; None,  // Detected: Error swallowed without logging
    }
}

// ‚úÖ GOOD: Log the error
fn try_parse(s: &amp;str) -&gt; Option&lt;i32&gt; {
    match s.parse::&lt;i32&gt;() {
        Ok(v) =&gt; Some(v),
        Err(e) =&gt; {
            log::warn!("Failed to parse '{}': {}", s, e);
            None
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="python-error-handling-analysis"><a class="header" href="#python-error-handling-analysis">Python Error Handling Analysis</a></h2>
<h3 id="bare-except-clause-detection"><a class="header" href="#bare-except-clause-detection">Bare Except Clause Detection</a></h3>
<p>Python‚Äôs bare <code>except:</code> catches all exceptions, including system exits and keyboard interrupts:</p>
<pre><code class="language-python"># ‚ùå CRITICAL: Bare except catches everything
def process_file(path):
    try:
        with open(path) as f:
            return f.read()
    except:  # Detected: BareExceptClause
        return None  # Catches SystemExit, KeyboardInterrupt, etc.

# ‚ùå HIGH: Catching Exception is too broad
def load_config(path):
    try:
        return yaml.load(open(path))
    except Exception:  # Detected: OverlyBroadException
        return {}  # Silent failure loses error information

# ‚úÖ GOOD: Specific exception types
def process_file(path):
    try:
        with open(path) as f:
            return f.read()
    except FileNotFoundError:
        log.error(f"File not found: {path}")
        return None
    except PermissionError:
        log.error(f"Permission denied: {path}")
        return None
</code></pre>
<p><strong>Why bare except is dangerous:</strong></p>
<ul>
<li>Catches <code>SystemExit</code> (prevents clean shutdown)</li>
<li>Catches <code>KeyboardInterrupt</code> (prevents Ctrl+C)</li>
<li>Catches <code>GeneratorExit</code> (breaks generator protocol)</li>
<li>Masks programming errors like <code>NameError</code>, <code>AttributeError</code></li>
</ul>
<p><strong>Best practices:</strong></p>
<ul>
<li>Always specify exception types: <code>except ValueError</code>, <code>except (TypeError, KeyError)</code></li>
<li>Use <code>except Exception</code> only when truly catching all application errors</li>
<li>Never use bare <code>except:</code> in production code</li>
<li>Log exceptions with full context before suppressing</li>
</ul>
<h3 id="silent-exception-handling"><a class="header" href="#silent-exception-handling">Silent Exception Handling</a></h3>
<pre><code class="language-python"># ‚ùå Silent exception handling
def get_user_age(user_id):
    try:
        user = db.get_user(user_id)
        return user.age
    except:  # Detected: SilentException (no logging, no re-raise)
        pass

# ‚úÖ GOOD: Log and provide meaningful default
def get_user_age(user_id):
    try:
        user = db.get_user(user_id)
        return user.age
    except UserNotFound:
        logger.warning(f"User {user_id} not found")
        return None
    except DatabaseError as e:
        logger.error(f"Database error fetching user {user_id}: {e}")
        raise  # Re-raise for caller to handle
</code></pre>
<h3 id="exception-flow-analysis"><a class="header" href="#exception-flow-analysis">Exception Flow Analysis</a></h3>
<p>Debtmap tracks exception propagation through Python codebases to identify functions that can raise exceptions without proper handling. This analysis helps ensure that exceptions are either caught at appropriate levels or documented in the function‚Äôs interface.</p>
<pre><code class="language-python"># Potential issue: Exceptions may propagate unhandled
def process_batch(items):
    for item in items:
        validate_item(item)  # Can raise ValueError
        transform_item(item)  # Can raise TransformError
        save_item(item)  # Can raise DatabaseError

# ‚úÖ GOOD: Handle exceptions appropriately
def process_batch(items):
    results = {"success": 0, "failed": 0}
    for item in items:
        try:
            validate_item(item)
            transform_item(item)
            save_item(item)
            results["success"] += 1
        except ValueError as e:
            logger.warning(f"Invalid item {item.id}: {e}")
            results["failed"] += 1
        except (TransformError, DatabaseError) as e:
            logger.error(f"Failed to process item {item.id}: {e}")
            results["failed"] += 1
            # Optionally re-raise critical errors
            if isinstance(e, DatabaseError):
                raise
    return results
</code></pre>
<h2 id="async-error-handling"><a class="header" href="#async-error-handling">Async Error Handling</a></h2>
<h3 id="unhandled-promise-rejections-javascripttypescript"><a class="header" href="#unhandled-promise-rejections-javascripttypescript">Unhandled Promise Rejections (JavaScript/TypeScript)</a></h3>
<p><strong>Note:</strong> JavaScript and TypeScript support in debtmap currently focuses on complexity analysis and basic error patterns. Advanced async error handling detection (unhandled promise rejections, missing await) is primarily implemented for Rust async code. Enhanced JavaScript/TypeScript async error detection is planned for future releases.</p>
<pre><code class="language-javascript">// ‚ùå CRITICAL: Unhandled promise rejection
async function loadUserData(userId) {
    const response = await fetch(`/api/users/${userId}`);
    // If fetch rejects, promise is unhandled
    return response.json();
}

loadUserData(123);  // Detected: UnhandledPromiseRejection

// ‚úÖ GOOD: Handle rejections
async function loadUserData(userId) {
    try {
        const response = await fetch(`/api/users/${userId}`);
        if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }
        return await response.json();
    } catch (error) {
        console.error(`Failed to load user ${userId}:`, error);
        throw error;  // Re-throw or return default
    }
}

loadUserData(123).catch(err =&gt; {
    console.error("Top-level error handler:", err);
});
</code></pre>
<h3 id="missing-await-detection"><a class="header" href="#missing-await-detection">Missing Await Detection</a></h3>
<pre><code class="language-javascript">// ‚ùå HIGH: Missing await - promise dropped
async function saveAndNotify(data) {
    await saveToDatabase(data);
    sendNotification(data.userId);  // Detected: MissingAwait
    // Function returns before notification completes
}

// ‚úÖ GOOD: Await all async operations
async function saveAndNotify(data) {
    await saveToDatabase(data);
    await sendNotification(data.userId);
}
</code></pre>
<h3 id="async-rust-error-handling"><a class="header" href="#async-rust-error-handling">Async Rust Error Handling</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚ùå HIGH: Dropped future without error handling
async fn process_requests(requests: Vec&lt;Request&gt;) {
    for req in requests {
        tokio::spawn(async move {
            handle_request(req).await  // Detected: DroppedFuture
            // Errors silently dropped
        });
    }
}

// ‚úÖ GOOD: Join handles and propagate errors
async fn process_requests(requests: Vec&lt;Request&gt;) -&gt; Result&lt;()&gt; {
    let handles: Vec&lt;_&gt; = requests.into_iter()
        .map(|req| {
            tokio::spawn(async move {
                handle_request(req).await
            })
        })
        .collect();

    for handle in handles {
        handle.await??;  // Propagate both JoinError and handler errors
    }
    Ok(())
}

// ‚ùå HIGH: Task panic silently ignored
tokio::spawn(async {
    panic!("task failed");  // Detected: SilentTaskPanic
});

// ‚úÖ GOOD: Handle task panics
let handle = tokio::spawn(async {
    critical_operation().await
});

match handle.await {
    Ok(Ok(result)) =&gt; println!("Success: {:?}", result),
    Ok(Err(e)) =&gt; eprintln!("Task failed: {}", e),
    Err(e) =&gt; eprintln!("Task panicked: {}", e),
}
<span class="boring">}</span></code></pre></pre>
<h2 id="severity-levels-and-prioritization"><a class="header" href="#severity-levels-and-prioritization">Severity Levels and Prioritization</a></h2>
<p>Error handling issues are assigned severity based on their impact:</p>
<div class="table-wrapper"><table><thead><tr><th>Pattern</th><th>Severity</th><th>Weight</th><th>Priority</th><th>Rationale</th></tr></thead><tbody>
<tr><td>Panic in production</td><td>CRITICAL</td><td>4</td><td>Critical</td><td>Crashes the process</td></tr>
<tr><td>Bare except clause</td><td>CRITICAL</td><td>4</td><td>Critical</td><td>Masks system signals</td></tr>
<tr><td>Silent task panic</td><td>CRITICAL</td><td>4</td><td>Critical</td><td>Hidden failures</td></tr>
<tr><td>Unwrap on Result/Option</td><td>HIGH</td><td>4</td><td>High</td><td>Likely to panic</td></tr>
<tr><td>Dropped future</td><td>HIGH</td><td>4</td><td>High</td><td>Lost error information</td></tr>
<tr><td>Unhandled promise rejection</td><td>HIGH</td><td>4</td><td>High</td><td>Silently fails</td></tr>
<tr><td>Error swallowing</td><td>MEDIUM</td><td>4</td><td>Medium</td><td>Loses debugging context</td></tr>
<tr><td>Missing error context</td><td>MEDIUM</td><td>4</td><td>Medium</td><td>Hard to debug</td></tr>
<tr><td>Expect with generic message</td><td>MEDIUM</td><td>4</td><td>Medium</td><td>Uninformative errors</td></tr>
<tr><td>TODO in production</td><td>MEDIUM</td><td>4</td><td>Medium</td><td>Incomplete implementation</td></tr>
</tbody></table>
</div>
<p>All ErrorSwallowing debt has <strong>weight 4</strong> (Major severity), but individual patterns receive different priorities based on production impact.</p>
<h3 id="integration-with-risk-scoring"><a class="header" href="#integration-with-risk-scoring">Integration with Risk Scoring</a></h3>
<p>Error handling issues contribute to the <code>debt_factor</code> in Debtmap‚Äôs risk scoring formula:</p>
<pre><code>risk_score = (complexity_factor * 0.4) + (debt_factor * 0.3) + (coverage_factor * 0.3)

where debt_factor includes:
- ErrorSwallowing count * weight (4)
- Combined with other debt types
</code></pre>
<p><strong>Compound risk example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// HIGH RISK: High complexity + error swallowing + low coverage
fn process_transaction(tx: Transaction) -&gt; bool {  // Cyclomatic: 12, Cognitive: 18
    if tx.amount &gt; 1000 {
        if tx.verified {
            if validate_funds(&amp;tx).unwrap() {  // ‚ùå Panic pattern
                if tx.user_type == "premium" {
                    match apply_premium_discount(&amp;tx) {
                        Ok(_) =&gt; {},
                        Err(_) =&gt; return false,  // ‚ùå Error swallowed
                    }
                }
                charge_account(&amp;tx).unwrap();  // ‚ùå Another panic
                return true;
            }
        }
    }
    false
}
// Coverage: 45% (untested error paths)
// Risk Score: Very High (complexity + error handling + coverage gaps)
<span class="boring">}</span></code></pre></pre>
<p>This function would be flagged as <strong>Priority 1</strong> in Debtmap‚Äôs output due to:</p>
<ul>
<li>High cyclomatic complexity (12)</li>
<li>Multiple panic patterns (unwrap calls)</li>
<li>Error swallowing (ignored Result)</li>
<li>Coverage gaps in error handling paths</li>
</ul>
<h2 id="configuration-8"><a class="header" href="#configuration-8">Configuration</a></h2>
<h3 id="error-handling-configuration-options"><a class="header" href="#error-handling-configuration-options">Error Handling Configuration Options</a></h3>
<p>Configure error handling analysis in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[error_handling]
# Enable/disable specific detection patterns (all enabled by default)
detect_panic_patterns = true     # Rust unwrap/expect/panic detection
detect_swallowing = true         # Silent exception handling
detect_async_errors = true       # Unhandled promises, dropped futures
detect_context_loss = true       # Error propagation without context
detect_propagation = true        # Error propagation analysis

# Disable specific patterns for gradual adoption
# detect_async_errors = false
</code></pre>
<p><strong>Note:</strong> The <code>[error_handling]</code> configuration is currently in development. Most error handling patterns are detected by default with <code>ErrorSwallowing</code> debt category (weight 4). Per-pattern severity customization is planned for future releases.</p>
<h2 id="detection-examples"><a class="header" href="#detection-examples">Detection Examples</a></h2>
<h3 id="what-gets-detected-vs-not-detected"><a class="header" href="#what-gets-detected-vs-not-detected">What Gets Detected vs. Not Detected</a></h3>
<p><strong>Rust examples:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚ùå Detected: unwrap() in production code
pub fn get_config() -&gt; Config {
    load_config().unwrap()
}

// ‚úÖ Not detected: ? operator (proper error propagation)
pub fn get_config() -&gt; Result&lt;Config&gt; {
    load_config()?
}

// ‚úÖ Not detected: unwrap() in test
#[test]
fn test_config() {
    let config = load_config().unwrap();  // OK in tests
    assert_eq!(config.port, 8080);
}

// ‚ùå Detected: expect() with generic message
let value = map.get("key").expect("missing");

// ‚úÖ Not detected: expect() with descriptive context
let value = map.get("key")
    .expect("Configuration must contain 'key' field");
<span class="boring">}</span></code></pre></pre>
<p><strong>Python examples:</strong></p>
<pre><code class="language-python"># ‚ùå Detected: bare except
try:
    risky_operation()
except:
    pass

# ‚úÖ Not detected: specific exception
try:
    risky_operation()
except ValueError:
    handle_value_error()

# ‚ùå Detected: silent exception (no logging/re-raise)
try:
    db.save(record)
except DatabaseError:
    pass  # Silent failure

# ‚úÖ Not detected: logged exception
try:
    db.save(record)
except DatabaseError as e:
    logger.error(f"Failed to save record: {e}")
    raise
</code></pre>
<h2 id="suppression-patterns-1"><a class="header" href="#suppression-patterns-1">Suppression Patterns</a></h2>
<p>For cases where error handling patterns are intentional, use suppression comments:</p>
<p><strong>Rust:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap: ignore - Unwrap is safe here due to prior validation
let value = validated_map.get("key").unwrap();
<span class="boring">}</span></code></pre></pre>
<p><strong>Python:</strong></p>
<pre><code class="language-python">try:
    experimental_feature()
except:  # debtmap: ignore - Intentional catch-all during migration
    use_fallback()
</code></pre>
<p>See <a href="suppression-patterns.html">Suppression Patterns</a> for complete syntax and usage.</p>
<h2 id="best-practices-11"><a class="header" href="#best-practices-11">Best Practices</a></h2>
<h3 id="rust-error-handling"><a class="header" href="#rust-error-handling">Rust Error Handling</a></h3>
<ol>
<li>
<p><strong>Prefer <code>?</code> operator over unwrap/expect</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Instead of: fs::read_to_string(path).unwrap()
// Use: fs::read_to_string(path)?
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Use anyhow for application errors, thiserror for libraries</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use anyhow::{Context, Result};

fn load_data(path: &amp;Path) -&gt; Result&lt;Data&gt; {
    let content = fs::read_to_string(path)
        .with_context(|| format!("Failed to read {}", path.display()))?;
    parse_data(&amp;content)
        .context("Invalid data format")
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Add context at each error boundary</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.with_context(|| format!("meaningful message with {}", value))
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Handle Option explicitly</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>map.get(key).ok_or_else(|| anyhow!("Missing key: {}", key))?
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="python-error-handling"><a class="header" href="#python-error-handling">Python Error Handling</a></h3>
<ol>
<li>
<p><strong>Always use specific exception types</strong></p>
<pre><code class="language-python">except (ValueError, KeyError) as e:
</code></pre>
</li>
<li>
<p><strong>Log before suppressing</strong></p>
<pre><code class="language-python">except DatabaseError as e:
    logger.error(f"Database operation failed: {e}", exc_info=True)
    # Then decide: re-raise, return default, or handle
</code></pre>
</li>
<li>
<p><strong>Avoid bare except completely</strong></p>
<pre><code class="language-python"># If you must catch everything:
except Exception as e:  # Not bare except:
    logger.exception("Unexpected error")
    raise
</code></pre>
</li>
<li>
<p><strong>Use context managers for resource cleanup</strong></p>
<pre><code class="language-python">with open(path) as f:  # Ensures cleanup even on exception
    process(f)
</code></pre>
</li>
</ol>
<h3 id="javascripttypescript-error-handling"><a class="header" href="#javascripttypescript-error-handling">JavaScript/TypeScript Error Handling</a></h3>
<ol>
<li>
<p><strong>Always handle promise rejections</strong></p>
<pre><code class="language-javascript">fetchData().catch(err =&gt; console.error(err));
// Or use try/catch with async/await
</code></pre>
</li>
<li>
<p><strong>Use async/await consistently</strong></p>
<pre><code class="language-javascript">async function process() {
    try {
        const data = await fetchData();
        await saveData(data);
    } catch (error) {
        console.error("Failed:", error);
        throw error;
    }
}
</code></pre>
</li>
<li>
<p><strong>Don‚Äôt forget await</strong></p>
<pre><code class="language-javascript">await asyncOperation();  // Don't drop promises
</code></pre>
</li>
</ol>
<h2 id="improving-error-handling-based-on-debtmap-reports"><a class="header" href="#improving-error-handling-based-on-debtmap-reports">Improving Error Handling Based on Debtmap Reports</a></h2>
<h3 id="workflow"><a class="header" href="#workflow">Workflow</a></h3>
<ol>
<li>
<p><strong>Run analysis with error focus</strong></p>
<pre><code class="language-bash">debtmap analyze --filter-categories ErrorSwallowing
</code></pre>
</li>
<li>
<p><strong>Review priority issues first</strong></p>
<ul>
<li>Address CRITICAL (panic in production, bare except) immediately</li>
<li>Schedule HIGH (unwrap, dropped futures) for next sprint</li>
<li>Plan MEDIUM (missing context) for gradual improvement</li>
</ul>
</li>
<li>
<p><strong>Fix systematically</strong></p>
<ul>
<li>One file or module at a time</li>
<li>Add tests as you improve error handling</li>
<li>Run debtmap after each fix to verify</li>
</ul>
</li>
<li>
<p><strong>Validate improvements</strong></p>
<pre><code class="language-bash"># Before fixes
debtmap analyze --output before.json

# After fixes
debtmap analyze --output after.json

# Compare
debtmap compare before.json after.json
</code></pre>
</li>
</ol>
<h3 id="migration-strategy-for-legacy-code"><a class="header" href="#migration-strategy-for-legacy-code">Migration Strategy for Legacy Code</a></h3>
<pre><code class="language-toml"># .debtmap.toml - Gradual adoption
[error_handling]
# Start with just critical panic patterns
detect_panic_patterns = true
detect_swallowing = false      # Add later
detect_async_errors = false    # Add later
detect_context_loss = false    # Add later

# After fixing panic patterns, enable error swallowing detection
# detect_swallowing = true

# Eventually enable all patterns
# detect_swallowing = true
# detect_async_errors = true
# detect_context_loss = true
# detect_propagation = true
</code></pre>
<p>Track progress over time:</p>
<pre><code class="language-bash"># Weekly error handling health check
debtmap analyze --filter-categories ErrorSwallowing | tee weekly-error-health.txt
</code></pre>
<h2 id="troubleshooting-13"><a class="header" href="#troubleshooting-13">Troubleshooting</a></h2>
<h3 id="too-many-false-positives-in-test-code"><a class="header" href="#too-many-false-positives-in-test-code">Too Many False Positives in Test Code</a></h3>
<p><strong>Problem:</strong> Debtmap flagging <code>unwrap()</code> in test functions</p>
<p><strong>Solution:</strong> Debtmap should automatically detect test code via:</p>
<ul>
<li><code>#[cfg(test)]</code> modules in Rust</li>
<li><code>#[test]</code> attributes</li>
<li><code>test_</code> function name prefix in Python</li>
<li><code>*.test.ts</code>, <code>*.spec.js</code> file patterns</li>
</ul>
<p>If false positives persist:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use suppression comment
let value = result.unwrap();  // debtmap: ignore - Test assertion
<span class="boring">}</span></code></pre></pre>
<h3 id="error-patterns-not-being-detected"><a class="header" href="#error-patterns-not-being-detected">Error Patterns Not Being Detected</a></h3>
<p><strong>Problem:</strong> Known error patterns not appearing in report</p>
<p><strong>Causes and solutions:</strong></p>
<ol>
<li>
<p><strong>Language support not enabled</strong></p>
<pre><code class="language-bash">debtmap analyze --languages rust,python,javascript
</code></pre>
</li>
<li>
<p><strong>Pattern disabled in config</strong></p>
<pre><code class="language-toml">[error_handling]
detect_panic_patterns = true
detect_swallowing = true
detect_async_errors = true  # Ensure relevant detectors are enabled
</code></pre>
</li>
<li>
<p><strong>Suppression comment present</strong></p>
<ul>
<li>Check for <code>debtmap: ignore</code> comments</li>
<li>Review <code>.debtmap.toml</code> ignore patterns</li>
</ul>
</li>
</ol>
<h3 id="disagreement-with-severity-levels"><a class="header" href="#disagreement-with-severity-levels">Disagreement with Severity Levels</a></h3>
<p><strong>Problem:</strong> Severity feels too high/low for your codebase</p>
<p><strong>Solution:</strong> Customize in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[debt_categories.ErrorSwallowing]
weight = 2  # Reduce from default 4 to Warning level
severity = "Warning"

# Or increase for stricter enforcement
# weight = 5
# severity = "Critical"
</code></pre>
<h3 id="cant-find-which-line-has-the-issue"><a class="header" href="#cant-find-which-line-has-the-issue">Can‚Äôt Find Which Line Has the Issue</a></h3>
<p><strong>Problem:</strong> Debtmap reports error at wrong line number</p>
<p><strong>Causes:</strong></p>
<ul>
<li>Source code changed since analysis</li>
<li>Parser approximation for line numbers</li>
</ul>
<p><strong>Solutions:</strong></p>
<ol>
<li>Re-run analysis: <code>debtmap analyze</code></li>
<li>Search for pattern: <code>rg "\.unwrap\(\)" src/</code></li>
<li>Enable debug logging: <code>debtmap analyze --log-level debug</code></li>
</ol>
<h3 id="validating-error-handling-improvements"><a class="header" href="#validating-error-handling-improvements">Validating Error Handling Improvements</a></h3>
<p><strong>Problem:</strong> Unsure if fixes actually improved code quality</p>
<p><strong>Solution:</strong> Use compare workflow:</p>
<pre><code class="language-bash"># Baseline before fixes
git checkout main
debtmap analyze --output baseline.json

# After fixes
git checkout feature/improve-errors
debtmap analyze --output improved.json

# Compare reports
debtmap compare baseline.json improved.json
</code></pre>
<p>Look for:</p>
<ul>
<li>Reduced ErrorSwallowing debt count</li>
<li>Lower risk scores for affected functions</li>
<li>Improved coverage of error paths (if running with coverage)</li>
</ul>
<h2 id="related-topics-4"><a class="header" href="#related-topics-4">Related Topics</a></h2>
<ul>
<li><a href="configuration.html">Configuration</a> - Complete <code>.debtmap.toml</code> reference</li>
<li><a href="suppression-patterns.html">Suppression Patterns</a> - Suppress false positives</li>
<li><a href="scoring-strategies.html">Scoring Strategies</a> - How error handling affects risk scores</li>
<li><a href="coverage-integration.html">Coverage Integration</a> - Detect untested error paths</li>
<li><a href="cli-reference.html">CLI Reference</a> - Command-line options for error analysis</li>
<li><a href="troubleshooting.html">Troubleshooting</a> - General debugging guide</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="functional-composition-analysis"><a class="header" href="#functional-composition-analysis">Functional Composition Analysis</a></h1>
<p>Debtmap provides deep AST-based analysis to detect and evaluate functional programming patterns in Rust code. This feature helps you understand how effectively your codebase uses functional composition patterns like iterator pipelines, identify opportunities for refactoring imperative code to functional style, and rewards pure, side-effect-free functions in complexity scoring.</p>
<h2 id="overview-10"><a class="header" href="#overview-10">Overview</a></h2>
<p>Functional analysis examines your code at the AST level to detect:</p>
<ul>
<li><strong>Iterator pipelines</strong> - Chains like <code>.iter().map().filter().collect()</code></li>
<li><strong>Purity analysis</strong> - Functions with no mutable state or side effects</li>
<li><strong>Composition quality metrics</strong> - Overall functional programming quality scores</li>
<li><strong>Side effect classification</strong> - Categorization of Pure, Benign, and Impure side effects</li>
</ul>
<p>This analysis integrates with debtmap‚Äôs scoring system, providing score bonuses for high-quality functional code and reducing god object warnings for codebases with many small pure helper functions.</p>
<p><strong>Specification</strong>: This feature implements <a href="https://github.com/yourusername/debtmap/specs/111">Specification 111: AST-Based Functional Pattern Detection</a> with accuracy targets of precision ‚â•90%, recall ‚â•85%, F1 ‚â•0.87, and performance overhead &lt;10%.</p>
<h2 id="configuration-profiles"><a class="header" href="#configuration-profiles">Configuration Profiles</a></h2>
<p>Debtmap provides three pre-configured analysis profiles to match different codebases:</p>
<div class="table-wrapper"><table><thead><tr><th>Profile</th><th>Use Case</th><th>Min Pipeline Depth</th><th>Max Closure Complexity</th><th>Purity Threshold</th><th>Quality Threshold</th></tr></thead><tbody>
<tr><td><strong>Strict</strong></td><td>Functional-first codebases</td><td>3</td><td>3</td><td>0.9</td><td>0.7</td></tr>
<tr><td><strong>Balanced</strong> (default)</td><td>Typical Rust projects</td><td>2</td><td>5</td><td>0.8</td><td>0.6</td></tr>
<tr><td><strong>Lenient</strong></td><td>Imperative-heavy legacy code</td><td>2</td><td>10</td><td>0.5</td><td>0.4</td></tr>
</tbody></table>
</div>
<h3 id="choosing-a-profile"><a class="header" href="#choosing-a-profile">Choosing a Profile</a></h3>
<p><strong>Use Strict</strong> when:</p>
<ul>
<li>Your codebase emphasizes functional programming patterns</li>
<li>You want to enforce high purity standards</li>
<li>You‚Äôre building a new project with functional-first principles</li>
<li>You want to detect even simple pipelines (3+ stages)</li>
</ul>
<p><strong>Use Balanced</strong> (default) when:</p>
<ul>
<li>You have a typical Rust codebase mixing functional and imperative styles</li>
<li>You want reasonable detection without being overly strict</li>
<li>You‚Äôre working on a mature project with mixed patterns</li>
<li>You want to reward functional patterns without penalizing pragmatic imperative code</li>
</ul>
<p><strong>Use Lenient</strong> when:</p>
<ul>
<li>You‚Äôre analyzing legacy code with heavy imperative patterns</li>
<li>You want to identify only the most obviously functional code</li>
<li>You‚Äôre migrating from an imperative codebase and want gradual improvement</li>
<li>You have complex closures that are still fundamentally functional</li>
</ul>
<h3 id="cli-usage"><a class="header" href="#cli-usage">CLI Usage</a></h3>
<p>Enable functional analysis with the <code>--ast-functional-analysis</code> flag and select a profile with <code>--functional-analysis-profile</code>:</p>
<pre><code class="language-bash"># Enable with balanced profile (default)
debtmap analyze . --ast-functional-analysis --functional-analysis-profile balanced

# Use strict profile for functional-first codebases
debtmap analyze . --ast-functional-analysis --functional-analysis-profile strict

# Use lenient profile for legacy code
debtmap analyze . --ast-functional-analysis --functional-analysis-profile lenient
</code></pre>
<p><strong>Note:</strong> The <code>--ast-functional-analysis</code> flag enables the feature, while <code>--functional-analysis-profile</code> selects the configuration profile (strict/balanced/lenient).</p>
<h2 id="pure-function-detection"><a class="header" href="#pure-function-detection">Pure Function Detection</a></h2>
<p>A function is considered pure when it:</p>
<ol>
<li>Returns same output for same input (deterministic)</li>
<li>Has no observable side effects</li>
<li>Doesn‚Äôt mutate external state</li>
<li>Doesn‚Äôt perform I/O</li>
</ol>
<h3 id="examples-3"><a class="header" href="#examples-3">Examples</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pure function
fn add(a: i32, b: i32) -&gt; i32 {
    a + b
}

// Pure function with internal iteration
fn factorial(n: u32) -&gt; u32 {
    (1..=n).product()  // Pure despite internal iteration
}

// Not pure: I/O side effect
fn log_and_add(a: i32, b: i32) -&gt; i32 {
    println!("Adding {} and {}", a, b);  // Side effect!
    a + b
}

// Not pure: mutates external state
fn increment_counter(counter: &amp;mut i32) -&gt; i32 {
    *counter += 1;  // Side effect!
    *counter
}
<span class="boring">}</span></code></pre></pre>
<h2 id="pipeline-detection"><a class="header" href="#pipeline-detection">Pipeline Detection</a></h2>
<p>Debtmap detects functional pipelines through deep AST analysis, identifying iterator chains and their transformations.</p>
<h3 id="pipeline-stages"><a class="header" href="#pipeline-stages">Pipeline Stages</a></h3>
<p>The analyzer recognizes these pipeline stage types:</p>
<h4 id="1-iterator-initialization"><a class="header" href="#1-iterator-initialization">1. Iterator Initialization</a></h4>
<p>Methods that start an iterator chain:</p>
<ul>
<li><code>.iter()</code> - Immutable iteration</li>
<li><code>.into_iter()</code> - Consuming iteration</li>
<li><code>.iter_mut()</code> - Mutable iteration</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected iterator initialization
let results = collection.iter()
    .map(|x| x * 2)
    .collect();
<span class="boring">}</span></code></pre></pre>
<h4 id="2-map-transformations"><a class="header" href="#2-map-transformations">2. Map Transformations</a></h4>
<p>Applies a transformation function to each element:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected Map stage
items.iter()
    .map(|x| x * 2)          // Simple closure (low complexity)
    .map(|x| {                // Complex closure (higher complexity)
        let doubled = x * 2;
        doubled + 1
    })
    .collect()
<span class="boring">}</span></code></pre></pre>
<p>The analyzer tracks <strong>closure complexity</strong> for each map operation. Complex closures may indicate code smells and affect quality scoring based on your <code>max_closure_complexity</code> threshold.</p>
<h4 id="3-filter-predicates"><a class="header" href="#3-filter-predicates">3. Filter Predicates</a></h4>
<p>Selects elements based on a predicate:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected Filter stage
items.iter()
    .filter(|x| *x &gt; 0)      // Simple predicate
    .filter(|x| {             // Complex predicate
        x.is_positive() &amp;&amp; x &lt; 100
    })
    .collect()
<span class="boring">}</span></code></pre></pre>
<h4 id="4-foldreduce-aggregation"><a class="header" href="#4-foldreduce-aggregation">4. Fold/Reduce Aggregation</a></h4>
<p>Combines elements into a single value:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected Fold stage
items.iter()
    .fold(0, |acc, x| acc + x)

// Or using reduce
items.iter()
    .reduce(|a, b| a + b)
<span class="boring">}</span></code></pre></pre>
<h4 id="5-flatmap-transformations"><a class="header" href="#5-flatmap-transformations">5. FlatMap Transformations</a></h4>
<p>Maps and flattens nested structures:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected FlatMap stage
items.iter()
    .flat_map(|x| vec![x, x * 2])
    .collect()
<span class="boring">}</span></code></pre></pre>
<h4 id="6-inspect-side-effect-aware"><a class="header" href="#6-inspect-side-effect-aware">6. Inspect (Side-Effect Aware)</a></h4>
<p>Performs side effects while passing through values:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected Inspect stage (affects purity scoring)
items.iter()
    .inspect(|x| println!("Processing: {}", x))
    .map(|x| x * 2)
    .collect()
<span class="boring">}</span></code></pre></pre>
<h4 id="7-resultoption-chaining"><a class="header" href="#7-resultoption-chaining">7. Result/Option Chaining</a></h4>
<p>Specialized stages for error handling:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected AndThen stage
results.iter()
    .and_then(|x| try_process(x))
    .collect()

// Detected MapErr stage
results.iter()
    .map_err(|e| format!("Error: {}", e))
    .collect()
<span class="boring">}</span></code></pre></pre>
<h3 id="terminal-operations"><a class="header" href="#terminal-operations">Terminal Operations</a></h3>
<p>Pipelines typically end with a terminal operation that consumes the iterator:</p>
<ul>
<li><strong><code>collect()</code></strong> - Gather elements into a collection</li>
<li><strong><code>sum()</code></strong> - Sum numeric values</li>
<li><strong><code>count()</code></strong> - Count elements</li>
<li><strong><code>any()</code></strong> - Check if any element matches</li>
<li><strong><code>all()</code></strong> - Check if all elements match</li>
<li><strong><code>find()</code></strong> - Find first matching element</li>
<li><strong><code>reduce()</code></strong> - Reduce to single value</li>
<li><strong><code>for_each()</code></strong> - Execute side effects for each element</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Complete pipeline with terminal operation
let total: i32 = items.iter()
    .filter(|x| **x &gt; 0)
    .map(|x| x * 2)
    .sum();  // Terminal operation: sum
<span class="boring">}</span></code></pre></pre>
<h3 id="nested-pipelines"><a class="header" href="#nested-pipelines">Nested Pipelines</a></h3>
<p>Debtmap detects pipelines nested within closures, indicating highly functional code patterns:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Nested pipeline detected
let results = outer_items.iter()
    .map(|item| {
        // Inner pipeline (nesting_level = 1)
        item.values.iter()
            .filter(|v| **v &gt; 0)
            .collect()
    })
    .collect();
<span class="boring">}</span></code></pre></pre>
<p><strong>Nesting level</strong> tracking helps identify sophisticated functional composition patterns.</p>
<h3 id="parallel-pipelines"><a class="header" href="#parallel-pipelines">Parallel Pipelines</a></h3>
<p>Parallel iteration using Rayon is automatically detected:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use rayon::prelude::*;

// Detected as parallel pipeline (is_parallel = true)
let results: Vec&lt;_&gt; = items.par_iter()
    .filter(|x| **x &gt; 0)
    .map(|x| x * 2)
    .collect();
<span class="boring">}</span></code></pre></pre>
<p>Parallel pipelines indicate high-performance functional patterns and receive positive quality scoring.</p>
<h3 id="builder-pattern-filtering"><a class="header" href="#builder-pattern-filtering">Builder Pattern Filtering</a></h3>
<p>To avoid false positives, debtmap distinguishes builder patterns from functional pipelines:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// This is a builder pattern, NOT counted as a functional pipeline
let config = ConfigBuilder::new()
    .with_host("localhost")
    .with_port(8080)
    .build();

// This IS a functional pipeline
let values = items.iter()
    .map(|x| x * 2)
    .collect();
<span class="boring">}</span></code></pre></pre>
<p>Builder patterns are filtered out to ensure accurate functional composition metrics.</p>
<h2 id="purity-analysis"><a class="header" href="#purity-analysis">Purity Analysis</a></h2>
<p>Debtmap analyzes functions to determine their purity level - whether they have side effects and mutable state.</p>
<h3 id="purity-levels"><a class="header" href="#purity-levels">Purity Levels</a></h3>
<p>Functions are classified into three purity levels for god object weighting (defined in <code>src/organization/purity_analyzer.rs</code>):</p>
<blockquote>
<p><strong>Note:</strong> Debtmap has two purity analysis systems serving different purposes:</p>
<ol>
<li><strong>PurityLevel</strong> (three levels) - Used for god object scoring with weight multipliers (this section)</li>
<li><strong>PurityLevel</strong> (four levels) - Used in <code>src/analysis/purity_analysis.rs</code> for detailed responsibility classification (Strictly Pure, Locally Pure, Read-Only, Impure)</li>
</ol>
<p>This chapter focuses on the three-level system for god object integration.</p>
</blockquote>
<h4 id="pure-weight-03"><a class="header" href="#pure-weight-03">Pure (Weight 0.3)</a></h4>
<p>Guaranteed no side effects:</p>
<ul>
<li>No mutable parameters (<code>&amp;mut</code>, <code>mut self</code>)</li>
<li>No I/O operations</li>
<li>No global mutations</li>
<li>No <code>unsafe</code> blocks</li>
<li>Only immutable bindings</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pure function
fn calculate_total(items: &amp;[i32]) -&gt; i32 {
    items.iter().sum()
}

// Pure function with immutable bindings
fn process_value(x: i32) -&gt; i32 {
    let doubled = x * 2;  // Immutable binding
    let result = doubled + 10;
    result
}
<span class="boring">}</span></code></pre></pre>
<h4 id="probably-pure-weight-05"><a class="header" href="#probably-pure-weight-05">Probably Pure (Weight 0.5)</a></h4>
<p>Likely no side effects:</p>
<ul>
<li>Static functions (<code>fn</code> items, not methods)</li>
<li>Associated functions (no <code>self</code>)</li>
<li>No obvious side effects detected</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Probably pure - static function
fn transform(value: i32) -&gt; i32 {
    value * 2
}

// Probably pure - associated function
impl MyType {
    fn create_default() -&gt; Self {
        MyType { value: 0 }
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="impure-weight-10"><a class="header" href="#impure-weight-10">Impure (Weight 1.0)</a></h4>
<p>Has side effects:</p>
<ul>
<li>Uses mutable references (<code>&amp;mut</code>, <code>mut self</code>)</li>
<li>Performs I/O operations (<code>println!</code>, file I/O, network)</li>
<li>Uses <code>async</code> (potential side effects)</li>
<li>Mutates global state</li>
<li>Uses <code>unsafe</code></li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Impure - mutable reference
fn increment(value: &amp;mut i32) {
    *value += 1;
}

// Impure - I/O operation
fn log_value(value: i32) {
    println!("Value: {}", value);
}

// Impure - mutation
fn process_items(items: &amp;mut Vec&lt;i32&gt;) {
    items.push(42);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="purity-weight-multipliers"><a class="header" href="#purity-weight-multipliers">Purity Weight Multipliers</a></h3>
<p>Purity levels affect god object detection through weight multipliers (implemented in <code>src/organization/purity_analyzer.rs:29-39</code>). Pure functions contribute <strong>less</strong> to god object scores, rewarding codebases with many small pure helper functions:</p>
<ul>
<li><strong>Pure (0.3)</strong>: A pure function counts as 30% of a regular function in god object method count calculations</li>
<li><strong>Probably Pure (0.5)</strong>: Counts as 50%</li>
<li><strong>Impure (1.0)</strong>: Full weight</li>
</ul>
<p>The <code>purity_score</code> dampens god object scores via the <code>weight_multiplier</code> calculation. For example, pure functions with weight 0.3 count as only 30% of a regular function when calculating method counts for god object detection.</p>
<p><strong>Example</strong>: A module with 20 pure helper functions (20 √ó 0.3 = 6.0 effective) is less likely to trigger god object warnings than a module with 10 impure functions (10 √ó 1.0 = 10.0 effective).</p>
<h2 id="side-effect-detection"><a class="header" href="#side-effect-detection">Side Effect Detection</a></h2>
<h3 id="detected-side-effects"><a class="header" href="#detected-side-effects">Detected Side Effects</a></h3>
<p><strong>I/O Operations:</strong></p>
<ul>
<li>File reading/writing</li>
<li>Network calls</li>
<li>Console output</li>
<li>Database queries</li>
</ul>
<p><strong>State Mutation:</strong></p>
<ul>
<li>Mutable global variables</li>
<li>Shared mutable state</li>
<li>Reference mutations</li>
</ul>
<p><strong>Randomness:</strong></p>
<ul>
<li>Random number generation</li>
<li>Time-dependent behavior</li>
</ul>
<p><strong>System Interaction:</strong></p>
<ul>
<li>Environment variable access</li>
<li>System calls</li>
<li>Thread spawning</li>
</ul>
<h3 id="rust-specific-detection"><a class="header" href="#rust-specific-detection">Rust-Specific Detection</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Interior mutability detection
use std::cell::RefCell;

fn has_side_effect() {
    let data = RefCell::new(vec![]);
    data.borrow_mut().push(1);  // Detected as mutation
}

// Unsafe code detection
fn unsafe_side_effect() {
    unsafe {
        // Automatically flagged as potentially impure
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="side-effect-classification"><a class="header" href="#side-effect-classification">Side Effect Classification</a></h3>
<p>Side effects are categorized by severity:</p>
<h4 id="pure---no-side-effects"><a class="header" href="#pure---no-side-effects">Pure - No Side Effects</a></h4>
<p>No mutations, I/O, or global state changes:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pure - only computation
fn fibonacci(n: u32) -&gt; u32 {
    match n {
        0 =&gt; 0,
        1 =&gt; 1,
        _ =&gt; fibonacci(n - 1) + fibonacci(n - 2),
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="benign---small-penalty"><a class="header" href="#benign---small-penalty">Benign - Small Penalty</a></h4>
<p>Only logging, tracing, or metrics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::debug;

// Benign - logging side effect
fn process(value: i32) -&gt; i32 {
    debug!("Processing value: {}", value);
    value * 2
}
<span class="boring">}</span></code></pre></pre>
<p>Benign side effects receive a <strong>small penalty</strong> in purity scoring. Logging and observability are recognized as practical necessities.</p>
<h4 id="impure---large-penalty"><a class="header" href="#impure---large-penalty">Impure - Large Penalty</a></h4>
<p>I/O, mutations, network operations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Impure - file I/O
fn save_to_file(data: &amp;str) -&gt; std::io::Result&lt;()&gt; {
    std::fs::write("output.txt", data)
}

// Impure - network operation
async fn fetch_data(url: &amp;str) -&gt; Result&lt;String, reqwest::Error&gt; {
    reqwest::get(url).await?.text().await
}
<span class="boring">}</span></code></pre></pre>
<p>Impure side effects receive a <strong>large penalty</strong> in purity scoring.</p>
<h3 id="purity-metrics"><a class="header" href="#purity-metrics">Purity Metrics</a></h3>
<p>For each function, debtmap calculates purity metrics through the functional composition analysis (<code>src/analysis/functional_composition.rs</code>). These metrics are computed by <code>analyze_composition()</code> and returned in <code>CompositionMetrics</code> and <code>PurityMetrics</code>:</p>
<ul>
<li><strong><code>has_mutable_state</code></strong> - Whether the function uses mutable bindings</li>
<li><strong><code>has_side_effects</code></strong> - Whether I/O or global mutations are detected</li>
<li><strong><code>immutability_ratio</code></strong> - Ratio of immutable to total bindings (0.0-1.0)</li>
<li><strong><code>is_const_fn</code></strong> - Whether declared as <code>const fn</code></li>
<li><strong><code>side_effect_kind</code></strong> - Classification: Pure, Benign, or Impure</li>
<li><strong><code>purity_score</code></strong> - Overall purity score (0.0 impure to 1.0 pure)</li>
</ul>
<h4 id="immutability-ratio"><a class="header" href="#immutability-ratio">Immutability Ratio</a></h4>
<p>The immutability ratio measures how much of a function‚Äôs local state is immutable:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn example() {
    let x = 10;         // Immutable
    let y = 20;         // Immutable
    let mut z = 30;     // Mutable
    z += 1;
    // immutability_ratio = 2/3 = 0.67
}
<span class="boring">}</span></code></pre></pre>
<p>Higher immutability ratios contribute to better purity scores.</p>
<h2 id="composition-pattern-recognition"><a class="header" href="#composition-pattern-recognition">Composition Pattern Recognition</a></h2>
<h3 id="function-composition"><a class="header" href="#function-composition">Function Composition</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected composition pattern
fn process_data(input: String) -&gt; Result&lt;Output&gt; {
    input
        .parse()
        .map(validate)
        .and_then(transform)
        .map(normalize)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="higher-order-functions"><a class="header" href="#higher-order-functions">Higher-Order Functions</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected HOF pattern
fn apply_twice&lt;F&gt;(f: F, x: i32) -&gt; i32
where
    F: Fn(i32) -&gt; i32,
{
    f(f(x))
}
<span class="boring">}</span></code></pre></pre>
<h3 id="mapfilterfold-chains"><a class="header" href="#mapfilterfold-chains">Map/Filter/Fold Chains</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected functional pipeline
let result = items
    .iter()
    .filter(|x| x.is_valid())
    .map(|x| x.transform())
    .fold(0, |acc, x| acc + x);
<span class="boring">}</span></code></pre></pre>
<h2 id="composition-quality-scoring"><a class="header" href="#composition-quality-scoring">Composition Quality Scoring</a></h2>
<p>Debtmap combines pipeline metrics and purity analysis into an overall <strong>composition quality score</strong> (0.0-1.0).</p>
<h3 id="scoring-factors"><a class="header" href="#scoring-factors">Scoring Factors</a></h3>
<p>The composition quality score considers:</p>
<ol>
<li><strong>Pipeline depth</strong> - Longer pipelines indicate more functional composition</li>
<li><strong>Purity score</strong> - Higher purity means better functional programming</li>
<li><strong>Immutability ratio</strong> - More immutable bindings improve the score</li>
<li><strong>Closure complexity</strong> - Simpler closures score better</li>
<li><strong>Parallel execution</strong> - Parallel pipelines receive bonuses</li>
<li><strong>Nested pipelines</strong> - Sophisticated composition patterns score higher</li>
</ol>
<h3 id="quality-thresholds"><a class="header" href="#quality-thresholds">Quality Thresholds</a></h3>
<p>Based on your configuration profile, functions with composition quality above the threshold receive <strong>score boosts</strong> in debtmap‚Äôs overall analysis:</p>
<ul>
<li><strong>Strict</strong>: Quality ‚â• 0.7 required for boost</li>
<li><strong>Balanced</strong>: Quality ‚â• 0.6 required for boost</li>
<li><strong>Lenient</strong>: Quality ‚â• 0.4 required for boost</li>
</ul>
<p>High-quality functional code can offset complexity in other areas of your codebase.</p>
<h3 id="purity-scoring"><a class="header" href="#purity-scoring">Purity Scoring</a></h3>
<h4 id="distribution-analysis"><a class="header" href="#distribution-analysis">Distribution Analysis</a></h4>
<p>Debtmap calculates purity distribution:</p>
<ul>
<li><strong>Pure functions</strong>: 0 side effects detected</li>
<li><strong>Mostly pure</strong>: Minor side effects (e.g., logging)</li>
<li><strong>Impure</strong>: Multiple side effects</li>
<li><strong>Highly impure</strong>: Extensive state mutation and I/O</li>
</ul>
<h4 id="scoring-formula-1"><a class="header" href="#scoring-formula-1">Scoring Formula</a></h4>
<pre><code>Purity Score = (pure_functions / total_functions) √ó 100
Side Effect Density = total_side_effects / total_functions
</code></pre>
<h4 id="codebase-health-metrics"><a class="header" href="#codebase-health-metrics">Codebase Health Metrics</a></h4>
<pre><code>Target Purity Levels:
- Core business logic: 80%+ pure
- Utilities: 70%+ pure
- I/O layer: 20-30% pure (expected)
- Overall: 50%+ pure
</code></pre>
<h3 id="integration-with-risk-scoring-1"><a class="header" href="#integration-with-risk-scoring-1">Integration with Risk Scoring</a></h3>
<p>Functional composition quality integrates with debtmap‚Äôs risk scoring system and multi-signal aggregation framework:</p>
<ul>
<li><strong>High composition quality</strong> ‚Üí Lower risk scores (functions with quality above threshold receive score boosts)</li>
<li><strong>Pure functions</strong> ‚Üí Reduced god object penalties (via weight multipliers in <code>purity_analyzer.rs</code>)</li>
<li><strong>Deep pipelines</strong> ‚Üí Bonus for functional patterns</li>
<li><strong>Impure side effects</strong> ‚Üí Risk penalties applied</li>
</ul>
<p><strong>Multi-Signal Integration</strong>: Functional composition analysis is one of several signals aggregated in the unified analysis system (<code>src/builders/unified_analysis.rs</code> and <code>src/analysis/multi_signal_aggregation.rs</code>) alongside complexity metrics, god object detection, and risk assessment. This ensures that functional programming quality contributes to the comprehensive technical debt assessment across multiple dimensions.</p>
<p>This integration ensures that well-written functional code is properly rewarded in the overall technical debt assessment.</p>
<h2 id="practical-examples-3"><a class="header" href="#practical-examples-3">Practical Examples</a></h2>
<h3 id="example-1-detecting-imperative-vs-functional-code"><a class="header" href="#example-1-detecting-imperative-vs-functional-code">Example 1: Detecting Imperative vs Functional Code</a></h3>
<p><strong>Imperative style</strong> (lower composition quality):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn process_items_imperative(items: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    let mut results = Vec::new();
    for item in items {
        if item &gt; 0 {
            results.push(item * 2);
        }
    }
    results
}
// Detected: No pipelines, mutable state, lower purity score
<span class="boring">}</span></code></pre></pre>
<p><strong>Functional style</strong> (higher composition quality):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn process_items_functional(items: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    items.iter()
        .filter(|x| **x &gt; 0)
        .map(|x| x * 2)
        .collect()
}
// Detected: Pipeline depth 3, pure function, high composition quality
<span class="boring">}</span></code></pre></pre>
<h3 id="example-2-identifying-refactoring-opportunities"><a class="header" href="#example-2-identifying-refactoring-opportunities">Example 2: Identifying Refactoring Opportunities</a></h3>
<p>When debtmap detects low composition quality, it suggests refactoring:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Original: Imperative with mutations
fn calculate_statistics(data: &amp;[f64]) -&gt; (f64, f64, f64) {
    let mut sum = 0.0;
    let mut min = f64::MAX;
    let mut max = f64::MIN;

    for &amp;value in data {
        sum += value;
        if value &lt; min { min = value; }
        if value &gt; max { max = value; }
    }

    (sum / data.len() as f64, min, max)
}

// Refactored: Functional style
fn calculate_statistics_functional(data: &amp;[f64]) -&gt; (f64, f64, f64) {
    let sum: f64 = data.iter().sum();
    let min = data.iter().min_by(|a, b| a.partial_cmp(b).unwrap()).unwrap();
    let max = data.iter().max_by(|a, b| a.partial_cmp(b).unwrap()).unwrap();

    (sum / data.len() as f64, *min, *max)
}
// Higher purity score, multiple pipelines detected
<span class="boring">}</span></code></pre></pre>
<h3 id="example-3-using-profiles-for-different-codebases"><a class="header" href="#example-3-using-profiles-for-different-codebases">Example 3: Using Profiles for Different Codebases</a></h3>
<p><strong>Strict profile</strong> - Catches subtle functional patterns:</p>
<pre><code class="language-bash">$ debtmap analyze --ast-functional-analysis --functional-analysis-profile strict src/
# Detects pipelines with 3+ stages
# Requires purity ‚â• 0.9 for "pure" classification
# Flags closures with complexity &gt; 3
</code></pre>
<p><strong>Balanced profile</strong> - Default for most projects:</p>
<pre><code class="language-bash">$ debtmap analyze --ast-functional-analysis --functional-analysis-profile balanced src/
# Detects pipelines with 2+ stages
# Requires purity ‚â• 0.8 for "pure" classification
# Flags closures with complexity &gt; 5
</code></pre>
<p><strong>Lenient profile</strong> - For legacy code:</p>
<pre><code class="language-bash">$ debtmap analyze --ast-functional-analysis --functional-analysis-profile lenient src/
# Detects pipelines with 2+ stages
# Requires purity ‚â• 0.5 for "pure" classification
# Flags closures with complexity &gt; 10
</code></pre>
<h3 id="example-4-interpreting-purity-scores"><a class="header" href="#example-4-interpreting-purity-scores">Example 4: Interpreting Purity Scores</a></h3>
<p><strong>Pure function</strong> (score: 1.0):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn add(a: i32, b: i32) -&gt; i32 {
    a + b
}
// Purity: 1.0 (perfect)
// Immutability ratio: 1.0 (no bindings)
// Side effects: None
<span class="boring">}</span></code></pre></pre>
<p><strong>Mostly pure</strong> (score: 0.8):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn process(values: &amp;[i32]) -&gt; i32 {
    let doubled: Vec&lt;_&gt; = values.iter().map(|x| x * 2).collect();
    let sum: i32 = doubled.iter().sum();
    sum
}
// Purity: 0.8 (high)
// Immutability ratio: 1.0 (both bindings immutable)
// Side effects: None
// Pipelines: 2 detected
<span class="boring">}</span></code></pre></pre>
<p><strong>Impure function</strong> (score: 0.2):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn log_and_process(values: &amp;mut Vec&lt;i32&gt;) {
    println!("Processing {} items", values.len());
    values.iter_mut().for_each(|x| *x *= 2);
}
// Purity: 0.2 (low)
// Immutability ratio: 0.0 (mutable parameter)
// Side effects: I/O (println), mutation
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices-12"><a class="header" href="#best-practices-12">Best Practices</a></h2>
<h3 id="writing-functional-rust-code"><a class="header" href="#writing-functional-rust-code">Writing Functional Rust Code</a></h3>
<p>To achieve high composition quality scores:</p>
<ol>
<li>
<p><strong>Prefer iterator chains over manual loops</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good
let evens: Vec&lt;_&gt; = items.iter().filter(|x| *x % 2 == 0).collect();

// Avoid
let mut evens = Vec::new();
for item in &amp;items {
    if item % 2 == 0 { evens.push(item); }
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Minimize mutable state</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good
let result = calculate(input);

// Avoid
let mut result = 0;
result = calculate(input);
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Separate pure logic from side effects</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good - pure computation
fn calculate_price(quantity: u32, unit_price: f64) -&gt; f64 {
    quantity as f64 * unit_price
}

// Good - I/O at the boundary
fn display_price(price: f64) {
    println!("Total: ${:.2}", price);
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Keep closures simple</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good - simple closure
items.map(|x| x * 2)

// Consider extracting - complex closure
items.map(|x| {
    let temp = expensive_operation(x);
    transform(temp)
})

// Better
fn transform_item(x: i32) -&gt; i32 {
    let temp = expensive_operation(x);
    transform(temp)
}
items.map(transform_item)
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Use parallel iteration for CPU-intensive work</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use rayon::prelude::*;

let results: Vec&lt;_&gt; = large_dataset.par_iter()
    .map(|item| expensive_computation(item))
    .collect();
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<h3 id="code-organization"><a class="header" href="#code-organization">Code Organization</a></h3>
<p><strong>Separate pure from impure:</strong></p>
<ul>
<li>Keep pure logic in core modules</li>
<li>Isolate I/O at boundaries</li>
<li>Use dependency injection for testability</li>
</ul>
<p><strong>Maximize purity in:</strong></p>
<ul>
<li>Business logic</li>
<li>Calculations and transformations</li>
<li>Validation functions</li>
<li>Data structure operations</li>
</ul>
<p><strong>Accept impurity in:</strong></p>
<ul>
<li>I/O layers</li>
<li>Logging and monitoring</li>
<li>External system integration</li>
<li>Application boundaries</li>
</ul>
<p><strong>Refactoring strategy:</strong></p>
<ol>
<li>Identify impure functions</li>
<li>Extract pure logic</li>
<li>Push side effects to boundaries</li>
<li>Test pure functions exhaustively</li>
</ol>
<h3 id="migration-guide"><a class="header" href="#migration-guide">Migration Guide</a></h3>
<p>To enable functional analysis on existing projects:</p>
<ol>
<li>
<p><strong>Start with lenient profile</strong> to understand current state:</p>
<pre><code class="language-bash">debtmap analyze --ast-functional-analysis --functional-analysis-profile lenient .
</code></pre>
</li>
<li>
<p><strong>Identify quick wins</strong> - functions that are almost functional:</p>
<ul>
<li>Look for loops that can become iterator chains</li>
<li>Find mutable variables that can be immutable</li>
<li>Spot side effects that can be extracted</li>
</ul>
</li>
<li>
<p><strong>Gradually refactor</strong> to functional patterns:</p>
<ul>
<li>Convert one function at a time</li>
<li>Run tests after each change</li>
<li>Measure improvements with debtmap</li>
</ul>
</li>
<li>
<p><strong>Tighten profile</strong> as codebase improves:</p>
<pre><code class="language-bash"># After refactoring
debtmap analyze --ast-functional-analysis --functional-analysis-profile balanced .

# For new modules
debtmap analyze --ast-functional-analysis --functional-analysis-profile strict src/new_module/
</code></pre>
</li>
<li>
<p><strong>Monitor composition quality trends</strong> over time</p>
</li>
</ol>
<h2 id="use-cases-4"><a class="header" href="#use-cases-4">Use Cases</a></h2>
<h3 id="code-quality-audit"><a class="header" href="#code-quality-audit">Code Quality Audit</a></h3>
<pre><code class="language-bash"># Assess functional purity
debtmap analyze . --ast-functional-analysis --functional-analysis-profile balanced --format markdown
</code></pre>
<h3 id="refactoring-targets"><a class="header" href="#refactoring-targets">Refactoring Targets</a></h3>
<pre><code class="language-bash"># Find impure functions in core logic
debtmap analyze src/core/ --ast-functional-analysis --functional-analysis-profile strict
</code></pre>
<h3 id="onboarding-guide"><a class="header" href="#onboarding-guide">Onboarding Guide</a></h3>
<pre><code class="language-bash"># Show functional patterns in codebase
debtmap analyze . --ast-functional-analysis --functional-analysis-profile balanced --summary
</code></pre>
<h2 id="troubleshooting-14"><a class="header" href="#troubleshooting-14">Troubleshooting</a></h2>
<h3 id="no-pipelines-detected-but-i-have-iterator-chains"><a class="header" href="#no-pipelines-detected-but-i-have-iterator-chains">‚ÄúNo pipelines detected‚Äù but I have iterator chains</a></h3>
<ul>
<li><strong>Check pipeline depth</strong>: Your chains may be too short for the profile
<ul>
<li>Strict requires 3+ stages</li>
<li>Balanced/Lenient require 2+ stages</li>
</ul>
</li>
<li><strong>Check for builder patterns</strong>: Method chaining for construction is filtered out</li>
<li><strong>Verify terminal operation</strong>: Ensure the chain ends with <code>collect()</code>, <code>sum()</code>, etc.</li>
</ul>
<h3 id="low-purity-score-for-seemingly-pure-functions"><a class="header" href="#low-purity-score-for-seemingly-pure-functions">‚ÄúLow purity score‚Äù for seemingly pure functions</a></h3>
<ul>
<li><strong>Check for hidden side effects</strong>:
<ul>
<li><code>println!</code> or logging statements</li>
<li>Calls to impure helper functions</li>
<li><code>unsafe</code> blocks</li>
</ul>
</li>
<li><strong>Review immutability ratio</strong>: Unnecessary <code>mut</code> bindings lower the score</li>
<li><strong>Verify no I/O operations</strong>: File access, network calls affect purity</li>
</ul>
<h3 id="high-complexity-closures-flagged"><a class="header" href="#high-complexity-closures-flagged">‚ÄúHigh complexity closures flagged‚Äù</a></h3>
<ul>
<li><strong>Extract complex closures</strong> into named functions:
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Instead of
items.map(|x| { /* 10 lines */ })

// Use
fn process_item(x: Item) -&gt; Result { /* 10 lines */ }
items.map(process_item)
<span class="boring">}</span></code></pre></pre>
</li>
<li><strong>Adjust <code>max_closure_complexity</code></strong>: Consider lenient profile if needed</li>
<li><strong>Refactor closure logic</strong>: Break down complex operations</li>
</ul>
<h3 id="too-many-false-positives"><a class="header" href="#too-many-false-positives">Too Many False Positives</a></h3>
<p><strong>Issue:</strong> Pure functions flagged as impure</p>
<p><strong>Solution:</strong></p>
<ul>
<li>Use lenient profile</li>
<li>Suppress known patterns</li>
<li>Review detection criteria</li>
<li>Report false positives</li>
</ul>
<h3 id="missing-side-effects"><a class="header" href="#missing-side-effects">Missing Side Effects</a></h3>
<p><strong>Issue:</strong> Known impure functions not detected</p>
<p><strong>Solution:</strong></p>
<ul>
<li>Use strict profile</li>
<li>Check for exotic side effect patterns</li>
<li>Enable comprehensive analysis</li>
</ul>
<h3 id="performance-impact-concerns"><a class="header" href="#performance-impact-concerns">Performance impact concerns</a></h3>
<ul>
<li><strong>Spec 111 targets &lt;10% overhead</strong>: Performance impact should be minimal</li>
<li><strong>Disable for hot paths</strong>: Analyze functional patterns in separate runs if needed</li>
<li><strong>Use caching</strong>: Debtmap caches analysis results between runs</li>
</ul>
<h2 id="related-chapters-1"><a class="header" href="#related-chapters-1">Related Chapters</a></h2>
<ul>
<li><a href="analysis-guide.html">Analysis Guide</a> - Understanding analysis types</li>
<li><a href="./complexity-analysis.html">Complexity Analysis</a> - How functional patterns affect complexity metrics</li>
<li><a href="./scoring.html">Scoring Strategies</a> - Integration with overall technical debt scoring</li>
<li><a href="./god-objects.html">God Object Detection</a> - How purity weights reduce false positives</li>
<li><a href="./configuration.html">Configuration</a> - Advanced functional analysis configuration options</li>
<li><a href="refactoring-guide.html">Refactoring</a> - Extracting pure functions</li>
</ul>
<h2 id="summary-5"><a class="header" href="#summary-5">Summary</a></h2>
<p>Functional composition analysis helps you:</p>
<ul>
<li><strong>Identify functional patterns</strong> in your Rust codebase through AST-based pipeline detection</li>
<li><strong>Measure purity</strong> with side effect detection and immutability analysis</li>
<li><strong>Improve code quality</strong> by refactoring imperative code to functional style</li>
<li><strong>Get scoring benefits</strong> for high-quality functional programming patterns</li>
<li><strong>Choose appropriate profiles</strong> (strict/balanced/lenient) for different codebases</li>
</ul>
<p>Enable it with <code>--functional-analysis-profile</code> to start benefiting from functional programming insights in your technical debt analysis.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="god-object-detection-1"><a class="header" href="#god-object-detection-1">God Object Detection</a></h1>
<h2 id="overview-11"><a class="header" href="#overview-11">Overview</a></h2>
<p>Debtmap includes sophisticated god object detection that identifies files and types that have grown too large and taken on too many responsibilities. God objects (also called ‚Äúgod classes‚Äù or ‚Äúgod modules‚Äù) are a significant source of technical debt as they:</p>
<ul>
<li>Violate the Single Responsibility Principle</li>
<li>Become difficult to maintain and test</li>
<li>Create bottlenecks in development</li>
<li>Increase the risk of bugs due to high coupling</li>
<li>Have high coupling with many other modules</li>
<li>Are hard to test effectively</li>
</ul>
<p>This chapter explains how Debtmap identifies god objects, calculates their scores, and provides actionable refactoring recommendations.</p>
<h2 id="detection-criteria"><a class="header" href="#detection-criteria">Detection Criteria</a></h2>
<p>Debtmap uses two distinct detection strategies depending on the file structure:</p>
<h3 id="god-class-criteria"><a class="header" href="#god-class-criteria">God Class Criteria</a></h3>
<p>A struct/class is classified as a god class when it violates multiple thresholds:</p>
<ol>
<li><strong>Method Count</strong> - Number of impl methods on the struct</li>
<li><strong>Field Count</strong> - Number of struct/class fields</li>
<li><strong>Responsibility Count</strong> - Distinct responsibilities inferred from method names (max_traits in config)</li>
<li><strong>Lines of Code</strong> - Estimated lines for the struct and its impl blocks</li>
<li><strong>Complexity Sum</strong> - Combined cyclomatic complexity of struct methods</li>
</ol>
<p><strong>Note:</strong> All five criteria are evaluated by the <code>determine_confidence</code> function to calculate confidence levels. Each criterion that exceeds its threshold contributes to the violation count.</p>
<h3 id="god-module-criteria"><a class="header" href="#god-module-criteria">God Module Criteria</a></h3>
<p>A file is classified as a god module when it has excessive standalone functions:</p>
<ol>
<li><strong>Standalone Function Count</strong> - Total standalone functions (not in impl blocks)</li>
<li><strong>Responsibility Count</strong> - Distinct responsibilities across all functions</li>
<li><strong>Lines of Code</strong> - Total lines in the file</li>
<li><strong>Complexity Sum</strong> - Combined cyclomatic complexity (estimated as <code>function_count √ó 5</code>)</li>
</ol>
<p><strong>Key Difference:</strong> God class detection focuses on a single struct‚Äôs methods, while god module detection counts standalone functions across the entire file.</p>
<h3 id="language-specific-thresholds"><a class="header" href="#language-specific-thresholds">Language-Specific Thresholds</a></h3>
<h4 id="rust"><a class="header" href="#rust">Rust</a></h4>
<ul>
<li><strong>Max Methods</strong>: 20 (includes both impl methods and standalone functions)</li>
<li><strong>Max Fields</strong>: 15</li>
<li><strong>Max Responsibilities</strong>: 5</li>
<li><strong>Max Lines</strong>: 1000</li>
<li><strong>Max Complexity</strong>: 200</li>
</ul>
<h4 id="python"><a class="header" href="#python">Python</a></h4>
<ul>
<li><strong>Max Methods</strong>: 15</li>
<li><strong>Max Fields</strong>: 10</li>
<li><strong>Max Responsibilities</strong>: 3</li>
<li><strong>Max Lines</strong>: 500</li>
<li><strong>Max Complexity</strong>: 150</li>
</ul>
<h4 id="javascripttypescript"><a class="header" href="#javascripttypescript">JavaScript/TypeScript</a></h4>
<ul>
<li><strong>Max Methods</strong>: 15</li>
<li><strong>Max Fields</strong>: 20</li>
<li><strong>Max Responsibilities</strong>: 3</li>
<li><strong>Max Lines</strong>: 500</li>
<li><strong>Max Complexity</strong>: 150</li>
</ul>
<p><strong>Note:</strong> TypeScript uses the same thresholds as JavaScript since both languages have similar structural patterns. The implementation treats them identically for god object detection purposes.</p>
<p>These thresholds can be customized per-language in your <code>.debtmap.toml</code> configuration file.</p>
<h2 id="god-class-vs-god-module-detection"><a class="header" href="#god-class-vs-god-module-detection">God Class vs God Module Detection</a></h2>
<p>Debtmap distinguishes between two distinct types of god objects:</p>
<h3 id="god-class-detection"><a class="header" href="#god-class-detection">God Class Detection</a></h3>
<p>A <strong>god class</strong> is a single struct/class with excessive methods and fields. Debtmap analyzes the largest type in a file using:</p>
<ol>
<li>Find the largest type (struct/class) by <code>method_count + field_count √ó 2</code></li>
<li>Count <strong>only the impl methods</strong> for that struct</li>
<li>Check against thresholds:
<ul>
<li>Rust: &gt;20 methods, &gt;15 fields</li>
<li>Python: &gt;15 methods, &gt;10 fields</li>
<li>JavaScript/TypeScript: &gt;15 methods, &gt;20 fields</li>
</ul>
</li>
</ol>
<p><strong>Example:</strong> A struct with 25 methods and 18 fields would be flagged as a god class.</p>
<h3 id="god-module-detection"><a class="header" href="#god-module-detection">God Module Detection</a></h3>
<p>A <strong>god module</strong> is a file with excessive standalone functions (no dominant struct). Debtmap counts standalone functions when:</p>
<ol>
<li>No struct/class is found, OR</li>
<li>The file has many standalone functions outside of any impl blocks</li>
</ol>
<p><strong>Implementation Detail:</strong> Debtmap uses the <code>DetectionType</code> enum with three variants:</p>
<ul>
<li><code>GodClass</code> - Single struct with excessive methods/fields</li>
<li><code>GodFile</code> - File with excessive functions or lines of code</li>
<li><code>GodModule</code> - Alias for <code>GodFile</code> (both represent the same detection type)</li>
</ul>
<p>The <code>GodModule</code> variant is provided for clarity when discussing files with many standalone functions, but internally it‚Äôs the same as <code>GodFile</code>.</p>
<p><strong>Example:</strong> A file like <code>rust_call_graph.rs</code> with 270 standalone functions would be flagged as a god module (using the <code>GodFile</code>/<code>GodModule</code> detection type).</p>
<h3 id="why-separate-analysis"><a class="header" href="#why-separate-analysis">Why Separate Analysis?</a></h3>
<p>Previously, Debtmap combined standalone functions with struct methods, causing <strong>false positives</strong> for functional/procedural modules. The current implementation analyzes them separately to:</p>
<ul>
<li>Avoid penalizing pure functional modules</li>
<li>Distinguish between architectural issues (god class) and organizational issues (god module)</li>
<li>Provide more accurate refactoring recommendations</li>
</ul>
<p><strong>Key Distinction:</strong> A file containing a struct with 15 methods plus 20 standalone functions is analyzed as:</p>
<ul>
<li><strong>God Class:</strong> No (15 methods &lt; 20 threshold)</li>
<li><strong>God Module:</strong> Possibly (20 standalone functions, approaching threshold)</li>
</ul>
<p>See <code>src/organization/god_object_detector.rs:449-505</code> for implementation details.</p>
<h2 id="confidence-levels"><a class="header" href="#confidence-levels">Confidence Levels</a></h2>
<p>Debtmap assigns confidence levels based <strong>solely on the number of thresholds violated</strong>:</p>
<ul>
<li><strong>Definite</strong> (5 violations) - All five metrics exceed thresholds - clear god object requiring immediate refactoring</li>
<li><strong>Probable</strong> (3-4 violations) - Most metrics exceed thresholds - likely god object that should be refactored</li>
<li><strong>Possible</strong> (1-2 violations) - Some metrics exceed thresholds - potential god object worth reviewing</li>
<li><strong>NotGodObject</strong> (0 violations) - All metrics within acceptable limits</li>
</ul>
<p><strong>Note:</strong> The confidence level is determined by violation count alone. The god object score (calculated separately) is used for prioritization and ranking, but does not affect the confidence classification.</p>
<p><strong>Example:</strong> Consider two files both with <code>violation_count=2</code> (Possible confidence):</p>
<ul>
<li>File A: 21 methods, 16 fields (just over the threshold)</li>
<li>File B: 100 methods, 50 fields (severely over the threshold)</li>
</ul>
<p>Both receive the same ‚ÄúPossible‚Äù confidence level, but File B will have a much higher god object score for prioritization purposes. This separation ensures consistent confidence classification while still allowing scores to reflect severity.</p>
<p>See <code>src/organization/god_object_analysis.rs:236-268</code> for the <code>determine_confidence</code> function.</p>
<h2 id="scoring-algorithms"><a class="header" href="#scoring-algorithms">Scoring Algorithms</a></h2>
<p>Debtmap provides three scoring algorithms to accommodate different analysis needs.</p>
<h3 id="simple-scoring"><a class="header" href="#simple-scoring">Simple Scoring</a></h3>
<p>The base scoring algorithm calculates god object score using four factors:</p>
<pre><code>method_factor = min(method_count / max_methods, 3.0)
field_factor = min(field_count / max_fields, 3.0)
responsibility_factor = min(responsibility_count / 3, 3.0)
size_factor = min(lines_of_code / max_lines, 3.0)

base_score = method_factor √ó field_factor √ó responsibility_factor √ó size_factor
</code></pre>
<p><strong>Score Enforcement:</strong></p>
<ul>
<li>If <code>violation_count &gt; 0</code>: <code>final_score = max(base_score √ó 50 √ó violation_count, 100)</code></li>
<li>Else: <code>final_score = base_score √ó 10</code></li>
</ul>
<p>The minimum score of 100 ensures that any god object receives sufficient priority in the technical debt analysis.</p>
<h3 id="complexity-weighted-scoring"><a class="header" href="#complexity-weighted-scoring">Complexity-Weighted Scoring</a></h3>
<p>Unlike raw method counting, this algorithm weights each method by its cyclomatic complexity. This ensures that 100 simple functions (complexity 1-3) score better than 10 highly complex functions (complexity 17+).</p>
<p>The formula is similar to simple scoring, but uses <code>weighted_method_count</code> (sum of complexity weights) instead of raw counts:</p>
<pre><code>method_factor = min(weighted_method_count / max_methods, 3.0)
</code></pre>
<p>Additionally, a <strong>complexity factor</strong> is applied:</p>
<ul>
<li>Average complexity &lt; 3.0: <code>0.7</code> (reward simple functions)</li>
<li>Average complexity &gt; 10.0: <code>1.5</code> (penalize complex functions)</li>
<li>Otherwise: <code>1.0</code></li>
</ul>
<p>The final score becomes:</p>
<pre><code>final_score = max(base_score √ó 50 √ó complexity_factor √ó violation_count, 100)
</code></pre>
<p>This approach better reflects the true maintainability burden of a large module.</p>
<p>See <code>src/organization/god_object_analysis.rs:142-209</code>.</p>
<h3 id="purity-weighted-scoring-advanced"><a class="header" href="#purity-weighted-scoring-advanced">Purity-Weighted Scoring (Advanced)</a></h3>
<p><strong>Available for Rust only</strong> (requires <code>syn::ItemFn</code> analysis)</p>
<p>This advanced scoring variant combines both <strong>complexity weighting</strong> and <strong>purity analysis</strong>, building on top of complexity-weighted scoring to further reduce the impact of pure functions. This prevents pure functional modules from being unfairly penalized. The algorithm:</p>
<ol>
<li>
<p>Analyzes each function for purity using three levels:</p>
<ul>
<li>
<p><strong>Pure</strong> (no side effects): Functions with read-only operations, no I/O, no mutation</p>
<ul>
<li>Weight multiplier: <code>0.3</code></li>
<li>Examples: <code>calculate_sum()</code>, <code>format_string()</code>, <code>is_valid()</code></li>
</ul>
</li>
<li>
<p><strong>Probably Pure</strong> (likely no side effects): Functions that appear pure but may have hidden side effects</p>
<ul>
<li>Weight multiplier: <code>0.5</code></li>
<li>Examples: Functions using trait methods (could have side effects), generic operations</li>
</ul>
</li>
<li>
<p><strong>Impure</strong> (has side effects): Functions with clear side effects like I/O, mutation, external calls</p>
<ul>
<li>Weight multiplier: <code>1.0</code></li>
<li>Examples: <code>save_to_file()</code>, <code>update_state()</code>, <code>send_request()</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Purity Detection Heuristics:</p>
<ul>
<li><strong>Pure indicators</strong>: No <code>mut</code> references, no I/O operations, no external function calls</li>
<li><strong>Impure indicators</strong>: File/network operations, mutable state, database access, logging</li>
<li><strong>Probably Pure</strong>: Generic functions, trait method calls, or ambiguous patterns</li>
</ul>
</li>
<li>
<p>Combines complexity and purity weights to calculate the total contribution:</p>
<pre><code>total_weight = complexity_weight √ó purity_multiplier
</code></pre>
<p>This means pure functions get both the complexity-based weight AND the purity multiplier applied together.</p>
<p><strong>Example:</strong> A pure function with complexity 5 contributes only <code>5 √ó 0.3 = 1.5</code> to the weighted count (compared to 5.0 for an impure function of the same complexity).</p>
</li>
<li>
<p>Tracks the <code>PurityDistribution</code>:</p>
<ul>
<li><code>pure_count</code>, <code>probably_pure_count</code>, <code>impure_count</code></li>
<li><code>pure_weight_contribution</code>, <code>probably_pure_weight_contribution</code>, <code>impure_weight_contribution</code></li>
</ul>
</li>
</ol>
<p><strong>Impact:</strong> A file with 100 pure helper functions (total complexity 150) might have a weighted method count of only <code>150 √ó 0.3 = 45</code>, avoiding false positives while still catching stateful god objects with many impure methods.</p>
<p>See <code>src/organization/god_object_detector.rs:196-258</code> and <code>src/organization/purity_analyzer.rs</code>.</p>
<h2 id="responsibility-detection"><a class="header" href="#responsibility-detection">Responsibility Detection</a></h2>
<p>Responsibilities are inferred from method names using common prefixes. Debtmap recognizes the following categories:</p>
<div class="table-wrapper"><table><thead><tr><th>Prefix(es)</th><th>Responsibility Category</th></tr></thead><tbody>
<tr><td><code>format</code>, <code>render</code>, <code>write</code>, <code>print</code></td><td>Formatting &amp; Output</td></tr>
<tr><td><code>parse</code>, <code>read</code>, <code>extract</code></td><td>Parsing &amp; Input</td></tr>
<tr><td><code>filter</code>, <code>select</code>, <code>find</code></td><td>Filtering &amp; Selection</td></tr>
<tr><td><code>transform</code>, <code>convert</code>, <code>map</code>, <code>apply</code></td><td>Transformation</td></tr>
<tr><td><code>get</code>, <code>set</code></td><td>Data Access</td></tr>
<tr><td><code>validate</code>, <code>check</code>, <code>verify</code>, <code>is</code></td><td>Validation</td></tr>
<tr><td><code>calculate</code>, <code>compute</code></td><td>Computation</td></tr>
<tr><td><code>create</code>, <code>build</code>, <code>new</code></td><td>Construction</td></tr>
<tr><td><code>save</code>, <code>load</code>, <code>store</code></td><td>Persistence</td></tr>
<tr><td><code>process</code>, <code>handle</code></td><td>Processing</td></tr>
<tr><td><code>send</code>, <code>receive</code></td><td>Communication</td></tr>
<tr><td><em>(no prefix match)</em></td><td>Utilities</td></tr>
</tbody></table>
</div>
<p><strong>Note:</strong> <code>Utilities</code> serves as both a category in the responsibility list and the fallback when no prefix matches. In the implementation, <code>Utilities</code> is included in <code>RESPONSIBILITY_CATEGORIES</code> with an empty prefixes array, making it the catch-all category returned by <code>infer_responsibility_from_method</code> when no other category matches.</p>
<p><strong>Distinct Responsibility Counting:</strong> Debtmap counts the number of <strong>unique</strong> responsibility categories used by a struct/module‚Äôs methods. A high responsibility count (e.g., &gt;5) indicates the module is handling too many different concerns, violating the Single Responsibility Principle.</p>
<p>Responsibility count directly affects:</p>
<ul>
<li>God object scoring (via <code>responsibility_factor</code>)</li>
<li>Refactoring recommendations (methods grouped by responsibility for suggested splits)</li>
<li>Detection confidence (counted as one of the five violation criteria)</li>
</ul>
<p>See <code>src/organization/god_object_analysis.rs:318-388</code> for the <code>infer_responsibility_from_method</code> function.</p>
<h2 id="examples-and-case-studies"><a class="header" href="#examples-and-case-studies">Examples and Case Studies</a></h2>
<h3 id="example-1-large-rust-module"><a class="header" href="#example-1-large-rust-module">Example 1: Large Rust Module</a></h3>
<p><strong>File:</strong> <code>rust_call_graph.rs</code> with 270 standalone functions</p>
<p><strong>Detection:</strong></p>
<ul>
<li><strong>Is God Object:</strong> Yes</li>
<li><strong>Method Count:</strong> 270</li>
<li><strong>Field Count:</strong> 0 (no struct)</li>
<li><strong>Responsibilities:</strong> 8</li>
<li><strong>Confidence:</strong> Definite</li>
<li><strong>Score:</strong> &gt;1000 (severe violation)</li>
</ul>
<p><strong>Recommendation:</strong> Break into multiple focused modules:</p>
<ul>
<li><code>CallGraphBuilder</code> (construction methods)</li>
<li><code>CallGraphAnalyzer</code> (analysis methods)</li>
<li><code>CallGraphFormatter</code> (output methods)</li>
</ul>
<h3 id="example-2-complex-python-class"><a class="header" href="#example-2-complex-python-class">Example 2: Complex Python Class</a></h3>
<p><strong>File:</strong> <code>data_manager.py</code> with class containing 25 methods and 12 fields</p>
<p><strong>Detection:</strong></p>
<ul>
<li><strong>Is God Object:</strong> Yes</li>
<li><strong>Method Count:</strong> 25</li>
<li><strong>Field Count:</strong> 12</li>
<li><strong>Responsibilities:</strong> 6 (Data Access, Validation, Persistence, etc.)</li>
<li><strong>Confidence:</strong> Probable</li>
<li><strong>Score:</strong> ~150-200</li>
</ul>
<p><strong>Recommendation:</strong> Split by responsibility:</p>
<ul>
<li><code>DataAccessLayer</code> (get/set methods)</li>
<li><code>DataValidator</code> (validate/check methods)</li>
<li><code>DataPersistence</code> (save/load methods)</li>
</ul>
<h3 id="example-3-mixed-paradigm-file-god-module"><a class="header" href="#example-3-mixed-paradigm-file-god-module">Example 3: Mixed Paradigm File (God Module)</a></h3>
<p><strong>File:</strong> <code>utils.rs</code> with small struct (5 methods, 3 fields) + 60 standalone functions</p>
<p><strong>Detection:</strong></p>
<ul>
<li><strong>God Class (struct):</strong> No (5 methods &lt; 20 threshold, 3 fields &lt; 15 threshold)</li>
<li><strong>God Module (file):</strong> Yes (60 standalone functions &gt; 50 threshold)</li>
<li><strong>Confidence:</strong> Probable</li>
<li><strong>Score:</strong> ~120</li>
</ul>
<p><strong>Analysis:</strong> The struct and standalone functions are analyzed separately. The struct is not a god class, but the file is a god module due to the excessive standalone functions. This indicates an overgrown utility module that should be split into smaller, focused modules.</p>
<p><strong>Recommendation:</strong> Split standalone functions into focused utility modules:</p>
<ul>
<li><code>StringUtils</code> (formatting, parsing)</li>
<li><code>FileUtils</code> (file operations)</li>
<li><code>MathUtils</code> (calculations)</li>
</ul>
<h2 id="refactoring-recommendations-5"><a class="header" href="#refactoring-recommendations-5">Refactoring Recommendations</a></h2>
<p>When <code>is_god_object = true</code>, Debtmap generates <strong>recommended module splits</strong> using the <code>recommend_module_splits</code> function. This feature:</p>
<ol>
<li>
<p>Groups methods by their inferred responsibilities</p>
</li>
<li>
<p>Creates a <code>ModuleSplit</code> for each responsibility group containing:</p>
<ul>
<li><code>suggested_name</code> (e.g., ‚ÄúDataAccessManager‚Äù, ‚ÄúValidationManager‚Äù)</li>
<li><code>methods_to_move</code> (list of method names)</li>
<li><code>responsibility</code> (category name)</li>
<li><code>estimated_lines</code> (approximate LOC for the new module)</li>
</ul>
</li>
<li>
<p>Orders splits by cohesion (most focused responsibility groups first)</p>
</li>
</ol>
<p><strong>Example output:</strong></p>
<pre><code>Recommended Splits:
  1. DataAccessManager (12 methods, ~150 lines)
  2. ValidationManager (8 methods, ~100 lines)
  3. PersistenceManager (5 methods, ~75 lines)
</code></pre>
<p>This provides an actionable roadmap for breaking down god objects into focused, single-responsibility modules.</p>
<p>See <code>src/organization/god_object_detector.rs:165-177</code> and <code>src/organization/god_object_analysis.rs:40-45</code>.</p>
<h3 id="code-examples"><a class="header" href="#code-examples">Code Examples</a></h3>
<h4 id="split-by-responsibility"><a class="header" href="#split-by-responsibility">Split by Responsibility</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Before: UserManager (god object)
struct UserManager { ... }

// After: Split into focused modules
struct AuthService { ... }
struct ProfileService { ... }
struct PermissionService { ... }
struct NotificationService { ... }
<span class="boring">}</span></code></pre></pre>
<h4 id="extract-common-functionality"><a class="header" href="#extract-common-functionality">Extract Common Functionality</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Extract shared dependencies
struct ServiceContext {
    db: Database,
    cache: Cache,
    logger: Logger,
}

// Each service gets a reference
struct AuthService&lt;'a&gt; {
    context: &amp;'a ServiceContext,
}
<span class="boring">}</span></code></pre></pre>
<h4 id="use-composition"><a class="header" href="#use-composition">Use Composition</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Compose services instead of inheriting
struct UserFacade {
    auth: AuthService,
    profile: ProfileService,
    permissions: PermissionService,
}

impl UserFacade {
    fn login(&amp;mut self, credentials: Credentials) -&gt; Result&lt;Session&gt; {
        self.auth.login(credentials)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-9"><a class="header" href="#configuration-9">Configuration</a></h2>
<h3 id="toml-configuration-1"><a class="header" href="#toml-configuration-1">TOML Configuration</a></h3>
<p>Add a <code>[god_object_detection]</code> section to your <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[god_object_detection]
enabled = true

[god_object_detection.rust]
max_methods = 20
max_fields = 15
max_traits = 5      # max_traits = max responsibilities
max_lines = 1000
max_complexity = 200

# Note: The configuration field is named 'max_traits' for historical reasons,
# but it controls the maximum number of responsibilities/concerns, not Rust traits.
# This is a legacy naming issue from early development.

[god_object_detection.python]
max_methods = 15
max_fields = 10
max_traits = 3
max_lines = 500
max_complexity = 150

[god_object_detection.javascript]
max_methods = 15
max_fields = 20
max_traits = 3
max_lines = 500
max_complexity = 150
</code></pre>
<p><strong>Note:</strong> <code>enabled</code> defaults to <code>true</code>. Set to <code>false</code> to disable god object detection entirely (equivalent to <code>--no-god-object</code> CLI flag).</p>
<p>See <code>src/config.rs:500-582</code>.</p>
<h3 id="tuning-for-your-project-1"><a class="header" href="#tuning-for-your-project-1">Tuning for Your Project</a></h3>
<p><strong>Strict mode (smaller modules):</strong></p>
<pre><code class="language-toml">[god_object_detection.rust]
max_methods = 15
max_fields = 10
max_traits = 3
</code></pre>
<p><strong>Lenient mode (larger modules acceptable):</strong></p>
<pre><code class="language-toml">[god_object_detection.rust]
max_methods = 30
max_fields = 20
max_traits = 7
</code></pre>
<h3 id="cli-options-1"><a class="header" href="#cli-options-1">CLI Options</a></h3>
<p>Debtmap provides several CLI flags to control god object detection behavior:</p>
<h4 id="--no-god-object"><a class="header" href="#--no-god-object"><code>--no-god-object</code></a></h4>
<p>Disables god object detection entirely.</p>
<pre><code class="language-bash">debtmap analyze . --no-god-object
</code></pre>
<p><strong>Use case:</strong> When you only want function-level complexity analysis without file-level aggregation.</p>
<h4 id="--aggregate-only"><a class="header" href="#--aggregate-only"><code>--aggregate-only</code></a></h4>
<p>Shows only file-level god object scores, hiding individual function details.</p>
<pre><code class="language-bash">debtmap analyze . --aggregate-only
</code></pre>
<p><strong>Use case:</strong> High-level overview of which files are god objects without function-by-function breakdowns.</p>
<h4 id="--no-aggregation"><a class="header" href="#--no-aggregation"><code>--no-aggregation</code></a></h4>
<p>Disables file-level aggregation, showing only individual function metrics.</p>
<pre><code class="language-bash">debtmap analyze . --no-aggregation
</code></pre>
<p><strong>Use case:</strong> Detailed function-level analysis without combining into file scores.</p>
<h4 id="--aggregation-method-method"><a class="header" href="#--aggregation-method-method"><code>--aggregation-method &lt;METHOD&gt;</code></a></h4>
<p>Chooses how to combine function scores into file-level scores:</p>
<ul>
<li><code>sum</code> - Add all function scores</li>
<li><code>weighted_sum</code> - Weight by complexity (default)</li>
<li><code>logarithmic_sum</code> - Logarithmic scaling for large files</li>
<li><code>max_plus_average</code> - Max score + average of others</li>
</ul>
<pre><code class="language-bash">debtmap analyze . --aggregation-method logarithmic_sum
</code></pre>
<h4 id="--min-problematic-n"><a class="header" href="#--min-problematic-n"><code>--min-problematic &lt;N&gt;</code></a></h4>
<p>Sets minimum number of problematic functions required for file-level aggregation.</p>
<pre><code class="language-bash">debtmap analyze . --min-problematic 3
</code></pre>
<p><strong>Use case:</strong> Avoid flagging files with only 1-2 complex functions as god objects.</p>
<p>See <code>features.json:65-71</code> and <code>features.json:507-512</code>.</p>
<h2 id="output-display-1"><a class="header" href="#output-display-1">Output Display</a></h2>
<h3 id="file-level-display"><a class="header" href="#file-level-display">File-Level Display</a></h3>
<p>When a god object is detected, Debtmap displays:</p>
<pre><code>‚ö†Ô∏è God Object: 270 methods, 0 fields, 8 responsibilities
Score: 1350 (Confidence: Definite)
</code></pre>
<h3 id="function-level-display"><a class="header" href="#function-level-display">Function-Level Display</a></h3>
<p>Within a god object file, individual functions show:</p>
<pre><code>‚îú‚îÄ ‚ö†Ô∏è God Object: 45 methods, 20 fields, 5 responsibilities
‚îÇ      Score: 250 (Confidence: Probable)
</code></pre>
<p>The <code>‚ö†Ô∏è God Object</code> indicator makes it immediately clear which files need architectural refactoring.</p>
<h2 id="integration-with-file-level-scoring"><a class="header" href="#integration-with-file-level-scoring">Integration with File-Level Scoring</a></h2>
<p>God object detection affects the overall technical debt prioritization through a <strong>god object multiplier</strong>:</p>
<pre><code>god_object_multiplier = 2.0 + normalized_god_object_score
</code></pre>
<h3 id="normalization-1"><a class="header" href="#normalization-1">Normalization</a></h3>
<p>The <code>normalized_god_object_score</code> is scaled to the 0-1 range using:</p>
<pre><code>normalized_score = min(god_object_score / max_expected_score, 1.0)
</code></pre>
<p>Where <code>max_expected_score</code> is typically based on the maximum score in the analysis (e.g., 1000 for severe violations).</p>
<h3 id="impact-on-prioritization"><a class="header" href="#impact-on-prioritization">Impact on Prioritization</a></h3>
<p>This multiplier means:</p>
<ol>
<li><strong>Non-god objects</strong> (score = 0): multiplier = 2.0 (baseline)</li>
<li><strong>Moderate god objects</strong> (score = 200): multiplier ‚âà 2.2-2.5</li>
<li><strong>Severe god objects</strong> (score = 1000+): multiplier ‚âà 3.0 (maximum)</li>
</ol>
<p><strong>Result:</strong> God objects receive <strong>2-3√ó higher priority</strong> in debt rankings, ensuring that:</p>
<ul>
<li>Functions within god objects inherit elevated scores due to architectural concerns</li>
<li>God objects surface in the ‚Äútop 10 most problematic‚Äù lists</li>
<li>Architectural debt is weighted appropriately alongside function-level complexity</li>
</ul>
<p>See file-level scoring documentation for complete details on how this multiplier integrates into the overall debt calculation.</p>
<h2 id="metrics-tracking-advanced"><a class="header" href="#metrics-tracking-advanced">Metrics Tracking (Advanced)</a></h2>
<p>For teams tracking god object evolution over time, Debtmap provides <code>GodObjectMetrics</code> with:</p>
<ul>
<li><strong>Snapshots</strong> - Historical god object data per file</li>
<li><strong>Trends</strong> - Improving/Stable/Worsening classification (based on ¬±10 point score changes)</li>
<li><strong>New God Objects</strong> - Files that crossed the threshold</li>
<li><strong>Resolved God Objects</strong> - Files that were refactored below thresholds</li>
</ul>
<p>This enables longitudinal analysis: ‚ÄúAre we reducing god objects sprint-over-sprint?‚Äù</p>
<p>See <code>src/organization/god_object_metrics.rs:1-228</code>.</p>
<h2 id="troubleshooting-15"><a class="header" href="#troubleshooting-15">Troubleshooting</a></h2>
<h3 id="why-is-my-functional-module-flagged-as-a-god-object"><a class="header" href="#why-is-my-functional-module-flagged-as-a-god-object">‚ÄúWhy is my functional module flagged as a god object?‚Äù</a></h3>
<p><strong>Answer:</strong> Debtmap now analyzes god classes (structs) separately from god modules (standalone functions). If your functional module with 100 pure helper functions is flagged, it‚Äôs being detected as a <strong>god module</strong> (not a god class), which indicates the file has grown too large and should be split for better organization.</p>
<p><strong>Solutions:</strong></p>
<ol>
<li><strong>Accept the finding</strong>: 100+ functions in one file is difficult to navigate and maintain, even if each function is simple</li>
<li><strong>Split by responsibility</strong>: Organize functions into smaller, focused modules (e.g., <code>string_utils.rs</code>, <code>file_utils.rs</code>, <code>math_utils.rs</code>)</li>
<li><strong>Use purity-weighted scoring</strong> (Rust only): Pure functions contribute only 0.3√ó weight, dramatically reducing scores for functional modules</li>
<li><strong>Adjust thresholds</strong>: Increase <code>max_methods</code> in <code>.debtmap.toml</code> if your project standards allow larger modules</li>
</ol>
<h3 id="my-god-object-score-seems-too-high"><a class="header" href="#my-god-object-score-seems-too-high">‚ÄúMy god object score seems too high‚Äù</a></h3>
<p><strong>Answer:</strong> The scoring algorithm uses exponential scaling (<code>base_score √ó 50 √ó violation_count</code>) to ensure god objects are prioritized.</p>
<p><strong>Solutions:</strong></p>
<ol>
<li>Check the violation count - 5 violations means severe issues</li>
<li>Review each metric - are method count, field count, responsibilities, LOC, and complexity all high?</li>
<li>Consider if the score accurately reflects maintainability burden</li>
</ol>
<h3 id="can-i-disable-god-object-detection-for-specific-files"><a class="header" href="#can-i-disable-god-object-detection-for-specific-files">‚ÄúCan I disable god object detection for specific files?‚Äù</a></h3>
<p><strong>Answer:</strong> Currently, god object detection is global. However, you can:</p>
<ol>
<li>Use <code>--no-god-object</code> to disable entirely</li>
<li>Use <code>--no-aggregation</code> to skip file-level analysis</li>
<li>Adjust thresholds in <code>.debtmap.toml</code> to be more lenient</li>
</ol>
<h2 id="best-practices-13"><a class="header" href="#best-practices-13">Best Practices</a></h2>
<p>To avoid god objects:</p>
<ol>
<li><strong>Follow Single Responsibility Principle</strong> - Each module should have one clear purpose</li>
<li><strong>Regular Refactoring</strong> - Split modules before they reach thresholds</li>
<li><strong>Monitor Growth</strong> - Track method and field counts as modules evolve</li>
<li><strong>Use Composition</strong> - Prefer smaller, composable units over large monoliths</li>
<li><strong>Clear Boundaries</strong> - Define clear module interfaces and responsibilities</li>
<li><strong>Leverage Purity</strong> - Keep pure functions separate from stateful logic (reduces scores in Rust)</li>
<li><strong>Set Project Thresholds</strong> - Customize <code>.debtmap.toml</code> to match your team‚Äôs standards</li>
</ol>
<h2 id="configuration-tradeoffs"><a class="header" href="#configuration-tradeoffs">Configuration Tradeoffs</a></h2>
<p><strong>Strict Thresholds</strong> (e.g., Rust: 10 methods):</p>
<ul>
<li>‚úÖ Catch problems early</li>
<li>‚úÖ Enforce strong modularity</li>
<li>‚ùå May flag legitimate large modules</li>
<li>‚ùå More noise in reports</li>
</ul>
<p><strong>Lenient Thresholds</strong> (e.g., Rust: 50 methods):</p>
<ul>
<li>‚úÖ Reduce false positives</li>
<li>‚úÖ Focus on egregious violations</li>
<li>‚ùå Miss real god objects</li>
<li>‚ùå Allow technical debt to grow</li>
</ul>
<p><strong>Recommended:</strong> Start with defaults, then adjust based on your codebase‚Äôs characteristics. Use metrics tracking to monitor trends over time.</p>
<h2 id="related-documentation-2"><a class="header" href="#related-documentation-2">Related Documentation</a></h2>
<ul>
<li><a href="./file-level-scoring.html">File-Level Scoring</a> - How god objects affect overall file scores</li>
<li><a href="./configuration.html">Configuration</a> - Complete <code>.debtmap.toml</code> reference</li>
<li><a href="./cli-reference.html">CLI Reference</a> - All command-line options</li>
<li><a href="./tiered-prioritization.html">Tiered Prioritization</a> - How god objects are prioritized</li>
</ul>
<h2 id="summary-6"><a class="header" href="#summary-6">Summary</a></h2>
<p>God object detection is a powerful architectural analysis feature that:</p>
<ul>
<li>Identifies files/types violating single responsibility principle</li>
<li>Provides multiple scoring algorithms (simple, complexity-weighted, purity-weighted)</li>
<li>Generates actionable refactoring recommendations</li>
<li>Integrates with file-level scoring for holistic debt prioritization</li>
<li>Supports customization via TOML config and CLI flags</li>
</ul>
<p>By combining quantitative metrics (method count, LOC, complexity) with qualitative analysis (responsibility detection, purity), Debtmap helps teams systematically address architectural debt.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multi-pass-analysis"><a class="header" href="#multi-pass-analysis">Multi-Pass Analysis</a></h1>
<p>Multi-pass analysis is an advanced feature that performs two separate complexity analyses on your code to distinguish between genuine logical complexity and complexity artifacts introduced by code formatting. By comparing raw and normalized versions of your code, debtmap can attribute complexity to specific sources and provide actionable insights for refactoring.</p>
<h2 id="overview-12"><a class="header" href="#overview-12">Overview</a></h2>
<p>Traditional complexity analysis treats all code as-is, which means formatting choices like multiline expressions, whitespace, and indentation can artificially inflate complexity metrics. Multi-pass analysis solves this problem by:</p>
<ol>
<li><strong>Raw Analysis</strong> - Measures complexity of code exactly as written</li>
<li><strong>Normalized Analysis</strong> - Measures complexity after removing formatting artifacts</li>
<li><strong>Attribution</strong> - Compares the two analyses to identify complexity sources</li>
</ol>
<p>The difference between raw and normalized complexity reveals how much ‚Äúcomplexity‚Äù comes from formatting versus genuine logical complexity from control flow, branching, and nesting.</p>
<h2 id="how-it-works-4"><a class="header" href="#how-it-works-4">How It Works</a></h2>
<h3 id="two-pass-analysis-process"><a class="header" href="#two-pass-analysis-process">Two-Pass Analysis Process</a></h3>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Raw Code   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                     ‚îÇ
       ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Raw Analysis ‚îÇ    ‚îÇ Normalize Formatting‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                      ‚îÇ
       ‚îÇ                      ‚ñº
       ‚îÇ            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ            ‚îÇ Normalized Analysis  ‚îÇ
       ‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                      ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Attribution      ‚îÇ
         ‚îÇ Engine           ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                    ‚îÇ
         ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Insights        ‚îÇ  ‚îÇ Recommendations ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<p><strong>Raw Analysis</strong> examines your code as-is, capturing all complexity including:</p>
<ul>
<li>Logical control flow (if, loops, match, try/catch)</li>
<li>Function calls and closures</li>
<li>Formatting artifacts (multiline expressions, whitespace, indentation)</li>
</ul>
<p><strong>Normalized Analysis</strong> processes semantically equivalent code with standardized formatting:</p>
<ul>
<li>Removes excessive whitespace</li>
<li>Normalizes multiline expressions to single lines where appropriate</li>
<li>Standardizes indentation</li>
<li>Preserves logical structure</li>
</ul>
<p><strong>Attribution Engine</strong> compares the results to categorize complexity sources:</p>
<ul>
<li><strong>Logical Complexity</strong> - From control flow and branching (normalized result)</li>
<li><strong>Formatting Artifacts</strong> - From code formatting choices (difference between raw and normalized)</li>
<li><strong>Pattern Complexity</strong> - From recognized code patterns (error handling, validation, etc.)</li>
</ul>
<blockquote>
<p><strong>Note</strong>: Pattern complexity analysis is part of the standard multi-pass analysis. No additional configuration is required to enable pattern detection.</p>
</blockquote>
<h2 id="cli-usage-1"><a class="header" href="#cli-usage-1">CLI Usage</a></h2>
<p>Enable multi-pass analysis with the <code>--multi-pass</code> flag:</p>
<pre><code class="language-bash"># Basic multi-pass analysis
debtmap analyze . --multi-pass

# Multi-pass with detailed attribution breakdown
debtmap analyze . --multi-pass --attribution

# Control detail level
debtmap analyze . --multi-pass --attribution --detail-level comprehensive

# Output as JSON for tooling integration
debtmap analyze . --multi-pass --attribution --json
</code></pre>
<h3 id="available-flags"><a class="header" href="#available-flags">Available Flags</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Flag</th><th>Description</th></tr></thead><tbody>
<tr><td><code>--multi-pass</code></td><td>Enable two-pass analysis (raw + normalized)</td></tr>
<tr><td><code>--attribution</code></td><td>Show detailed complexity attribution breakdown (requires <code>--multi-pass</code>)</td></tr>
<tr><td><code>--detail-level &lt;level&gt;</code></td><td>Set output detail: <code>summary</code>, <code>standard</code>, <code>comprehensive</code>, <code>debug</code></td></tr>
<tr><td><code>--json</code></td><td>Output results in JSON format</td></tr>
</tbody></table>
</div>
<blockquote>
<p><strong>Note</strong>: The <code>--attribution</code> flag requires <code>--multi-pass</code> to be enabled, as attribution depends on comparing raw and normalized analyses.</p>
</blockquote>
<h2 id="attribution-engine"><a class="header" href="#attribution-engine">Attribution Engine</a></h2>
<p>The attribution engine breaks down complexity into three main categories, each with detailed tracking and suggestions.</p>
<h3 id="logical-complexity"><a class="header" href="#logical-complexity">Logical Complexity</a></h3>
<p>Represents inherent complexity from your code‚Äôs control flow and structure:</p>
<ul>
<li><strong>Function complexity</strong> - Cyclomatic and cognitive complexity per function</li>
<li><strong>Control flow</strong> - If statements, loops, match expressions</li>
<li><strong>Error handling</strong> - Try/catch blocks, Result/Option handling</li>
<li><strong>Closures and callbacks</strong> - Anonymous functions and callbacks</li>
<li><strong>Nesting levels</strong> - Depth of nested control structures</li>
</ul>
<p>Each logical complexity component includes:</p>
<ul>
<li><strong>Contribution</strong> - Complexity points from this construct</li>
<li><strong>Location</strong> - File, line, column, and span information</li>
<li><strong>Suggestions</strong> - Specific refactoring recommendations</li>
</ul>
<p>Example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Function with high logical complexity
fn process_data(items: Vec&lt;Item&gt;) -&gt; Result&lt;Vec&lt;Output&gt;&gt; {
    let mut results = Vec::new();

    for item in items {                          // +1 (loop)
        if item.is_valid() {                     // +1 (if)
            match item.category {                // +1 (match)
                Category::A =&gt; {
                    if item.value &gt; 100 {        // +2 (nested if)
                        results.push(transform_a(&amp;item)?);
                    }
                }
                Category::B =&gt; {
                    results.push(transform_b(&amp;item)?);
                }
                _ =&gt; continue,                   // +1 (match arm)
            }
        }
    }

    Ok(results)
}
// Logical complexity: ~7 points
<span class="boring">}</span></code></pre></pre>
<h3 id="formatting-artifacts"><a class="header" href="#formatting-artifacts">Formatting Artifacts</a></h3>
<p>Identifies complexity introduced by code formatting choices:</p>
<ul>
<li><strong>Multiline expressions</strong> - Long expressions split across multiple lines</li>
<li><strong>Excessive whitespace</strong> - Blank lines within code blocks</li>
<li><strong>Inconsistent indentation</strong> - Mixed tabs/spaces or irregular indentation</li>
<li><strong>Line breaks in chains</strong> - Method chains split across many lines</li>
</ul>
<p>Formatting artifacts are categorized by severity:</p>
<ul>
<li><strong>Low</strong> - Minor formatting inconsistencies (&lt;10% impact)</li>
<li><strong>Medium</strong> - Noticeable formatting impact (10-25% impact)</li>
<li><strong>High</strong> - Significant complexity inflation (&gt;25% impact)</li>
</ul>
<p>Example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Same function with formatting that inflates complexity
fn process_data(
    items: Vec&lt;Item&gt;
) -&gt; Result&lt;Vec&lt;Output&gt;&gt; {
    let mut results =
        Vec::new();

    for item in
        items
    {
        if item
            .is_valid()
        {
            match item
                .category
            {
                Category::A =&gt;
                {
                    if item
                        .value
                        &gt; 100
                    {
                        results
                            .push(
                                transform_a(
                                    &amp;item
                                )?
                            );
                    }
                }
                Category::B =&gt;
                {
                    results
                        .push(
                            transform_b(
                                &amp;item
                            )?
                        );
                }
                _ =&gt; continue,
            }
        }
    }

    Ok(results)
}
// Raw complexity: ~12 points (formatting adds ~5 points)
// Normalized complexity: ~7 points (true logical complexity)
<span class="boring">}</span></code></pre></pre>
<h3 id="pattern-complexity"><a class="header" href="#pattern-complexity">Pattern Complexity</a></h3>
<p>Recognizes common code patterns and their complexity characteristics:</p>
<ul>
<li><strong>Error handling patterns</strong> - Result/Option propagation, error conversion</li>
<li><strong>Validation patterns</strong> - Input validation, constraint checking</li>
<li><strong>Data transformation</strong> - Map/filter/fold chains, data conversions</li>
<li><strong>Builder patterns</strong> - Fluent interfaces and builders</li>
<li><strong>State machines</strong> - Explicit state management</li>
</ul>
<p>Each pattern includes:</p>
<ul>
<li><strong>Confidence score</strong> (0.0-1.0) - How certain the pattern recognition is</li>
<li><strong>Opportunities</strong> - Suggestions for pattern extraction or improvement</li>
</ul>
<p>Example:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Error handling pattern (confidence: 0.85)
fn load_config(path: &amp;Path) -&gt; Result&lt;Config&gt; {
    let contents = fs::read_to_string(path)
        .context("Failed to read config file")?;

    let config: Config = serde_json::from_str(&amp;contents)
        .context("Failed to parse config JSON")?;

    config.validate()
        .context("Config validation failed")?;

    Ok(config)
}
// Pattern complexity: moderate error handling overhead
// Suggestion: Consider error enum for better type safety
<span class="boring">}</span></code></pre></pre>
<h2 id="understanding-attribution-output"><a class="header" href="#understanding-attribution-output">Understanding Attribution Output</a></h2>
<p>When you run with <code>--attribution</code>, you‚Äôll see a detailed breakdown:</p>
<pre><code class="language-bash">$ debtmap analyze src/main.rs --multi-pass --attribution --detail-level comprehensive
</code></pre>
<h3 id="sample-output"><a class="header" href="#sample-output">Sample Output</a></h3>
<pre><code>Multi-Pass Analysis Results
============================

File: src/main.rs
Raw Complexity: 45
Normalized Complexity: 32
Formatting Impact: 28.9%

Attribution Breakdown
---------------------

Logical Complexity: 32 points
‚îú‚îÄ Function 'main' (line 10): 8 points
‚îÇ  ‚îú‚îÄ Control flow: 5 points (2 if, 1 match, 2 loops)
‚îÇ  ‚îú‚îÄ Nesting: 3 points (max depth: 3)
‚îÇ  ‚îî‚îÄ Suggestions:
‚îÇ     - Break down into smaller functions
‚îÇ     - Extract complex conditions into named variables
‚îÇ
‚îú‚îÄ Function 'process_request' (line 45): 12 points
‚îÇ  ‚îú‚îÄ Control flow: 8 points (4 if, 1 match, 3 early returns)
‚îÇ  ‚îú‚îÄ Nesting: 4 points (max depth: 4)
‚îÇ  ‚îî‚îÄ Suggestions:
‚îÇ     - Consider using early returns to reduce nesting
‚îÇ     - Extract validation logic into separate function
‚îÇ
‚îî‚îÄ Function 'handle_error' (line 89): 12 points
   ‚îú‚îÄ Control flow: 9 points (5 match arms, 4 if conditions)
   ‚îú‚îÄ Pattern: Error handling (confidence: 0.90)
   ‚îî‚îÄ Suggestions:
      - Consider error enum instead of multiple match arms

Formatting Artifacts: 13 points (28.9% of raw complexity)
‚îú‚îÄ Multiline expressions: 8 points (Medium severity)
‚îÇ  ‚îî‚îÄ Locations: lines 23, 45, 67, 89
‚îú‚îÄ Excessive whitespace: 3 points (Low severity)
‚îÇ  ‚îî‚îÄ Locations: lines 12-14, 56-58
‚îî‚îÄ Inconsistent indentation: 2 points (Low severity)
   ‚îî‚îÄ Locations: lines 34, 78

Pattern Complexity: 3 recognized patterns
‚îú‚îÄ Error handling (confidence: 0.85): 8 occurrences
‚îÇ  ‚îî‚îÄ Opportunity: Consider centralizing error handling
‚îú‚îÄ Validation (confidence: 0.72): 5 occurrences
‚îÇ  ‚îî‚îÄ Opportunity: Extract validation to separate module
‚îî‚îÄ Data transformation (confidence: 0.68): 3 occurrences
   ‚îî‚îÄ Opportunity: Review for functional composition
</code></pre>
<h3 id="interpreting-the-results"><a class="header" href="#interpreting-the-results">Interpreting the Results</a></h3>
<p><strong>Logical Complexity Breakdown</strong></p>
<ul>
<li>Each function is listed with its complexity contribution</li>
<li>Control flow elements are itemized (if, loops, match, etc.)</li>
<li>Nesting depth shows how deeply structures are nested</li>
<li>Suggestions are specific to that function‚Äôs complexity patterns</li>
</ul>
<p><strong>Formatting Artifacts</strong></p>
<ul>
<li>Shows percentage of ‚Äúfalse‚Äù complexity from formatting</li>
<li>Severity indicates impact on metrics</li>
<li>Locations help you find the formatting issues</li>
<li>High formatting impact (&gt;25%) suggests inconsistent style</li>
</ul>
<p><strong>Pattern Analysis</strong></p>
<ul>
<li>Confidence score shows pattern recognition certainty</li>
<li>High confidence (&gt;0.7) means reliable pattern detection</li>
<li>Low confidence (&lt;0.5) suggests unique code structure</li>
<li>Opportunities highlight potential refactoring</li>
</ul>
<h2 id="insights-and-recommendations"><a class="header" href="#insights-and-recommendations">Insights and Recommendations</a></h2>
<p>Multi-pass analysis automatically generates insights and recommendations based on the attribution results.</p>
<h3 id="insight-types"><a class="header" href="#insight-types">Insight Types</a></h3>
<p><strong>FormattingImpact</strong></p>
<ul>
<li>Triggered when formatting contributes &gt;20% of measured complexity</li>
<li>Suggests using automated formatting tools</li>
<li>Recommends standardizing team coding style</li>
</ul>
<p><strong>PatternOpportunity</strong></p>
<ul>
<li>Triggered when pattern confidence is low (&lt;0.5)</li>
<li>Suggests extracting common patterns</li>
<li>Recommends reviewing for code duplication</li>
</ul>
<p><strong>RefactoringCandidate</strong></p>
<ul>
<li>Triggered when logical complexity exceeds threshold (&gt;20)</li>
<li>Identifies functions needing breakdown</li>
<li>Provides specific refactoring strategies</li>
</ul>
<p><strong>ComplexityHotspot</strong></p>
<ul>
<li>Identifies areas of concentrated complexity</li>
<li>Highlights files or modules needing attention</li>
<li>Suggests architectural improvements</li>
</ul>
<h3 id="recommendation-structure-1"><a class="header" href="#recommendation-structure-1">Recommendation Structure</a></h3>
<p>Each recommendation includes:</p>
<ul>
<li><strong>Priority</strong>: Low, Medium, High</li>
<li><strong>Category</strong>: Refactoring, Pattern, Formatting, General</li>
<li><strong>Title</strong>: Brief description of the issue</li>
<li><strong>Description</strong>: Detailed explanation</li>
<li><strong>Estimated Impact</strong>: Expected complexity reduction (in points)</li>
<li><strong>Suggested Actions</strong>: Specific steps to take</li>
</ul>
<h3 id="example-recommendations"><a class="header" href="#example-recommendations">Example Recommendations</a></h3>
<pre><code class="language-json">{
  "recommendations": [
    {
      "priority": "High",
      "category": "Refactoring",
      "title": "Simplify control flow in 'process_request'",
      "description": "This function contributes 12 complexity points with deeply nested conditions",
      "estimated_impact": 6,
      "suggested_actions": [
        "Extract validation logic into separate function",
        "Use early returns to reduce nesting depth",
        "Consider state pattern for complex branching"
      ]
    },
    {
      "priority": "Medium",
      "category": "Formatting",
      "title": "Formatting contributes 29% of measured complexity",
      "description": "Code formatting choices are inflating complexity metrics",
      "estimated_impact": 13,
      "suggested_actions": [
        "Use automated formatting tools (rustfmt, prettier)",
        "Standardize code formatting across the team",
        "Configure editor to format on save"
      ]
    },
    {
      "priority": "Low",
      "category": "Pattern",
      "title": "Low pattern recognition suggests unique code structure",
      "description": "Pattern confidence score of 0.45 indicates non-standard patterns",
      "estimated_impact": 3,
      "suggested_actions": [
        "Consider extracting common patterns into utilities",
        "Review for code duplication opportunities",
        "Document unique patterns for team understanding"
      ]
    }
  ]
}
</code></pre>
<h2 id="performance-considerations-2"><a class="header" href="#performance-considerations-2">Performance Considerations</a></h2>
<p>Multi-pass analysis adds overhead compared to single-pass analysis, but debtmap monitors and limits this overhead.</p>
<h3 id="performance-metrics"><a class="header" href="#performance-metrics">Performance Metrics</a></h3>
<p>When performance tracking is enabled, you‚Äôll see:</p>
<pre><code>Performance Metrics
-------------------
Raw analysis: 145ms
Normalized analysis: 132ms
Attribution: 45ms
Total time: 322ms
Memory used: 12.3 MB

Overhead: 121.7% vs single-pass (145ms baseline)
‚ö†Ô∏è  Warning: Overhead exceeds 25% target
</code></pre>
<p><strong>Tracked Metrics:</strong></p>
<ul>
<li><strong>Raw analysis time</strong> - Time to analyze original code</li>
<li><strong>Normalized analysis time</strong> - Time to analyze normalized code</li>
<li><strong>Attribution time</strong> - Time to compute attribution breakdown</li>
<li><strong>Total time</strong> - Complete multi-pass analysis duration</li>
<li><strong>Memory used</strong> - Additional memory for two-pass analysis</li>
</ul>
<h3 id="performance-overhead-1"><a class="header" href="#performance-overhead-1">Performance Overhead</a></h3>
<p><strong>Target Overhead</strong>: ‚â§25% compared to single-pass analysis</p>
<p>Multi-pass analysis aims to add no more than 25% overhead versus standard single-pass analysis. If overhead exceeds this threshold, a warning is issued.</p>
<p><strong>Typical Overhead:</strong></p>
<ul>
<li>Attribution adds ~10-15% on average</li>
<li>Normalization adds ~5-10% on average</li>
<li>Total overhead usually 15-25%</li>
</ul>
<p><strong>Factors Affecting Performance:</strong></p>
<ul>
<li><strong>File size</strong> - Larger files take proportionally longer</li>
<li><strong>Complexity</strong> - More complex code requires more analysis time</li>
<li><strong>Language</strong> - Some languages (TypeScript) are slower to parse</li>
<li><strong>Parallel processing</strong> - Overhead is per-file, parallel reduces impact</li>
</ul>
<h3 id="optimization-tips-1"><a class="header" href="#optimization-tips-1">Optimization Tips</a></h3>
<p><strong>Enable Caching</strong></p>
<pre><code class="language-bash"># Use shared cache for repeated analyses
debtmap analyze . --multi-pass --cache-location shared
</code></pre>
<p><strong>Disable Performance Tracking in Production</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>MultiPassOptions {
    performance_tracking: false,  // Reduces overhead slightly
    ..Default::default()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Use Parallel Processing</strong></p>
<pre><code class="language-bash"># Parallel analysis amortizes overhead across cores
# Note: --jobs is a general debtmap flag controlling parallelism for all analysis
debtmap analyze . --multi-pass --jobs 8
</code></pre>
<p><strong>Target Specific Files</strong></p>
<pre><code class="language-bash"># Analyze only files that need detailed attribution
debtmap analyze src/complex_module.rs --multi-pass --attribution
</code></pre>
<h2 id="comparative-analysis"><a class="header" href="#comparative-analysis">Comparative Analysis</a></h2>
<p>Multi-pass analysis supports comparing code changes to validate refactoring efforts.</p>
<h3 id="basic-comparison"><a class="header" href="#basic-comparison">Basic Comparison</a></h3>
<p>The <code>compare_complexity</code> function is a standalone convenience function that performs complete multi-pass analysis on both code versions and returns the computed differences:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::analysis::multi_pass::compare_complexity;
use debtmap::core::Language;

let before_code = r#"
fn process(items: Vec&lt;i32&gt;) -&gt; i32 {
    let mut sum = 0;
    for item in items {
        if item &gt; 0 {
            if item % 2 == 0 {
                sum += item * 2;
            } else {
                sum += item;
            }
        }
    }
    sum
}
"#;

let after_code = r#"
fn process(items: Vec&lt;i32&gt;) -&gt; i32 {
    items
        .into_iter()
        .filter(|&amp;item| item &gt; 0)
        .map(|item| if item % 2 == 0 { item * 2 } else { item })
        .sum()
}
"#;

let comparison = compare_complexity(before_code, after_code, Language::Rust)?;

println!("Complexity change: {}", comparison.complexity_change);
println!("Cognitive complexity change: {}", comparison.cognitive_change);
println!("Formatting impact change: {}", comparison.formatting_impact_change);
<span class="boring">}</span></code></pre></pre>
<h3 id="comparison-results"><a class="header" href="#comparison-results">Comparison Results</a></h3>
<p>The <code>ComparativeAnalysis</code> struct contains the computed differences between before and after analyses:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ComparativeAnalysis {
    pub complexity_change: i32,        // Negative = improvement
    pub cognitive_change: i32,         // Negative = improvement
    pub formatting_impact_change: f32, // Negative = less formatting noise
    pub improvements: Vec&lt;String&gt;,
    pub regressions: Vec&lt;String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><strong>Note</strong>: The <code>compare_complexity</code> function performs both analyses internally and returns only the change metrics. To access the full before/after results, perform separate analyses using <code>MultiPassAnalyzer</code>.</p>
</blockquote>
<p><strong>Interpreting Changes:</strong></p>
<ul>
<li><strong>Negative complexity change</strong> - Refactoring reduced complexity ‚úì</li>
<li><strong>Positive complexity change</strong> - Refactoring increased complexity ‚úó</li>
<li><strong>Improvements</strong> - List of detected improvements (reduced nesting, extracted functions, etc.)</li>
<li><strong>Regressions</strong> - List of detected regressions (increased complexity, new anti-patterns, etc.)</li>
</ul>
<h3 id="example-output-3"><a class="header" href="#example-output-3">Example Output</a></h3>
<pre><code>Comparative Analysis
====================

Complexity Changes:
‚îú‚îÄ Cyclomatic: 8 ‚Üí 4 (-4, -50%)
‚îú‚îÄ Cognitive: 12 ‚Üí 5 (-7, -58.3%)
‚îî‚îÄ Formatting Impact: 25% ‚Üí 10% (-15%, -60%)

Improvements Detected:
‚úì Reduced nesting depth (3 ‚Üí 1)
‚úì Eliminated mutable state
‚úì Replaced imperative loop with functional chain
‚úì Improved formatting consistency

No regressions detected.

Verdict: Refactoring reduced complexity by 50% and improved code clarity.
</code></pre>
<h2 id="configuration-options"><a class="header" href="#configuration-options">Configuration Options</a></h2>
<p>Configure multi-pass analysis programmatically:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::analysis::multi_pass::{MultiPassAnalyzer, MultiPassOptions};
use debtmap::analysis::diagnostics::{DetailLevel, OutputFormat};
use debtmap::core::Language;

let options = MultiPassOptions {
    language: Language::Rust,
    detail_level: DetailLevel::Comprehensive,
    enable_recommendations: true,
    track_source_locations: true,
    generate_insights: true,
    output_format: OutputFormat::Json, // Also available: Yaml, Markdown, Html, Text
    performance_tracking: true,
};

let analyzer = MultiPassAnalyzer::new(options);
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-fields"><a class="header" href="#configuration-fields">Configuration Fields</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr></thead><tbody>
<tr><td><code>language</code></td><td><code>Language</code></td><td><code>Rust</code></td><td>Target programming language</td></tr>
<tr><td><code>detail_level</code></td><td><code>DetailLevel</code></td><td><code>Standard</code></td><td>Output detail: Summary, Standard, Comprehensive, Debug (CLI uses lowercase: <code>--detail-level standard</code>)</td></tr>
<tr><td><code>enable_recommendations</code></td><td><code>bool</code></td><td><code>true</code></td><td>Generate actionable recommendations</td></tr>
<tr><td><code>track_source_locations</code></td><td><code>bool</code></td><td><code>true</code></td><td>Include file/line/column in attribution</td></tr>
<tr><td><code>generate_insights</code></td><td><code>bool</code></td><td><code>true</code></td><td>Automatically generate insights</td></tr>
<tr><td><code>output_format</code></td><td><code>OutputFormat</code></td><td><code>Json</code></td><td>Output format: Json, Yaml, Markdown, Html, Text</td></tr>
<tr><td><code>performance_tracking</code></td><td><code>bool</code></td><td><code>false</code></td><td>Track and report performance metrics</td></tr>
</tbody></table>
</div>
<h2 id="use-cases-5"><a class="header" href="#use-cases-5">Use Cases</a></h2>
<h3 id="when-to-use-multi-pass-analysis"><a class="header" href="#when-to-use-multi-pass-analysis">When to Use Multi-Pass Analysis</a></h3>
<p><strong>Refactoring Validation</strong></p>
<ul>
<li>Compare before/after complexity to validate refactoring</li>
<li>Ensure complexity actually decreased</li>
<li>Identify unintended complexity increases</li>
</ul>
<p><strong>Formatting Impact Assessment</strong></p>
<ul>
<li>Determine how much formatting affects your metrics</li>
<li>Justify automated formatting tool adoption</li>
<li>Identify formatting inconsistencies</li>
</ul>
<p><strong>Targeted Refactoring</strong></p>
<ul>
<li>Use attribution to find highest-impact refactoring targets</li>
<li>Focus on logical complexity, not formatting artifacts</li>
<li>Prioritize functions with actionable suggestions</li>
</ul>
<p><strong>Code Review</strong></p>
<ul>
<li>Provide objective complexity data in pull requests</li>
<li>Identify genuine complexity increases vs formatting changes</li>
<li>Guide refactoring discussions with data</li>
</ul>
<p><strong>Codebase Health Monitoring</strong></p>
<ul>
<li>Track logical complexity trends over time</li>
<li>Separate signal (logic) from noise (formatting)</li>
<li>Identify complexity hotspots for architectural review</li>
</ul>
<h3 id="when-to-use-standard-analysis"><a class="header" href="#when-to-use-standard-analysis">When to Use Standard Analysis</a></h3>
<p><strong>Quick Feedback</strong></p>
<ul>
<li>Fast complexity checks during development</li>
<li>CI/CD gates that need speed</li>
<li>Large codebases where overhead matters</li>
</ul>
<p><strong>Sufficient Metrics</strong></p>
<ul>
<li>When overall complexity trends are enough</li>
<li>No need for detailed attribution</li>
<li>Formatting is already standardized</li>
</ul>
<h2 id="future-enhancements-1"><a class="header" href="#future-enhancements-1">Future Enhancements</a></h2>
<h3 id="spec-84-detailed-ast-based-source-mapping"><a class="header" href="#spec-84-detailed-ast-based-source-mapping">Spec 84: Detailed AST-Based Source Mapping</a></h3>
<p>The current implementation uses estimated complexity locations based on function metrics. <a href="https://github.com/yourusername/debtmap/blob/master/specs/84-detailed-ast-source-mapping.md">Spec 84</a> will enhance attribution with precise AST-based source mapping:</p>
<p><strong>Planned Improvements:</strong></p>
<ul>
<li><strong>Exact AST node locations</strong> - Precise line, column, and span for each complexity point</li>
<li><strong>100% accurate mapping</strong> - No estimation, direct AST-to-source mapping</li>
<li><strong>IDE integration</strong> - Jump from complexity reports directly to source code</li>
<li><strong>Inline visualization</strong> - Show complexity heat maps in your editor</li>
<li><strong>Statement-level tracking</strong> - Complexity attribution at statement granularity</li>
</ul>
<p><strong>Current vs Future:</strong></p>
<p>Current (estimated):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ComplexityComponent {
    location: CodeLocation {
        line: 45,      // Function start line
        column: 0,     // Estimated
        span: None,    // Not available
    },
    description: "Function: process_request",
}
<span class="boring">}</span></code></pre></pre>
<p>Future (precise):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>ComplexityComponent {
    location: SourceLocation {
        line: 47,           // Exact if statement line
        column: 8,          // Exact column
        span: Some(47, 52), // Exact span of construct
        ast_path: "fn::process_request::body::if[0]",
    },
    description: "If condition: item.is_valid()",
}
<span class="boring">}</span></code></pre></pre>
<p>This will enable:</p>
<ul>
<li>Click-to-navigate from reports to exact code locations</li>
<li>Visual Studio Code / IntelliJ integration for inline complexity display</li>
<li>More precise refactoring suggestions</li>
<li>Better complexity trend tracking at fine granularity</li>
</ul>
<h2 id="summary-7"><a class="header" href="#summary-7">Summary</a></h2>
<p>Multi-pass analysis provides deep insights into your code‚Äôs complexity by:</p>
<ol>
<li><strong>Separating signal from noise</strong> - Distinguishing logical complexity from formatting artifacts</li>
<li><strong>Attributing complexity sources</strong> - Identifying what contributes to complexity and why</li>
<li><strong>Generating actionable insights</strong> - Providing specific refactoring recommendations</li>
<li><strong>Validating refactoring</strong> - Comparing before/after to prove complexity reduction</li>
<li><strong>Monitoring performance</strong> - Ensuring overhead stays within acceptable bounds</li>
</ol>
<p>Use <code>--multi-pass --attribution</code> when you need detailed complexity analysis and targeted refactoring guidance. The overhead (typically 15-25%) is worthwhile when you need to understand <em>why</em> code is complex and <em>how</em> to improve it.</p>
<p>For quick complexity checks and CI/CD integration, standard single-pass analysis is usually sufficient. Save multi-pass analysis for deep dives, refactoring validation, and complexity investigations.</p>
<hr />
<p><strong>See Also:</strong></p>
<ul>
<li><a href="analysis-guide.html">Analysis Guide</a> - General analysis capabilities</li>
<li><a href="scoring-strategies.html">Scoring Strategies</a> - How complexity affects debt scores</li>
<li><a href="coverage-integration.html">Coverage Integration</a> - Combining complexity with coverage</li>
<li><a href="examples.html">Examples</a> - Real-world multi-pass analysis examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parallel-processing"><a class="header" href="#parallel-processing">Parallel Processing</a></h1>
<p>Debtmap leverages Rust‚Äôs powerful parallel processing capabilities to analyze large codebases efficiently. Built on Rayon for data parallelism and DashMap for lock-free concurrent data structures, debtmap achieves 10-100x faster performance than Java/Python-based competitors.</p>
<h2 id="overview-13"><a class="header" href="#overview-13">Overview</a></h2>
<p>Debtmap‚Äôs parallel processing architecture uses a three-phase approach:</p>
<ol>
<li><strong>Parallel File Parsing</strong> - Parse source files concurrently across all available CPU cores</li>
<li><strong>Parallel Multi-File Extraction</strong> - Extract call graphs from parsed files in parallel</li>
<li><strong>Parallel Enhanced Analysis</strong> - Analyze trait dispatch, function pointers, and framework patterns</li>
</ol>
<p>This parallel pipeline is controlled by CLI flags that let you tune performance for your environment.</p>
<h2 id="performance-characteristics-3"><a class="header" href="#performance-characteristics-3">Performance Characteristics</a></h2>
<p><strong>Typical analysis times:</strong></p>
<ul>
<li>Small project (1k-5k LOC): &lt;1 second</li>
<li>Medium project (10k-50k LOC): 2-8 seconds</li>
<li>Large project (100k-500k LOC): 10-45 seconds</li>
</ul>
<p><strong>Comparison with other tools (medium-sized Rust project, ~50k LOC):</strong></p>
<ul>
<li>SonarQube: 3-4 minutes</li>
<li>CodeClimate: 2-3 minutes</li>
<li>Debtmap: 5-8 seconds</li>
</ul>
<h2 id="cli-flags-for-parallelization"><a class="header" href="#cli-flags-for-parallelization">CLI Flags for Parallelization</a></h2>
<p>Debtmap provides two flags to control parallel processing behavior:</p>
<h3 id="jobs---j"><a class="header" href="#jobs---j">‚Äìjobs / -j</a></h3>
<p>Control the number of worker threads for parallel processing:</p>
<pre><code class="language-bash"># Use all available CPU cores (default)
debtmap analyze --jobs 0

# Limit to 4 threads
debtmap analyze --jobs 4
debtmap analyze -j 4
</code></pre>
<p><strong>Behavior:</strong></p>
<ul>
<li><code>--jobs 0</code> (default): Auto-detects available CPU cores using <code>std::thread::available_parallelism()</code>. Falls back to 4 threads if detection fails.</li>
<li><code>--jobs N</code>: Explicitly sets the thread pool to N threads.</li>
</ul>
<p><strong>When to use:</strong></p>
<ul>
<li>Use <code>--jobs 0</code> for maximum performance on developer workstations</li>
<li>Use <code>--jobs 1-4</code> in memory-constrained environments like CI/CD</li>
<li>Use <code>--jobs 1</code> for deterministic analysis order during debugging</li>
</ul>
<p><strong>Environment Variables:</strong></p>
<p>You can also set the default via environment variables:</p>
<p><strong><code>DEBTMAP_JOBS</code></strong> - Set the default thread count:</p>
<pre><code class="language-bash">export DEBTMAP_JOBS=4
debtmap analyze  # Uses 4 threads
</code></pre>
<p><strong><code>DEBTMAP_PARALLEL</code></strong> - Enable/disable parallel processing programmatically:</p>
<pre><code class="language-bash">export DEBTMAP_PARALLEL=true
debtmap analyze  # Parallel processing enabled

export DEBTMAP_PARALLEL=1
debtmap analyze  # Parallel processing enabled (also accepts '1')
</code></pre>
<p>The <code>DEBTMAP_PARALLEL</code> variable accepts <code>true</code> or <code>1</code> to enable parallel processing. This is useful for programmatic control in scripts or CI environments.</p>
<p>The CLI flags (<code>--jobs</code>, <code>--no-parallel</code>) take precedence over environment variables.</p>
<h3 id="no-parallel"><a class="header" href="#no-parallel">‚Äìno-parallel</a></h3>
<p>Disable parallel call graph construction entirely:</p>
<pre><code class="language-bash">debtmap analyze --no-parallel
</code></pre>
<p><strong>When to use:</strong></p>
<ul>
<li><strong>Debugging concurrency issues</strong>: Isolate whether a problem is parallelism-related</li>
<li><strong>Memory-constrained environments</strong>: Parallel processing increases memory usage</li>
<li><strong>Deterministic analysis</strong>: Ensures consistent ordering for reproducibility</li>
</ul>
<p><strong>Performance Impact:</strong></p>
<p>Disabling parallelization significantly increases analysis time:</p>
<ul>
<li>Small projects (&lt; 100 files): 2-3x slower</li>
<li>Medium projects (100-1000 files): 5-10x slower</li>
<li>Large projects (&gt; 1000 files): 10-50x slower</li>
</ul>
<p>For more details on both flags, see the <a href="./cli-reference.html#performance--caching">CLI Reference</a>.</p>
<h2 id="rayon-parallel-iterators"><a class="header" href="#rayon-parallel-iterators">Rayon Parallel Iterators</a></h2>
<p>Debtmap uses <a href="https://docs.rs/rayon">Rayon</a>, a data parallelism library for Rust, to parallelize file processing operations.</p>
<h3 id="thread-pool-configuration"><a class="header" href="#thread-pool-configuration">Thread Pool Configuration</a></h3>
<p>The global Rayon thread pool is configured at startup based on the <code>--jobs</code> parameter:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/builders/parallel_call_graph.rs:46-52
if self.config.num_threads &gt; 0 {
    rayon::ThreadPoolBuilder::new()
        .num_threads(self.config.num_threads)
        .build_global()
        .ok(); // Ignore if already configured
}
<span class="boring">}</span></code></pre></pre>
<p>This configures Rayon to use a specific number of worker threads for all parallel operations throughout the analysis.</p>
<h3 id="worker-thread-selection"><a class="header" href="#worker-thread-selection">Worker Thread Selection</a></h3>
<p>The <code>get_worker_count()</code> function determines how many threads to use:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/main.rs:750-758
fn get_worker_count(jobs: usize) -&gt; usize {
    if jobs == 0 {
        std::thread::available_parallelism()
            .map(|n| n.get())
            .unwrap_or(4)  // Fallback if detection fails
    } else {
        jobs  // Use explicit value
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Auto-detection behavior:</strong></p>
<ul>
<li>Queries the OS for available parallelism (CPU cores)</li>
<li>Respects cgroup limits in containers (Docker, Kubernetes)</li>
<li>Falls back to 4 threads if detection fails (rare)</li>
</ul>
<p><strong>Manual configuration:</strong></p>
<ul>
<li>Useful in shared environments (CI/CD, shared build servers)</li>
<li>Prevents resource contention with other processes</li>
<li>Enables reproducible benchmarking</li>
</ul>
<h3 id="parallel-file-processing"><a class="header" href="#parallel-file-processing">Parallel File Processing</a></h3>
<p><strong>Phase 1: Parallel File Parsing</strong></p>
<p>Files are parsed concurrently using Rayon‚Äôs parallel iterators:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/builders/parallel_call_graph.rs:98-128
let parsed_files: Vec&lt;_&gt; = rust_files
    .par_iter()  // Convert to parallel iterator
    .filter_map(|file_path| {
        let content = io::read_file(file_path).ok()?;

        // Update progress atomically
        parallel_graph.stats().increment_files();

        Some((file_path.clone(), content))
    })
    .collect();
<span class="boring">}</span></code></pre></pre>
<p>Key features:</p>
<ul>
<li><code>.par_iter()</code> converts a sequential iterator to a parallel one</li>
<li>Each file is read independently on a worker thread</li>
<li>Progress tracking uses atomic counters (see <a href="parallel-processing.html#parallel-call-graph-statistics">Parallel Call Graph Statistics</a>)</li>
</ul>
<p><strong>Phase 2: Parallel Multi-File Extraction</strong></p>
<p>Files are grouped into chunks for optimal parallelization:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/builders/parallel_call_graph.rs:130-161
let chunk_size = std::cmp::max(10, parsed_files.len() / rayon::current_num_threads());

parsed_files.par_chunks(chunk_size).for_each(|chunk| {
    // Parse syn files within each chunk
    let parsed_chunk: Vec&lt;_&gt; = chunk
        .iter()
        .filter_map(|(path, content)| {
            syn::parse_file(content)
                .ok()
                .map(|parsed| (parsed, path.clone()))
        })
        .collect();

    if !parsed_chunk.is_empty() {
        // Extract call graph for this chunk
        let chunk_graph = extract_call_graph_multi_file(&amp;parsed_chunk);

        // Merge into main graph concurrently
        parallel_graph.merge_concurrent(chunk_graph);
    }
});
<span class="boring">}</span></code></pre></pre>
<p>This chunking strategy balances parallelism with overhead:</p>
<ul>
<li>Minimum chunk size of 10 files prevents excessive overhead</li>
<li>Dynamic chunk sizing based on available threads</li>
<li>Each chunk produces a local call graph that‚Äôs merged concurrently</li>
</ul>
<p><strong>AST Parsing Optimization (Spec 132)</strong></p>
<p>Prior to spec 132, files were parsed twice during call graph construction:</p>
<ol>
<li>Phase 1: Read files and store content as strings</li>
<li>Phase 2: <strong>Re-parse the same content</strong> to extract call graphs</li>
</ol>
<p>This redundant parsing was eliminated by parsing each file exactly once and reusing the parsed <code>syn::File</code> AST:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Optimized: Parse once in Phase 1
let parsed_files: Vec&lt;(PathBuf, syn::File)&gt; = rust_files
    .par_iter()
    .filter_map(|file_path| {
        let content = io::read_file(file_path).ok()?;
        let parsed = syn::parse_file(&amp;content).ok()?;  // Parse ONCE
        Some((file_path.clone(), parsed))
    })
    .collect();

// Phase 2: Reuse parsed ASTs (no re-parsing)
for chunk in parsed_files.chunks(chunk_size) {
    let chunk_for_extraction: Vec&lt;_&gt; = chunk
        .iter()
        .map(|(path, parsed)| (parsed.clone(), path.clone()))  // Clone AST
        .collect();
    // Extract call graph...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Performance Impact:</strong></p>
<ul>
<li><strong>Before</strong>: 2N parse operations (404 files √ó 2 = 808 parses)</li>
<li><strong>After</strong>: N parse operations (404 files √ó 1 = 404 parses)</li>
<li><strong>Speedup</strong>: Cloning a parsed AST is <strong>44% faster</strong> than re-parsing</li>
<li><strong>Time saved</strong>: ~432ms per analysis run on 400-file projects</li>
<li><strong>Memory overhead</strong>: &lt;100MB for parsed AST storage</li>
</ul>
<p><strong>Why Clone Instead of Borrow?</strong></p>
<ul>
<li><code>syn::File</code> is not <code>Send + Sync</code> (cannot be shared across threads)</li>
<li>Call graph extraction requires owned AST values</li>
<li>Cloning is still significantly faster than re-parsing (1.33ms vs 2.40ms per file)</li>
</ul>
<p>See <code>docs/spec-132-benchmark-results.md</code> for detailed benchmarks validating these improvements.</p>
<p><strong>Phase 3: Enhanced Analysis</strong></p>
<p>The third phase analyzes trait dispatch, function pointers, and framework patterns. This phase is currently sequential due to complex shared state requirements, but benefits from the parallel foundation built in phases 1-2.</p>
<h3 id="parallel-architecture"><a class="header" href="#parallel-architecture">Parallel Architecture</a></h3>
<p>Debtmap processes files in parallel using Rayon‚Äôs parallel iterators:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>files.par_iter()
    .map(|file| analyze_file(file))
    .collect()
<span class="boring">}</span></code></pre></pre>
<p>Each file is:</p>
<ol>
<li>Parsed independently</li>
<li>Analyzed for complexity</li>
<li>Scored and prioritized</li>
</ol>
<h2 id="dashmap-for-lock-free-concurrency"><a class="header" href="#dashmap-for-lock-free-concurrency">DashMap for Lock-Free Concurrency</a></h2>
<p>Debtmap uses <a href="https://docs.rs/dashmap">DashMap</a>, a concurrent hash map implementation, for lock-free data structures during parallel call graph construction.</p>
<h3 id="why-dashmap"><a class="header" href="#why-dashmap">Why DashMap?</a></h3>
<p>Traditional approaches to concurrent hash maps use a single <code>Mutex&lt;HashMap&gt;</code>, which creates contention:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚ùå Traditional approach - serializes all access
let map = Arc&lt;Mutex&lt;HashMap&lt;K, V&gt;&gt;&gt;;

// Thread 1 blocks Thread 2, even for reads
let val = map.lock().unwrap().get(&amp;key);
<span class="boring">}</span></code></pre></pre>
<p>DashMap provides <strong>lock-free reads</strong> and <strong>fine-grained write locking</strong> through internal sharding:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ‚úÖ DashMap approach - concurrent reads, fine-grained writes
let map = Arc&lt;DashMap&lt;K, V&gt;&gt;;

// Multiple threads can read concurrently without blocking
let val = map.get(&amp;key);

// Writes only lock the specific shard, not the whole map
map.insert(key, value);
<span class="boring">}</span></code></pre></pre>
<h3 id="parallelcallgraph-implementation"><a class="header" href="#parallelcallgraph-implementation">ParallelCallGraph Implementation</a></h3>
<p>The <code>ParallelCallGraph</code> uses DashMap for all concurrent data structures:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/parallel_call_graph.rs:49-56
pub struct ParallelCallGraph {
    nodes: Arc&lt;DashMap&lt;FunctionId, NodeInfo&gt;&gt;,      // Functions
    edges: Arc&lt;DashSet&lt;FunctionCall&gt;&gt;,              // Calls
    caller_index: Arc&lt;DashMap&lt;FunctionId, DashSet&lt;FunctionId&gt;&gt;&gt;,  // Who calls this?
    callee_index: Arc&lt;DashMap&lt;FunctionId, DashSet&lt;FunctionId&gt;&gt;&gt;,  // Who does this call?
    stats: Arc&lt;ParallelStats&gt;,                      // Atomic counters
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Key components:</strong></p>
<ol>
<li><strong>nodes</strong>: Maps function identifiers to metadata (complexity, lines, flags)</li>
<li><strong>edges</strong>: Set of all function calls (deduplicated automatically)</li>
<li><strong>caller_index</strong>: Reverse index for ‚Äúwho calls this function?‚Äù</li>
<li><strong>callee_index</strong>: Forward index for ‚Äúwhat does this function call?‚Äù</li>
<li><strong>stats</strong>: Atomic counters for progress tracking</li>
</ol>
<h3 id="concurrent-operations"><a class="header" href="#concurrent-operations">Concurrent Operations</a></h3>
<p><strong>Adding Functions Concurrently</strong></p>
<p>Multiple analyzer threads can add functions simultaneously:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/parallel_call_graph.rs:78-96
pub fn add_function(
    &amp;self,
    id: FunctionId,
    is_entry_point: bool,
    is_test: bool,
    complexity: u32,
    lines: usize,
) {
    let node_info = NodeInfo {
        id: id.clone(),
        is_entry_point,
        is_test,
        complexity,
        lines,
    };
    self.nodes.insert(id, node_info);
    self.stats.add_nodes(1);  // Atomic increment
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Atomicity guarantees:</strong></p>
<ul>
<li><code>DashMap::insert()</code> is atomic - no data races</li>
<li><code>AtomicUsize</code> counters can be incremented from multiple threads safely</li>
<li>No locks required for reading existing nodes</li>
</ul>
<p><strong>Adding Calls Concurrently</strong></p>
<p>Function calls are added with automatic deduplication:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/parallel_call_graph.rs:98-117
pub fn add_call(&amp;self, caller: FunctionId, callee: FunctionId, call_type: CallType) {
    let call = FunctionCall {
        caller: caller.clone(),
        callee: callee.clone(),
        call_type,
    };

    if self.edges.insert(call) {  // DashSet deduplicates automatically
        // Update indices concurrently
        self.caller_index
            .entry(caller.clone())
            .or_default()
            .insert(callee.clone());

        self.callee_index.entry(callee).or_default().insert(caller);

        self.stats.add_edges(1);  // Only increment if actually inserted
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Deduplication:</strong></p>
<ul>
<li><code>DashSet::insert()</code> returns <code>true</code> only for new items</li>
<li>Duplicate calls from multiple threads are safely ignored</li>
<li>Indices are updated atomically using <code>entry()</code> API</li>
</ul>
<h3 id="shared-read-only-data"><a class="header" href="#shared-read-only-data">Shared Read-Only Data</a></h3>
<p>Analysis configuration and indexes are shared across threads:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let coverage_index = Arc::new(build_coverage_index());

// All threads share the same index
files.par_iter()
    .map(|file| analyze_with_coverage(file, &amp;coverage_index))
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-overhead"><a class="header" href="#memory-overhead">Memory Overhead</a></h3>
<p>DashMap uses internal sharding for parallelism, which has a memory overhead:</p>
<ul>
<li><strong>DashMap overhead</strong>: ~2x the memory of a regular <code>HashMap</code> due to sharding</li>
<li><strong>DashSet overhead</strong>: Similar to DashMap</li>
<li><strong>Benefit</strong>: Enables concurrent access without contention</li>
<li><strong>Trade-off</strong>: Debtmap prioritizes speed over memory for large codebases</li>
</ul>
<p>For memory-constrained environments, use <code>--jobs 2-4</code> or <code>--no-parallel</code> to reduce parallel overhead.</p>
<h2 id="parallel-call-graph-statistics"><a class="header" href="#parallel-call-graph-statistics">Parallel Call Graph Statistics</a></h2>
<p>Debtmap tracks parallel processing progress using atomic counters that can be safely updated from multiple threads.</p>
<h3 id="parallelstats-structure"><a class="header" href="#parallelstats-structure">ParallelStats Structure</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/parallel_call_graph.rs:7-47
pub struct ParallelStats {
    pub total_nodes: AtomicUsize,      // Functions processed
    pub total_edges: AtomicUsize,      // Calls discovered
    pub files_processed: AtomicUsize,  // Files completed
    pub total_files: AtomicUsize,      // Total files to process
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Atomic operations:</strong></p>
<ul>
<li><code>fetch_add()</code> - Atomically increment counters from any thread</li>
<li><code>load()</code> - Read current value without blocking</li>
<li><code>Ordering::Relaxed</code> - Sufficient for statistics (no synchronization needed)</li>
</ul>
<h3 id="progress-tracking"><a class="header" href="#progress-tracking">Progress Tracking</a></h3>
<p>Progress ratio calculation for long-running analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/parallel_call_graph.rs:38-46
pub fn progress_ratio(&amp;self) -&gt; f64 {
    let processed = self.files_processed.load(Ordering::Relaxed) as f64;
    let total = self.total_files.load(Ordering::Relaxed) as f64;
    if total &gt; 0.0 {
        processed / total
    } else {
        0.0
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This enables progress callbacks during analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/builders/parallel_call_graph.rs:110-121
parallel_graph.stats().increment_files();
if let Some(ref callback) = self.config.progress_callback {
    let processed = parallel_graph
        .stats()
        .files_processed
        .load(std::sync::atomic::Ordering::Relaxed);
    let total = parallel_graph
        .stats()
        .total_files
        .load(std::sync::atomic::Ordering::Relaxed);
    callback(processed, total);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="log-output-format"><a class="header" href="#log-output-format">Log Output Format</a></h3>
<p>After analysis completes, debtmap reports final statistics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/builders/parallel_call_graph.rs:84-92
log::info!(
    "Parallel call graph complete: {} nodes, {} edges, {} files processed",
    stats.total_nodes.load(std::sync::atomic::Ordering::Relaxed),
    stats.total_edges.load(std::sync::atomic::Ordering::Relaxed),
    stats
        .files_processed
        .load(std::sync::atomic::Ordering::Relaxed),
);
<span class="boring">}</span></code></pre></pre>
<p><strong>Example output:</strong></p>
<pre><code>INFO - Processing 1247 Rust files in parallel
INFO - Progress: 100/1247 files processed
INFO - Progress: 500/1247 files processed
INFO - Progress: 1000/1247 files processed
INFO - Parallel call graph complete: 8942 nodes, 23451 edges, 1247 files processed
</code></pre>
<h2 id="cross-file-call-resolution"><a class="header" href="#cross-file-call-resolution">Cross-File Call Resolution</a></h2>
<p>Debtmap uses a two-phase parallel resolution approach for resolving cross-file function calls, achieving 10-15% faster call graph construction on multi-core systems.</p>
<h3 id="two-phase-architecture"><a class="header" href="#two-phase-architecture">Two-Phase Architecture</a></h3>
<p><strong>Phase 1: Parallel Resolution (Read-Only)</strong></p>
<p>The first phase processes unresolved calls concurrently using Rayon‚Äôs parallel iterators:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/call_graph/cross_file.rs
let resolutions: Vec&lt;(FunctionCall, FunctionId)&gt; = calls_to_resolve
    .par_iter()  // Parallel iteration
    .filter_map(|call| {
        // Pure function - safe for parallel execution
        Self::resolve_call_with_advanced_matching(
            &amp;all_functions,
            &amp;call.callee.name,
            &amp;call.caller.file,
        ).map(|resolved_callee| {
            (call.clone(), resolved_callee)
        })
    })
    .collect();
<span class="boring">}</span></code></pre></pre>
<p><strong>Key benefits:</strong></p>
<ul>
<li><strong>Pure functional resolution</strong>: No side effects, safe for concurrent execution</li>
<li><strong>Immutable data</strong>: All inputs are read-only during the parallel phase</li>
<li><strong>Independent operations</strong>: Each call resolution is independent of others</li>
<li><strong>Parallel efficiency</strong>: Utilizes all available CPU cores</li>
</ul>
<p><strong>Phase 2: Sequential Updates (Mutation)</strong></p>
<p>The second phase applies all resolutions to the graph sequentially:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Apply resolutions to graph in sequence
for (original_call, resolved_callee) in resolutions {
    self.apply_call_resolution(&amp;original_call, &amp;resolved_callee);
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Key benefits:</strong></p>
<ul>
<li><strong>Batch updates</strong>: All resolutions processed together</li>
<li><strong>Data consistency</strong>: Sequential updates maintain index synchronization</li>
<li><strong>Deterministic</strong>: Same results regardless of parallel execution order</li>
</ul>
<h3 id="performance-impact"><a class="header" href="#performance-impact">Performance Impact</a></h3>
<p>The two-phase approach provides significant speedups on multi-core systems:</p>
<div class="table-wrapper"><table><thead><tr><th>CPU Cores</th><th>Speedup</th><th>Example Time (1500 calls)</th></tr></thead><tbody>
<tr><td>1</td><td>0%</td><td>100ms (baseline)</td></tr>
<tr><td>2</td><td>~8%</td><td>92ms</td></tr>
<tr><td>4</td><td>~12%</td><td>88ms</td></tr>
<tr><td>8</td><td>~15%</td><td>85ms</td></tr>
</tbody></table>
</div>
<p><strong>Performance characteristics:</strong></p>
<ul>
<li><strong>Best case</strong>: 10-15% reduction in call graph construction time</li>
<li><strong>Scaling</strong>: Diminishing returns beyond 8 cores due to batching overhead</li>
<li><strong>Memory overhead</strong>: &lt;10MB for resolutions vector, even for large projects</li>
</ul>
<h3 id="thread-safety"><a class="header" href="#thread-safety">Thread Safety</a></h3>
<p>The parallel resolution phase is thread-safe without locks because:</p>
<ol>
<li><strong>Pure resolution logic</strong>: <code>resolve_call_with_advanced_matching()</code> is a static method with no side effects</li>
<li><strong>Immutable inputs</strong>: All function data is read-only during parallel phase</li>
<li><strong>Independent resolutions</strong>: No dependencies between different call resolutions</li>
<li><strong>Safe collection</strong>: Rayon handles thread synchronization for result collection</li>
</ol>
<p>The sequential update phase requires no synchronization since it runs single-threaded.</p>
<h3 id="memory-efficiency"><a class="header" href="#memory-efficiency">Memory Efficiency</a></h3>
<p><strong>Resolutions vector overhead:</strong></p>
<ul>
<li>Per-resolution size: ~200 bytes (FunctionCall + FunctionId)</li>
<li>For 1000 resolutions: ~200KB</li>
<li>For 2000 resolutions: ~400KB</li>
<li>Maximum overhead: &lt;10MB even for very large projects</li>
</ul>
<p><strong>Total memory footprint:</strong></p>
<pre><code>Total Memory = Base Graph + Resolutions Vector
             ‚âà 5-10MB + 0.2-0.4MB
             ‚âà 5-10MB (negligible overhead)
</code></pre>
<h3 id="integration-with-call-graph-construction"><a class="header" href="#integration-with-call-graph-construction">Integration with Call Graph Construction</a></h3>
<p>The two-phase resolution integrates seamlessly into the existing call graph construction pipeline:</p>
<pre><code>File Parsing (Parallel)
    ‚Üì
Function Extraction (Parallel)
    ‚Üì
Build Initial Call Graph
    ‚Üì
[NEW] Parallel Cross-File Resolution
    ‚îú‚îÄ Phase 1: Parallel resolution ‚Üí collect resolutions
    ‚îî‚îÄ Phase 2: Sequential updates ‚Üí apply to graph
    ‚Üì
Call Graph Complete
</code></pre>
<h3 id="configuration-10"><a class="header" href="#configuration-10">Configuration</a></h3>
<p>Cross-file resolution respects the <code>--jobs</code> flag for thread pool sizing:</p>
<pre><code class="language-bash"># Use all cores for maximum speedup
debtmap analyze --jobs 0

# Limit to 4 threads
debtmap analyze --jobs 4

# Disable parallelism (debugging)
debtmap analyze --no-parallel
</code></pre>
<p>The <code>--no-parallel</code> flag disables parallel call graph construction entirely, including cross-file resolution parallelization.</p>
<h3 id="debugging"><a class="header" href="#debugging">Debugging</a></h3>
<p>To verify parallel resolution is working:</p>
<pre><code class="language-bash"># Enable verbose logging
debtmap analyze -vv

# Look for messages like:
# "Resolving 1523 cross-file calls in parallel"
# "Parallel resolution complete: 1423 resolved in 87ms"
</code></pre>
<p>To compare parallel vs sequential performance:</p>
<pre><code class="language-bash"># Parallel (default)
time debtmap analyze .

# Sequential (for comparison)
time debtmap analyze . --no-parallel
</code></pre>
<p>Expected difference: 10-15% faster with parallel resolution on 4-8 core systems.</p>
<h2 id="concurrent-merging"><a class="header" href="#concurrent-merging">Concurrent Merging</a></h2>
<p>The <code>merge_concurrent()</code> method combines call graphs from different analysis phases using parallel iteration.</p>
<h3 id="implementation"><a class="header" href="#implementation">Implementation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/parallel_call_graph.rs:119-138
pub fn merge_concurrent(&amp;self, other: CallGraph) {
    // Parallelize node merging
    let nodes_vec: Vec&lt;_&gt; = other.get_all_functions().collect();
    nodes_vec.par_iter().for_each(|func_id| {
        if let Some((is_entry, is_test, complexity, lines)) = other.get_function_info(func_id) {
            self.add_function((*func_id).clone(), is_entry, is_test, complexity, lines);
        }
    });

    // Parallelize edge merging
    let calls_vec: Vec&lt;_&gt; = other.get_all_calls();
    calls_vec.par_iter().for_each(|call| {
        self.add_call(
            call.caller.clone(),
            call.callee.clone(),
            call.call_type.clone(),
        );
    });
}
<span class="boring">}</span></code></pre></pre>
<p><strong>How it works:</strong></p>
<ol>
<li>Extract all nodes and edges from the source <code>CallGraph</code></li>
<li>Use <code>par_iter()</code> to merge nodes in parallel</li>
<li>Use <code>par_iter()</code> to merge edges in parallel</li>
<li>DashMap/DashSet automatically handle concurrent insertions</li>
</ol>
<h3 id="converting-between-representations"><a class="header" href="#converting-between-representations">Converting Between Representations</a></h3>
<p>Debtmap uses two call graph representations:</p>
<ul>
<li><strong>ParallelCallGraph</strong>: Concurrent data structures (DashMap/DashSet) for parallel construction</li>
<li><strong>CallGraph</strong>: Sequential data structures (HashMap/HashSet) for analysis algorithms</li>
</ul>
<p>Conversion happens at phase boundaries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// From src/priority/parallel_call_graph.rs:140-162
pub fn to_call_graph(&amp;self) -&gt; CallGraph {
    let mut call_graph = CallGraph::new();

    // Add all nodes
    for entry in self.nodes.iter() {
        let node = entry.value();
        call_graph.add_function(
            node.id.clone(),
            node.is_entry_point,
            node.is_test,
            node.complexity,
            node.lines,
        );
    }

    // Add all edges
    for call in self.edges.iter() {
        call_graph.add_call(call.clone());
    }

    call_graph
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Why two representations?</strong></p>
<ul>
<li><strong>ParallelCallGraph</strong>: Optimized for concurrent writes during construction</li>
<li><strong>CallGraph</strong>: Optimized for graph algorithms (PageRank, connectivity, transitive reduction)</li>
<li>Conversion overhead is negligible compared to analysis time</li>
</ul>
<h2 id="coverage-index-optimization"><a class="header" href="#coverage-index-optimization">Coverage Index Optimization</a></h2>
<p>Debtmap uses an optimized nested HashMap structure for coverage data lookups, providing significant performance improvements for coverage-enabled analysis.</p>
<h3 id="nested-hashmap-architecture"><a class="header" href="#nested-hashmap-architecture">Nested HashMap Architecture</a></h3>
<p>The <code>CoverageIndex</code> structure uses a two-level nested HashMap instead of a flat structure:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Optimized structure (nested)
pub struct CoverageIndex {
    /// Outer map: file path ‚Üí inner map of functions
    by_file: HashMap&lt;PathBuf, HashMap&lt;String, FunctionCoverage&gt;&gt;,

    /// Line-based index for range queries
    by_line: HashMap&lt;PathBuf, BTreeMap&lt;usize, FunctionCoverage&gt;&gt;,

    /// Pre-computed file paths for efficient iteration
    file_paths: Vec&lt;PathBuf&gt;,
}

// OLD structure (flat) - no longer used
HashMap&lt;(PathBuf, String), FunctionCoverage&gt;
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-characteristics-4"><a class="header" href="#performance-characteristics-4">Performance Characteristics</a></h3>
<p>The nested structure provides dramatic performance improvements:</p>
<p><strong>Lookup Complexity:</strong></p>
<ul>
<li><strong>Exact match</strong>: O(1) file hash + O(1) function hash</li>
<li><strong>Path strategies</strong>: O(files) instead of O(functions)</li>
<li><strong>Line-based</strong>: O(log functions_in_file) binary search</li>
</ul>
<p><strong>Real-World Performance:</strong></p>
<ul>
<li>Exact match lookups: ~100 nanoseconds</li>
<li>Path matching fallback: ~10 microseconds (375 file checks vs 1,500 function checks)</li>
<li>Overall speedup: <strong>50-100x faster</strong> coverage lookups</li>
</ul>
<h3 id="why-this-matters-1"><a class="header" href="#why-this-matters-1">Why This Matters</a></h3>
<p>When analyzing a typical Rust project with coverage enabled:</p>
<ul>
<li><strong>Function count</strong>: ~1,500 functions (after demangling)</li>
<li><strong>File count</strong>: ~375 files</li>
<li><strong>Lookups per analysis</strong>: ~19,600</li>
<li><strong>Average functions per file</strong>: ~4</li>
</ul>
<p><strong>OLD flat structure (O(n) scans):</strong></p>
<ul>
<li>19,600 lookups √ó 4,500 comparisons = 88 million operations</li>
<li>Estimated time: ~1 minute</li>
</ul>
<p><strong>NEW nested structure (O(1) lookups):</strong></p>
<ul>
<li>19,600 lookups √ó 1-3 operations = ~60,000 operations</li>
<li>Estimated time: ~3 seconds</li>
</ul>
<p><strong>Speedup</strong>: ~20x faster just from index structure optimization</p>
<h3 id="combined-with-function-demangling"><a class="header" href="#combined-with-function-demangling">Combined with Function Demangling</a></h3>
<p>This optimization works synergistically with LLVM coverage function name demangling (Spec 134):</p>
<p><strong>Original (no demangling, flat structure):</strong></p>
<ul>
<li>18,631 mangled functions</li>
<li>O(n) linear scans</li>
<li>Total time: 10+ minutes</li>
</ul>
<p><strong>After demangling (Spec 134):</strong></p>
<ul>
<li>1,500 demangled functions</li>
<li>O(n) linear scans (still)</li>
<li>Total time: ~1 minute</li>
</ul>
<p><strong>After nested structure (Spec 135):</strong></p>
<ul>
<li>1,500 demangled functions</li>
<li>O(1) hash lookups</li>
<li>Total time: ~3 seconds</li>
</ul>
<p><strong>Combined speedup: ~50,000x</strong> (10+ minutes ‚Üí 3 seconds)</p>
<h3 id="implementation-details"><a class="header" href="#implementation-details">Implementation Details</a></h3>
<p><strong>Exact Match Lookup (O(1)):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get_function_coverage(&amp;self, file: &amp;Path, function_name: &amp;str) -&gt; Option&lt;f64&gt; {
    // Two O(1) hash lookups
    if let Some(file_functions) = self.by_file.get(file) {
        if let Some(coverage) = file_functions.get(function_name) {
            return Some(coverage.coverage_percentage / 100.0);
        }
    }
    // Fallback to path strategies (rare)
    self.find_by_path_strategies(file, function_name)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Path Strategy Fallback (O(files)):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn find_by_path_strategies(&amp;self, query_path: &amp;Path, function_name: &amp;str) -&gt; Option&lt;f64&gt; {
    // Iterate over FILES not FUNCTIONS (375 vs 1,500 = 4x faster)
    for file_path in &amp;self.file_paths {
        if query_path.ends_with(file_path) {
            // O(1) lookup once we find the right file
            if let Some(file_functions) = self.by_file.get(file_path) {
                if let Some(coverage) = file_functions.get(function_name) {
                    return Some(coverage.coverage_percentage / 100.0);
                }
            }
        }
    }
    None
}
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-overhead-1"><a class="header" href="#memory-overhead-1">Memory Overhead</a></h3>
<p>The nested structure has minimal memory overhead:</p>
<p><strong>Flat structure:</strong></p>
<ul>
<li>1,500 entries √ó ~200 bytes = 300KB</li>
</ul>
<p><strong>Nested structure:</strong></p>
<ul>
<li>Outer HashMap: 375 entries √ó ~50 bytes = 18.75KB</li>
<li>Inner HashMaps: 375 √ó ~4 functions √ó ~200 bytes = 300KB</li>
<li>File paths vector: 375 √ó ~100 bytes = 37.5KB</li>
<li><strong>Total: ~356KB</strong></li>
</ul>
<p><strong>Memory increase: ~56KB (18%)</strong> - negligible cost for 50-100x speedup</p>
<h3 id="benchmarking-coverage-performance"><a class="header" href="#benchmarking-coverage-performance">Benchmarking Coverage Performance</a></h3>
<p>Debtmap includes benchmarks to validate coverage index performance:</p>
<pre><code class="language-bash"># Run coverage performance benchmarks
cargo bench --bench coverage_performance

# Compare old flat structure vs new nested structure
# Expected results:
#   old_flat_structure:    450ms
#   new_nested_structure:  8ms
#   Speedup: ~56x
</code></pre>
<p>The <code>flat_vs_nested_comparison</code> benchmark simulates the old O(n) scan behavior and compares it with the new nested structure, demonstrating the 50-100x improvement.</p>
<h3 id="impact-on-analysis-time"><a class="header" href="#impact-on-analysis-time">Impact on Analysis Time</a></h3>
<p>Coverage lookups are now negligible overhead:</p>
<p><strong>Without coverage optimization:</strong></p>
<ul>
<li>Analysis overhead from coverage: ~1 minute</li>
<li>Percentage of total time: 60-80%</li>
</ul>
<p><strong>With coverage optimization:</strong></p>
<ul>
<li>Analysis overhead from coverage: ~3 seconds</li>
<li>Percentage of total time: 5-10%</li>
</ul>
<p>This makes coverage-enabled analysis practical for CI/CD pipelines and real-time feedback during development.</p>
<h2 id="performance-tuning-2"><a class="header" href="#performance-tuning-2">Performance Tuning</a></h2>
<h3 id="optimal-thread-count"><a class="header" href="#optimal-thread-count">Optimal Thread Count</a></h3>
<p><strong>General rule:</strong> Use physical core count, not logical cores.</p>
<pre><code class="language-bash"># Check physical core count
lscpu | grep "Core(s) per socket"

# macOS
sysctl hw.physicalcpu
</code></pre>
<p><strong>Recommended settings:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>System</th><th>Cores</th><th>Recommended ‚Äìjobs</th></tr></thead><tbody>
<tr><td>Laptop</td><td>4</td><td>Default or 4</td></tr>
<tr><td>Desktop</td><td>8</td><td>Default</td></tr>
<tr><td>Workstation</td><td>16+</td><td>Default</td></tr>
<tr><td>CI/CD</td><td>Varies</td><td>2-4 (shared resources)</td></tr>
</tbody></table>
</div>
<h3 id="memory-considerations"><a class="header" href="#memory-considerations">Memory Considerations</a></h3>
<p>Each thread requires memory for:</p>
<ul>
<li>AST parsing (~1-5 MB per file)</li>
<li>Analysis state (~500 KB per file)</li>
<li>Temporary buffers</li>
</ul>
<p><strong>Memory usage estimate:</strong></p>
<pre><code>Total Memory ‚âà (Thread Count) √ó (Average File Size) √ó 2-3
</code></pre>
<p><strong>Example (50 files, average 10 KB each, 8 threads):</strong></p>
<pre><code>Memory ‚âà 8 √ó 10 KB √ó 3 = 240 KB (negligible)
</code></pre>
<p>For very large files (&gt;1 MB), consider reducing thread count.</p>
<h3 id="memory-vs-speed-tradeoffs"><a class="header" href="#memory-vs-speed-tradeoffs">Memory vs Speed Tradeoffs</a></h3>
<p>Parallel processing uses more memory:</p>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Memory Overhead</th><th>Speed Benefit</th></tr></thead><tbody>
<tr><td><code>--no-parallel</code></td><td>Baseline</td><td>Baseline</td></tr>
<tr><td><code>--jobs 1</code></td><td>+10% (data structures)</td><td>1x</td></tr>
<tr><td><code>--jobs 4</code></td><td>+30% (+ worker buffers)</td><td>4-6x</td></tr>
<tr><td><code>--jobs 8</code></td><td>+50% (+ worker buffers)</td><td>6-10x</td></tr>
<tr><td><code>--jobs 16</code></td><td>+80% (+ worker buffers)</td><td>10-15x</td></tr>
</tbody></table>
</div>
<p><strong>Memory overhead sources:</strong></p>
<ul>
<li>DashMap internal sharding (~2x HashMap)</li>
<li>Per-worker thread stacks and buffers</li>
<li>Parallel iterator intermediates</li>
</ul>
<h3 id="io-bound-vs-cpu-bound"><a class="header" href="#io-bound-vs-cpu-bound">I/O Bound vs CPU Bound</a></h3>
<p><strong>CPU-bound analysis (default):</strong></p>
<ul>
<li>Complexity calculations</li>
<li>Pattern detection</li>
<li>Risk scoring</li>
</ul>
<p>Parallel processing provides 4-8x speedup.</p>
<p><strong>I/O-bound operations:</strong></p>
<ul>
<li>Reading files from disk</li>
<li>Loading coverage data</li>
</ul>
<p>Limited speedup from parallelism (1.5-2x).</p>
<p><strong>If analysis is I/O-bound:</strong></p>
<ol>
<li>Move cache to SSD</li>
<li>Reduce thread count (less I/O contention)</li>
<li>Use <code>--max-files</code> to limit scope</li>
</ol>
<h2 id="scaling-strategies"><a class="header" href="#scaling-strategies">Scaling Strategies</a></h2>
<h3 id="small-projects-10k-loc"><a class="header" href="#small-projects-10k-loc">Small Projects (&lt;10k LOC)</a></h3>
<pre><code class="language-bash"># Default settings are fine
debtmap analyze .
</code></pre>
<p>Parallel overhead may exceed benefits. Consider <code>--no-parallel</code> if analysis is &lt;1 second.</p>
<h3 id="medium-projects-10k-100k-loc"><a class="header" href="#medium-projects-10k-100k-loc">Medium Projects (10k-100k LOC)</a></h3>
<pre><code class="language-bash"># Use all cores
debtmap analyze .
</code></pre>
<p>Optimal parallel efficiency. Expect 4-8x speedup from parallelism.</p>
<h3 id="large-projects-100k-loc"><a class="header" href="#large-projects-100k-loc">Large Projects (&gt;100k LOC)</a></h3>
<pre><code class="language-bash"># Use all cores with optimized cache
export DEBTMAP_CACHE_MAX_SIZE=5368709120  # 5GB
debtmap analyze . --jobs 0  # 0 = all cores
</code></pre>
<p>Maximize cache size to avoid re-analysis.</p>
<h3 id="cicd-environments"><a class="header" href="#cicd-environments">CI/CD Environments</a></h3>
<pre><code class="language-bash"># Limit threads to avoid resource contention
debtmap analyze . --jobs 2
</code></pre>
<p>CI environments often limit CPU cores per job.</p>
<h3 id="scaling-behavior"><a class="header" href="#scaling-behavior">Scaling Behavior</a></h3>
<p>Debtmap‚Äôs parallel processing scales with CPU core count:</p>
<p><strong>Strong Scaling (Fixed Problem Size):</strong></p>
<div class="table-wrapper"><table><thead><tr><th>CPU Cores</th><th>Speedup</th><th>Efficiency</th></tr></thead><tbody>
<tr><td>1</td><td>1x</td><td>100%</td></tr>
<tr><td>2</td><td>1.8x</td><td>90%</td></tr>
<tr><td>4</td><td>3.4x</td><td>85%</td></tr>
<tr><td>8</td><td>6.2x</td><td>78%</td></tr>
<tr><td>16</td><td>10.5x</td><td>66%</td></tr>
<tr><td>32</td><td>16.8x</td><td>53%</td></tr>
</tbody></table>
</div>
<p>Efficiency decreases at higher core counts due to:</p>
<ul>
<li>Synchronization overhead (atomic operations, DashMap locking)</li>
<li>Memory bandwidth saturation</li>
<li>Diminishing returns from Amdahl‚Äôs law (sequential portions)</li>
</ul>
<p><strong>Weak Scaling (Problem Size Grows with Cores):</strong></p>
<p>Debtmap maintains high efficiency when problem size scales with core count, making it ideal for analyzing larger codebases on more powerful machines.</p>
<h2 id="tuning-guidelines-1"><a class="header" href="#tuning-guidelines-1">Tuning Guidelines</a></h2>
<p><strong>Development Workstations:</strong></p>
<pre><code class="language-bash"># Use all cores for maximum speed
debtmap analyze --jobs 0
</code></pre>
<p><strong>CI/CD Environments:</strong></p>
<pre><code class="language-bash"># Limit threads to avoid resource contention
debtmap analyze --jobs 2

# Or disable parallelism on very constrained runners
debtmap analyze --no-parallel
</code></pre>
<p><strong>Containers:</strong></p>
<pre><code class="language-bash"># Auto-detection respects cgroup limits
debtmap analyze --jobs 0

# Or explicitly match container CPU allocation
debtmap analyze --jobs 4
</code></pre>
<p><strong>Benchmarking:</strong></p>
<pre><code class="language-bash"># Use fixed thread count for reproducible results
debtmap analyze --jobs 8
</code></pre>
<h2 id="profiling-and-debugging"><a class="header" href="#profiling-and-debugging">Profiling and Debugging</a></h2>
<h3 id="measure-analysis-time"><a class="header" href="#measure-analysis-time">Measure Analysis Time</a></h3>
<pre><code class="language-bash">time debtmap analyze .
</code></pre>
<h3 id="disable-parallelism-for-debugging"><a class="header" href="#disable-parallelism-for-debugging">Disable Parallelism for Debugging</a></h3>
<pre><code class="language-bash">debtmap analyze . --no-parallel -vv
</code></pre>
<p>Single-threaded mode with verbose output for debugging.</p>
<h3 id="profile-thread-usage"><a class="header" href="#profile-thread-usage">Profile Thread Usage</a></h3>
<p>Use system tools to monitor thread usage:</p>
<pre><code class="language-bash"># Linux
htop

# macOS
Activity Monitor (View &gt; CPU Usage &gt; Show Threads)
</code></pre>
<p>Look for:</p>
<ul>
<li>All cores at ~100% utilization (optimal)</li>
<li>Some cores idle (I/O bound or insufficient work)</li>
<li>Excessive context switching (too many threads)</li>
</ul>
<h3 id="finding-optimal-settings"><a class="header" href="#finding-optimal-settings">Finding Optimal Settings</a></h3>
<p><strong>Finding the optimal setting:</strong></p>
<pre><code class="language-bash"># Benchmark different configurations
time debtmap analyze --jobs 0  # Auto
time debtmap analyze --jobs 4  # 4 threads
time debtmap analyze --jobs 8  # 8 threads
time debtmap analyze --no-parallel  # Sequential
</code></pre>
<p>Monitor memory usage during analysis:</p>
<pre><code class="language-bash"># Monitor peak memory usage
/usr/bin/time -v debtmap analyze --jobs 8
</code></pre>
<h2 id="best-practices-14"><a class="header" href="#best-practices-14">Best Practices</a></h2>
<ol>
<li><strong>Use default settings</strong> - Debtmap auto-detects optimal thread count</li>
<li><strong>Limit threads in CI</strong> - Use <code>--jobs 2</code> or <code>--jobs 4</code> in shared environments</li>
<li><strong>Profile before tuning</strong> - Measure actual performance impact</li>
<li><strong>Consider I/O</strong> - If using slow storage, reduce thread count</li>
<li><strong>Cache aggressively</strong> - Large caches reduce repeated work</li>
</ol>
<h2 id="troubleshooting-16"><a class="header" href="#troubleshooting-16">Troubleshooting</a></h2>
<h3 id="analysis-is-slow-despite-parallelism"><a class="header" href="#analysis-is-slow-despite-parallelism">Analysis is Slow Despite Parallelism</a></h3>
<p><strong>Possible causes:</strong></p>
<ol>
<li>I/O bottleneck (slow disk)</li>
<li>Cache disabled or cleared</li>
<li>Excessive cache pruning</li>
<li>Memory pressure (swapping)</li>
</ol>
<p><strong>Solutions:</strong></p>
<ul>
<li>Move cache to SSD</li>
<li>Increase <code>DEBTMAP_CACHE_MAX_SIZE</code></li>
<li>Reduce thread count to avoid memory pressure</li>
</ul>
<h3 id="slow-analysis-performance"><a class="header" href="#slow-analysis-performance">Slow Analysis Performance</a></h3>
<p>If analysis is slower than expected:</p>
<ol>
<li>
<p><strong>Check thread count:</strong></p>
<pre><code class="language-bash"># Ensure you're using all cores
debtmap analyze --jobs 0 -vv | grep "threads"
</code></pre>
</li>
<li>
<p><strong>Check I/O bottleneck:</strong></p>
<pre><code class="language-bash"># Use iotop or similar to check disk saturation
# SSD storage significantly improves performance
</code></pre>
</li>
<li>
<p><strong>Check memory pressure:</strong></p>
<pre><code class="language-bash"># Monitor memory usage during analysis
top -p $(pgrep debtmap)
</code></pre>
</li>
<li>
<p><strong>Try different thread counts:</strong></p>
<pre><code class="language-bash"># Sometimes less threads = less contention
debtmap analyze --jobs 4
</code></pre>
</li>
</ol>
<h3 id="high-cpu-usage-but-no-progress"><a class="header" href="#high-cpu-usage-but-no-progress">High CPU Usage But No Progress</a></h3>
<p><strong>Possible cause:</strong> Analyzing very complex files (large ASTs)</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash"># Reduce thread count to avoid memory thrashing
debtmap analyze . --jobs 2
</code></pre>
<h3 id="high-memory-usage"><a class="header" href="#high-memory-usage">High Memory Usage</a></h3>
<p>If debtmap uses too much memory:</p>
<ol>
<li>
<p><strong>Reduce parallelism:</strong></p>
<pre><code class="language-bash">debtmap analyze --jobs 2
</code></pre>
</li>
<li>
<p><strong>Disable parallel call graph:</strong></p>
<pre><code class="language-bash">debtmap analyze --no-parallel
</code></pre>
</li>
<li>
<p><strong>Analyze subdirectories separately:</strong></p>
<pre><code class="language-bash"># Process codebase in chunks
debtmap analyze src/module1
debtmap analyze src/module2
</code></pre>
</li>
</ol>
<h3 id="inconsistent-results-between-runs"><a class="header" href="#inconsistent-results-between-runs">Inconsistent Results Between Runs</a></h3>
<p><strong>Possible cause:</strong> Non-deterministic parallel aggregation (rare)</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash"># Use single-threaded mode
debtmap analyze . --no-parallel
</code></pre>
<p>If results differ, report as a bug.</p>
<h3 id="debugging-concurrency-issues"><a class="header" href="#debugging-concurrency-issues">Debugging Concurrency Issues</a></h3>
<p>If you suspect a concurrency bug:</p>
<ol>
<li>
<p><strong>Run sequentially to isolate:</strong></p>
<pre><code class="language-bash">debtmap analyze --no-parallel
</code></pre>
</li>
<li>
<p><strong>Use deterministic mode:</strong></p>
<pre><code class="language-bash"># Single-threaded = deterministic order
debtmap analyze --jobs 1
</code></pre>
</li>
<li>
<p><strong>Enable verbose logging:</strong></p>
<pre><code class="language-bash">debtmap analyze -vvv --no-parallel &gt; debug.log 2&gt;&amp;1
</code></pre>
</li>
<li>
<p><strong>Report the issue:</strong>
If behavior differs between <code>--no-parallel</code> and parallel mode, please <a href="https://github.com/yourusername/debtmap/issues">report it</a> with:</p>
<ul>
<li>Command used</li>
<li>Platform (OS, CPU core count)</li>
<li>Debtmap version</li>
<li>Minimal reproduction case</li>
</ul>
</li>
</ol>
<h3 id="thread-contention-warning"><a class="header" href="#thread-contention-warning">Thread Contention Warning</a></h3>
<p>If you see warnings about thread contention:</p>
<pre><code>WARN - High contention detected on parallel call graph
</code></pre>
<p>This indicates too many threads competing for locks. Try:</p>
<pre><code class="language-bash"># Reduce thread count
debtmap analyze --jobs 4
</code></pre>
<h2 id="see-also-4"><a class="header" href="#see-also-4">See Also</a></h2>
<ul>
<li><a href="./cli-reference.html#performance--caching">CLI Reference - Performance &amp; Caching</a> - Complete flag documentation</li>
<li><a href="cache-management.html">Cache Management</a> - Cache configuration for performance</li>
<li><a href="configuration.html">Configuration</a> - Project-specific settings</li>
<li><a href="troubleshooting.html">Troubleshooting</a> - General troubleshooting guide</li>
<li><a href="./troubleshooting.html#slow-analysis-performance">Troubleshooting - Slow Analysis</a> - Performance debugging guide</li>
<li><a href="./troubleshooting.html#high-memory-usage">Troubleshooting - High Memory Usage</a> - Memory optimization tips</li>
<li><a href="./faq.html">FAQ - Reducing Parallelism</a> - Common questions about parallel processing</li>
<li><a href="./architecture.html">Architecture</a> - High-level system design</li>
</ul>
<h2 id="summary-8"><a class="header" href="#summary-8">Summary</a></h2>
<p>Debtmap‚Äôs parallel processing architecture provides:</p>
<ul>
<li><strong>10-100x speedup</strong> over sequential analysis using Rayon parallel iterators</li>
<li><strong>Lock-free concurrency</strong> with DashMap for minimal contention</li>
<li><strong>Flexible configuration</strong> via <code>--jobs</code> and <code>--no-parallel</code> flags</li>
<li><strong>Automatic thread pool tuning</strong> that respects system resources</li>
<li><strong>Production-grade reliability</strong> with atomic progress tracking and concurrent merging</li>
</ul>
<p>The three-phase parallel pipeline (parse ‚Üí extract ‚Üí analyze) maximizes parallelism while maintaining correctness through carefully designed concurrent data structures.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prodigy-integration"><a class="header" href="#prodigy-integration">Prodigy Integration</a></h1>
<p>Debtmap integrates with <a href="https://github.com/iepathos/prodigy">Prodigy</a> to provide fully automated technical debt reduction through AI-driven workflows. This chapter explains how to set up and use Prodigy workflows to automatically refactor code, add tests, and improve codebase quality.</p>
<h2 id="prerequisites-checklist"><a class="header" href="#prerequisites-checklist">Prerequisites Checklist</a></h2>
<p>Before using Prodigy with Debtmap, ensure you have:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Rust 1.70 or later installed</li>
<li><input disabled="" type="checkbox"/>
Debtmap installed (<code>cargo install debtmap</code>)</li>
<li><input disabled="" type="checkbox"/>
Prodigy installed (<code>cargo install --git https://github.com/iepathos/prodigy prodigy</code>)</li>
<li><input disabled="" type="checkbox"/>
Anthropic API key for Claude access</li>
<li><input disabled="" type="checkbox"/>
Git (for worktree management)</li>
<li><input disabled="" type="checkbox"/>
Optional: <code>just</code> command runner (a command runner like make), or use direct <code>cargo</code> commands as alternatives</li>
</ul>
<h2 id="what-is-prodigy"><a class="header" href="#what-is-prodigy">What is Prodigy?</a></h2>
<blockquote>
<p><strong>Note</strong>: Prodigy is a separate open-source tool (https://github.com/iepathos/prodigy). You need to install both Debtmap and Prodigy to use this integration.</p>
</blockquote>
<p>Prodigy is an AI-powered workflow automation system that uses Claude to execute complex multi-step tasks. When integrated with Debtmap, it can:</p>
<ul>
<li><strong>Automatically refactor</strong> high-complexity functions identified by Debtmap</li>
<li><strong>Add unit tests</strong> for untested code</li>
<li><strong>Fix code duplication</strong> by extracting shared logic</li>
<li><strong>Improve code organization</strong> by addressing architectural issues</li>
<li><strong>Validate improvements</strong> with automated testing</li>
</ul>
<p>All changes are made in isolated git worktrees, validated with tests and linting, and only committed if all checks pass.</p>
<h2 id="benefits"><a class="header" href="#benefits">Benefits</a></h2>
<h3 id="automated-debt-reduction"><a class="header" href="#automated-debt-reduction">Automated Debt Reduction</a></h3>
<p>Instead of manually addressing each technical debt item, Prodigy can:</p>
<ol>
<li>Analyze Debtmap‚Äôs output</li>
<li>Select high-priority items</li>
<li>Generate refactoring plans</li>
<li>Execute refactorings automatically</li>
<li>Validate with tests</li>
<li>Commit clean changes</li>
</ol>
<h3 id="iterative-improvement"><a class="header" href="#iterative-improvement">Iterative Improvement</a></h3>
<p>Prodigy supports <strong>iterative workflows</strong>:</p>
<ul>
<li>Run analysis ‚Üí fix top items ‚Üí re-analyze ‚Üí fix more</li>
<li>Configurable iteration count (default: 5 iterations)</li>
<li>Each iteration focuses on highest-priority remaining items</li>
</ul>
<h3 id="safe-experimentation"><a class="header" href="#safe-experimentation">Safe Experimentation</a></h3>
<p>All changes happen in <strong>isolated git worktrees</strong>:</p>
<ul>
<li>Original branch remains untouched</li>
<li>Failed attempts don‚Äôt affect main codebase</li>
<li>Easy to review before merging</li>
<li>Automatic cleanup after workflow</li>
</ul>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<h3 id="install-prodigy"><a class="header" href="#install-prodigy">Install Prodigy</a></h3>
<pre><code class="language-bash"># Install Prodigy from GitHub repository
cargo install --git https://github.com/iepathos/prodigy prodigy

# Verify installation
prodigy --version
</code></pre>
<blockquote>
<p><strong>Note</strong>: Currently, Prodigy must be installed from GitHub. Check the <a href="https://github.com/iepathos/prodigy">Prodigy repository</a> for the latest installation instructions.</p>
</blockquote>
<p><strong>Requirements:</strong></p>
<ul>
<li>Rust 1.70 or later</li>
<li>Git (for worktree management)</li>
<li>Anthropic API key for Claude access</li>
</ul>
<h3 id="configure-claude-api"><a class="header" href="#configure-claude-api">Configure Claude API</a></h3>
<pre><code class="language-bash"># Set Claude API key
export ANTHROPIC_API_KEY="your-api-key-here"

# Or in ~/.prodigy/config.toml:
[api]
anthropic_key = "your-api-key-here"
</code></pre>
<h3 id="ensure-debtmap-is-installed"><a class="header" href="#ensure-debtmap-is-installed">Ensure Debtmap is Installed</a></h3>
<pre><code class="language-bash"># Install Debtmap
cargo install debtmap

# Verify installation
debtmap --version
</code></pre>
<h2 id="quick-start-2"><a class="header" href="#quick-start-2">Quick Start</a></h2>
<h3 id="1-initialize-workflow"><a class="header" href="#1-initialize-workflow">1. Initialize Workflow</a></h3>
<p>Create a workflow file <code>workflows/debtmap.yml</code>:</p>
<pre><code class="language-yaml"># Sequential workflow. Fix top technical debt item

# Phase 1: Generate coverage data
- shell: "just coverage-lcov"  # or: cargo tarpaulin --out lcov --output-dir target/coverage

# Phase 2: Analyze tech debt and capture baseline
- shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-before.json --format json"

# Phase 3: Create implementation plan (PLANNING PHASE)
- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"
  capture_output: true
  validate:
    commands:
      - claude: "/prodigy-validate-debtmap-plan --before .prodigy/debtmap-before.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/plan-validation.json"
    result_file: ".prodigy/plan-validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-revise-debtmap-plan --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
      max_attempts: 3
      fail_workflow: false

# Phase 4: Execute the plan (IMPLEMENTATION PHASE)
- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
  validate:
    commands:
      - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
      - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      - shell: "debtmap validate-improvement --comparison .prodigy/comparison.json --output .prodigy/debtmap-validation.json"
    result_file: ".prodigy/debtmap-validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
          commit_required: true
        - shell: "just coverage-lcov"
        - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
        - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      max_attempts: 5
      fail_workflow: true

# Phase 5: Run tests with automatic fixing
- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true

# Phase 6: Run linting and formatting
- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<blockquote>
<p><strong>Note about <code>just</code></strong>: This example uses <code>just</code> (a command runner like <code>make</code>). If you don‚Äôt have a <code>justfile</code>, replace <code>just coverage-lcov</code> with <code>cargo tarpaulin --out lcov --output-dir target/coverage</code>, <code>just test</code> with <code>cargo test</code>, and <code>just fmt-check &amp;&amp; just lint</code> with <code>cargo fmt --check &amp;&amp; cargo clippy -- -D warnings</code>.</p>
</blockquote>
<h3 id="2-run-workflow"><a class="header" href="#2-run-workflow">2. Run Workflow</a></h3>
<pre><code class="language-bash"># Run with auto-confirm, 5 iterations
prodigy run workflows/debtmap.yml -yn 5

# Run with custom iteration count
prodigy run workflows/debtmap.yml -yn 10

# Run single iteration for testing
prodigy run workflows/debtmap.yml -yn 1
</code></pre>
<p><strong>Command Flags:</strong></p>
<ul>
<li><code>-y</code> (<code>--yes</code>) - Auto-confirm workflow steps (skip prompts)</li>
<li><code>-n 5</code> (<code>--max-iterations 5</code>) - Run workflow for up to 5 iterations</li>
</ul>
<p><strong>Note</strong>: Worktrees are managed separately via the <code>prodigy worktree</code> command. In MapReduce mode, Prodigy automatically creates isolated worktrees for each parallel agent.</p>
<h3 id="3-review-results"><a class="header" href="#3-review-results">3. Review Results</a></h3>
<p>Prodigy creates a detailed report:</p>
<pre><code>üìä WORKFLOW SUMMARY
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Iterations: 5
Items Fixed: 12
Tests Added: 8
Complexity Reduced: 145 ‚Üí 78 (-46%)
Coverage Improved: 45% ‚Üí 72% (+27%)

‚úÖ All validations passed
</code></pre>
<h2 id="useful-prodigy-commands"><a class="header" href="#useful-prodigy-commands">Useful Prodigy Commands</a></h2>
<p>Beyond <code>prodigy run</code>, several commands help manage workflows and sessions:</p>
<h3 id="resume-interrupted-workflows"><a class="header" href="#resume-interrupted-workflows">Resume Interrupted Workflows</a></h3>
<pre><code class="language-bash"># Resume an interrupted sequential workflow
prodigy resume &lt;SESSION_ID&gt;

# Resume an interrupted MapReduce job
prodigy resume-job &lt;JOB_ID&gt;

# List all sessions to find the SESSION_ID
prodigy sessions
</code></pre>
<p><strong>When to use</strong>: If a workflow is interrupted (Ctrl-C, system crash, network issues), you can resume from the last checkpoint rather than starting over.</p>
<h3 id="view-checkpoints"><a class="header" href="#view-checkpoints">View Checkpoints</a></h3>
<pre><code class="language-bash"># List all available checkpoints
prodigy checkpoints

# List checkpoints for specific session
prodigy checkpoints --session &lt;SESSION_ID&gt;
</code></pre>
<p><strong>When to use</strong>: To see available restore points for interrupted workflows.</p>
<h3 id="manage-worktrees"><a class="header" href="#manage-worktrees">Manage Worktrees</a></h3>
<pre><code class="language-bash"># List all Prodigy worktrees
prodigy worktree list

# Clean up old worktrees
prodigy worktree clean

# Remove specific worktree
prodigy worktree remove &lt;SESSION_ID&gt;
</code></pre>
<p><strong>When to use</strong>: MapReduce workflows create many worktrees. Clean them up periodically to save disk space.</p>
<h3 id="monitor-mapreduce-progress"><a class="header" href="#monitor-mapreduce-progress">Monitor MapReduce Progress</a></h3>
<pre><code class="language-bash"># View progress of running MapReduce job
prodigy progress &lt;JOB_ID&gt;

# View events and logs from MapReduce job
prodigy events &lt;JOB_ID&gt;

# Filter events by type
prodigy events &lt;JOB_ID&gt; --type agent_started
prodigy events &lt;JOB_ID&gt; --type agent_completed
prodigy events &lt;JOB_ID&gt; --type agent_failed
</code></pre>
<p><strong>When to use</strong>: Monitor long-running MapReduce jobs to see how many agents have completed, which are still running, and which have failed.</p>
<h3 id="manage-dead-letter-queue"><a class="header" href="#manage-dead-letter-queue">Manage Dead Letter Queue</a></h3>
<pre><code class="language-bash"># View failed MapReduce items in DLQ
prodigy dlq list &lt;JOB_ID&gt;

# Retry failed items from DLQ
prodigy dlq retry &lt;JOB_ID&gt; &lt;ITEM_ID&gt;

# Remove items from DLQ
prodigy dlq remove &lt;JOB_ID&gt; &lt;ITEM_ID&gt;
</code></pre>
<p><strong>When to use</strong>: When some MapReduce agents fail, their items go to the Dead Letter Queue. You can retry them individually or investigate why they failed.</p>
<h3 id="session-management"><a class="header" href="#session-management">Session Management</a></h3>
<pre><code class="language-bash"># List all workflow sessions
prodigy sessions

# Clean up old sessions
prodigy clean
</code></pre>
<p><strong>When to use</strong>: View history of workflow runs and clean up old data.</p>
<h2 id="workflow-configuration"><a class="header" href="#workflow-configuration">Workflow Configuration</a></h2>
<p>Prodigy workflows are defined as YAML lists of steps. Each step can be either a <code>shell</code> command or a <code>claude</code> slash command.</p>
<h3 id="workflow-step-types"><a class="header" href="#workflow-step-types">Workflow Step Types</a></h3>
<h4 id="shell-commands"><a class="header" href="#shell-commands">Shell Commands</a></h4>
<p>Execute shell commands directly:</p>
<pre><code class="language-yaml"># Simple shell command
- shell: "cargo test"

# With timeout (in seconds)
- shell: "just coverage-lcov"
  timeout: 900  # 15 minutes

# With error handling
- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<p><strong>Shell Command Fields:</strong></p>
<ul>
<li><code>shell</code>: Command to execute (string)</li>
<li><code>timeout</code>: Maximum execution time in seconds (optional)</li>
<li><code>on_failure</code>: Error handler configuration (optional)
<ul>
<li><code>claude</code>: Slash command to run on failure</li>
<li><code>max_attempts</code>: Maximum retry attempts</li>
<li><code>fail_workflow</code>: If true, fail entire workflow after max attempts</li>
</ul>
</li>
</ul>
<h4 id="claude-commands"><a class="header" href="#claude-commands">Claude Commands</a></h4>
<p>Execute Claude Code slash commands:</p>
<pre><code class="language-yaml"># Simple Claude command
- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"

# With output capture (makes command output available in ${shell.output})
- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"
  capture_output: true

# With commit requirement (workflow fails if no git commit made)
- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true

# With timeout and validation
- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
  timeout: 1800  # 30 minutes
  validate:
    commands:
      - shell: "cargo test"
    result_file: ".prodigy/validation.json"
    threshold: 75
</code></pre>
<p><strong>Claude Command Fields:</strong></p>
<ul>
<li><code>claude</code>: Slash command to execute (string)</li>
<li><code>capture_output</code>: If true, command output is available in <code>${shell.output}</code> variable (optional)</li>
<li><code>commit_required</code>: If true, workflow fails if command doesn‚Äôt create a git commit (optional)</li>
<li><code>timeout</code>: Maximum execution time in seconds (optional)</li>
<li><code>validate</code>: Validation configuration (optional, see Step-Level Validation below)</li>
</ul>
<h3 id="step-level-validation"><a class="header" href="#step-level-validation">Step-Level Validation</a></h3>
<p>Steps can include validation that must pass:</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
  validate:
    commands:
      - shell: "cargo test"
      - shell: "cargo clippy -- -D warnings"
    result_file: ".prodigy/validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
          commit_required: true
      max_attempts: 5
      fail_workflow: true
</code></pre>
<p><strong>Validation Options:</strong></p>
<ul>
<li><code>commands</code>: List of commands to run for validation</li>
<li><code>result_file</code>: JSON file containing validation results</li>
<li><code>threshold</code>: Minimum score (0-100) required to pass</li>
<li><code>on_incomplete</code>: Actions to take if validation score &lt; threshold</li>
<li><code>max_attempts</code>: Maximum retry attempts</li>
<li><code>fail_workflow</code>: Whether to fail entire workflow if validation never passes</li>
</ul>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<p>Use <code>on_failure</code> to handle command failures:</p>
<pre><code class="language-yaml">- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<p><strong>Error Handling Options:</strong></p>
<ul>
<li><code>claude</code>: Slash command to fix the failure</li>
<li><code>max_attempts</code>: Maximum fix attempts</li>
<li><code>fail_workflow</code>: If true, workflow fails after max_attempts; if false, continues to next step</li>
</ul>
<h3 id="coverage-integration-3"><a class="header" href="#coverage-integration-3">Coverage Integration</a></h3>
<p>Generate and use coverage data in workflows. See <a href="./coverage-integration.html">Coverage Integration</a> for details on generating LCOV files and understanding coverage metrics.</p>
<pre><code class="language-yaml"># Generate coverage
- shell: "just coverage-lcov"

# Use coverage in analysis
- shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-before.json --format json"
</code></pre>
<h2 id="claude-slash-commands"><a class="header" href="#claude-slash-commands">Claude Slash Commands</a></h2>
<blockquote>
<p><strong>Important</strong>: The slash commands documented below are custom commands provided in Debtmap‚Äôs <code>.claude/commands/</code> directory as examples. They are not built into Prodigy or Debtmap. You can use them as-is from the Debtmap repository or create your own based on these patterns.</p>
</blockquote>
<p>Prodigy workflows use Claude Code slash commands to perform analysis, planning, and implementation. The key commands used in the debtmap workflow are:</p>
<h3 id="planning-commands"><a class="header" href="#planning-commands">Planning Commands</a></h3>
<h4 id="prodigy-debtmap-plan"><a class="header" href="#prodigy-debtmap-plan"><code>/prodigy-debtmap-plan</code></a></h4>
<p>Creates an implementation plan for the top priority debt item.</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"
  capture_output: true
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--before</code>: Path to debtmap analysis JSON file</li>
<li><code>--output</code>: Path to write implementation plan</li>
</ul>
<h4 id="prodigy-validate-debtmap-plan"><a class="header" href="#prodigy-validate-debtmap-plan"><code>/prodigy-validate-debtmap-plan</code></a></h4>
<p>Validates that the implementation plan is complete and addresses the debt item.</p>
<pre><code class="language-yaml">- claude: "/prodigy-validate-debtmap-plan --before .prodigy/debtmap-before.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/plan-validation.json"
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--before</code>: Original debtmap analysis</li>
<li><code>--plan</code>: Implementation plan to validate</li>
<li><code>--output</code>: Validation results JSON (with score 0-100)</li>
</ul>
<h4 id="prodigy-revise-debtmap-plan"><a class="header" href="#prodigy-revise-debtmap-plan"><code>/prodigy-revise-debtmap-plan</code></a></h4>
<p>Revises an incomplete plan based on validation gaps.</p>
<pre><code class="language-yaml">- claude: "/prodigy-revise-debtmap-plan --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--gaps</code>: List of missing items from validation</li>
<li><code>--plan</code>: Plan file to update</li>
</ul>
<h3 id="implementation-commands"><a class="header" href="#implementation-commands">Implementation Commands</a></h3>
<h4 id="prodigy-debtmap-implement"><a class="header" href="#prodigy-debtmap-implement"><code>/prodigy-debtmap-implement</code></a></h4>
<p>Executes the implementation plan.</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--plan</code>: Path to implementation plan</li>
</ul>
<h4 id="prodigy-validate-debtmap-improvement-1"><a class="header" href="#prodigy-validate-debtmap-improvement-1"><code>/prodigy-validate-debtmap-improvement</code></a></h4>
<p>Validates that the implementation successfully addressed the debt item.</p>
<blockquote>
<p><strong>Note</strong>: This slash command now wraps the <code>debtmap validate-improvement</code> subcommand. You can use either approach:</p>
<ul>
<li>Claude slash command: <code>/prodigy-validate-debtmap-improvement</code> (recommended for Prodigy workflows)</li>
<li>Direct subcommand: <code>debtmap validate-improvement</code> (recommended for shell scripts)</li>
</ul>
</blockquote>
<pre><code class="language-yaml"># Using Claude slash command (recommended for workflows)
- claude: "/prodigy-validate-debtmap-improvement --comparison .prodigy/comparison.json --output .prodigy/debtmap-validation.json"

# Or using shell command directly
- shell: "debtmap validate-improvement --comparison .prodigy/comparison.json --output .prodigy/debtmap-validation.json"
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--comparison</code>: Debtmap comparison results (before vs after)</li>
<li><code>--output</code>: Validation results JSON (with score 0-100)</li>
<li><code>--previous-validation</code>: (Optional) Previous validation result for trend tracking</li>
<li><code>--threshold</code>: (Optional) Improvement threshold percentage (default: 75.0)</li>
</ul>
<h4 id="prodigy-complete-debtmap-fix"><a class="header" href="#prodigy-complete-debtmap-fix"><code>/prodigy-complete-debtmap-fix</code></a></h4>
<p>Completes a partial fix based on validation gaps.</p>
<pre><code class="language-yaml">- claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--gaps</code>: Validation gaps to address</li>
<li><code>--plan</code>: Original implementation plan</li>
</ul>
<h3 id="testing-and-quality-commands"><a class="header" href="#testing-and-quality-commands">Testing and Quality Commands</a></h3>
<h4 id="prodigy-debug-test-failure"><a class="header" href="#prodigy-debug-test-failure"><code>/prodigy-debug-test-failure</code></a></h4>
<p>Automatically fixes failing tests.</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--output</code>: Test failure output from shell command</li>
</ul>
<h4 id="prodigy-lint"><a class="header" href="#prodigy-lint"><code>/prodigy-lint</code></a></h4>
<p>Fixes linting and formatting issues.</p>
<pre><code class="language-yaml">- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li>Shell output with linting errors</li>
</ul>
<h2 id="target-selection"><a class="header" href="#target-selection">Target Selection</a></h2>
<p>Target selection happens through the debtmap analysis and slash commands, not through workflow configuration:</p>
<h3 id="how-targets-are-selected"><a class="header" href="#how-targets-are-selected">How Targets Are Selected</a></h3>
<ol>
<li><strong>Debtmap analyzes</strong> the codebase and scores all items by complexity, coverage, and risk</li>
<li><strong>Planning command</strong> (<code>/prodigy-debtmap-plan</code>) selects the highest priority item</li>
<li><strong>Implementation command</strong> (<code>/prodigy-debtmap-implement</code>) fixes that specific item</li>
<li><strong>Next iteration</strong> re-analyzes and selects the next highest priority item</li>
</ol>
<h3 id="factors-in-prioritization"><a class="header" href="#factors-in-prioritization">Factors in Prioritization</a></h3>
<ul>
<li><strong>Complexity score</strong>: Functions with cyclomatic complexity &gt; 10</li>
<li><strong>Coverage percentage</strong>: Lower coverage increases priority</li>
<li><strong>Risk score</strong>: Complexity √ó (100 - coverage%)</li>
<li><strong>Debt type</strong>: Complexity, TestGap, Duplication, GodObject, DeepNesting</li>
</ul>
<h3 id="customizing-target-selection"><a class="header" href="#customizing-target-selection">Customizing Target Selection</a></h3>
<p>To focus on specific debt types or modules, modify the slash commands or create custom commands in <code>.claude/commands/</code></p>
<h2 id="mapreduce-workflows"><a class="header" href="#mapreduce-workflows">MapReduce Workflows</a></h2>
<p>Prodigy supports MapReduce workflows for processing multiple items in parallel. This is powerful for large-scale refactoring where you want to fix many debt items simultaneously.</p>
<h3 id="when-to-use-mapreduce"><a class="header" href="#when-to-use-mapreduce">When to Use MapReduce</a></h3>
<ul>
<li>Processing multiple independent debt items simultaneously (e.g., refactor 10 high-complexity functions in parallel)</li>
<li>Applying the same fix pattern across many files</li>
<li>Large-scale codebase cleanup tasks</li>
<li>Situations where sequential iteration would be too slow</li>
</ul>
<h3 id="mapreduce-vs-sequential-workflows"><a class="header" href="#mapreduce-vs-sequential-workflows">MapReduce vs Sequential Workflows</a></h3>
<p><strong>Sequential Workflow</strong> (<code>-n 5</code>):</p>
<ul>
<li>Runs entire workflow N times in sequence</li>
<li>Fixes one item per iteration</li>
<li>Each iteration re-analyzes the codebase</li>
<li>Total time: N √ó workflow_duration</li>
</ul>
<p><strong>MapReduce Workflow</strong>:</p>
<ul>
<li>Processes multiple items in parallel in a single run</li>
<li>Setup phase runs once</li>
<li>Map phase spawns N parallel agents (each in isolated worktree)</li>
<li>Reduce phase aggregates results</li>
<li>Total time: setup + max(map_agent_durations) + reduce</li>
</ul>
<h3 id="complete-mapreduce-example"><a class="header" href="#complete-mapreduce-example">Complete MapReduce Example</a></h3>
<p>Create <code>workflows/debtmap-reduce.yml</code>:</p>
<pre><code class="language-yaml">name: debtmap-parallel-elimination
mode: mapreduce

# Setup phase: Analyze the codebase and generate debt items
setup:
  timeout: 900  # 15 minutes for coverage generation
  commands:
    # Generate coverage data with tarpaulin
    - shell: "just coverage-lcov"

    # Run debtmap with coverage data to establish baseline
    - shell: "debtmap analyze src --lcov target/coverage/lcov.info --output .prodigy/debtmap-before.json --format json"

# Map phase: Process each debt item in parallel with planning and validation
map:
  # Input configuration - debtmap-before.json contains items array
  input: .prodigy/debtmap-before.json
  json_path: "$.items[*]"

  # Commands to execute for each debt item
  agent_template:
    # Phase 1: Create implementation plan
    - claude: "/prodigy-debtmap-plan --item '${item}' --output .prodigy/plan-${item_id}.md"
      capture_output: true
      validate:
        commands:
          - claude: "/prodigy-validate-debtmap-plan --item '${item}' --plan .prodigy/plan-${item_id}.md --output .prodigy/validation-${item_id}.json"
        result_file: ".prodigy/validation-${item_id}.json"
        threshold: 75
        on_incomplete:
          commands:
            - claude: "/prodigy-revise-debtmap-plan --gaps ${validation.gaps} --plan .prodigy/plan-${item_id}.md"
          max_attempts: 3
          fail_workflow: false

    # Phase 2: Execute the plan
    - claude: "/prodigy-debtmap-implement --plan .prodigy/plan-${item_id}.md"
      commit_required: true
      validate:
        commands:
          - shell: "just coverage-lcov"
          - shell: "debtmap analyze src --lcov target/coverage/lcov.info --output .prodigy/debtmap-after-${item_id}.json --format json"
          - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after-${item_id}.json --plan .prodigy/plan-${item_id}.md --output .prodigy/comparison-${item_id}.json --format json"
          - shell: "debtmap validate-improvement --comparison .prodigy/comparison-${item_id}.json --output .prodigy/debtmap-validation-${item_id}.json"
        result_file: ".prodigy/debtmap-validation-${item_id}.json"
        threshold: 75
        on_incomplete:
          commands:
            - claude: "/prodigy-complete-debtmap-fix --plan .prodigy/plan-${item_id}.md --validation .prodigy/debtmap-validation-${item_id}.json --attempt ${validation.attempt_number}"
              commit_required: true
            - shell: "just coverage-lcov"
            - shell: "debtmap analyze src --lcov target/coverage/lcov.info --output .prodigy/debtmap-after-${item_id}.json --format json"
            - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after-${item_id}.json --plan .prodigy/plan-${item_id}.md --output .prodigy/comparison-${item_id}.json --format json"
          max_attempts: 5
          fail_workflow: true

    # Phase 3: Verify tests pass
    - shell: "just test"
      on_failure:
        claude: "/prodigy-debug-test-failure --output ${shell.output}"
        max_attempts: 5
        fail_workflow: true

    # Phase 4: Check formatting and linting
    - shell: "just fmt-check &amp;&amp; just lint"
      on_failure:
        claude: "/prodigy-lint ${shell.output}"
        max_attempts: 5
        fail_workflow: true

  # Parallelization settings
  max_parallel: 5  # Run up to 5 agents in parallel

  # Filter and sort items
  filter: "File.score &gt;= 10 OR Function.unified_score.final_score &gt;= 10"
  sort_by: "File.score DESC, Function.unified_score.final_score DESC"
  max_items: 10  # Limit to 10 items per run

# Reduce phase: Aggregate results and verify overall improvements
reduce:
  # Phase 1: Run final tests across all changes
  - shell: "just test"
    on_failure:
      claude: "/prodigy-debug-test-failure --output ${shell.output}"
      max_attempts: 5
      fail_workflow: true

  # Phase 2: Check formatting and linting
  - shell: "just fmt-check &amp;&amp; just lint"
    on_failure:
      claude: "/prodigy-lint ${shell.output}"
      max_attempts: 5
      fail_workflow: true

  # Phase 3: Re-run debtmap to measure cumulative improvements
  - shell: "just coverage-lcov"
  - shell: "debtmap analyze src --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"

  # Phase 4: Create final commit with summary
  - write_file:
      path: ".prodigy/map-results.json"
      content: "${map.results}"
      format: json
      create_dirs: true

  - claude: |
      /prodigy-compare-debt-results \
        --before .prodigy/debtmap-before.json \
        --after .prodigy/debtmap-after.json \
        --map-results-file .prodigy/map-results.json \
        --successful ${map.successful} \
        --failed ${map.failed} \
        --total ${map.total}
    commit_required: true
</code></pre>
<h3 id="running-mapreduce-workflows"><a class="header" href="#running-mapreduce-workflows">Running MapReduce Workflows</a></h3>
<pre><code class="language-bash"># Run MapReduce workflow (single execution processes multiple items in parallel)
prodigy run workflows/debtmap-reduce.yml

# Run with auto-confirm
prodigy run workflows/debtmap-reduce.yml -y
</code></pre>
<p><strong>Note</strong>: MapReduce workflows don‚Äôt typically use <code>-n</code> for iterations. Instead, they process multiple items in a single run through parallel map agents.</p>
<h3 id="mapreduce-configuration-options"><a class="header" href="#mapreduce-configuration-options">MapReduce Configuration Options</a></h3>
<h4 id="top-level-fields"><a class="header" href="#top-level-fields">Top-Level Fields</a></h4>
<ul>
<li><code>name</code>: Workflow name (string)</li>
<li><code>mode: mapreduce</code>: Enables MapReduce mode (required)</li>
<li><code>setup</code>: Commands to run once before map phase</li>
<li><code>map</code>: Map phase configuration</li>
<li><code>reduce</code>: Commands to run after all map agents complete</li>
</ul>
<h4 id="setup-phase-fields"><a class="header" href="#setup-phase-fields">Setup Phase Fields</a></h4>
<ul>
<li><code>timeout</code>: Maximum time in seconds for setup phase</li>
<li><code>commands</code>: List of shell or claude commands to run</li>
</ul>
<h4 id="map-phase-fields"><a class="header" href="#map-phase-fields">Map Phase Fields</a></h4>
<ul>
<li><code>input</code>: Path to JSON file containing items to process</li>
<li><code>json_path</code>: JSONPath expression to extract items array (e.g., <code>$.items[*]</code>)</li>
<li><code>agent_template</code>: List of commands to run for each item (each item gets its own agent in an isolated worktree)</li>
<li><code>max_parallel</code>: Maximum number of agents to run concurrently</li>
<li><code>filter</code>: Expression to filter which items to process (e.g., <code>"score &gt;= 10"</code>)</li>
<li><code>sort_by</code>: Expression to sort items (e.g., <code>"score DESC"</code>)</li>
<li><code>max_items</code>: Limit total items processed</li>
</ul>
<h4 id="mapreduce-specific-variables"><a class="header" href="#mapreduce-specific-variables">MapReduce-Specific Variables</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Available In</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>${item}</code></td><td>map phase</td><td>JSON</td><td>The full JSON object for current item</td></tr>
<tr><td><code>${item_id}</code></td><td>map phase</td><td>string</td><td>Unique ID for current item (auto-generated)</td></tr>
<tr><td><code>${validation.gaps}</code></td><td>map phase</td><td>array</td><td>List of validation gaps from failed validation</td></tr>
<tr><td><code>${validation.attempt_number}</code></td><td>map phase</td><td>number</td><td>Current retry attempt number (1, 2, 3, etc.)</td></tr>
<tr><td><code>${shell.output}</code></td><td>both phases</td><td>string</td><td>Output from previous shell command</td></tr>
<tr><td><code>${map.results}</code></td><td>reduce phase</td><td>array</td><td>All map agent results as JSON</td></tr>
<tr><td><code>${map.successful}</code></td><td>reduce phase</td><td>number</td><td>Count of successful map agents</td></tr>
<tr><td><code>${map.failed}</code></td><td>reduce phase</td><td>number</td><td>Count of failed map agents</td></tr>
<tr><td><code>${map.total}</code></td><td>reduce phase</td><td>number</td><td>Total number of map agents</td></tr>
</tbody></table>
</div>
<h3 id="mapreduce-architecture"><a class="header" href="#mapreduce-architecture">MapReduce Architecture</a></h3>
<pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Setup Phase (main worktree)                            ‚îÇ
‚îÇ - Generate coverage data                               ‚îÇ
‚îÇ - Run debtmap analysis                                 ‚îÇ
‚îÇ - Output: .prodigy/debtmap-before.json                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Map Phase (parallel worktrees)                         ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Agent 1      ‚îÇ  ‚îÇ Agent 2      ‚îÇ  ‚îÇ Agent 3      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Item #1      ‚îÇ  ‚îÇ Item #2      ‚îÇ  ‚îÇ Item #3      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Worktree A   ‚îÇ  ‚îÇ Worktree B   ‚îÇ  ‚îÇ Worktree C   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Plan ‚Üí Fix   ‚îÇ  ‚îÇ Plan ‚Üí Fix   ‚îÇ  ‚îÇ Plan ‚Üí Fix   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Üí Validate   ‚îÇ  ‚îÇ ‚Üí Validate   ‚îÇ  ‚îÇ ‚Üí Validate   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Üí Test       ‚îÇ  ‚îÇ ‚Üí Test       ‚îÇ  ‚îÇ ‚Üí Test       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Üí Commit     ‚îÇ  ‚îÇ ‚Üí Commit     ‚îÇ  ‚îÇ ‚Üí Commit     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ  ‚îÇ Agent 4      ‚îÇ  ‚îÇ Agent 5      ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ Item #4      ‚îÇ  ‚îÇ Item #5      ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ Worktree D   ‚îÇ  ‚îÇ Worktree E   ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ Plan ‚Üí Fix   ‚îÇ  ‚îÇ Plan ‚Üí Fix   ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ ‚Üí Validate   ‚îÇ  ‚îÇ ‚Üí Validate   ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ ‚Üí Test       ‚îÇ  ‚îÇ ‚Üí Test       ‚îÇ                   ‚îÇ
‚îÇ  ‚îÇ ‚Üí Commit     ‚îÇ  ‚îÇ ‚Üí Commit     ‚îÇ                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Reduce Phase (main worktree)                           ‚îÇ
‚îÇ - Merge all agent worktrees                            ‚îÇ
‚îÇ - Run final tests on merged code                       ‚îÇ
‚îÇ - Run final linting                                    ‚îÇ
‚îÇ - Re-analyze with debtmap                              ‚îÇ
‚îÇ - Generate summary commit                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre>
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Isolation</strong>: Each map agent works in its own git worktree</li>
<li><strong>Parallelism</strong>: Multiple agents process different items simultaneously</li>
<li><strong>Validation</strong>: Each agent validates its changes independently</li>
<li><strong>Merging</strong>: Reduce phase merges all successful agent worktrees</li>
<li><strong>Final Validation</strong>: Reduce phase ensures merged code passes all tests</li>
</ul>
<h2 id="iteration-strategy"><a class="header" href="#iteration-strategy">Iteration Strategy</a></h2>
<h3 id="how-iterations-work"><a class="header" href="#how-iterations-work">How Iterations Work</a></h3>
<p>When you run <code>prodigy run workflows/debtmap.yml -yn 5</code>, the workflow executes up to 5 times:</p>
<ol>
<li>
<p><strong>Iteration 1</strong>:</p>
<ul>
<li>Analyze codebase with debtmap</li>
<li>Select highest priority item</li>
<li>Create implementation plan</li>
<li>Execute plan and validate</li>
<li>Run tests and linting</li>
</ul>
</li>
<li>
<p><strong>Iteration 2</strong>:</p>
<ul>
<li>Re-analyze codebase (scores updated based on Iteration 1 changes)</li>
<li>Select next highest priority item</li>
<li>Repeat plan/implement/validate cycle</li>
</ul>
</li>
<li>
<p><strong>Continue</strong> until iteration limit reached or workflow completes without finding issues</p>
</li>
</ol>
<h3 id="controlling-iterations"><a class="header" href="#controlling-iterations">Controlling Iterations</a></h3>
<p>Iterations are controlled via the <code>-n</code> flag:</p>
<pre><code class="language-bash"># Single iteration (testing)
prodigy run workflows/debtmap.yml -yn 1

# Standard run (5 iterations)
prodigy run workflows/debtmap.yml -yn 5

# Deep cleanup (10+ iterations)
prodigy run workflows/debtmap.yml -yn 20
</code></pre>
<h3 id="what-happens-each-iteration"><a class="header" href="#what-happens-each-iteration">What Happens Each Iteration</a></h3>
<p>Each iteration runs the <strong>entire workflow from start to finish</strong>:</p>
<ol>
<li>Generate coverage data</li>
<li>Analyze technical debt</li>
<li>Create implementation plan</li>
<li>Execute plan</li>
<li>Validate improvement</li>
<li>Run tests (with auto-fixing)</li>
<li>Run linting (with auto-fixing)</li>
</ol>
<p>The workflow continues to the next iteration automatically if all steps succeed.</p>
<h3 id="example-output-4"><a class="header" href="#example-output-4">Example Output</a></h3>
<pre><code>Iteration 1:
  - Fixed: parse_expression() (9.2 ‚Üí 5.1)
  - Fixed: calculate_score() (8.8 ‚Üí 4.2)
  - Fixed: apply_weights() (8.5 ‚Üí 5.8)
  ‚úì Tests pass

Iteration 2:
  - Fixed: normalize_results() (7.5 ‚Üí 3.9)
  - Fixed: aggregate_data() (7.2 ‚Üí 4.1)
  ‚úì Tests pass

Iteration 3:
  - No items above threshold (6.0)
  ‚úì Early stop

Final Results:
  Items fixed: 5
  Average complexity: 15.2 ‚Üí 8.6
</code></pre>
<h2 id="validation-1"><a class="header" href="#validation-1">Validation</a></h2>
<p>Prodigy validates changes at the workflow step level, not as a standalone configuration.</p>
<h3 id="step-level-validation-1"><a class="header" href="#step-level-validation-1">Step-Level Validation</a></h3>
<p>Validation is attached to specific workflow steps:</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
  validate:
    commands:
      - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
      - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      - claude: "/prodigy-validate-debtmap-improvement --comparison .prodigy/comparison.json --output .prodigy/debtmap-validation.json"
    result_file: ".prodigy/debtmap-validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
          commit_required: true
        - shell: "just coverage-lcov"
        - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
        - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      max_attempts: 5
      fail_workflow: true
</code></pre>
<h3 id="validation-process"><a class="header" href="#validation-process">Validation Process</a></h3>
<ol>
<li><strong>Commands run</strong>: Execute validation commands (shell or claude)</li>
<li><strong>Check result file</strong>: Read JSON file specified in <code>result_file</code></li>
<li><strong>Compare to threshold</strong>: Score must be &gt;= threshold (0-100 scale)</li>
<li><strong>On incomplete</strong>: If score &lt; threshold, run <code>on_incomplete</code> commands</li>
<li><strong>Retry</strong>: Repeat up to <code>max_attempts</code> times</li>
<li><strong>Fail or continue</strong>: If <code>fail_workflow: true</code>, stop workflow; otherwise continue</li>
</ol>
<h3 id="validation-result-format"><a class="header" href="#validation-result-format">Validation Result Format</a></h3>
<p>The <code>result_file</code> JSON should contain:</p>
<pre><code class="language-json">{
  "score": 85,
  "passed": true,
  "gaps": [],
  "details": "All debt improvement criteria met"
}
</code></pre>
<h3 id="test-validation-with-auto-fix"><a class="header" href="#test-validation-with-auto-fix">Test Validation with Auto-Fix</a></h3>
<p>Tests are validated with automatic fixing on failure:</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<p>If tests fail, Prodigy automatically attempts to fix them up to 5 times before failing the workflow.</p>
<h2 id="output-and-metrics"><a class="header" href="#output-and-metrics">Output and Metrics</a></h2>
<h3 id="workflow-report"><a class="header" href="#workflow-report">Workflow Report</a></h3>
<pre><code class="language-json">{
  "workflow": "debtmap-debt-reduction",
  "iterations": 5,
  "items_processed": 12,
  "items_fixed": 10,
  "items_failed": 2,
  "metrics": {
    "complexity_before": 145,
    "complexity_after": 78,
    "complexity_reduction": -46.2,
    "coverage_before": 45.3,
    "coverage_after": 72.1,
    "coverage_improvement": 26.8
  },
  "changes": [
    {
      "file": "src/parser.rs",
      "function": "parse_expression",
      "before_score": 9.2,
      "after_score": 5.1,
      "improvements": ["Reduced complexity", "Added tests"]
    }
  ]
}
</code></pre>
<h3 id="commit-messages"><a class="header" href="#commit-messages">Commit Messages</a></h3>
<p>Prodigy generates descriptive commit messages:</p>
<pre><code>refactor(parser): reduce complexity in parse_expression

- Extract nested conditionals to helper functions
- Add unit tests for edge cases
- Coverage: 0% ‚Üí 85%
- Complexity: 22 ‚Üí 8

Generated by Prodigy workflow: debtmap-debt-reduction
Iteration: 1/5
</code></pre>
<h2 id="integration-with-cicd"><a class="header" href="#integration-with-cicd">Integration with CI/CD</a></h2>
<h3 id="github-actions-1"><a class="header" href="#github-actions-1">GitHub Actions</a></h3>
<pre><code class="language-yaml">name: Prodigy Debt Reduction

on:
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday
  workflow_dispatch:

jobs:
  reduce-debt:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable

      - name: Install Prodigy
        run: cargo install prodigy

      - name: Install dependencies
        run: |
          cargo install debtmap
          cargo install just

      - name: Run Prodigy workflow
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: prodigy run workflows/debtmap.yml -yn 5

      - name: Create PR
        uses: peter-evans/create-pull-request@v5
        with:
          title: "chore: automated debt reduction via Prodigy"
          body: |
            Automated technical debt reduction using Prodigy workflow.

            This PR was generated by the weekly debt reduction workflow.
            Review changes carefully before merging.
          branch: prodigy-debt-reduction
</code></pre>
<h3 id="gitlab-ci-1"><a class="header" href="#gitlab-ci-1">GitLab CI</a></h3>
<pre><code class="language-yaml">prodigy-debt-reduction:
  stage: quality
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  script:
    - cargo install prodigy
    - cargo install debtmap
    - cargo install just
    - prodigy run workflows/debtmap.yml -yn 5
  artifacts:
    paths:
      - .prodigy/debtmap-*.json
      - .prodigy/comparison.json
</code></pre>
<h3 id="important-ci-considerations"><a class="header" href="#important-ci-considerations">Important CI Considerations</a></h3>
<ul>
<li><strong>API Keys</strong>: Store <code>ANTHROPIC_API_KEY</code> as a secret</li>
<li><strong>Worktrees</strong>: MapReduce mode creates isolated worktrees automatically for parallel processing</li>
<li><strong>Dependencies</strong>: Install <code>prodigy</code>, <code>debtmap</code>, and <code>just</code> (or your build tool)</li>
<li><strong>Timeout</strong>: CI jobs may need extended timeout for multiple iterations</li>
<li><strong>Review</strong>: Always create a PR for human review before merging automated changes</li>
</ul>
<h2 id="best-practices-15"><a class="header" href="#best-practices-15">Best Practices</a></h2>
<h3 id="1-start-small"><a class="header" href="#1-start-small">1. Start Small</a></h3>
<p>Begin with low iteration counts:</p>
<pre><code class="language-bash"># First run: 1 iteration to test workflow
prodigy run workflows/debtmap.yml -yn 1

# Standard run: 3-5 iterations
prodigy run workflows/debtmap.yml -yn 5
</code></pre>
<h3 id="2-focus-on-high-priority-items"><a class="header" href="#2-focus-on-high-priority-items">2. Focus on High-Priority Items</a></h3>
<p>The debtmap analysis automatically prioritizes by:</p>
<ul>
<li>Complexity score (cyclomatic complexity)</li>
<li>Coverage percentage (lower coverage = higher priority)</li>
<li>Risk score (complexity √ó (100 - coverage%))</li>
</ul>
<p>To focus on specific areas, create custom slash commands in <code>.claude/commands/</code> that filter by:</p>
<ul>
<li>Module/file patterns</li>
<li>Specific debt types (Complexity, TestGap, Duplication)</li>
<li>Score thresholds</li>
</ul>
<h3 id="3-validate-thoroughly"><a class="header" href="#3-validate-thoroughly">3. Validate Thoroughly</a></h3>
<p>Use comprehensive validation in your workflow:</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true

- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<h3 id="4-review-before-merging"><a class="header" href="#4-review-before-merging">4. Review Before Merging</a></h3>
<p>Always review Prodigy‚Äôs changes:</p>
<pre><code class="language-bash"># Find your worktree
ls ~/.prodigy/worktrees/

# Check changes
cd ~/.prodigy/worktrees/session-xxx
git diff main

# Review commit history
git log --oneline

# Run full test suite
cargo test --all-features
</code></pre>
<h3 id="5-monitor-progress"><a class="header" href="#5-monitor-progress">5. Monitor Progress</a></h3>
<p>Track debt reduction over iterations:</p>
<pre><code class="language-bash"># Compare before and after
debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json

# View detailed metrics
cat .prodigy/comparison.json | jq
</code></pre>
<h2 id="troubleshooting-17"><a class="header" href="#troubleshooting-17">Troubleshooting</a></h2>
<h3 id="workflow-fails-to-start"><a class="header" href="#workflow-fails-to-start">Workflow Fails to Start</a></h3>
<p><strong>Issue</strong>: ‚ÄúProdigy not found‚Äù or ‚ÄúAPI key missing‚Äù</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Install Prodigy
cargo install prodigy

# Set API key
export ANTHROPIC_API_KEY="your-key"

# Verify installation
prodigy --version
</code></pre>
<h3 id="validation-failures"><a class="header" href="#validation-failures">Validation Failures</a></h3>
<p><strong>Issue</strong>: Validation score below threshold</p>
<p><strong>Solution</strong>: Check validation results:</p>
<pre><code class="language-bash"># View validation details
cat .prodigy/debtmap-validation.json

# Check what gaps remain
cat .prodigy/debtmap-validation.json | jq '.gaps'

# Review comparison results
cat .prodigy/comparison.json
</code></pre>
<p>The workflow will automatically retry up to <code>max_attempts</code> times with <code>/prodigy-complete-debtmap-fix</code>.</p>
<h3 id="test-failures"><a class="header" href="#test-failures">Test Failures</a></h3>
<p><strong>Issue</strong>: Tests fail after implementation</p>
<p><strong>Solution</strong>: The workflow includes automatic test fixing:</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<p>If tests still fail after 5 attempts, review manually:</p>
<pre><code class="language-bash"># Check test output
just test

# Review recent changes
git diff HEAD~1
</code></pre>
<h3 id="no-items-processed"><a class="header" href="#no-items-processed">No Items Processed</a></h3>
<p><strong>Issue</strong>: Workflow completes but doesn‚Äôt find debt to fix</p>
<p><strong>Possible Causes</strong>:</p>
<ol>
<li>Codebase has very low debt scores (below selection threshold)</li>
<li>Coverage data not generated properly</li>
<li>Debtmap analysis found no high-priority items</li>
</ol>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Check debtmap analysis results
cat .prodigy/debtmap-before.json | jq '.items | sort_by(-.unified_score.final_score) | .[0:5]'

# Verify coverage was generated
ls -lh target/coverage/lcov.info

# Run debtmap manually to see what's detected
debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<h3 id="workflow-hangs-or-times-out"><a class="header" href="#workflow-hangs-or-times-out">Workflow Hangs or Times Out</a></h3>
<p><strong>Issue</strong>: Workflow takes too long or appears stuck</p>
<p><strong>Possible Causes</strong>:</p>
<ul>
<li>Large codebase with many files</li>
<li>Complex refactoring requiring extensive analysis</li>
<li>Network issues with Claude API</li>
</ul>
<p><strong>Solution</strong>:</p>
<ul>
<li>Reduce iteration count for testing (<code>-n 1</code>)</li>
<li>Check Claude API connectivity</li>
<li>Monitor worktree for progress: <code>cd ~/.prodigy/worktrees/session-xxx &amp;&amp; git log</code></li>
</ul>
<h3 id="mapreduce-specific-troubleshooting"><a class="header" href="#mapreduce-specific-troubleshooting">MapReduce-Specific Troubleshooting</a></h3>
<h4 id="resuming-failed-mapreduce-jobs"><a class="header" href="#resuming-failed-mapreduce-jobs">Resuming Failed MapReduce Jobs</a></h4>
<p><strong>Issue</strong>: MapReduce job was interrupted or failed</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Find the job ID from recent sessions
prodigy sessions

# Resume the MapReduce job from checkpoint
prodigy resume-job &lt;JOB_ID&gt;
</code></pre>
<p>The job will resume from where it left off, skipping already-completed items.</p>
<h4 id="checking-mapreduce-progress"><a class="header" href="#checking-mapreduce-progress">Checking MapReduce Progress</a></h4>
<p><strong>Issue</strong>: Want to monitor long-running MapReduce job</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># View overall progress
prodigy progress &lt;JOB_ID&gt;

# View detailed events
prodigy events &lt;JOB_ID&gt;

# Filter for specific event types
prodigy events &lt;JOB_ID&gt; --type agent_completed
prodigy events &lt;JOB_ID&gt; --type agent_failed
</code></pre>
<p><strong>Output example</strong>:</p>
<pre><code>MapReduce Job: job-abc123
Status: running
Progress: 7/10 items (70%)
- Completed: 5
- Running: 2
- Failed: 3
</code></pre>
<h4 id="managing-failed-mapreduce-items"><a class="header" href="#managing-failed-mapreduce-items">Managing Failed MapReduce Items</a></h4>
<p><strong>Issue</strong>: Some agents failed, items in Dead Letter Queue</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># View failed items
prodigy dlq list &lt;JOB_ID&gt;

# Review why an item failed (check events)
prodigy events &lt;JOB_ID&gt; --item &lt;ITEM_ID&gt;

# Retry specific failed item
prodigy dlq retry &lt;JOB_ID&gt; &lt;ITEM_ID&gt;

# Remove unfixable items from DLQ
prodigy dlq remove &lt;JOB_ID&gt; &lt;ITEM_ID&gt;
</code></pre>
<p><strong>Common failure reasons</strong>:</p>
<ul>
<li>Validation threshold not met after max_attempts</li>
<li>Tests fail and can‚Äôt be fixed automatically</li>
<li>Merge conflicts with other agents‚Äô changes</li>
<li>Timeout exceeded for complex refactoring</li>
</ul>
<h4 id="cleaning-up-mapreduce-worktrees"><a class="header" href="#cleaning-up-mapreduce-worktrees">Cleaning Up MapReduce Worktrees</a></h4>
<p><strong>Issue</strong>: Disk space consumed by many MapReduce worktrees</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># List all worktrees
prodigy worktree list

# Clean up completed job worktrees
prodigy worktree clean

# Remove specific session's worktrees
prodigy worktree remove &lt;SESSION_ID&gt;

# Manual cleanup (if Prodigy commands don't work)
rm -rf ~/.prodigy/worktrees/session-xxx
</code></pre>
<p><strong>When to clean</strong>:</p>
<ul>
<li>After successful job completion and merge</li>
<li>When disk space is low</li>
<li>After abandoned or failed jobs</li>
</ul>
<h4 id="mapreduce-merge-conflicts"><a class="header" href="#mapreduce-merge-conflicts">MapReduce Merge Conflicts</a></h4>
<p><strong>Issue</strong>: Reduce phase fails due to merge conflicts between agent worktrees</p>
<p><strong>Possible Causes</strong>:</p>
<ul>
<li>Multiple agents modified overlapping code</li>
<li>Agents made conflicting architectural changes</li>
<li>Shared dependencies updated differently</li>
</ul>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Review which agents succeeded
prodigy events &lt;JOB_ID&gt; --type agent_completed

# Check merge conflicts
cd ~/.prodigy/worktrees/session-xxx
git status

# Manually resolve conflicts
# Edit conflicting files
git add .
git commit -m "Resolve MapReduce merge conflicts"

# Resume the job
prodigy resume-job &lt;JOB_ID&gt;
</code></pre>
<p><strong>Prevention</strong>:</p>
<ul>
<li>Use <code>filter</code> to ensure agents work on independent items</li>
<li>Reduce <code>max_parallel</code> to minimize conflicts</li>
<li>Design debt items to be truly independent</li>
</ul>
<h4 id="understanding-mapreduce-variables"><a class="header" href="#understanding-mapreduce-variables">Understanding MapReduce Variables</a></h4>
<p>If you‚Äôre debugging workflow files, these variables are available:</p>
<p><strong>In map phase (agent_template)</strong>:</p>
<ul>
<li><code>${item}</code>: Full JSON of current item being processed</li>
<li><code>${item_id}</code>: Unique ID for current item</li>
<li><code>${validation.gaps}</code>: Validation gaps from validation result</li>
<li><code>${validation.attempt_number}</code>: Current retry attempt (1, 2, 3‚Ä¶)</li>
<li><code>${shell.output}</code>: Output from previous shell command</li>
</ul>
<p><strong>In reduce phase</strong>:</p>
<ul>
<li><code>${map.results}</code>: All map agent results as JSON</li>
<li><code>${map.successful}</code>: Count of successful agents</li>
<li><code>${map.failed}</code>: Count of failed agents</li>
<li><code>${map.total}</code>: Total number of agents</li>
</ul>
<p><strong>Example debug command</strong>:</p>
<pre><code class="language-yaml"># In agent_template, log the item being processed
- shell: "echo 'Processing item: ${item_id}' &gt;&gt; .prodigy/debug.log"
</code></pre>
<h2 id="example-workflows"><a class="header" href="#example-workflows">Example Workflows</a></h2>
<h3 id="full-repository-cleanup"><a class="header" href="#full-repository-cleanup">Full Repository Cleanup</a></h3>
<p>For comprehensive debt reduction, use a higher iteration count:</p>
<pre><code class="language-bash"># Run 10 iterations for deeper cleanup
prodigy run workflows/debtmap.yml -yn 10

# Run 20 iterations for major refactoring
prodigy run workflows/debtmap.yml -yn 20
</code></pre>
<p>The workflow automatically:</p>
<ol>
<li>Selects highest priority items each iteration</li>
<li>Addresses different debt types (Complexity, TestGap, Duplication)</li>
<li>Validates all changes with tests and linting</li>
<li>Commits only successful improvements</li>
</ol>
<h3 id="custom-workflow-for-specific-focus"><a class="header" href="#custom-workflow-for-specific-focus">Custom Workflow for Specific Focus</a></h3>
<p>Create a custom workflow file for focused improvements:</p>
<p><strong><code>workflows/add-tests.yml</code></strong> - Focus on test coverage:</p>
<pre><code class="language-yaml"># Generate coverage
- shell: "just coverage-lcov"

# Analyze with focus on test gaps
- shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-before.json --format json"

# Create plan (slash command will prioritize TestGap items)
- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"

# ... rest of standard workflow steps
</code></pre>
<p>Run with:</p>
<pre><code class="language-bash">prodigy run workflows/add-tests.yml -yn 5
</code></pre>
<h3 id="targeted-module-cleanup"><a class="header" href="#targeted-module-cleanup">Targeted Module Cleanup</a></h3>
<p>Create a custom slash command to focus on specific modules:</p>
<p><strong><code>.claude/commands/refactor-module.md</code></strong>:</p>
<pre><code class="language-markdown"># /refactor-module

Refactor the highest complexity item in the specified module.

Arguments: --module &lt;module_name&gt;

... implementation details ...
</code></pre>
<p>Then create a workflow using this command for targeted refactoring.</p>
<h2 id="see-also-5"><a class="header" href="#see-also-5">See Also</a></h2>
<ul>
<li><a href="./cli-reference.html">Debtmap CLI Reference</a> - All Debtmap command options including <code>analyze</code>, <code>compare</code>, and <code>validate</code></li>
<li><a href="./coverage-integration.html">Coverage Integration</a> - Generating and using LCOV coverage data with Debtmap</li>
<li><a href="./configuration.html">Configuration</a> - Debtmap configuration file options</li>
<li><a href="./tiered-prioritization.html">Tiered Prioritization</a> - Understanding how Debtmap scores and prioritizes debt items</li>
<li><a href="https://github.com/iepathos/prodigy">Prodigy Documentation</a> - Full Prodigy reference and advanced features</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="responsibility-analysis"><a class="header" href="#responsibility-analysis">Responsibility Analysis</a></h1>
<h2 id="overview-14"><a class="header" href="#overview-14">Overview</a></h2>
<p>Responsibility analysis is a core feature of Debtmap that helps identify violations of the <strong>Single Responsibility Principle (SRP)</strong>, one of the fundamental SOLID design principles. By analyzing function and method names, Debtmap automatically infers the distinct functional responsibilities within a code unit and detects when a single module, struct, or class has taken on too many concerns.</p>
<p>This chapter provides an in-depth look at how Debtmap determines responsibilities, categorizes them, and uses this information to guide refactoring decisions.</p>
<h2 id="what-are-responsibilities"><a class="header" href="#what-are-responsibilities">What Are Responsibilities?</a></h2>
<p>In the context of Debtmap, a <strong>responsibility</strong> is a distinct functional domain or concern that a code unit handles. Examples include:</p>
<ul>
<li><strong>Data Access</strong> - Getting and setting values from data structures</li>
<li><strong>Validation</strong> - Checking inputs, verifying constraints, ensuring correctness</li>
<li><strong>Persistence</strong> - Saving and loading data to/from storage</li>
<li><strong>Computation</strong> - Performing calculations and transformations</li>
<li><strong>Communication</strong> - Sending and receiving messages or events</li>
</ul>
<p>According to the Single Responsibility Principle, each module should have <strong>one and only one reason to change</strong>. When a module handles multiple unrelated responsibilities (e.g., validation, persistence, AND computation), it becomes:</p>
<ul>
<li><strong>Harder to understand</strong> - Developers must mentally juggle multiple concerns</li>
<li><strong>More fragile</strong> - Changes to one responsibility can break others</li>
<li><strong>Difficult to test</strong> - Testing requires complex setup across multiple domains</li>
<li><strong>Prone to coupling</strong> - Dependencies from different domains become entangled</li>
</ul>
<p>Debtmap‚Äôs responsibility analysis automatically identifies these violations and provides concrete recommendations for splitting modules along responsibility boundaries.</p>
<h2 id="how-responsibilities-are-detected"><a class="header" href="#how-responsibilities-are-detected">How Responsibilities Are Detected</a></h2>
<h3 id="pattern-based-inference"><a class="header" href="#pattern-based-inference">Pattern-Based Inference</a></h3>
<p>Debtmap uses <strong>prefix-based pattern matching</strong> to infer responsibilities from function and method names. This approach is both simple and effective because well-named functions naturally express their intent through conventional prefixes.</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_analysis.rs:316-386</code></p>
<p>The <code>infer_responsibility_from_method()</code> function performs case-insensitive prefix matching:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn infer_responsibility_from_method(method_name: &amp;str) -&gt; String {
    let lower_name = method_name.to_lowercase();

    if lower_name.starts_with("format_") || lower_name.starts_with("render_") {
        return "Formatting &amp; Output".to_string();
    }
    if lower_name.starts_with("parse_") || lower_name.starts_with("read_") {
        return "Parsing &amp; Input".to_string();
    }
    // ... additional patterns
}
<span class="boring">}</span></code></pre></pre>
<p>This approach works across languages (Rust, Python, JavaScript/TypeScript) because naming conventions are relatively consistent in modern codebases.</p>
<h3 id="responsibility-categories"><a class="header" href="#responsibility-categories">Responsibility Categories</a></h3>
<p>Debtmap recognizes <strong>11 built-in responsibility categories</strong> plus a generic ‚ÄúUtilities‚Äù fallback:</p>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Prefixes</th><th>Examples</th></tr></thead><tbody>
<tr><td><strong>Formatting &amp; Output</strong></td><td><code>format_</code>, <code>render_</code>, <code>write_</code>, <code>print_</code></td><td><code>format_json()</code>, <code>render_table()</code>, <code>write_report()</code></td></tr>
<tr><td><strong>Parsing &amp; Input</strong></td><td><code>parse_</code>, <code>read_</code>, <code>extract_</code></td><td><code>parse_config()</code>, <code>read_file()</code>, <code>extract_fields()</code></td></tr>
<tr><td><strong>Filtering &amp; Selection</strong></td><td><code>filter_</code>, <code>select_</code>, <code>find_</code></td><td><code>filter_results()</code>, <code>select_top()</code>, <code>find_item()</code></td></tr>
<tr><td><strong>Transformation</strong></td><td><code>transform_</code>, <code>convert_</code>, <code>map_</code>, <code>apply_</code></td><td><code>transform_data()</code>, <code>convert_type()</code>, <code>map_fields()</code></td></tr>
<tr><td><strong>Data Access</strong></td><td><code>get_</code>, <code>set_</code></td><td><code>get_value()</code>, <code>set_name()</code></td></tr>
<tr><td><strong>Validation</strong></td><td><code>validate_</code>, <code>check_</code>, <code>verify_</code>, <code>is_*</code></td><td><code>validate_input()</code>, <code>check_bounds()</code>, <code>is_valid()</code></td></tr>
<tr><td><strong>Computation</strong></td><td><code>calculate_</code>, <code>compute_</code></td><td><code>calculate_score()</code>, <code>compute_sum()</code></td></tr>
<tr><td><strong>Construction</strong></td><td><code>create_</code>, <code>build_</code>, <code>new_*</code>, <code>make_</code></td><td><code>create_instance()</code>, <code>build_config()</code>, <code>new_user()</code></td></tr>
<tr><td><strong>Persistence</strong></td><td><code>save_</code>, <code>load_</code>, <code>store_</code></td><td><code>save_data()</code>, <code>load_cache()</code>, <code>store_result()</code></td></tr>
<tr><td><strong>Processing</strong></td><td><code>process_</code>, <code>handle_</code></td><td><code>process_request()</code>, <code>handle_error()</code></td></tr>
<tr><td><strong>Communication</strong></td><td><code>send_</code>, <code>receive_</code></td><td><code>send_message()</code>, <code>receive_data()</code></td></tr>
<tr><td><strong>Utilities</strong></td><td><em>(all others)</em></td><td><code>helper()</code>, <code>do_work()</code>, <code>utility_fn()</code></td></tr>
</tbody></table>
</div>
<h3 id="grouping-methods-by-responsibility"><a class="header" href="#grouping-methods-by-responsibility">Grouping Methods by Responsibility</a></h3>
<p>Once individual methods are categorized, Debtmap groups them using <code>group_methods_by_responsibility()</code>:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_analysis.rs:268-280</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn group_methods_by_responsibility(methods: &amp;[String]) -&gt; HashMap&lt;String, Vec&lt;String&gt;&gt; {
    let mut groups: HashMap&lt;String, Vec&lt;String&gt;&gt; = HashMap::new();
    for method in methods {
        let responsibility = infer_responsibility_from_method(method);
        groups.entry(responsibility).or_default().push(method.clone());
    }
    groups
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Output Structure:</strong></p>
<ul>
<li><strong>Keys</strong>: Responsibility category names (e.g., ‚ÄúData Access‚Äù, ‚ÄúValidation‚Äù)</li>
<li><strong>Values</strong>: Lists of method names belonging to each category</li>
</ul>
<p>The <strong>responsibility count</strong> is simply the number of unique keys in this HashMap.</p>
<h3 id="example-analysis"><a class="header" href="#example-analysis">Example Analysis</a></h3>
<p>Consider a Rust struct with these methods:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl UserManager {
    fn get_user(&amp;self, id: UserId) -&gt; Option&lt;User&gt; { }
    fn set_password(&amp;mut self, id: UserId, password: &amp;str) { }
    fn validate_email(&amp;self, email: &amp;str) -&gt; bool { }
    fn validate_password(&amp;self, password: &amp;str) -&gt; bool { }
    fn save_user(&amp;self, user: &amp;User) -&gt; Result&lt;()&gt; { }
    fn load_user(&amp;self, id: UserId) -&gt; Result&lt;User&gt; { }
    fn send_notification(&amp;self, user_id: UserId, msg: &amp;str) { }
    fn format_user_profile(&amp;self, user: &amp;User) -&gt; String { }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Debtmap‚Äôs Analysis:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Inferred Responsibility</th></tr></thead><tbody>
<tr><td><code>get_user</code></td><td>Data Access</td></tr>
<tr><td><code>set_password</code></td><td>Data Access</td></tr>
<tr><td><code>validate_email</code></td><td>Validation</td></tr>
<tr><td><code>validate_password</code></td><td>Validation</td></tr>
<tr><td><code>save_user</code></td><td>Persistence</td></tr>
<tr><td><code>load_user</code></td><td>Persistence</td></tr>
<tr><td><code>send_notification</code></td><td>Communication</td></tr>
<tr><td><code>format_user_profile</code></td><td>Formatting &amp; Output</td></tr>
</tbody></table>
</div>
<p><strong>Result:</strong></p>
<ul>
<li><strong>Responsibility Count</strong>: 5 (Data Access, Validation, Persistence, Communication, Formatting)</li>
<li><strong>Assessment</strong>: This violates SRP - <code>UserManager</code> has too many distinct concerns</li>
</ul>
<h2 id="responsibility-scoring"><a class="header" href="#responsibility-scoring">Responsibility Scoring</a></h2>
<h3 id="integration-with-god-object-detection"><a class="header" href="#integration-with-god-object-detection">Integration with God Object Detection</a></h3>
<p>Responsibility count is a critical factor in <a href="./god-object-detection.html">God Object Detection</a>. The scoring algorithm includes:</p>
<pre><code>responsibility_factor = min(responsibility_count / 3.0, 3.0)
god_object_score = method_factor √ó field_factor √ó responsibility_factor √ó size_factor
</code></pre>
<p><strong>Why divide by 3.0?</strong></p>
<ul>
<li><strong>1-3 responsibilities</strong>: Normal, well-scoped module</li>
<li><strong>4-6 responsibilities</strong>: Warning signs, approaching problematic territory</li>
<li><strong>7+ responsibilities</strong>: Severe violation, likely a god object</li>
</ul>
<h3 id="language-specific-thresholds-1"><a class="header" href="#language-specific-thresholds-1">Language-Specific Thresholds</a></h3>
<p>Different languages have different expectations for responsibility counts:</p>
<div class="table-wrapper"><table><thead><tr><th>Language</th><th>Max Responsibilities</th><th>Rationale</th></tr></thead><tbody>
<tr><td><strong>Rust</strong></td><td>5</td><td>Strong module system encourages tight boundaries</td></tr>
<tr><td><strong>Python</strong></td><td>3</td><td>Duck typing makes mixing concerns more dangerous</td></tr>
<tr><td><strong>JavaScript/TypeScript</strong></td><td>3</td><td>Prototype-based, benefits from focused classes</td></tr>
</tbody></table>
</div>
<p>These thresholds can be customized in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[god_object_detection.rust]
max_traits = 5      # max_traits = max responsibilities

[god_object_detection.python]
max_traits = 3
</code></pre>
<h3 id="confidence-determination"><a class="header" href="#confidence-determination">Confidence Determination</a></h3>
<p>Responsibility count contributes to overall confidence levels:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_analysis.rs:234-266</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn determine_confidence(
    method_count: usize,
    field_count: usize,
    responsibility_count: usize,
    lines_of_code: usize,
    complexity_sum: u32,
    thresholds: &amp;GodObjectThresholds,
) -&gt; GodObjectConfidence {
    let mut violations = 0;

    if responsibility_count &gt; thresholds.max_traits {
        violations += 1;
    }
    // ... check other metrics

    match violations {
        5 =&gt; GodObjectConfidence::Definite,
        3..=4 =&gt; GodObjectConfidence::Probable,
        1..=2 =&gt; GodObjectConfidence::Possible,
        _ =&gt; GodObjectConfidence::NotGodObject,
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="advanced-responsibility-detection"><a class="header" href="#advanced-responsibility-detection">Advanced Responsibility Detection</a></h2>
<h3 id="module-level-analysis"><a class="header" href="#module-level-analysis">Module-Level Analysis</a></h3>
<p>For large modules without a single dominant struct, Debtmap performs <strong>module-level responsibility detection</strong>:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_detector.rs:682-697</code></p>
<p>The <code>classify_responsibility()</code> function provides extended categorization:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn classify_responsibility(prefix: &amp;str) -&gt; String {
    match prefix {
        "get" | "set" =&gt; "Data Access",
        "calculate" | "compute" =&gt; "Computation",
        "validate" | "check" | "verify" | "ensure" =&gt; "Validation",
        "save" | "load" | "store" | "retrieve" | "fetch" =&gt; "Persistence",
        "create" | "build" | "new" | "make" | "init" =&gt; "Construction",
        "send" | "receive" | "handle" | "manage" =&gt; "Communication",
        "update" | "modify" | "change" | "edit" =&gt; "Modification",
        "delete" | "remove" | "clear" | "reset" =&gt; "Deletion",
        "is" | "has" | "can" | "should" | "will" =&gt; "State Query",
        "process" | "transform" =&gt; "Processing",
        _ =&gt; format!("{} Operations", capitalize_first(prefix)),
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This extended mapping covers 10 core categories plus dynamic fallback for custom prefixes.</p>
<h3 id="responsibility-groups"><a class="header" href="#responsibility-groups">Responsibility Groups</a></h3>
<p>The <code>ResponsibilityGroup</code> data structure tracks detailed information about each responsibility:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/mod.rs:156-161</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug, Clone, PartialEq)]
pub struct ResponsibilityGroup {
    pub name: String,           // e.g., "DataAccessManager"
    pub methods: Vec&lt;String&gt;,   // Methods in this group
    pub fields: Vec&lt;String&gt;,    // Associated fields
    pub responsibility: String, // e.g., "Data Access"
}
<span class="boring">}</span></code></pre></pre>
<p>This structure enables:</p>
<ul>
<li><strong>Refactoring recommendations</strong> - Suggest splitting by responsibility group</li>
<li><strong>Cohesion analysis</strong> - Measure how tightly methods are related</li>
<li><strong>Field-method correlation</strong> - Identify which fields belong to which responsibilities</li>
</ul>
<h2 id="refactoring-based-on-responsibilities"><a class="header" href="#refactoring-based-on-responsibilities">Refactoring Based on Responsibilities</a></h2>
<h3 id="recommended-module-splits"><a class="header" href="#recommended-module-splits">Recommended Module Splits</a></h3>
<p>When Debtmap detects a module with multiple responsibilities, it generates actionable refactoring recommendations using <code>recommend_module_splits()</code>:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_detector.rs:165-177</code></p>
<p><strong>Process:</strong></p>
<ol>
<li>Group all methods by their inferred responsibilities</li>
<li>Create a <code>ModuleSplit</code> for each responsibility group</li>
<li>Suggest module names (e.g., ‚ÄúDataAccessManager‚Äù, ‚ÄúValidationManager‚Äù)</li>
<li>Estimate lines of code for each new module</li>
<li>Order by cohesion (most focused groups first)</li>
</ol>
<p><strong>Example Output:</strong></p>
<pre><code>Recommended Splits for UserManager:
  1. DataAccessManager (5 methods, ~80 lines)
     - get_user, set_password, get_email, set_email, update_profile

  2. ValidationManager (4 methods, ~60 lines)
     - validate_email, validate_password, check_permissions, verify_token

  3. PersistenceManager (3 methods, ~50 lines)
     - save_user, load_user, delete_user

  4. NotificationManager (2 methods, ~30 lines)
     - send_notification, send_bulk_notifications
</code></pre>
<h3 id="practical-refactoring-patterns"><a class="header" href="#practical-refactoring-patterns">Practical Refactoring Patterns</a></h3>
<h4 id="pattern-1-extract-service-classes"><a class="header" href="#pattern-1-extract-service-classes">Pattern 1: Extract Service Classes</a></h4>
<p><strong>Before (God Object):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct UserManager {
    db: Database,
    cache: Cache,
    notifier: Notifier,
}

impl UserManager {
    fn get_user(&amp;self, id: UserId) -&gt; Option&lt;User&gt; { }
    fn validate_email(&amp;self, email: &amp;str) -&gt; bool { }
    fn save_user(&amp;self, user: &amp;User) -&gt; Result&lt;()&gt; { }
    fn send_notification(&amp;self, id: UserId, msg: &amp;str) { }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>After (Split by Responsibility):</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Data Access
struct UserRepository {
    db: Database,
    cache: Cache,
}

// Validation
struct UserValidator;

// Persistence
struct UserPersistence {
    db: Database,
}

// Communication
struct NotificationService {
    notifier: Notifier,
}
<span class="boring">}</span></code></pre></pre>
<h4 id="pattern-2-use-facade-for-composition"><a class="header" href="#pattern-2-use-facade-for-composition">Pattern 2: Use Facade for Composition</a></h4>
<p>After splitting, create a facade to coordinate:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct UserFacade {
    repository: UserRepository,
    validator: UserValidator,
    persistence: UserPersistence,
    notifier: NotificationService,
}

impl UserFacade {
    fn register_user(&amp;mut self, user: User) -&gt; Result&lt;()&gt; {
        self.validator.validate_email(&amp;user.email)?;
        self.persistence.save_user(&amp;user)?;
        self.notifier.send_welcome(&amp;user.id)?;
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="pattern-3-trait-based-separation-rust"><a class="header" href="#pattern-3-trait-based-separation-rust">Pattern 3: Trait-Based Separation (Rust)</a></h4>
<p>Use traits to define responsibility boundaries:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait DataAccess {
    fn get_user(&amp;self, id: UserId) -&gt; Option&lt;User&gt;;
}

trait Validation {
    fn validate_email(&amp;self, email: &amp;str) -&gt; bool;
}

trait Persistence {
    fn save_user(&amp;self, user: &amp;User) -&gt; Result&lt;()&gt;;
}

// Implement only the needed traits per struct
impl DataAccess for UserRepository { }
impl Validation for UserValidator { }
impl Persistence for UserPersistence { }
<span class="boring">}</span></code></pre></pre>
<h2 id="data-structures"><a class="header" href="#data-structures">Data Structures</a></h2>
<h3 id="godobjectanalysis"><a class="header" href="#godobjectanalysis">GodObjectAnalysis</a></h3>
<p>The main result structure includes responsibility information:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_analysis.rs:5-18</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct GodObjectAnalysis {
    pub is_god_object: bool,
    pub method_count: usize,
    pub field_count: usize,
    pub responsibility_count: usize,      // Number of distinct responsibilities
    pub lines_of_code: usize,
    pub complexity_sum: u32,
    pub god_object_score: f64,
    pub recommended_splits: Vec&lt;ModuleSplit&gt;,
    pub confidence: GodObjectConfidence,
    pub responsibilities: Vec&lt;String&gt;,    // List of responsibility names
    pub purity_distribution: Option&lt;PurityDistribution&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="modulesplit"><a class="header" href="#modulesplit">ModuleSplit</a></h3>
<p>Recommendations for splitting modules:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_analysis.rs:40-45</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ModuleSplit {
    pub suggested_name: String,         // e.g., "ValidationManager"
    pub methods_to_move: Vec&lt;String&gt;,   // Methods for this module
    pub responsibility: String,          // Responsibility category
    pub estimated_lines: usize,         // Approximate LOC
}
<span class="boring">}</span></code></pre></pre>
<h2 id="testing-responsibility-detection"><a class="header" href="#testing-responsibility-detection">Testing Responsibility Detection</a></h2>
<p>Debtmap includes comprehensive tests for responsibility detection:</p>
<p><strong>Implementation Location:</strong> <code>src/organization/god_object_analysis.rs:623-838</code></p>
<h3 id="test-coverage"><a class="header" href="#test-coverage">Test Coverage</a></h3>
<p><strong>Key test cases:</strong></p>
<ul>
<li><strong>Prefix recognition</strong> - Each of the 11 categories is tested individually</li>
<li><strong>Case insensitivity</strong> - <code>Format_Output</code> and <code>format_output</code> both map to ‚ÄúFormatting &amp; Output‚Äù</li>
<li><strong>Multiple responsibilities</strong> - Grouping diverse methods correctly</li>
<li><strong>Empty input handling</strong> - Graceful handling of empty method lists</li>
<li><strong>Edge cases</strong> - Methods without recognized prefixes default to ‚ÄúUtilities‚Äù</li>
</ul>
<p><strong>Example Test:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_multiple_responsibility_groups() {
    let methods = vec![
        "format_output".to_string(),
        "parse_input".to_string(),
        "get_value".to_string(),
        "validate_data".to_string(),
    ];

    let groups = group_methods_by_responsibility(&amp;methods);

    assert_eq!(groups.len(), 4); // 4 distinct responsibilities
    assert!(groups.contains_key("Formatting &amp; Output"));
    assert!(groups.contains_key("Parsing &amp; Input"));
    assert!(groups.contains_key("Data Access"));
    assert!(groups.contains_key("Validation"));
}
<span class="boring">}</span></code></pre></pre>
<h2 id="configuration-11"><a class="header" href="#configuration-11">Configuration</a></h2>
<h3 id="toml-configuration-2"><a class="header" href="#toml-configuration-2">TOML Configuration</a></h3>
<p>Customize responsibility thresholds in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[god_object_detection]
enabled = true

[god_object_detection.rust]
max_traits = 5      # Max responsibilities for Rust

[god_object_detection.python]
max_traits = 3      # Max responsibilities for Python

[god_object_detection.javascript]
max_traits = 3      # Max responsibilities for JavaScript/TypeScript
</code></pre>
<h3 id="tuning-guidelines-2"><a class="header" href="#tuning-guidelines-2">Tuning Guidelines</a></h3>
<p><strong>Strict SRP Enforcement:</strong></p>
<pre><code class="language-toml">[god_object_detection.rust]
max_traits = 3
</code></pre>
<ul>
<li>Enforces very tight single responsibility</li>
<li>Suitable for greenfield projects or strict refactoring efforts</li>
</ul>
<p><strong>Balanced Approach (Default):</strong></p>
<pre><code class="language-toml">[god_object_detection.rust]
max_traits = 5
</code></pre>
<ul>
<li>Allows some flexibility while catching major violations</li>
<li>Works well for most projects</li>
</ul>
<p><strong>Lenient Mode:</strong></p>
<pre><code class="language-toml">[god_object_detection.rust]
max_traits = 7
</code></pre>
<ul>
<li>Only flags severe SRP violations</li>
<li>Useful for large legacy codebases during initial assessment</li>
</ul>
<h2 id="output-and-reporting"><a class="header" href="#output-and-reporting">Output and Reporting</a></h2>
<h3 id="console-output"><a class="header" href="#console-output">Console Output</a></h3>
<p>When analyzing a file with multiple responsibilities:</p>
<pre><code>src/services/user_manager.rs
  ‚ö†Ô∏è God Object: 18 methods, 8 fields, 5 responsibilities
     Score: 185 (Confidence: Probable)

     Responsibilities:
       - Data Access (5 methods)
       - Validation (4 methods)
       - Persistence (3 methods)
       - Communication (3 methods)
       - Formatting &amp; Output (3 methods)

     Recommended Splits:
       1. DataAccessManager (5 methods, ~75 lines)
       2. ValidationManager (4 methods, ~60 lines)
       3. PersistenceManager (3 methods, ~45 lines)
</code></pre>
<h3 id="json-output-1"><a class="header" href="#json-output-1">JSON Output</a></h3>
<p>For programmatic analysis, use <code>--format json</code>:</p>
<pre><code class="language-json">{
  "file": "src/services/user_manager.rs",
  "is_god_object": true,
  "responsibility_count": 5,
  "responsibilities": [
    "Data Access",
    "Validation",
    "Persistence",
    "Communication",
    "Formatting &amp; Output"
  ],
  "recommended_splits": [
    {
      "suggested_name": "DataAccessManager",
      "methods_to_move": ["get_user", "set_password", "get_email"],
      "responsibility": "Data Access",
      "estimated_lines": 75
    }
  ]
}
</code></pre>
<h2 id="best-practices-16"><a class="header" href="#best-practices-16">Best Practices</a></h2>
<h3 id="writing-srp-compliant-code"><a class="header" href="#writing-srp-compliant-code">Writing SRP-Compliant Code</a></h3>
<ol>
<li><strong>Name functions descriptively</strong> - Use standard prefixes (<code>get_</code>, <code>validate_</code>, etc.)</li>
<li><strong>Group related functions</strong> - Keep similar responsibilities together</li>
<li><strong>Limit responsibility count</strong> - Aim for 1-3 responsibilities per module</li>
<li><strong>Review regularly</strong> - Run Debtmap periodically to catch responsibility creep</li>
<li><strong>Refactor early</strong> - Split modules before they hit thresholds</li>
</ol>
<h3 id="code-review-guidelines"><a class="header" href="#code-review-guidelines">Code Review Guidelines</a></h3>
<p>When reviewing responsibility analysis results:</p>
<ol>
<li><strong>Check responsibility boundaries</strong> - Are they logically distinct?</li>
<li><strong>Validate groupings</strong> - Do the recommended splits make sense?</li>
<li><strong>Consider dependencies</strong> - Will splitting introduce more coupling?</li>
<li><strong>Estimate refactoring cost</strong> - Is the improvement worth the effort?</li>
<li><strong>Prioritize by score</strong> - Focus on high-scoring god objects first</li>
</ol>
<h3 id="team-adoption"><a class="header" href="#team-adoption">Team Adoption</a></h3>
<p><strong>Phase 1: Assessment</strong></p>
<ul>
<li>Run Debtmap on codebase</li>
<li>Review responsibility violations</li>
<li>Identify top 10 problematic modules</li>
</ul>
<p><strong>Phase 2: Education</strong></p>
<ul>
<li>Share responsibility analysis results with team</li>
<li>Discuss SRP and its benefits</li>
<li>Agree on responsibility threshold standards</li>
</ul>
<p><strong>Phase 3: Incremental Refactoring</strong></p>
<ul>
<li>Start with highest-scoring modules</li>
<li>Apply recommended splits</li>
<li>Measure improvement with follow-up analysis</li>
</ul>
<p><strong>Phase 4: Continuous Monitoring</strong></p>
<ul>
<li>Integrate Debtmap into CI/CD</li>
<li>Track responsibility counts over time</li>
<li>Prevent new SRP violations from merging</li>
</ul>
<h2 id="limitations-and-edge-cases"><a class="header" href="#limitations-and-edge-cases">Limitations and Edge Cases</a></h2>
<h3 id="false-positives"><a class="header" href="#false-positives">False Positives</a></h3>
<p><strong>Scenario 1: Utilities Module</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// utilities.rs - 15 helper functions with different prefixes
fn format_date() { }
fn parse_config() { }
fn validate_email() { }
// ... 12 more diverse utilities
<span class="boring">}</span></code></pre></pre>
<p><strong>Issue:</strong> Flagged as having multiple responsibilities, but it‚Äôs intentionally a utility collection.</p>
<p><strong>Solution:</strong> Either accept the flagging (utilities should perhaps be split) or increase <code>max_traits</code> threshold.</p>
<h3 id="false-negatives"><a class="header" href="#false-negatives">False Negatives</a></h3>
<p><strong>Scenario 2: Poor Naming</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl DataProcessor {
    fn process_data(&amp;mut self) { /* does everything */ }
    fn handle_stuff(&amp;mut self) { /* also does everything */ }
    fn do_work(&amp;mut self) { /* yet more mixed concerns */ }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Issue:</strong> All methods map to ‚ÄúProcessing‚Äù or ‚ÄúUtilities‚Äù, so responsibility count is low despite clear SRP violations.</p>
<p><strong>Solution:</strong> Encourage better naming conventions in your team. Debtmap relies on descriptive function names.</p>
<h3 id="language-specific-challenges"><a class="header" href="#language-specific-challenges">Language-Specific Challenges</a></h3>
<p><strong>Rust:</strong> Trait implementations may group methods by trait rather than responsibility, artificially inflating counts.</p>
<p><strong>Python:</strong> Dynamic typing and duck typing make responsibility boundaries less clear from signatures alone.</p>
<p><strong>JavaScript:</strong> Prototype methods and closures may not follow conventional naming patterns.</p>
<h2 id="integration-with-other-features"><a class="header" href="#integration-with-other-features">Integration with Other Features</a></h2>
<h3 id="god-object-detection-2"><a class="header" href="#god-object-detection-2">God Object Detection</a></h3>
<p>Responsibility analysis is a core component of <a href="./god-object-detection.html">God Object Detection</a>. The responsibility count contributes to:</p>
<ul>
<li>God object scoring</li>
<li>Confidence level determination</li>
<li>Refactoring recommendations</li>
</ul>
<h3 id="tiered-prioritization-2"><a class="header" href="#tiered-prioritization-2">Tiered Prioritization</a></h3>
<p>High responsibility counts increase priority in <a href="./tiered-prioritization.html">Tiered Prioritization</a> through the god object multiplier.</p>
<h3 id="risk-assessment"><a class="header" href="#risk-assessment">Risk Assessment</a></h3>
<p>Modules with multiple responsibilities receive higher risk scores in risk assessment, as they are more prone to bugs and harder to maintain.</p>
<h2 id="related-documentation-3"><a class="header" href="#related-documentation-3">Related Documentation</a></h2>
<ul>
<li><a href="./god-object-detection.html">God Object Detection</a> - Full god object analysis including responsibility detection</li>
<li><a href="./configuration.html">Configuration</a> - TOML configuration reference</li>
<li><a href="./metrics-reference.html">Metrics Reference</a> - All metrics including responsibility count</li>
<li><a href="./architecture.html">Architecture</a> - High-level design including analysis pipelines</li>
</ul>
<h2 id="summary-9"><a class="header" href="#summary-9">Summary</a></h2>
<p>Responsibility analysis in Debtmap:</p>
<ul>
<li><strong>Automatically detects SRP violations</strong> through pattern-based method name analysis</li>
<li><strong>Categorizes methods</strong> into 11 built-in responsibility types</li>
<li><strong>Provides actionable refactoring recommendations</strong> with suggested module splits</li>
<li><strong>Integrates with god object detection</strong> for holistic architectural analysis</li>
<li><strong>Supports language-specific thresholds</strong> for Rust, Python, and JavaScript/TypeScript</li>
<li><strong>Is fully configurable</strong> via <code>.debtmap.toml</code> and CLI flags</li>
</ul>
<p>By surfacing responsibility violations early and suggesting concrete refactoring paths, Debtmap helps teams maintain clean, modular architectures that follow the Single Responsibility Principle.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scoring-strategies"><a class="header" href="#scoring-strategies">Scoring Strategies</a></h1>
<p>Debtmap provides two complementary scoring approaches: <strong>file-level</strong> and <strong>function-level</strong>. Understanding when to use each approach helps you make better refactoring decisions and prioritize work effectively.</p>
<h2 id="overview-15"><a class="header" href="#overview-15">Overview</a></h2>
<p>Different refactoring scenarios require different levels of granularity:</p>
<ul>
<li><strong>File-level scoring</strong>: Identifies architectural issues and planning major refactoring initiatives</li>
<li><strong>Function-level scoring</strong>: Pinpoints specific hot spots for targeted improvements</li>
</ul>
<p>This chapter explains both approaches, when to use each, and how to interpret the results.</p>
<h2 id="file-level-scoring"><a class="header" href="#file-level-scoring">File-Level Scoring</a></h2>
<p>File-level scoring aggregates metrics across all functions in a file to identify architectural problems and module-level refactoring opportunities.</p>
<h3 id="formula-1"><a class="header" href="#formula-1">Formula</a></h3>
<pre><code>File Score = Size √ó Complexity √ó Coverage Factor √ó Density √ó GodObject √ó FunctionScores
</code></pre>
<p><strong>Note</strong>: This is a conceptual formula showing the multiplicative relationship between factors. The actual implementation in <code>src/priority/file_metrics.rs</code> includes additional normalization steps and conditional adjustments. See source code for exact calculation details.</p>
<p>Where each factor is calculated as:</p>
<ul>
<li><strong>Size</strong> = <code>sqrt(total_lines / 100)</code></li>
<li><strong>Complexity</strong> = <code>(avg_complexity / 5.0) √ó sqrt(total_complexity / 50.0)</code></li>
<li><strong>Coverage Factor</strong> = <code>((1.0 - coverage_percent) √ó 2.0) + 1.0</code></li>
<li><strong>Density</strong> = <code>1.0 + ((function_count - 50) √ó 0.02)</code> if function_count &gt; 50, else 1.0</li>
<li><strong>GodObject</strong> = <code>2.0 + god_object_score</code> if detected</li>
<li><strong>FunctionScores</strong> = <code>sum(function_scores) / 10</code></li>
</ul>
<h3 id="factors"><a class="header" href="#factors">Factors</a></h3>
<p><strong>Size Factor</strong>: <code>sqrt(total_lines / 100)</code></p>
<ul>
<li>Larger files have higher impact</li>
<li>Square root dampens the effect to avoid over-penalizing large files</li>
<li>Rationale: Refactoring a 1000-line file affects more code than a 100-line file</li>
</ul>
<p><strong>Complexity Factor</strong>: Combines average and total complexity</p>
<ul>
<li><code>(average_cyclomatic + total_cyclomatic / function_count) / 2</code></li>
<li>Balances per-function and aggregate complexity</li>
<li>Rationale: Both concentrated complexity and spread-out complexity matter</li>
</ul>
<p><strong>Coverage Factor</strong>: <code>(coverage_gap √ó 2.0) + 1.0</code> where <code>coverage_gap = 1.0 - coverage_percent</code></p>
<ul>
<li>Lower coverage increases score multiplicatively</li>
<li>Range: 1.0 (100% coverage) to 3.0 (0% coverage)</li>
<li>Formula expands to: <code>((1.0 - coverage_percent) √ó 2.0) + 1.0</code></li>
<li>Example: 50% coverage ‚Üí gap=0.5 ‚Üí factor=(0.5√ó2.0)+1.0 = 2.0x</li>
<li>Rationale: Untested files amplify existing complexity and risk through a multiplicative factor greater than 1.0</li>
<li>Note: Earlier versions used <code>1.0 - coverage_percent</code> (range 0-1); current implementation uses expanded range 1-3 for stronger emphasis</li>
</ul>
<p><strong>Density Factor</strong>: Penalizes files with excessive function count</p>
<ul>
<li>Triggers when function count &gt; 50</li>
<li>Formula: <code>1.0 + ((function_count - 50) * 0.02)</code> if function_count &gt; 50, else 1.0</li>
<li>Creates a gradual linear increase: 51 functions = 1.02x, 75 functions = 1.50x, 100 functions = 2.0x</li>
<li>Example: A file with 75 functions gets 1.0 + ((75 - 50) * 0.02) = 1.0 + 0.50 = 1.50x multiplier</li>
<li>Rationale: Files with many functions likely violate single responsibility</li>
</ul>
<p><strong>God Object Multiplier</strong>: <code>2.0 + god_object_score</code> when detected</p>
<ul>
<li>Applies when god object detection flags the file</li>
<li>Range: 2.0 (borderline) to 3.0 (severe god object)</li>
<li>Rationale: God objects need immediate architectural attention</li>
</ul>
<p><strong>Function Scores</strong>: <code>sum(all_function_scores) / 10</code></p>
<ul>
<li>Normalized sum of individual function debt scores</li>
<li>Provides baseline before modifiers</li>
</ul>
<h3 id="use-cases-6"><a class="header" href="#use-cases-6">Use Cases</a></h3>
<p><strong>1. Planning Major Refactoring Initiatives</strong></p>
<pre><code class="language-bash"># Show top 10 files needing architectural refactoring
debtmap analyze . --aggregate-only --top 10
</code></pre>
<p>Use when:</p>
<ul>
<li>Planning sprint or quarterly refactoring work</li>
<li>Deciding which modules to split</li>
<li>Prioritizing architectural improvements</li>
<li>Allocating team resources</li>
</ul>
<p><strong>Note</strong>: File-level scoring is enabled with the <code>--aggregate-only</code> flag, which changes output to show only file-level metrics instead of function-level details.</p>
<p><strong>2. Identifying Architectural Issues</strong></p>
<p>File-level scoring excels at finding:</p>
<ul>
<li>God objects with too many responsibilities</li>
<li>Files with poor cohesion</li>
<li>Modules that should be split</li>
<li>Files with too many functions</li>
</ul>
<pre><code class="language-bash"># Focus on architectural problems
debtmap analyze . --aggregate-only --filter Architecture
</code></pre>
<p><strong>3. Breaking Up Monolithic Modules</strong></p>
<pre><code class="language-bash"># Find files with excessive function counts
debtmap analyze . --aggregate-only --min-problematic 50
</code></pre>
<p><strong>4. Evaluating Overall Codebase Health</strong></p>
<pre><code class="language-bash"># Generate file-level report for executive summary
debtmap analyze . --aggregate-only --format markdown -o report.md
</code></pre>
<h3 id="aggregation-methods"><a class="header" href="#aggregation-methods">Aggregation Methods</a></h3>
<p>Debtmap supports multiple aggregation methods for file-level scores, configurable via CLI or configuration file.</p>
<h4 id="weighted-sum-default"><a class="header" href="#weighted-sum-default">Weighted Sum (Default)</a></h4>
<p><strong>Formula</strong>: <code>Œ£(function_score √ó complexity_weight √ó coverage_weight)</code></p>
<pre><code class="language-bash">debtmap analyze . --aggregation-method weighted_sum
</code></pre>
<p>Or via configuration:</p>
<pre><code class="language-toml">[aggregation]
method = "weighted_sum"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Weights functions by their complexity and coverage gaps</li>
<li>Emphasizes high-impact functions over trivial ones</li>
<li>Best for most use cases where you want to focus on significant issues</li>
</ul>
<p><strong>Best for</strong>: Standard codebases where you want proportional emphasis on complex, untested code</p>
<h4 id="simple-sum"><a class="header" href="#simple-sum">Simple Sum</a></h4>
<p><strong>Formula</strong>: <code>Œ£(function_scores)</code></p>
<pre><code class="language-toml">[aggregation]
method = "sum"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Adds all function scores directly without weighting</li>
<li>Treats all functions equally regardless of complexity</li>
<li>Useful for broad overview and trend analysis</li>
</ul>
<p><strong>Best for</strong>: Getting a raw count-based view of technical debt across all functions</p>
<h4 id="logarithmic-sum"><a class="header" href="#logarithmic-sum">Logarithmic Sum</a></h4>
<p><strong>Formula</strong>: <code>log(1 + Œ£(function_scores))</code></p>
<pre><code class="language-toml">[aggregation]
method = "logarithmic_sum"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Dampens impact of many small issues to prevent score explosion</li>
<li>Prevents files with hundreds of minor issues from dominating</li>
<li>Creates more balanced comparisons across files of different sizes</li>
</ul>
<p><strong>Best for</strong>: Legacy codebases with many small issues where you want to avoid extreme scores</p>
<h4 id="max-plus-average"><a class="header" href="#max-plus-average">Max Plus Average</a></h4>
<p><strong>Formula</strong>: <code>max_score √ó 0.6 + avg_score √ó 0.4</code></p>
<pre><code class="language-toml">[aggregation]
method = "max_plus_average"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Considers worst function (60%) plus average of all functions (40%)</li>
<li>Balances worst-case and typical-case scenarios</li>
<li>Highlights files with both a critical hot spot and general issues</li>
</ul>
<p><strong>Best for</strong>: Identifying files with concentrated complexity alongside general code quality concerns</p>
<h4 id="choosing-an-aggregation-method"><a class="header" href="#choosing-an-aggregation-method">Choosing an Aggregation Method</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Codebase Type</th><th>Recommended Method</th><th>Rationale</th></tr></thead><tbody>
<tr><td>New/Modern</td><td><code>weighted_sum</code></td><td>Proportional emphasis on real issues</td></tr>
<tr><td>Legacy with many small issues</td><td><code>logarithmic_sum</code></td><td>Prevents score explosion</td></tr>
<tr><td>Mixed quality</td><td><code>max_plus_average</code></td><td>Balances hot spots with overall quality</td></tr>
<tr><td>Trend analysis</td><td><code>sum</code></td><td>Simple, consistent metric over time</td></tr>
</tbody></table>
</div>
<p><strong>Performance Note</strong>: All aggregation methods have O(n) complexity where n = number of functions. Performance differences are negligible for typical codebases (&lt;100k functions). Choose based on prioritization strategy, not performance concerns.</p>
<h3 id="configuration-12"><a class="header" href="#configuration-12">Configuration</a></h3>
<pre><code class="language-toml">[aggregation]
method = "weighted_sum"
min_problematic = 3              # Need 3+ problematic functions for file-level score

[god_object_detection]
enabled = true
max_methods = 20
max_fields = 15
max_responsibilities = 5
</code></pre>
<h2 id="function-level-scoring"><a class="header" href="#function-level-scoring">Function-Level Scoring</a></h2>
<p>Function-level scoring identifies specific functions needing attention for targeted improvements.</p>
<h3 id="formula-2"><a class="header" href="#formula-2">Formula</a></h3>
<pre><code>Base Score = (Complexity Factor √ó 10 √ó 0.50) + (Dependency Factor √ó 10 √ó 0.25)
Coverage Multiplier = 1.0 - coverage_percent
Final Score = Base Score √ó Coverage Multiplier √ó Role Multiplier
</code></pre>
<p><strong>Formula Breakdown:</strong></p>
<ol>
<li><strong>Complexity Factor</strong>: Raw complexity / 2.0, clamped to 0-10 range (complexity of 20+ maps to 10.0)</li>
<li><strong>Dependency Factor</strong>: Upstream dependency count / 2.0, capped at 10.0 (20+ dependencies map to 10.0)</li>
<li><strong>Base Score</strong>: (Complexity Factor √ó 10 √ó 0.50) + (Dependency Factor √ó 10 √ó 0.25)
<ul>
<li>50% weight on complexity, 25% weight on dependencies</li>
</ul>
</li>
<li><strong>Coverage Multiplier</strong>: 1.0 - coverage_percent (0% coverage = 1.0, 100% coverage = 0.0)</li>
<li><strong>Final Score</strong>: Base Score √ó Coverage Multiplier √ó Role Multiplier</li>
</ol>
<p><strong>Note</strong>: Coverage acts as a dampening multiplier rather than an additive factor. Lower coverage (higher multiplier) increases the final score, making untested complex code a higher priority. The weights (0.50 for complexity, 0.25 for dependencies) are hard-coded in the implementation to ensure consistent scoring across environments. Role multipliers and coverage weights remain configurable to allow customization while maintaining stable base calculations.</p>
<p><strong>Why Hard-Coded Weights?</strong> These base weights are intentionally not configurable to:</p>
<ul>
<li><strong>Ensure consistency</strong>: Scores remain comparable across projects and teams</li>
<li><strong>Prevent instability</strong>: Avoid extreme configurations that break prioritization</li>
<li><strong>Simplify configuration</strong>: Reduce cognitive load for users</li>
<li><strong>Maintain calibration</strong>: Weights are empirically tuned based on analysis of real codebases</li>
</ul>
<p>You can still customize prioritization significantly through configurable <code>role_multipliers</code>, <code>coverage_weights</code>, and normalization settings.</p>
<p><strong>Migration Note</strong>: Earlier versions used an additive model with weights (Complexity √ó 0.35) + (Coverage √ó 0.50) + (Dependency √ó 0.15). The current model (spec 122) uses coverage as a multiplicative dampener, which better reflects that testing gaps amplify existing complexity rather than adding to it.</p>
<h3 id="metrics"><a class="header" href="#metrics">Metrics</a></h3>
<p><strong>Cyclomatic Complexity</strong></p>
<ul>
<li>Counts decision points (if, match, loops)</li>
<li>Guides test case count</li>
</ul>
<p><strong>Cognitive Complexity</strong></p>
<ul>
<li>Measures understanding difficulty</li>
<li>Accounts for nesting depth</li>
</ul>
<p><strong>Coverage Percentage</strong></p>
<ul>
<li>Direct line coverage from LCOV</li>
<li>0% coverage = maximum urgency</li>
</ul>
<p><strong>Dependency Count</strong></p>
<ul>
<li>Upstream callers + downstream callees</li>
<li>Higher dependencies = higher impact</li>
</ul>
<p><strong>Role Multiplier</strong></p>
<p>Functions are classified by role, and each role receives a multiplier based on its architectural importance:</p>
<div class="table-wrapper"><table><thead><tr><th>Role</th><th>Multiplier</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>Pure logic</strong></td><td>1.2x</td><td>Core business rules and algorithms</td></tr>
<tr><td><strong>Unknown</strong></td><td>1.0x</td><td>Functions without clear classification</td></tr>
<tr><td><strong>Entry point</strong></td><td>0.9x</td><td>Public APIs, main functions, HTTP handlers</td></tr>
<tr><td><strong>Orchestrator</strong></td><td>0.8x</td><td>Functions that coordinate other functions</td></tr>
<tr><td><strong>IO wrapper</strong></td><td>0.7x</td><td>Simple file/network I/O wrappers</td></tr>
<tr><td><strong>Pattern match</strong></td><td>0.6x</td><td>Functions primarily doing pattern matching</td></tr>
</tbody></table>
</div>
<p><strong>Note</strong>: Role multipliers are configurable via the <code>[role_multipliers]</code> section in <code>.debtmap.toml</code>. The multipliers have been rebalanced to be less extreme than earlier versions - pure logic was reduced from 1.5x to 1.2x, while orchestrator and IO wrapper were increased to better reflect their importance in modern codebases.</p>
<h3 id="constructor-detection-1"><a class="header" href="#constructor-detection-1">Constructor Detection</a></h3>
<p>Debtmap includes intelligent constructor detection to prevent false positives where trivial initialization functions are misclassified as critical business logic.</p>
<p><strong>Problem</strong>: Simple constructors like <code>new()</code>, <code>default()</code>, or <code>from_config()</code> often have low complexity but were being flagged as high-priority pure logic functions.</p>
<p><strong>Solution</strong>: Constructor detection automatically identifies and classifies these functions as <code>IOWrapper</code> (low priority) instead of <code>PureLogic</code> (high priority).</p>
<p><strong>Detection Criteria</strong>:</p>
<p>A function is considered a simple constructor if it meets ALL of the following:</p>
<ol>
<li>
<p><strong>Name matches a constructor pattern</strong> (configurable):</p>
<ul>
<li>Exact match: <code>new</code>, <code>default</code>, <code>empty</code>, <code>zero</code>, <code>any</code></li>
<li>Prefix match: <code>from_*</code>, <code>with_*</code>, <code>create_*</code>, <code>make_*</code>, <code>build_*</code>, <code>of_*</code></li>
</ul>
</li>
<li>
<p><strong>Low cyclomatic complexity</strong> (‚â§ 2 by default)</p>
</li>
<li>
<p><strong>Short length</strong> (&lt; 15 lines by default)</p>
</li>
<li>
<p><strong>Minimal nesting</strong> (‚â§ 1 level by default)</p>
</li>
<li>
<p><strong>Low cognitive complexity</strong> (‚â§ 3 by default)</p>
</li>
</ol>
<p><strong>Example</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simple constructor - detected and classified as IOWrapper
fn new() -&gt; Self {
    Self {
        field1: 0,
        field2: String::new(),
    }
}

// Complex factory - NOT detected as constructor, remains PureLogic
fn create_with_validation(data: Data) -&gt; Result&lt;Self&gt; {
    validate(&amp;data)?;
    // ... 30 lines of logic
    Ok(Self { ... })
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Configuration</strong>:</p>
<p>Constructor detection is fully configurable in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[classification.constructors]
# Enable AST-based constructor detection (default: true)
# When enabled, uses Abstract Syntax Tree analysis for accurate detection
# Disable only if experiencing performance issues with very large codebases
ast_detection = true

# Constructor name patterns
patterns = [
    "new",
    "default",
    "from_",
    "with_",
    "create_",
    "make_",
    "build_",
    "of_",
    "empty",
    "zero",
    "any",
]

# Complexity thresholds
max_cyclomatic = 2     # Maximum cyclomatic complexity
max_cognitive = 3      # Maximum cognitive complexity
max_length = 15        # Maximum lines
max_nesting = 1        # Maximum nesting depth
</code></pre>
<p><strong>Customization Example</strong>:</p>
<p>To add custom constructor patterns or adjust thresholds:</p>
<pre><code class="language-toml">[classification.constructors]
ast_detection = true      # Keep AST detection enabled (recommended)

patterns = [
    "new",
    "default",
    "from_",
    "with_",
    "init_",        # Add custom pattern
    "setup_",       # Add custom pattern
]
max_cyclomatic = 3    # Allow slightly more complex constructors
max_length = 20       # Allow longer constructors
</code></pre>
<p>To disable AST-based detection (if experiencing performance issues):</p>
<pre><code class="language-toml">[classification.constructors]
ast_detection = false     # Fall back to pattern-only matching
# Note: May reduce detection accuracy but improves performance
</code></pre>
<p><strong>Performance and Disabling</strong>:</p>
<p>Constructor detection is <strong>always enabled</strong> and cannot be fully disabled, as it‚Äôs integral to accurate priority scoring. However, you can:</p>
<ol>
<li><strong>Disable AST analysis</strong> (shown above): Falls back to pattern-only matching, reducing accuracy but improving performance for very large codebases (100k+ functions)</li>
<li><strong>Adjust thresholds</strong>: Make detection more lenient by increasing <code>max_cyclomatic</code>, <code>max_cognitive</code>, or <code>max_length</code></li>
<li><strong>Remove patterns</strong>: Delete specific patterns from the <code>patterns</code> list to exclude them from detection</li>
</ol>
<p><strong>Performance Impact</strong>:</p>
<ul>
<li>AST-based detection: Negligible impact (&lt;5% overhead) for typical codebases</li>
<li>Pattern-only detection: Near-zero performance impact</li>
<li>Recommendation: Keep <code>ast_detection = true</code> unless profiling shows it‚Äôs a bottleneck</li>
</ul>
<p><strong>Accuracy Trade-offs</strong>:</p>
<ul>
<li>With AST: 95%+ accuracy in identifying simple constructors</li>
<li>Without AST: ~70% accuracy, more false negatives</li>
</ul>
<p>This feature is part of spec 117 and helps reduce false positives in priority scoring.</p>
<h3 id="role-based-adjustments"><a class="header" href="#role-based-adjustments">Role-Based Adjustments</a></h3>
<p>DebtMap uses a sophisticated two-stage role adjustment mechanism to ensure that scores accurately reflect both the testing strategy appropriate for each function type and the architectural importance of different roles.</p>
<h4 id="why-role-based-adjustments"><a class="header" href="#why-role-based-adjustments">Why Role-Based Adjustments?</a></h4>
<p><strong>Problem</strong>: Traditional scoring treats all functions equally, leading to false positives:</p>
<ol>
<li>
<p><strong>Entry points</strong> (CLI handlers, HTTP routes, <code>main</code> functions) typically use integration tests rather than unit tests</p>
<ul>
<li>Flagging them for ‚Äúlow unit test coverage‚Äù misses that they‚Äôre tested differently</li>
<li>They orchestrate other code but contain minimal business logic</li>
</ul>
</li>
<li>
<p><strong>Pure business logic</strong> functions should have comprehensive unit tests</p>
<ul>
<li>Easy to test in isolation with deterministic inputs/outputs</li>
<li>Core value of the application lives here</li>
</ul>
</li>
<li>
<p><strong>I/O wrappers</strong> are often tested implicitly through integration tests</p>
<ul>
<li>Thin abstractions over file system, network, or database operations</li>
<li>Unit testing them provides limited value compared to integration testing</li>
</ul>
</li>
</ol>
<p><strong>Solution</strong>: DebtMap applies role-based adjustments in two stages to address both coverage expectations and architectural importance.</p>
<h4 id="stage-1-role-based-coverage-weighting"><a class="header" href="#stage-1-role-based-coverage-weighting">Stage 1: Role-Based Coverage Weighting</a></h4>
<p>The first stage adjusts coverage penalty expectations based on function role. This prevents functions that use different testing strategies from unfairly dominating the priority list.</p>
<p><strong>How It Works</strong>:</p>
<p>For each function, DebtMap:</p>
<ol>
<li>Detects the function‚Äôs role (entry point, pure logic, I/O wrapper, etc.)</li>
<li>Applies a coverage weight multiplier based on that role</li>
<li>Reduces or increases the coverage penalty accordingly</li>
</ol>
<p><strong>Default Coverage Weights</strong> (configurable in <code>.debtmap.toml</code>):</p>
<div class="table-wrapper"><table><thead><tr><th>Function Role</th><th>Coverage Weight</th><th>Impact on Scoring</th></tr></thead><tbody>
<tr><td>Pure Logic</td><td>1.2</td><td>Higher coverage penalty (should have unit tests)</td></tr>
<tr><td>Unknown</td><td>1.0</td><td>Standard penalty</td></tr>
<tr><td>Pattern Match</td><td>1.0</td><td>Standard penalty</td></tr>
<tr><td>Orchestrator</td><td>0.8</td><td>Reduced penalty (partially integration tested)</td></tr>
<tr><td>I/O Wrapper</td><td>0.7</td><td>Reduced penalty (often integration tested)</td></tr>
<tr><td>Entry Point</td><td>0.6</td><td>Significantly reduced penalty (integration tested)</td></tr>
</tbody></table>
</div>
<p><strong>Example Score Changes</strong>:</p>
<p><strong>Before role-based coverage adjustment</strong>:</p>
<pre><code>Function: handle_request (Entry Point)
  Complexity: 5
  Coverage: 0%
  Raw Coverage Penalty: 1.0 (full penalty)
  Score: 8.5 (flagged as high priority)
</code></pre>
<p><strong>After role-based coverage adjustment</strong>:</p>
<pre><code>Function: handle_request (Entry Point)
  Complexity: 5
  Coverage: 0%
  Adjusted Coverage Penalty: 0.4 (60% reduction via 0.6 weight)
  Score: 4.2 (medium priority - more realistic)

  Rationale: Entry points are integration tested, not unit tested.
  This function is likely tested via API/CLI integration tests.
</code></pre>
<p><strong>Comparison with Pure Logic</strong>:</p>
<pre><code>Function: calculate_discount (Pure Logic)
  Complexity: 5
  Coverage: 0%
  Adjusted Coverage Penalty: 1.2 (20% increase via 1.2 weight)
  Score: 9.8 (critical priority)

  Rationale: Pure logic should have unit tests.
  This function needs immediate test coverage.
</code></pre>
<h4 id="stage-2-role-multiplier"><a class="header" href="#stage-2-role-multiplier">Stage 2: Role Multiplier</a></h4>
<p>The second stage applies a final role-based multiplier to reflect architectural importance. This multiplier is <strong>clamped by default</strong> to prevent extreme score swings.</p>
<p><strong>Configuration</strong> (<code>.debtmap.toml</code> under <code>[scoring.role_multiplier]</code>):</p>
<pre><code class="language-toml">[scoring.role_multiplier]
clamp_min = 0.3           # Minimum multiplier (default: 0.3)
clamp_max = 1.8           # Maximum multiplier (default: 1.8)
enable_clamping = true    # Enable clamping (default: true)
</code></pre>
<p><strong>Clamp Range Rationale</strong>:</p>
<ul>
<li><strong>Default [0.3, 1.8]</strong>: Balances differentiation with stability</li>
<li><strong>Lower bound (0.3)</strong>: I/O wrappers still contribute 30% of base score (not invisible)</li>
<li><strong>Upper bound (1.8)</strong>: Critical entry points don‚Äôt overwhelm other issues (max 180%)</li>
<li><strong>Configurable</strong>: Adjust based on project priorities</li>
</ul>
<p><strong>Example with Clamping</strong>:</p>
<pre><code>Function: process_data (Complex Pure Logic)
  Base Score: 45.0
  Unclamped Role Multiplier: 2.5
  Clamped Multiplier: 1.8 (clamp_max)
  Final Score: 45.0 √ó 1.8 = 81.0

  Effect: Prevents one complex function from dominating entire priority list
</code></pre>
<h4 id="why-two-stages"><a class="header" href="#why-two-stages">Why Two Stages?</a></h4>
<p>The separation of coverage weight adjustment and role multiplier ensures they work together without interfering:</p>
<p><strong>Stage 1 (Coverage Weight)</strong>: Adjusts testing expectations</p>
<ul>
<li><strong>Question</strong>: ‚ÄúHow much should we penalize missing unit tests for this type of function?‚Äù</li>
<li><strong>Example</strong>: Entry points get 60% of normal coverage penalty (they‚Äôre integration tested)</li>
</ul>
<p><strong>Stage 2 (Role Multiplier)</strong>: Adjusts architectural importance</p>
<ul>
<li><strong>Question</strong>: ‚ÄúHow important is this function relative to others with similar complexity?‚Äù</li>
<li><strong>Example</strong>: Critical entry points might get a 1.2x multiplier (clamped), while simple I/O wrappers get 0.5x (clamped)</li>
</ul>
<p><strong>Independent Contributions</strong>:</p>
<pre><code>1. Calculate base score from complexity + dependencies
2. Apply coverage weight by role ‚Üí adjusted coverage penalty
3. Combine into preliminary score
4. Apply clamped role multiplier ‚Üí final score
</code></pre>
<p>This approach ensures:</p>
<ul>
<li>Coverage adjustments don‚Äôt interfere with role multiplier</li>
<li>Both mechanisms contribute independently</li>
<li>Clamping prevents instability from extreme multipliers</li>
</ul>
<h4 id="how-this-reduces-false-positives"><a class="header" href="#how-this-reduces-false-positives">How This Reduces False Positives</a></h4>
<p><strong>False Positive #1: Entry Points Flagged for Low Coverage</strong></p>
<p><strong>Before</strong>:</p>
<pre><code>Top Priority Items:
1. main() - Score: 9.2 (0% unit test coverage)
2. handle_cli_command() - Score: 8.8 (5% unit test coverage)
3. run_server() - Score: 8.5 (0% unit test coverage)
</code></pre>
<p><strong>After</strong>:</p>
<pre><code>Top Priority Items:
1. calculate_tax() - Score: 9.8 (0% coverage, Pure Logic)
2. validate_payment() - Score: 9.2 (10% coverage, Pure Logic)
3. main() - Score: 4.2 (0% coverage, Entry Point - integration tested)
</code></pre>
<p><strong>Result</strong>: Business logic functions that actually need unit tests rise to the top.</p>
<p><strong>False Positive #2: I/O Wrappers Over-Prioritized</strong></p>
<p><strong>Before</strong>:</p>
<pre><code>Function: read_config_file
  Complexity: 3
  Coverage: 0%
  Score: 7.5 (high priority)

  Issue: This is a thin wrapper over std::fs::read_to_string.
  Unit testing it provides minimal value vs integration tests.
</code></pre>
<p><strong>After</strong>:</p>
<pre><code>Function: read_config_file
  Complexity: 3
  Coverage: 0%
  Adjusted Coverage Weight: 0.7
  Score: 3.2 (low priority)

  Rationale: I/O wrappers are integration tested.
  Focus on business logic instead.
</code></pre>
<h4 id="configuration-examples-1"><a class="header" href="#configuration-examples-1">Configuration Examples</a></h4>
<p><strong>Emphasize Pure Logic Testing</strong>:</p>
<pre><code class="language-toml">[scoring.role_coverage_weights]
pure_logic = 1.5        # Strong penalty for untested pure logic
entry_point = 0.5       # Minimal penalty for untested entry points
io_wrapper = 0.5        # Minimal penalty for untested I/O wrappers
</code></pre>
<p><strong>Conservative Approach (Smaller Adjustments)</strong>:</p>
<pre><code class="language-toml">[scoring.role_coverage_weights]
pure_logic = 1.1        # Slight increase
entry_point = 0.9       # Slight decrease
io_wrapper = 0.9        # Slight decrease
</code></pre>
<p><strong>Disable Multiplier Clamping</strong> (not recommended for production):</p>
<pre><code class="language-toml">[scoring.role_multiplier]
enable_clamping = false   # Allow unclamped multipliers
# Warning: May cause unstable prioritization
</code></pre>
<h4 id="verification-1"><a class="header" href="#verification-1">Verification</a></h4>
<p>To see how role-based adjustments affect your codebase:</p>
<pre><code class="language-bash"># Show detailed scoring breakdown
debtmap analyze . --verbose

# Compare with role adjustments disabled
debtmap analyze . --config minimal.toml
</code></pre>
<p><strong>Sample verbose output</strong>:</p>
<pre><code>Function: src/handlers/request.rs:handle_request
  Role: Entry Point
  Complexity: 5
  Coverage: 0%
  Coverage Weight: 0.6 (Entry Point adjustment)
  Adjusted Coverage Penalty: 0.4 (reduced from 1.0)
  Base Score: 15.0
  Role Multiplier: 1.2 (clamped from 1.5)
  Final Score: 18.0

  Interpretation:
    - Entry point gets 60% coverage penalty instead of 100%
    - Likely tested via integration tests
    - Still flagged due to complexity, but not over-penalized for coverage
</code></pre>
<h4 id="benefits-summary"><a class="header" href="#benefits-summary">Benefits Summary</a></h4>
<ul>
<li><strong>Fewer false positives</strong>: Entry points and I/O wrappers no longer dominate priority lists</li>
<li><strong>Better resource allocation</strong>: Testing efforts focus on pure logic where unit tests provide most value</li>
<li><strong>Recognition of testing strategies</strong>: Integration tests are valued equally with unit tests</li>
<li><strong>Stable prioritization</strong>: Clamping prevents extreme multipliers from causing volatile rankings</li>
<li><strong>Configurable</strong>: Adjust weights and clamp ranges to match your project‚Äôs testing philosophy</li>
</ul>
<h3 id="use-cases-7"><a class="header" href="#use-cases-7">Use Cases</a></h3>
<p><strong>1. Identifying Specific Hot Spots</strong></p>
<pre><code class="language-bash"># Show top 20 functions needing attention
debtmap analyze . --top 20
</code></pre>
<p>Use when:</p>
<ul>
<li>Planning individual developer tasks</li>
<li>Assigning specific refactoring work</li>
<li>Identifying functions to test first</li>
<li>Code review focus</li>
</ul>
<p><strong>2. Sprint Planning for Developers</strong></p>
<pre><code class="language-bash"># Get function-level tasks for this sprint
debtmap analyze . --top 10 --format json -o sprint-tasks.json
</code></pre>
<p><strong>3. Writing Unit Tests</strong></p>
<pre><code class="language-bash"># Find untested complex functions
debtmap analyze . --lcov coverage.lcov --filter Testing --top 15
</code></pre>
<p><strong>4. Targeted Performance Optimization</strong></p>
<pre><code class="language-bash"># Find complex hot paths
debtmap analyze . --filter Performance --context --top 10
</code></pre>
<h3 id="configuration-13"><a class="header" href="#configuration-13">Configuration</a></h3>
<p>Complete configuration file example showing all scoring-related sections.</p>
<p><strong>File name</strong>: <code>.debtmap.toml</code> (must be placed in your project root)</p>
<pre><code class="language-toml"># .debtmap.toml - Complete scoring configuration

# Role multipliers (applied to final score after coverage multiplier)
[role_multipliers]
pure_logic = 1.2             # Core business rules and algorithms
unknown = 1.0                # Functions without clear classification
entry_point = 0.9            # Public APIs, main functions, HTTP handlers
orchestrator = 0.8           # Functions that coordinate other functions
io_wrapper = 0.7             # File/network I/O wrappers
pattern_match = 0.6          # Functions primarily doing pattern matching

# Aggregation settings (for file-level scoring)
[aggregation]
method = "weighted_sum"      # Options: weighted_sum, sum, logarithmic_sum, max_plus_average
min_problematic = 3          # Minimum number of problematic functions to report file

# Normalization settings (for advanced multi-phase normalization)
[normalization]
linear_threshold = 10.0       # Scores below this use linear scaling (1:1 mapping)
logarithmic_threshold = 100.0 # Scores above this use logarithmic dampening
sqrt_multiplier = 3.33        # Applied to scores between linear and log thresholds
log_multiplier = 10.0         # Applied to scores above logarithmic threshold
show_raw_scores = true        # Display both normalized (0-100) and raw scores in output
</code></pre>
<p><strong>Note on Scoring Weights</strong>: The base complexity and dependency weights are hard-coded for consistency across environments. However, you can customize prioritization significantly through configurable options:</p>
<p><strong>What‚Äôs Configurable:</strong></p>
<ul>
<li><code>role_multipliers</code> - Adjust importance of different function types (pure logic, entry points, I/O wrappers)</li>
<li><code>coverage_weights</code> - Role-specific coverage penalty adjustments</li>
<li><code>normalization</code> settings - Control score scaling and range</li>
<li><code>aggregation.method</code> - Choose how function scores combine into file scores</li>
</ul>
<p><strong>What‚Äôs Hard-Coded:</strong></p>
<ul>
<li>Base complexity weight (50%) and dependency weight (25%)</li>
<li>Coverage multiplier formula: <code>1.0 - coverage_percent</code></li>
</ul>
<p><strong>Impact</strong>: While base weights are fixed, the configurable multipliers and weights provide significant control over final rankings and priorities. A function with <code>role_multiplier = 1.5</code> and <code>coverage_weight = 1.2</code> can have 80% higher priority than the same function with default settings.</p>
<p><strong>Note</strong>: The configuration file must be named <code>.debtmap.toml</code> (not <code>debtmap.yml</code> or other variants) and placed in your project root directory.</p>
<h2 id="when-to-use-each-approach"><a class="header" href="#when-to-use-each-approach">When to Use Each Approach</a></h2>
<h3 id="use-file-level-scoring-when"><a class="header" href="#use-file-level-scoring-when">Use File-Level Scoring When:</a></h3>
<p>‚úÖ Planning architectural refactoring
‚úÖ Quarterly or annual planning
‚úÖ Deciding which modules to split
‚úÖ Executive summaries and high-level reports
‚úÖ Team capacity planning
‚úÖ Identifying god objects
‚úÖ Module reorganization</p>
<p><strong>Command:</strong></p>
<pre><code class="language-bash">debtmap analyze . --aggregate-only
</code></pre>
<h3 id="use-function-level-scoring-when"><a class="header" href="#use-function-level-scoring-when">Use Function-Level Scoring When:</a></h3>
<p>‚úÖ Sprint planning
‚úÖ Individual developer task assignment
‚úÖ Writing specific unit tests
‚úÖ Code review preparation
‚úÖ Pair programming sessions
‚úÖ Daily or weekly development work
‚úÖ Targeted hot spot fixes</p>
<p><strong>Command:</strong></p>
<pre><code class="language-bash">debtmap analyze . --top 20
</code></pre>
<h3 id="use-both-together"><a class="header" href="#use-both-together">Use Both Together:</a></h3>
<p>Many workflows benefit from both views:</p>
<pre><code class="language-bash"># Step 1: Identify problematic files
debtmap analyze . --aggregate-only --top 5 -o files.json

# Step 2: Drill into specific file
debtmap analyze src/problematic/module.rs --format terminal
</code></pre>
<h2 id="comparison-examples"><a class="header" href="#comparison-examples">Comparison Examples</a></h2>
<h3 id="example-1-god-object-detection"><a class="header" href="#example-1-god-object-detection">Example 1: God Object Detection</a></h3>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/services/user_service.rs --aggregate-only
</code></pre>
<p><strong>File-Level View:</strong></p>
<pre><code>src/services/user_service.rs - Score: 245.8
  - 850 lines, 45 methods
  - God Object: 78% score
  - Action: Split into UserAuth, UserProfile, UserNotifications
</code></pre>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/services/user_service.rs --top 5
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>src/services/user_service.rs:142 - authenticate_user() - Score: 8.5
src/services/user_service.rs:298 - update_profile() - Score: 7.2
src/services/user_service.rs:456 - send_notification() - Score: 6.8
</code></pre>
<p><strong>Decision</strong>: File-level score (245.8) correctly identifies architectural issue. Individual functions aren‚Äôt exceptionally complex, but the file has too many responsibilities. <strong>Solution</strong>: Split the file.</p>
<h3 id="example-2-targeted-function-fix"><a class="header" href="#example-2-targeted-function-fix">Example 2: Targeted Function Fix</a></h3>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/parsers/expression.rs --aggregate-only
</code></pre>
<p><strong>File-Level View:</strong></p>
<pre><code>src/parsers/expression.rs - Score: 45.2
  - 320 lines, 12 functions
  - No god object detected
</code></pre>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/parsers/expression.rs --top 5
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>src/parsers/expression.rs:89 - parse_complex_expression() - Score: 9.1
  - Cyclomatic: 22, Cognitive: 35
  - Coverage: 0%
  - Action: Add tests and refactor
</code></pre>
<p><strong>Decision</strong>: File as a whole is acceptable, but one function needs attention. <strong>Solution</strong>: Focus on that specific function.</p>
<h3 id="example-3-balanced-refactoring"><a class="header" href="#example-3-balanced-refactoring">Example 3: Balanced Refactoring</a></h3>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/analysis/scoring.rs --aggregate-only --coverage-file coverage.lcov
</code></pre>
<p><strong>File-Level View:</strong></p>
<pre><code>src/analysis/scoring.rs - Score: 125.6
  - 580 lines, 18 functions
  - High complexity, low coverage
</code></pre>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/analysis/scoring.rs --coverage-file coverage.lcov --top 5
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>calculate_score() - Score: 8.8 (15% coverage)
apply_weights() - Score: 8.2 (10% coverage)
normalize_results() - Score: 7.5 (0% coverage)
</code></pre>
<p><strong>Decision</strong>: Both file and functions need work. <strong>Solution</strong>: Add tests first (function-level), then consider splitting if complexity persists (file-level).</p>
<h2 id="score-normalization"><a class="header" href="#score-normalization">Score Normalization</a></h2>
<p>Both scoring approaches normalize to a 0-10 scale for consistency.</p>
<h3 id="normalization-strategies"><a class="header" href="#normalization-strategies">Normalization Strategies</a></h3>
<p><strong>Default: Linear Clamping</strong></p>
<p>The default normalization uses simple linear clamping to the 0-100 range:</p>
<ul>
<li><strong>Formula</strong>: Score is clamped between 0.0 and 100.0</li>
<li><strong>Behavior</strong>: No transformation, just boundary enforcement</li>
<li><strong>Usage</strong>: Production output uses this method</li>
</ul>
<p>This ensures scores stay within the expected range without additional transformations.</p>
<p><strong>Advanced: Multi-Phase Normalization</strong></p>
<p>For more sophisticated normalization, debtmap provides multi-phase scaling with different formulas for different score ranges:</p>
<p><strong>Phase 1 - Linear (scores &lt; 10)</strong>:</p>
<ul>
<li>Formula: <code>normalized = raw_score</code></li>
<li>Behavior: 1:1 mapping, no scaling</li>
<li>Rationale: Preserve low score distinctions</li>
</ul>
<p><strong>Phase 2 - Square Root (scores 10-100)</strong>:</p>
<ul>
<li>Formula: <code>normalized = 10.0 + sqrt(raw_score - 10.0) √ó 3.33</code></li>
<li>Behavior: Moderate dampening</li>
<li>Rationale: Balance between linear and logarithmic</li>
</ul>
<p><strong>Phase 3 - Logarithmic (scores &gt; 100)</strong>:</p>
<ul>
<li>Formula: <code>normalized = 41.59 + ln(raw_score / 100.0) √ó 10.0</code></li>
<li>Behavior: Strong dampening of extreme values</li>
<li>Rationale: Prevent outliers from dominating</li>
</ul>
<p>This multi-phase approach dampens extreme values while preserving distinctions in the normal range. Configure via <code>[normalization]</code> section in <code>.debtmap.toml</code>.</p>
<h3 id="configuration-14"><a class="header" href="#configuration-14">Configuration</a></h3>
<pre><code class="language-toml">[normalization]
linear_threshold = 10.0       # Scores below this use linear scaling (1:1 mapping)
logarithmic_threshold = 100.0 # Scores above this use logarithmic dampening
sqrt_multiplier = 3.33        # Applied to scores between linear and log thresholds
log_multiplier = 10.0         # Applied to scores above logarithmic threshold
show_raw_scores = true        # Display both normalized (0-10) and raw scores in output
</code></pre>
<p><strong>Explanation</strong>:</p>
<ul>
<li><strong>linear_threshold</strong>: Scores below this value are mapped 1:1 (no scaling)</li>
<li><strong>logarithmic_threshold</strong>: Scores above this value are dampened logarithmically to prevent extreme values</li>
<li><strong>sqrt_multiplier</strong>: Square root scaling applied to mid-range scores (between linear and logarithmic thresholds)</li>
<li><strong>log_multiplier</strong>: Logarithmic dampening factor for very high scores</li>
<li><strong>show_raw_scores</strong>: When enabled, output includes both the normalized 0-10 score and the raw calculated score</li>
</ul>
<h2 id="best-practices-17"><a class="header" href="#best-practices-17">Best Practices</a></h2>
<h3 id="workflow-integration"><a class="header" href="#workflow-integration">Workflow Integration</a></h3>
<p><strong>Week 1: File-Level Assessment</strong></p>
<pre><code class="language-bash"># Identify architectural problems
debtmap analyze . --aggregate-only --top 10
</code></pre>
<p><strong>Week 2-4: Function-Level Work</strong></p>
<pre><code class="language-bash"># Work through specific functions
debtmap analyze src/target/module.rs
</code></pre>
<p><strong>Monthly: Compare Progress</strong></p>
<pre><code class="language-bash">debtmap compare --before baseline.json --after current.json
</code></pre>
<h3 id="team-collaboration"><a class="header" href="#team-collaboration">Team Collaboration</a></h3>
<ul>
<li><strong>Architects</strong>: Use file-level scores for strategic planning</li>
<li><strong>Tech Leads</strong>: Use both for sprint planning</li>
<li><strong>Developers</strong>: Use function-level for daily work</li>
<li><strong>QA</strong>: Use function-level for test prioritization</li>
</ul>
<h3 id="cicd-integration-3"><a class="header" href="#cicd-integration-3">CI/CD Integration</a></h3>
<pre><code class="language-bash"># Gate: No new file-level regressions
debtmap analyze . --aggregate-only --format json -o file-scores.json

# Gate: No new critical function-level issues
debtmap analyze . --min-priority critical --format json -o critical-items.json
</code></pre>
<h2 id="troubleshooting-18"><a class="header" href="#troubleshooting-18">Troubleshooting</a></h2>
<p><strong>Issue</strong>: File-level scores seem too high</p>
<p><strong>Solution</strong>: Check aggregation method:</p>
<pre><code class="language-toml">[aggregation]
method = "logarithmic_sum"  # Dampen scores
</code></pre>
<p><strong>Issue</strong>: Function-level scores all similar</p>
<p><strong>Solution</strong>: Adjust role multipliers to create more differentiation:</p>
<pre><code class="language-toml">[role_multipliers]
pure_logic = 1.5     # Emphasize business logic more
io_wrapper = 0.5     # De-emphasize I/O wrappers more
</code></pre>
<p><strong>Note</strong>: Base scoring weights (complexity 50%, dependency 25%) are hard-coded and cannot be configured.</p>
<p><strong>Issue</strong>: Too many low-priority items</p>
<p><strong>Solution</strong>: Use minimum thresholds:</p>
<pre><code class="language-toml">[thresholds]
minimum_debt_score = 3.0
</code></pre>
<h2 id="rebalanced-debt-scoring-spec-136"><a class="header" href="#rebalanced-debt-scoring-spec-136">Rebalanced Debt Scoring (Spec 136)</a></h2>
<p>Debtmap now includes an advanced <strong>rebalanced scoring algorithm</strong> that prioritizes actual code quality issues‚Äîcomplexity, coverage gaps, and structural problems‚Äîover pure file size concerns.</p>
<h3 id="enabling-rebalanced-scoring"><a class="header" href="#enabling-rebalanced-scoring">Enabling Rebalanced Scoring</a></h3>
<p><strong>Configuration-Based Activation</strong>: Rebalanced scoring is enabled through your <code>.debtmap.toml</code> configuration file, not via CLI flags.</p>
<p><strong>Default Behavior</strong>: By default, debtmap uses the standard scoring algorithm described earlier in this chapter. To use rebalanced scoring, add the <code>[scoring_rebalanced]</code> section to your config:</p>
<pre><code class="language-toml"># .debtmap.toml
[scoring_rebalanced]
preset = "balanced"  # Activates rebalanced scoring with balanced preset
</code></pre>
<p><strong>Relationship to Standard Scoring</strong>:</p>
<ul>
<li>Rebalanced scoring <strong>supplements</strong> standard scoring, providing an alternative prioritization strategy</li>
<li>Both algorithms can coexist - choose which to use based on your needs</li>
<li>File-level and function-level scoring both work with rebalanced scoring</li>
<li>Output format remains the same, only score calculations differ</li>
</ul>
<p><strong>Migration Path</strong>:</p>
<ol>
<li><strong>Test first</strong>: Add <code>[scoring_rebalanced]</code> section to a test config file</li>
<li><strong>Compare</strong>: Run analysis with both standard and rebalanced scoring on same codebase</li>
<li><strong>Evaluate</strong>: Review how priorities change (large simple files rank lower, complex untested code ranks higher)</li>
<li><strong>Adopt</strong>: Once satisfied, switch your primary config to use rebalanced scoring</li>
<li><strong>Tune</strong>: Adjust preset or custom weights based on your team‚Äôs priorities</li>
</ol>
<p><strong>Quick Start</strong>:</p>
<pre><code class="language-bash"># Create test config with rebalanced scoring
cat &gt; .debtmap-rebalanced.toml &lt;&lt;EOF
[scoring_rebalanced]
preset = "balanced"
EOF

# Compare results
debtmap analyze . --format terminal                            # Standard scoring
debtmap analyze . --config .debtmap-rebalanced.toml --format terminal  # Rebalanced scoring
</code></pre>
<h3 id="philosophy"><a class="header" href="#philosophy">Philosophy</a></h3>
<p>Traditional scoring often over-emphasizes file size, causing large but simple files to rank higher than complex, untested code. The rebalanced algorithm fixes this by:</p>
<ol>
<li><strong>De-emphasizing size</strong>: Reduces size weight from ~1.5 to 0.3 (80% reduction)</li>
<li><strong>Emphasizing quality</strong>: Increases weights for complexity (1.0) and coverage gaps (1.0)</li>
<li><strong>Additive bonuses</strong>: Provides +20 bonus for complex + untested code (not multiplicative)</li>
<li><strong>Context-aware thresholds</strong>: Integrates with file type classification from Spec 135</li>
</ol>
<h3 id="multi-dimensional-scoring"><a class="header" href="#multi-dimensional-scoring">Multi-Dimensional Scoring</a></h3>
<p>The rebalanced algorithm computes five scoring components:</p>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Weight</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>Complexity</strong></td><td>1.0</td><td>0-100</td><td>Cyclomatic + cognitive complexity</td></tr>
<tr><td><strong>Coverage Gap</strong></td><td>1.0</td><td>0-80</td><td>Testing coverage deficit with complexity bonus</td></tr>
<tr><td><strong>Structural</strong></td><td>0.8</td><td>0-60</td><td>God objects and architectural issues</td></tr>
<tr><td><strong>Size</strong></td><td>0.3</td><td>0-30</td><td>File size (reduced from previous ~1.5)</td></tr>
<tr><td><strong>Code Smells</strong></td><td>0.6</td><td>0-40</td><td>Long functions, deep nesting, impure logic</td></tr>
</tbody></table>
</div>
<p><strong>Weighted Total Formula</strong>:</p>
<pre><code>weighted_total = (complexity √ó 1.0) + (coverage √ó 1.0) + (structural √ó 0.8)
                 + (size √ó 0.3) + (smells √ó 0.6)

normalized_score = (weighted_total / 237.0) √ó 200.0  // Normalize to 0-200 range
</code></pre>
<h3 id="scoring-presets"><a class="header" href="#scoring-presets">Scoring Presets</a></h3>
<p>Debtmap provides four presets for different prioritization strategies:</p>
<h4 id="balanced-default"><a class="header" href="#balanced-default">Balanced (Default)</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "balanced"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 1.0, Coverage: 1.0, Structural: 0.8, Size: 0.3, Smells: 0.6</li>
</ul>
<p><strong>Use when</strong>: Standard development with focus on actual code quality</p>
<h4 id="quality-focused"><a class="header" href="#quality-focused">Quality-Focused</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "quality-focused"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 1.2, Coverage: 1.1, Structural: 0.9, Size: 0.2, Smells: 0.7</li>
</ul>
<p><strong>Use when</strong>: Maximum emphasis on code quality, minimal concern for file size</p>
<h4 id="test-coverage-focused"><a class="header" href="#test-coverage-focused">Test-Coverage-Focused</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "test-coverage"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 0.8, Coverage: 1.3, Structural: 0.6, Size: 0.2, Smells: 0.5</li>
</ul>
<p><strong>Use when</strong>: Prioritizing test coverage improvements</p>
<h4 id="size-focused-legacy"><a class="header" href="#size-focused-legacy">Size-Focused (Legacy)</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "size-focused"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 0.5, Coverage: 0.4, Structural: 0.6, Size: 1.5, Smells: 0.3</li>
</ul>
<p><strong>Use when</strong>: Maintaining legacy scoring behavior, file size is primary concern</p>
<h3 id="custom-weights"><a class="header" href="#custom-weights">Custom Weights</a></h3>
<p>You can define custom weights in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[scoring_rebalanced]
complexity_weight = 1.2
coverage_weight = 1.0
structural_weight = 0.8
size_weight = 0.2
smell_weight = 0.7
</code></pre>
<h3 id="severity-levels"><a class="header" href="#severity-levels">Severity Levels</a></h3>
<p>The rebalanced algorithm assigns severity based on normalized score and risk factors:</p>
<div class="table-wrapper"><table><thead><tr><th>Severity</th><th>Criteria</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>CRITICAL</strong></td><td>Score &gt; 120 OR (complexity &gt; 60 AND coverage &gt; 40)</td><td>Requires immediate attention</td></tr>
<tr><td><strong>HIGH</strong></td><td>Score &gt; 80 OR (complexity &gt; 40 AND coverage &gt; 20) OR structural &gt; 50</td><td>High priority for next sprint</td></tr>
<tr><td><strong>MEDIUM</strong></td><td>Score &gt; 40 OR single moderate issue</td><td>Plan for future sprint</td></tr>
<tr><td><strong>LOW</strong></td><td>Everything else</td><td>Minor concerns, size-only issues</td></tr>
</tbody></table>
</div>
<p><strong>Evaluation Logic</strong>: Severity is assigned based on the <strong>first matching criteria</strong> (logical OR). An item needs to satisfy <strong>only ONE condition</strong> to qualify for that severity level. For example, a function with score=90 is HIGH severity even if complexity and coverage are both low, because it meets the ‚ÄúScore &gt; 80‚Äù condition.</p>
<h3 id="example-prioritization"><a class="header" href="#example-prioritization">Example Prioritization</a></h3>
<p><strong>Complex Untested Function</strong> (HIGH priority):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn process_payment(cart: &amp;Cart, user: &amp;User) -&gt; Result&lt;Receipt&gt; {
    // 150 lines, cyclomatic: 42, cognitive: 77
    // Coverage: 38%

    // Rebalanced Score:
    // - Complexity: 100.0 (very high)
    // - Coverage: 57.2 (gap √ó 0.6 + 20 bonus for complex+untested)
    // - Structural: 0.0
    // - Size: 0.0 (function-level scoring)
    // - Smells: 25.0 (long function)
    // Total: 95.3 ‚Üí CRITICAL severity
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Large Simple Function</strong> (LOW priority):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_report(data: &amp;ReportData) -&gt; String {
    // 2000 lines, cyclomatic: 3, cognitive: 5
    // Coverage: 100%

    // Rebalanced Score:
    // - Complexity: 0.0 (trivial)
    // - Coverage: 0.0 (well tested)
    // - Structural: 0.0
    // - Size: 0.0 (function-level scoring)
    // - Smells: 15.0 (long but simple)
    // Total: 3.2 ‚Üí LOW severity
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Result</strong>: Complex untested code ranks 30√ó higher than large simple code.</p>
<h3 id="integration-with-file-classification-spec-135"><a class="header" href="#integration-with-file-classification-spec-135">Integration with File Classification (Spec 135)</a></h3>
<p>The rebalanced scoring integrates with context-aware file size thresholds:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::organization::file_classifier::{classify_file, get_threshold};

let file_type = classify_file(source, path);
let threshold = get_threshold(&amp;file_type, function_count, lines);

// Apply context-aware scoring:
// - Generated code: 0.1√ó size multiplier
// - Test code: Lenient thresholds (650 lines)
// - Business logic: Strict thresholds (400 lines)
<span class="boring">}</span></code></pre></pre>
<h3 id="generated-code-detection"><a class="header" href="#generated-code-detection">Generated Code Detection</a></h3>
<p>The rebalanced scoring automatically detects and reduces scores for generated code:</p>
<p><strong>Detection Markers</strong> (first 20 lines):</p>
<ul>
<li>‚ÄúDO NOT EDIT‚Äù</li>
<li>‚Äúautomatically generated‚Äù</li>
<li>‚ÄúAUTO-GENERATED‚Äù</li>
<li>‚Äú@generated‚Äù</li>
<li>‚ÄúCode generated by‚Äù</li>
</ul>
<p><strong>Generated Code Score Adjustment</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if is_generated_code(source) {
    size_score *= 0.1;  // 90% reduction
}
<span class="boring">}</span></code></pre></pre>
<h3 id="scoring-rationale"><a class="header" href="#scoring-rationale">Scoring Rationale</a></h3>
<p>Each debt item includes a detailed rationale explaining the score:</p>
<pre><code>Debt Item: src/payment/processor.rs:142 - process_payment()
Score: 95.3 (CRITICAL)

Primary factors:
  - High cyclomatic complexity (+100.0)
  - Significant coverage gap (+57.2)

Bonuses:
  - Complex + untested: +20 bonus applied
  - Code smells detected (+25.0)

Context adjustments:
  - Size de-emphasized (weight: 0.3)
</code></pre>
<h3 id="migration-from-legacy-scoring"><a class="header" href="#migration-from-legacy-scoring">Migration from Legacy Scoring</a></h3>
<p><strong>Breaking Changes</strong>:</p>
<ul>
<li>Scores will change significantly for all debt items</li>
<li>Large files with low complexity will rank lower</li>
<li>Complex untested code will rank higher</li>
<li>Size-based prioritization reduced by 80%</li>
</ul>
<p><strong>Restoring Legacy Behavior</strong>:</p>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "size-focused"
</code></pre>
<p><strong>Gradual Migration</strong>:</p>
<ol>
<li>Run analysis with both algorithms: <code>debtmap analyze . --legacy-scoring</code></li>
<li>Compare results to understand impact</li>
<li>Adjust team priorities based on new rankings</li>
<li>Switch to rebalanced scoring after validation</li>
</ol>
<p>See <a href="./migration-guide.html">Migration Guide</a> for detailed migration instructions.</p>
<h3 id="configuration-reference-1"><a class="header" href="#configuration-reference-1">Configuration Reference</a></h3>
<p>Complete configuration example:</p>
<pre><code class="language-toml"># .debtmap.toml

[scoring_rebalanced]
# Use a preset (balanced, quality-focused, test-coverage, size-focused)
preset = "balanced"

# Or define custom weights
complexity_weight = 1.0
coverage_weight = 1.0
structural_weight = 0.8
size_weight = 0.3
smell_weight = 0.6
</code></pre>
<h3 id="when-to-use-rebalanced-scoring"><a class="header" href="#when-to-use-rebalanced-scoring">When to Use Rebalanced Scoring</a></h3>
<p>‚úÖ <strong>Use rebalanced scoring when</strong>:</p>
<ul>
<li>You want to prioritize code quality over file size</li>
<li>Complex untested code is a concern</li>
<li>You‚Äôre building new features and need quality focus</li>
<li>Your team values testability and maintainability</li>
</ul>
<p>‚ùå <strong>Use legacy/size-focused when</strong>:</p>
<ul>
<li>You‚Äôre managing a legacy codebase with large files</li>
<li>File size reduction is the primary concern</li>
<li>You need compatibility with existing workflows</li>
<li>Your team‚Äôs priority is file splitting over quality</li>
</ul>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<p>The rebalanced scoring algorithm has minimal performance impact:</p>
<ul>
<li>Same O(n) complexity as legacy scoring</li>
<li>No additional file I/O required</li>
<li>Parallel processing compatible</li>
<li>Adds ~5% to analysis time for rationale generation</li>
</ul>
<h3 id="see-also-6"><a class="header" href="#see-also-6">See Also</a></h3>
<ul>
<li><a href="./tiered-prioritization.html">Tiered Prioritization</a> - Understanding tier-based classification</li>
<li><a href="./configuration.html">Configuration</a> - Scoring and aggregation configuration</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Detailed metric explanations</li>
<li><a href="./file-classification.html">File Classification</a> - Context-aware file size thresholds (Spec 135)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tiered-prioritization-3"><a class="header" href="#tiered-prioritization-3">Tiered Prioritization</a></h1>
<p>Debtmap uses a sophisticated tiered prioritization system to surface critical architectural issues above simple testing gaps. This chapter explains the tier strategy, how to interpret tier classifications, and how to customize tier thresholds for your project.</p>
<h2 id="overview-16"><a class="header" href="#overview-16">Overview</a></h2>
<p>The tiered prioritization system organizes technical debt into four distinct tiers based on impact, urgency, and architectural significance. This prevents ‚Äúwalls of similar-scored items‚Äù and ensures critical issues don‚Äôt get lost among minor problems.</p>
<p><strong>Two Tier Systems</strong>: Debtmap uses two complementary tier systems:</p>
<ol>
<li><strong>RecommendationTier</strong> (T1-T4): Used internally to classify items based on architectural significance and testing needs</li>
<li><strong>Display Tier</strong> (Critical/High/Moderate/Low): Score-based tiers shown in terminal output, derived from final calculated scores</li>
</ol>
<p>The configuration examples below control the RecommendationTier classification logic, which influences scoring through tier weights. The final display uses score-based tiers for consistency across all output formats.</p>
<h2 id="the-four-tiers"><a class="header" href="#the-four-tiers">The Four Tiers</a></h2>
<h3 id="tier-1-critical-architecture"><a class="header" href="#tier-1-critical-architecture">Tier 1: Critical Architecture</a></h3>
<p><strong>Description</strong>: God Objects, God Modules, excessive complexity requiring immediate architectural attention</p>
<p><strong>Priority</strong>: Must address before adding new features</p>
<p><strong>Weight</strong>: 1.5x (highest priority multiplier)</p>
<p><strong>Impact</strong>: High impact on maintainability and team velocity</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Files with 15+ responsibilities</li>
<li>Modules with 50+ methods</li>
<li>ComplexityHotspot debt items with cyclomatic complexity &gt; 50 (extreme complexity requiring architectural redesign)</li>
<li>God objects flagged by detection algorithms</li>
<li>Circular dependencies affecting core modules</li>
</ul>
<p><strong>When to Address</strong>: Immediately, before sprint work begins. These issues compound over time and block progress.</p>
<pre><code class="language-bash"># Focus on Tier 1 items
debtmap analyze . --min-priority high --top 5
</code></pre>
<h3 id="tier-2-complex-untested"><a class="header" href="#tier-2-complex-untested">Tier 2: Complex Untested</a></h3>
<p><strong>Description</strong>: Untested code with high complexity or critical dependencies. Items qualify for Tier 2 if they meet ANY of: cyclomatic complexity ‚â• 15, total dependencies ‚â• 10, or are entry point functions with any coverage gap.</p>
<p><strong>Priority</strong>: Risk of bugs in critical paths</p>
<p><strong>Weight</strong>: 1.0x (standard multiplier)</p>
<p><strong>Action</strong>: Should be tested before refactoring to prevent regressions</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Functions with cyclomatic complexity ‚â• 15 and 0% coverage</li>
<li>Functions with 10+ dependencies and low test coverage</li>
<li>Business logic entry points without tests</li>
<li>Complex error handling without validation</li>
</ul>
<p><strong>When to Address</strong>: Within current sprint. Add tests before making changes.</p>
<pre><code class="language-bash"># See Tier 2 testing gaps
debtmap analyze . --lcov coverage.lcov --min-priority high
</code></pre>
<h3 id="tier-3-testing-gaps"><a class="header" href="#tier-3-testing-gaps">Tier 3: Testing Gaps</a></h3>
<p><strong>Description</strong>: Untested code with moderate complexity</p>
<p><strong>Priority</strong>: Improve coverage to prevent future issues</p>
<p><strong>Weight</strong>: 0.7x (reduced multiplier)</p>
<p><strong>Action</strong>: Add tests opportunistically or during related changes</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Functions with cyclomatic complexity 10-15 and low coverage</li>
<li>Utility functions without edge case tests</li>
<li>Moderate complexity with partial coverage</li>
</ul>
<p><strong>When to Address</strong>: Next sprint or when touching related code.</p>
<h3 id="tier-4-maintenance"><a class="header" href="#tier-4-maintenance">Tier 4: Maintenance</a></h3>
<p><strong>Description</strong>: Low-complexity issues and code quality improvements</p>
<p><strong>Priority</strong>: Address opportunistically during other work</p>
<p><strong>Weight</strong>: 0.3x (lowest multiplier)</p>
<p><strong>Action</strong>: Fix when convenient, low urgency</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Simple functions with minor code quality issues</li>
<li>TODO markers in well-tested code</li>
<li>Minor duplication in test code</li>
</ul>
<p><strong>When to Address</strong>: During cleanup sprints or when refactoring nearby code.</p>
<h2 id="configuration-15"><a class="header" href="#configuration-15">Configuration</a></h2>
<p>Tier configuration is optional in <code>.debtmap.toml</code>. If not specified, Debtmap uses the balanced defaults shown below.</p>
<h3 id="default-tier-thresholds"><a class="header" href="#default-tier-thresholds">Default Tier Thresholds</a></h3>
<pre><code class="language-toml">[tiers]
# Tier 2 thresholds (Complex Untested)
t2_complexity_threshold = 15         # Cyclomatic complexity cutoff
t2_dependency_threshold = 10         # Dependency count cutoff

# Tier 3 thresholds (Testing Gaps)
t3_complexity_threshold = 10         # Lower complexity threshold

# Display options
show_t4_in_main_report = false      # Hide Tier 4 from main output (not yet implemented)

# Tier weights (multipliers applied to base scores)
t1_weight = 1.5    # Critical architecture
t2_weight = 1.0    # Complex untested
t3_weight = 0.7    # Testing gaps
t4_weight = 0.3    # Maintenance
</code></pre>
<p>To use tier-based prioritization with custom settings, add the <code>[tiers]</code> section to your <code>.debtmap.toml</code> configuration file:</p>
<pre><code class="language-bash"># Analyze with custom tier configuration
debtmap analyze . --config .debtmap.toml
</code></pre>
<h3 id="tier-preset-configurations"><a class="header" href="#tier-preset-configurations">Tier Preset Configurations</a></h3>
<p>Debtmap provides three built-in tier presets for different project needs:</p>
<p><strong>Balanced (Default)</strong></p>
<pre><code class="language-toml">[tiers]
t2_complexity_threshold = 15
t2_dependency_threshold = 10
t3_complexity_threshold = 10
</code></pre>
<p>Suitable for most projects. Balances detection sensitivity with manageable issue counts.</p>
<p><strong>Strict</strong></p>
<pre><code class="language-toml">[tiers]
t2_complexity_threshold = 10
t2_dependency_threshold = 7
t3_complexity_threshold = 7
</code></pre>
<p>For high-quality codebases or teams with strict quality standards. Flags more items as requiring attention.</p>
<p><strong>Lenient</strong></p>
<pre><code class="language-toml">[tiers]
t2_complexity_threshold = 20
t2_dependency_threshold = 15
t3_complexity_threshold = 15
</code></pre>
<p>For legacy codebases or gradual technical debt reduction. Focuses on the most critical issues first.</p>
<h3 id="customizing-tier-thresholds"><a class="header" href="#customizing-tier-thresholds">Customizing Tier Thresholds</a></h3>
<p>You can also create custom threshold configurations tailored to your project:</p>
<pre><code class="language-toml"># Custom thresholds for specific project needs
[tiers]
t2_complexity_threshold = 12
t2_dependency_threshold = 8
t3_complexity_threshold = 8
</code></pre>
<h3 id="tier-weight-customization"><a class="header" href="#tier-weight-customization">Tier Weight Customization</a></h3>
<p>Tier weights are multipliers applied to base debt scores during prioritization. A weight of 1.5 means items in that tier will score 50% higher than equivalent items in a tier with weight 1.0, pushing them higher in priority rankings.</p>
<p>Adjust weights based on your priorities:</p>
<pre><code class="language-toml"># Emphasize testing over architecture
[tiers]
t1_weight = 1.2    # Reduce architecture weight
t2_weight = 1.3    # Increase testing weight
t3_weight = 0.8
t4_weight = 0.3

# Focus on architecture first
[tiers]
t1_weight = 2.0    # Maximize architecture weight
t2_weight = 1.0
t3_weight = 0.5
t4_weight = 0.2
</code></pre>
<h2 id="use-cases-8"><a class="header" href="#use-cases-8">Use Cases</a></h2>
<h3 id="sprint-planning"><a class="header" href="#sprint-planning">Sprint Planning</a></h3>
<p>Use tiered prioritization to allocate work:</p>
<pre><code class="language-bash"># See Tier 1 items for architectural planning
debtmap analyze . --min-priority high --top 5

# See Tier 2/3 for testing sprint work
debtmap analyze . --lcov coverage.lcov --min-priority medium
</code></pre>
<h3 id="code-review-focus"><a class="header" href="#code-review-focus">Code Review Focus</a></h3>
<p>Prioritize review attention based on tiers:</p>
<ul>
<li><strong>Tier 1</strong>: Architectural review required, senior dev attention</li>
<li><strong>Tier 2</strong>: Test coverage validation critical</li>
<li><strong>Tier 3</strong>: Standard review process</li>
<li><strong>Tier 4</strong>: Quick review or automated checks</li>
</ul>
<h3 id="refactoring-strategy"><a class="header" href="#refactoring-strategy">Refactoring Strategy</a></h3>
<pre><code class="language-bash"># Phase 1: Address Tier 1 architectural issues
debtmap analyze . --min-priority high

# Phase 2: Add tests for Tier 2 complex code
debtmap analyze . --lcov coverage.lcov --min-priority high

# Phase 3: Improve Tier 3 coverage
debtmap analyze . --lcov coverage.lcov --min-priority medium
</code></pre>
<h2 id="best-practices-18"><a class="header" href="#best-practices-18">Best Practices</a></h2>
<ol>
<li><strong>Always address Tier 1 before feature work</strong> - Architectural issues compound</li>
<li><strong>Test Tier 2 items before refactoring</strong> - Avoid regressions</li>
<li><strong>Batch Tier 3 items</strong> - Address multiple in one sprint</li>
<li><strong>Defer Tier 4 items</strong> - Only fix during cleanup or when convenient</li>
<li><strong>Track tier distribution over time</strong> - Aim to reduce Tier 1/2 counts</li>
</ol>
<h2 id="interpreting-tier-output"><a class="header" href="#interpreting-tier-output">Interpreting Tier Output</a></h2>
<h3 id="terminal-output-1"><a class="header" href="#terminal-output-1">Terminal Output</a></h3>
<p>Terminal output displays items grouped by <strong>score-based tiers</strong>:</p>
<pre><code>TECHNICAL DEBT ANALYSIS - PRIORITY TIERS

Critical (score &gt;= 90)
  src/services.rs - God Object (score: 127.5)
  src/core/engine.rs - Circular dependency (score: 95.2)

High (score 70-89.9)
  src/processing/transform.rs:145 - UntestableComplexity (score: 85.0)
  src/api/handlers.rs - God Module (score: 78.3)
  ...

Moderate (score 50-69.9)
  src/utils/parser.rs:220 - TestingGap (score: 62.1)
  ...

Low (score &lt; 50)
  [Items with score &lt; 50 appear here]
</code></pre>
<p><strong>Note</strong>: The scores shown reflect tier weight multipliers applied during classification. Items classified as Tier 1 (Critical Architecture) receive a 1.5x weight boost, which often elevates them into the Critical or High score ranges.</p>
<h3 id="json-output-2"><a class="header" href="#json-output-2">JSON Output</a></h3>
<p>JSON output uses the same <strong>score-based priority</strong> levels as terminal output:</p>
<pre><code class="language-json">{
  "summary": {
    "score_distribution": {
      "critical": 2,
      "high": 5,
      "medium": 12,
      "low": 45
    }
  },
  "items": [
    {
      "type": "File",
      "score": 127.5,
      "priority": "critical",
      "location": {
        "file": "src/services.rs"
      },
      "debt_type": "GodObject"
    },
    {
      "type": "Function",
      "score": 85.0,
      "priority": "high",
      "location": {
        "file": "src/processing/transform.rs",
        "line": 145,
        "function": "process_data"
      },
      "debt_type": "UntestableComplexity"
    }
  ]
}
</code></pre>
<p>The <code>priority</code> field is derived from the <code>score</code> field using these thresholds:</p>
<ul>
<li><code>critical</code>: score &gt;= 100.0</li>
<li><code>high</code>: score &gt;= 50.0</li>
<li><code>medium</code>: score &gt;= 20.0</li>
<li><code>low</code>: score &lt; 20.0</li>
</ul>
<p><strong>Note</strong>: While RecommendationTier (T1-T4) classifications exist internally for applying tier weights, they are not included in JSON output. The output shows final calculated scores and their corresponding priority levels.</p>
<h2 id="troubleshooting-19"><a class="header" href="#troubleshooting-19">Troubleshooting</a></h2>
<p><strong>Issue</strong>: Too many Tier 1 items</p>
<p><strong>Solution</strong>: Lower tier weights or increase thresholds temporarily:</p>
<pre><code class="language-toml">[tiers]
t1_weight = 1.2    # Reduce from 1.5
</code></pre>
<p><strong>Issue</strong>: Not enough items in Tier 1</p>
<p><strong>Solution</strong>: Check if god object detection is enabled:</p>
<pre><code class="language-toml">[god_object_detection]
enabled = true
</code></pre>
<p><strong>Issue</strong>: All items in Tier 4</p>
<p><strong>Solution</strong>: Lower minimum thresholds:</p>
<pre><code class="language-toml">[thresholds]
minimum_debt_score = 1.0
minimum_cyclomatic_complexity = 2
</code></pre>
<h2 id="see-also-7"><a class="header" href="#see-also-7">See Also</a></h2>
<ul>
<li><a href="./scoring-strategies.html">Scoring Strategies</a> - Understanding file-level vs function-level scoring</li>
<li><a href="./configuration.html">Configuration</a> - Complete configuration reference</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Detailed metric explanations</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="validation-and-quality-gates"><a class="header" href="#validation-and-quality-gates">Validation and Quality Gates</a></h1>
<p>The <code>validate</code> command enforces quality gates in your development workflow, making it ideal for CI/CD integration. Unlike the <code>analyze</code> command which focuses on exploration and reporting, <code>validate</code> checks your codebase against configured thresholds and returns appropriate exit codes for automated workflows.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="validation-gates.html#validate-vs-analyze">Validate vs Analyze</a></li>
<li><a href="validation-gates.html#quick-start">Quick Start</a></li>
<li><a href="validation-gates.html#understanding-density-based-validation">Understanding Density-Based Validation</a></li>
<li><a href="validation-gates.html#configuration-setup">Configuration Setup</a></li>
<li><a href="validation-gates.html#validation-metrics">Validation Metrics</a></li>
<li><a href="validation-gates.html#exit-codes-and-ci-integration">Exit Codes and CI Integration</a></li>
<li><a href="validation-gates.html#coverage-integration">Coverage Integration</a></li>
<li><a href="validation-gates.html#context-aware-validation">Context-Aware Validation</a></li>
<li><a href="validation-gates.html#cicd-examples">CI/CD Examples</a></li>
<li><a href="validation-gates.html#migrating-from-deprecated-thresholds">Migrating from Deprecated Thresholds</a></li>
<li><a href="validation-gates.html#troubleshooting">Troubleshooting</a></li>
<li><a href="validation-gates.html#best-practices">Best Practices</a></li>
</ul>
<h2 id="validate-vs-analyze"><a class="header" href="#validate-vs-analyze">Validate vs Analyze</a></h2>
<p>Understanding when to use each command is crucial:</p>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th><code>validate</code></th><th><code>analyze</code></th></tr></thead><tbody>
<tr><td><strong>Purpose</strong></td><td>Enforce quality gates</td><td>Explore and understand debt</td></tr>
<tr><td><strong>Exit Codes</strong></td><td>Returns non-zero on failure</td><td>Always returns 0 (unless error)</td></tr>
<tr><td><strong>Thresholds</strong></td><td>From <code>.debtmap.toml</code> config</td><td>Command-line flags</td></tr>
<tr><td><strong>Use Case</strong></td><td>CI/CD pipelines, pre-commit hooks</td><td>Interactive analysis, reports</td></tr>
<tr><td><strong>Output Focus</strong></td><td>Pass/fail with violation details</td><td>Comprehensive metrics and insights</td></tr>
<tr><td><strong>Configuration</strong></td><td>Requires <code>.debtmap.toml</code></td><td>Works without config file</td></tr>
</tbody></table>
</div>
<p><strong>Rule of thumb:</strong> Use <code>validate</code> for automation and <code>analyze</code> for investigation.</p>
<h2 id="quick-start-3"><a class="header" href="#quick-start-3">Quick Start</a></h2>
<ol>
<li>
<p><strong>Initialize configuration:</strong></p>
<pre><code class="language-bash">debtmap init
</code></pre>
</li>
<li>
<p><strong>Edit <code>.debtmap.toml</code> to set thresholds:</strong></p>
<pre><code class="language-toml">[thresholds.validation]
max_debt_density = 50.0              # Debt items per 1000 LOC
max_average_complexity = 10.0        # Average cyclomatic complexity
max_codebase_risk_score = 7.0        # Overall risk level (1-10)
</code></pre>
</li>
<li>
<p><strong>Run validation:</strong></p>
<pre><code class="language-bash">debtmap validate .
</code></pre>
</li>
<li>
<p><strong>Check exit code:</strong></p>
<pre><code class="language-bash">echo $?  # 0 = pass, non-zero = fail
</code></pre>
</li>
</ol>
<h2 id="understanding-density-based-validation"><a class="header" href="#understanding-density-based-validation">Understanding Density-Based Validation</a></h2>
<p>Debtmap uses <strong>density-based metrics</strong> as the primary quality measure. This approach provides several advantages over traditional absolute count metrics.</p>
<h3 id="why-density-matters"><a class="header" href="#why-density-matters">Why Density Matters</a></h3>
<p>Traditional metrics like ‚Äúmaximum 50 high-complexity functions‚Äù fail as your codebase grows:</p>
<pre><code>Scenario: Your team adds 10,000 LOC of high-quality code
- Old metric: "max 50 complex functions" ‚Üí FAILS (now 55 total)
- Density metric: "max 50 per 1000 LOC" ‚Üí PASSES (density improved)
</code></pre>
<p><strong>Scale-dependent metrics</strong> (absolute counts):</p>
<ul>
<li>Grow linearly with codebase size</li>
<li>Require constant threshold adjustments</li>
<li>Punish healthy growth</li>
<li>Don‚Äôt reflect actual code quality</li>
</ul>
<p><strong>Density metrics</strong> (per 1000 LOC):</p>
<ul>
<li>Remain stable as codebase grows</li>
<li>Measure true quality ratios</li>
<li>No adjustment needed for growth</li>
<li>Directly comparable across projects</li>
</ul>
<h3 id="calculating-debt-density"><a class="header" href="#calculating-debt-density">Calculating Debt Density</a></h3>
<pre><code>Debt Density = (Total Debt Items / Total LOC) √ó 1000
</code></pre>
<p><strong>Example:</strong></p>
<ul>
<li>25 debt items in 5,000 LOC project</li>
<li>Density = (25 / 5000) √ó 1000 = <strong>5.0 debt items per 1000 LOC</strong></li>
</ul>
<p>This density remains meaningful whether your codebase is 5,000 or 500,000 LOC.</p>
<h3 id="recommended-density-thresholds"><a class="header" href="#recommended-density-thresholds">Recommended Density Thresholds</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Project Type</th><th>max_debt_density</th><th>Rationale</th></tr></thead><tbody>
<tr><td><strong>New/Greenfield</strong></td><td>20.0</td><td>High quality bar for new code</td></tr>
<tr><td><strong>Active Development</strong></td><td>50.0</td><td>Balanced quality/velocity (default)</td></tr>
<tr><td><strong>Legacy Modernization</strong></td><td>100.0</td><td>Prevent regression during refactoring</td></tr>
<tr><td><strong>Mature/Critical</strong></td><td>30.0</td><td>Maintain quality in stable systems</td></tr>
</tbody></table>
</div>
<h2 id="configuration-setup"><a class="header" href="#configuration-setup">Configuration Setup</a></h2>
<h3 id="creating-configuration-file"><a class="header" href="#creating-configuration-file">Creating Configuration File</a></h3>
<p>The <code>debtmap init</code> command generates a <code>.debtmap.toml</code> with sensible defaults:</p>
<pre><code class="language-bash">debtmap init
</code></pre>
<p>This creates:</p>
<pre><code class="language-toml">[thresholds.validation]
# Primary quality metrics (scale-independent)
max_average_complexity = 10.0
max_debt_density = 50.0
max_codebase_risk_score = 7.0

# Optional metrics
min_coverage_percentage = 0.0  # Disabled by default

# Safety net (high ceiling for extreme cases)
max_total_debt_score = 10000
</code></pre>
<h3 id="editing-thresholds"><a class="header" href="#editing-thresholds">Editing Thresholds</a></h3>
<p>Edit the <code>[thresholds.validation]</code> section to match your quality requirements:</p>
<pre><code class="language-toml">[thresholds.validation]
# Enforce stricter quality for new project
max_debt_density = 30.0              # Tighter density requirement
max_average_complexity = 8.0         # Lower complexity tolerance
max_codebase_risk_score = 6.0        # Reduced risk threshold
min_coverage_percentage = 80.0       # Require 80% test coverage
</code></pre>
<h3 id="override-via-command-line"><a class="header" href="#override-via-command-line">Override via Command Line</a></h3>
<p>You can override the density threshold from the command line:</p>
<pre><code class="language-bash"># Temporarily use stricter threshold
debtmap validate . --max-debt-density 40.0
</code></pre>
<h2 id="validation-metrics"><a class="header" href="#validation-metrics">Validation Metrics</a></h2>
<p>Debtmap organizes validation metrics into three categories:</p>
<h3 id="primary-metrics-scale-independent"><a class="header" href="#primary-metrics-scale-independent">Primary Metrics (Scale-Independent)</a></h3>
<p>These are the core quality measures that every project should monitor:</p>
<ol>
<li>
<p><strong><code>max_average_complexity</code></strong> (default: 10.0)</p>
<ul>
<li>Average cyclomatic complexity per function</li>
<li>Measures typical function complexity across codebase</li>
<li>Lower values indicate simpler, more maintainable code</li>
</ul>
<pre><code class="language-toml">max_average_complexity = 10.0
</code></pre>
</li>
<li>
<p><strong><code>max_debt_density</code></strong> (default: 50.0) - <strong>PRIMARY METRIC</strong></p>
<ul>
<li>Debt items per 1000 lines of code</li>
<li>Scale-independent quality measure</li>
<li>Remains stable as codebase grows</li>
</ul>
<pre><code class="language-toml">max_debt_density = 50.0
</code></pre>
</li>
<li>
<p><strong><code>max_codebase_risk_score</code></strong> (default: 7.0)</p>
<ul>
<li>Overall risk level combining complexity, coverage, and criticality</li>
<li>Score ranges from 1 (low risk) to 10 (high risk)</li>
<li>Considers context-aware analysis when enabled</li>
</ul>
<pre><code class="language-toml">max_codebase_risk_score = 7.0
</code></pre>
</li>
</ol>
<h3 id="optional-metrics-1"><a class="header" href="#optional-metrics-1">Optional Metrics</a></h3>
<p>Configure these when you want additional quality enforcement:</p>
<ol start="4">
<li>
<p><strong><code>min_coverage_percentage</code></strong> (default: 0.0 - disabled)</p>
<ul>
<li>Minimum required test coverage percentage</li>
<li>Only enforced when coverage data is provided via <code>--coverage-file</code></li>
<li>Set to 0.0 to disable coverage requirements</li>
</ul>
<pre><code class="language-toml">min_coverage_percentage = 75.0  # Require 75% coverage
</code></pre>
</li>
</ol>
<h3 id="safety-net-metrics"><a class="header" href="#safety-net-metrics">Safety Net Metrics</a></h3>
<p>High ceilings to catch extreme cases:</p>
<ol start="5">
<li>
<p><strong><code>max_total_debt_score</code></strong> (default: 10000)</p>
<ul>
<li>Absolute ceiling on total technical debt</li>
<li>Prevents runaway growth even if density stays low</li>
<li>Rarely triggers in normal operation</li>
</ul>
<pre><code class="language-toml">max_total_debt_score = 10000
</code></pre>
</li>
</ol>
<h3 id="metric-priority"><a class="header" href="#metric-priority">Metric Priority</a></h3>
<p>When validation fails, fix issues in this order:</p>
<ol>
<li><strong>Critical:</strong> <code>max_debt_density</code> violations (core quality metric)</li>
<li><strong>High:</strong> <code>max_average_complexity</code> violations (function-level quality)</li>
<li><strong>High:</strong> <code>max_codebase_risk_score</code> violations (overall risk)</li>
<li><strong>Medium:</strong> <code>min_coverage_percentage</code> violations (test coverage)</li>
<li><strong>Low:</strong> <code>max_total_debt_score</code> violations (extreme cases only)</li>
</ol>
<h2 id="exit-codes-and-ci-integration"><a class="header" href="#exit-codes-and-ci-integration">Exit Codes and CI Integration</a></h2>
<p>The <code>validate</code> command uses exit codes to signal success or failure:</p>
<h3 id="exit-code-behavior"><a class="header" href="#exit-code-behavior">Exit Code Behavior</a></h3>
<pre><code class="language-bash">debtmap validate .
echo $?
</code></pre>
<p><strong>Exit codes:</strong></p>
<ul>
<li><strong><code>0</code></strong> - Success: All thresholds passed</li>
<li><strong>Non-zero</strong> - Failure: One or more thresholds exceeded or errors occurred</li>
</ul>
<h3 id="using-exit-codes-in-ci"><a class="header" href="#using-exit-codes-in-ci">Using Exit Codes in CI</a></h3>
<p>Exit codes integrate naturally with CI/CD systems:</p>
<p><strong>GitHub Actions:</strong></p>
<pre><code class="language-yaml">- name: Validate code quality
  run: debtmap validate .
  # Step fails automatically if exit code is non-zero
</code></pre>
<p><strong>GitLab CI:</strong></p>
<pre><code class="language-yaml">script:
  - debtmap validate .
  # Pipeline fails if exit code is non-zero
</code></pre>
<p><strong>Shell scripts:</strong></p>
<pre><code class="language-bash">#!/bin/bash
if debtmap validate .; then
    echo "‚úÖ Validation passed"
else
    echo "‚ùå Validation failed"
    exit 1
fi
</code></pre>
<h3 id="understanding-validation-output"><a class="header" href="#understanding-validation-output">Understanding Validation Output</a></h3>
<p><strong>Success output:</strong></p>
<pre><code>‚úÖ Validation PASSED

Metrics:
  Average Complexity: 7.2 / 10.0 ‚úì
  Debt Density: 32.5 / 50.0 ‚úì
  Codebase Risk: 5.8 / 7.0 ‚úì
  Total Debt Score: 1250 / 10000 ‚úì
</code></pre>
<p><strong>Failure output:</strong></p>
<pre><code>‚ùå Validation FAILED

Metrics:
  Average Complexity: 12.3 / 10.0 ‚úó EXCEEDED
  Debt Density: 65.8 / 50.0 ‚úó EXCEEDED
  Codebase Risk: 5.2 / 7.0 ‚úì
  Total Debt Score: 2100 / 10000 ‚úì

Failed checks: 2
</code></pre>
<h2 id="coverage-integration-4"><a class="header" href="#coverage-integration-4">Coverage Integration</a></h2>
<p>Integrate test coverage data to enable risk-based validation:</p>
<h3 id="generating-coverage-data-3"><a class="header" href="#generating-coverage-data-3">Generating Coverage Data</a></h3>
<p><strong>For Rust projects with <code>cargo-tarpaulin</code>:</strong></p>
<pre><code class="language-bash">cargo tarpaulin --out Lcov --output-dir target/coverage
</code></pre>
<p><strong>For Python projects with <code>pytest-cov</code>:</strong></p>
<pre><code class="language-bash">pytest --cov --cov-report=lcov:coverage/lcov.info
</code></pre>
<p><strong>For JavaScript projects with Jest:</strong></p>
<pre><code class="language-bash">jest --coverage --coverageReporters=lcov
</code></pre>
<h3 id="running-validation-with-coverage"><a class="header" href="#running-validation-with-coverage">Running Validation with Coverage</a></h3>
<pre><code class="language-bash">debtmap validate . --coverage-file target/coverage/lcov.info
</code></pre>
<h3 id="benefits-of-coverage-integration"><a class="header" href="#benefits-of-coverage-integration">Benefits of Coverage Integration</a></h3>
<p>With coverage data, validation gains additional insights:</p>
<ol>
<li><strong>Risk-based prioritization</strong> - Identifies untested complex code</li>
<li><strong>Coverage threshold enforcement</strong> - via <code>min_coverage_percentage</code></li>
<li><strong>Enhanced risk scoring</strong> - Combines complexity + coverage + context</li>
<li><strong>Better failure diagnostics</strong> - Shows which untested areas need attention</li>
</ol>
<h3 id="coverage-enhanced-output"><a class="header" href="#coverage-enhanced-output">Coverage-Enhanced Output</a></h3>
<pre><code class="language-bash">debtmap validate . --coverage-file coverage/lcov.info -vv
</code></pre>
<p>Output includes:</p>
<ul>
<li>Overall coverage percentage</li>
<li>High-risk uncovered functions</li>
<li>Coverage-adjusted risk scores</li>
<li>Prioritized remediation recommendations</li>
</ul>
<h2 id="context-aware-validation"><a class="header" href="#context-aware-validation">Context-Aware Validation</a></h2>
<p>Enable context-aware analysis for deeper risk insights:</p>
<h3 id="available-context-providers"><a class="header" href="#available-context-providers">Available Context Providers</a></h3>
<ol>
<li><strong><code>critical_path</code></strong> - Analyzes call graph to find execution bottlenecks</li>
<li><strong><code>dependency</code></strong> - Identifies highly-coupled modules</li>
<li><strong><code>git_history</code></strong> - Detects frequently-changed code (churn)</li>
</ol>
<h3 id="enabling-context-providers-1"><a class="header" href="#enabling-context-providers-1">Enabling Context Providers</a></h3>
<p><strong>Enable all providers:</strong></p>
<pre><code class="language-bash">debtmap validate . --enable-context
</code></pre>
<p><strong>Select specific providers:</strong></p>
<pre><code class="language-bash">debtmap validate . --enable-context --context-providers critical_path,git_history
</code></pre>
<p><strong>Disable specific providers:</strong></p>
<pre><code class="language-bash">debtmap validate . --enable-context --disable-context dependency
</code></pre>
<h3 id="context-aware-configuration"><a class="header" href="#context-aware-configuration">Context-Aware Configuration</a></h3>
<p>Add context settings to <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[analysis]
enable_context = true
context_providers = ["critical_path", "git_history"]
</code></pre>
<p>Then run validation:</p>
<pre><code class="language-bash">debtmap validate .  # Uses config settings
</code></pre>
<h3 id="context-benefits-for-validation"><a class="header" href="#context-benefits-for-validation">Context Benefits for Validation</a></h3>
<p>Context-aware analysis improves risk scoring by:</p>
<ul>
<li>Prioritizing frequently-called functions</li>
<li>Weighting high-churn code more heavily</li>
<li>Identifying architectural bottlenecks</li>
<li>Surfacing critical code paths</li>
</ul>
<h2 id="cicd-examples"><a class="header" href="#cicd-examples">CI/CD Examples</a></h2>
<h3 id="github-actions-2"><a class="header" href="#github-actions-2">GitHub Actions</a></h3>
<p>Complete workflow with coverage generation and validation:</p>
<pre><code class="language-yaml">name: Code Quality Validation

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  validate:
    name: Technical Debt Validation
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        fetch-depth: 0  # Full history for git context

    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        components: rustfmt, clippy

    - name: Cache cargo dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-

    - name: Install cargo-tarpaulin
      run: |
        if ! command -v cargo-tarpaulin &amp;&gt; /dev/null; then
          cargo install cargo-tarpaulin
        fi

    - name: Build debtmap
      run: cargo build --release

    - name: Generate coverage data
      run: cargo tarpaulin --out Lcov --output-dir target/coverage --timeout 300

    - name: Run debtmap validation with coverage
      run: |
        if [ -f "target/coverage/lcov.info" ]; then
          ./target/release/debtmap validate . \
            --coverage-file target/coverage/lcov.info \
            --enable-context \
            --format json \
            --output debtmap-report.json
        else
          echo "Warning: LCOV file not found, running without coverage"
          ./target/release/debtmap validate . \
            --format json \
            --output debtmap-report.json
        fi

    - name: Upload debtmap report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: debtmap-analysis-artifacts
        path: |
          debtmap-report.json
          target/coverage/lcov.info
        retention-days: 7
</code></pre>
<h3 id="gitlab-ci-2"><a class="header" href="#gitlab-ci-2">GitLab CI</a></h3>
<pre><code class="language-yaml">stages:
  - test
  - quality

variables:
  CARGO_HOME: $CI_PROJECT_DIR/.cargo

debtmap:
  stage: quality
  image: rust:latest

  cache:
    paths:
      - .cargo/
      - target/

  before_script:
    # Install debtmap and coverage tools
    - cargo install debtmap
    - cargo install cargo-tarpaulin

  script:
    # Generate coverage
    - cargo tarpaulin --out Lcov --output-dir coverage

    # Validate with debtmap
    - debtmap validate . --coverage-file coverage/lcov.info -v

  artifacts:
    when: always
    paths:
      - coverage/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura.xml
</code></pre>
<h3 id="circleci"><a class="header" href="#circleci">CircleCI</a></h3>
<pre><code class="language-yaml">version: 2.1

jobs:
  validate:
    docker:
      - image: cimg/rust:1.75

    steps:
      - checkout

      - restore_cache:
          keys:
            - cargo-{{ checksum "Cargo.lock" }}

      - run:
          name: Install tools
          command: |
            cargo install debtmap
            cargo install cargo-tarpaulin

      - run:
          name: Generate coverage
          command: cargo tarpaulin --out Lcov

      - run:
          name: Validate code quality
          command: debtmap validate . --coverage-file lcov.info

      - save_cache:
          key: cargo-{{ checksum "Cargo.lock" }}
          paths:
            - ~/.cargo
            - target

workflows:
  version: 2
  quality:
    jobs:
      - validate
</code></pre>
<h2 id="migrating-from-deprecated-thresholds"><a class="header" href="#migrating-from-deprecated-thresholds">Migrating from Deprecated Thresholds</a></h2>
<p>Debtmap version 0.3.0 deprecated scale-dependent absolute count metrics in favor of density-based metrics.</p>
<h3 id="deprecated-metrics"><a class="header" href="#deprecated-metrics">Deprecated Metrics</a></h3>
<p>The following metrics will be <strong>removed in v1.0</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Deprecated Metric</th><th>Migration Path</th></tr></thead><tbody>
<tr><td><code>max_high_complexity_count</code></td><td>Use <code>max_debt_density</code></td></tr>
<tr><td><code>max_debt_items</code></td><td>Use <code>max_debt_density</code></td></tr>
<tr><td><code>max_high_risk_functions</code></td><td>Use <code>max_debt_density</code> + <code>max_codebase_risk_score</code></td></tr>
</tbody></table>
</div>
<h3 id="migration-example"><a class="header" href="#migration-example">Migration Example</a></h3>
<p><strong>Old configuration (deprecated):</strong></p>
<pre><code class="language-toml">[thresholds.validation]
max_high_complexity_count = 50    # ‚ùå Scale-dependent
max_debt_items = 100               # ‚ùå Scale-dependent
max_high_risk_functions = 20       # ‚ùå Scale-dependent
</code></pre>
<p><strong>New configuration (recommended):</strong></p>
<pre><code class="language-toml">[thresholds.validation]
max_debt_density = 50.0            # ‚úÖ Scale-independent
max_average_complexity = 10.0      # ‚úÖ Quality ratio
max_codebase_risk_score = 7.0      # ‚úÖ Risk level
</code></pre>
<h3 id="calculating-equivalent-density-threshold"><a class="header" href="#calculating-equivalent-density-threshold">Calculating Equivalent Density Threshold</a></h3>
<p>Convert your old absolute thresholds to density:</p>
<pre><code>Old: max_debt_items = 100 in 10,000 LOC codebase
New: max_debt_density = (100 / 10000) √ó 1000 = 10.0
</code></pre>
<h3 id="deprecation-warnings"><a class="header" href="#deprecation-warnings">Deprecation Warnings</a></h3>
<p>When you run <code>validate</code> with deprecated metrics, you‚Äôll see:</p>
<pre><code>‚ö†Ô∏è  DEPRECATION WARNING:
   The following validation thresholds are deprecated:
   - max_high_complexity_count
   - max_debt_items

   These scale-dependent metrics will be removed in v1.0.
   Please migrate to density-based validation:
     - Use 'max_debt_density' instead of absolute counts
     - Density metrics remain stable as your codebase grows
</code></pre>
<h3 id="migration-timeline"><a class="header" href="#migration-timeline">Migration Timeline</a></h3>
<ul>
<li><strong>v0.3.0</strong> - Density metrics introduced, old metrics deprecated</li>
<li><strong>v0.4.0 - v0.9.x</strong> - Deprecation warnings shown</li>
<li><strong>v1.0.0</strong> - Deprecated metrics removed</li>
</ul>
<h2 id="troubleshooting-20"><a class="header" href="#troubleshooting-20">Troubleshooting</a></h2>
<h3 id="debugging-validation-failures"><a class="header" href="#debugging-validation-failures">Debugging Validation Failures</a></h3>
<p>Use verbosity flags to understand why validation failed:</p>
<p><strong>Level 1: Basic details (<code>-v</code>)</strong></p>
<pre><code class="language-bash">debtmap validate . -v
</code></pre>
<p>Shows which thresholds failed, by how much, and timing breakdown:</p>
<ul>
<li>Call graph building time</li>
<li>Trait resolution time</li>
<li>Coverage loading time</li>
<li>Individual analysis phase durations</li>
</ul>
<p><strong>Level 2: Detailed breakdown (<code>-vv</code>)</strong></p>
<pre><code class="language-bash">debtmap validate . -vv
</code></pre>
<p>Shows everything from <code>-v</code> plus:</p>
<ul>
<li>Score calculation factors and weights</li>
<li>Top violating functions with metrics</li>
<li>Detailed phase timing information</li>
<li>Risk score component breakdown</li>
</ul>
<p><strong>Level 3: Full diagnostic output (<code>-vvv</code>)</strong></p>
<pre><code class="language-bash">debtmap validate . -vvv
</code></pre>
<p>Shows complete debug information:</p>
<ul>
<li>All debt items with full details</li>
<li>Complete risk calculations for each function</li>
<li>All timing information including sub-phases</li>
<li>File-level and function-level analysis data</li>
<li>Context provider outputs (if enabled)</li>
</ul>
<h3 id="common-issues-2"><a class="header" href="#common-issues-2">Common Issues</a></h3>
<p><strong>Issue: Validation fails but output unclear</strong></p>
<pre><code class="language-bash"># Solution: Increase verbosity
debtmap validate . -vv
</code></pre>
<p><strong>Issue: Want to see only the worst problems</strong></p>
<pre><code class="language-bash"># Solution: Use --top flag
debtmap validate . --top 10 -v
</code></pre>
<p><strong>Issue: Output is too verbose for CI logs</strong></p>
<pre><code class="language-bash"># Solution: Use --summary flag for compact tiered output
debtmap validate . --summary
# or
debtmap validate . -s
</code></pre>
<p>This provides a condensed view focused on priority tiers rather than individual items.</p>
<p><strong>Issue: Validation passes locally but fails in CI</strong></p>
<pre><code class="language-bash"># Possible causes:
# 1. Different code (stale local branch)
# 2. Different config file (check .debtmap.toml in CI)
# 3. Missing coverage data (check LCOV generation in CI)

# Debug in CI:
debtmap validate . -vvv  # Maximum verbosity
</code></pre>
<p><strong>Issue: Coverage threshold fails unexpectedly</strong></p>
<pre><code class="language-bash"># Check if coverage file is being read
debtmap validate . --coverage-file coverage/lcov.info -v

# Verify coverage file exists and is valid
ls -lh coverage/lcov.info
</code></pre>
<p><strong>Issue: Context providers causing performance issues</strong></p>
<pre><code class="language-bash"># Disable expensive providers
debtmap validate . --enable-context --disable-context git_history
</code></pre>
<p><strong>Issue: Semantic analysis causing errors or unexpected behavior</strong></p>
<pre><code class="language-bash"># Solution: Disable semantic analysis with fallback mode
debtmap validate . --semantic-off
</code></pre>
<p>This disables advanced semantic features and uses basic syntax analysis only. Useful for debugging or working with unsupported language constructs.</p>
<h3 id="validation-report-generation"><a class="header" href="#validation-report-generation">Validation Report Generation</a></h3>
<p>Generate detailed reports for debugging:</p>
<p><strong>JSON format for programmatic analysis:</strong></p>
<pre><code class="language-bash">debtmap validate . --format json --output validation-report.json
cat validation-report.json | jq '.validation_details'
</code></pre>
<p><strong>Markdown format for documentation:</strong></p>
<pre><code class="language-bash">debtmap validate . --format markdown --output validation-report.md
</code></pre>
<p><strong>Terminal format with filtering:</strong></p>
<pre><code class="language-bash">debtmap validate . --format terminal --top 20 -vv
</code></pre>
<h2 id="best-practices-19"><a class="header" href="#best-practices-19">Best Practices</a></h2>
<h3 id="setting-initial-thresholds"><a class="header" href="#setting-initial-thresholds">Setting Initial Thresholds</a></h3>
<p><strong>1. Establish baseline:</strong></p>
<pre><code class="language-bash"># Run analysis to see current metrics
debtmap analyze . --format json &gt; baseline.json
cat baseline.json | jq '.unified_analysis.debt_density'
</code></pre>
<p><strong>2. Set pragmatic thresholds:</strong></p>
<pre><code class="language-toml">[thresholds.validation]
# Start slightly above current values to prevent regression
max_debt_density = 60.0  # Current: 55.0
max_average_complexity = 12.0  # Current: 10.5
</code></pre>
<p><strong>3. Gradually tighten:</strong></p>
<pre><code class="language-toml"># After 1 month of cleanup
max_debt_density = 50.0
max_average_complexity = 10.0
</code></pre>
<h3 id="progressive-threshold-tightening"><a class="header" href="#progressive-threshold-tightening">Progressive Threshold Tightening</a></h3>
<p><strong>Month 1-2: Prevent regression</strong></p>
<pre><code class="language-toml">max_debt_density = 60.0  # Above current baseline
</code></pre>
<p><strong>Month 3-4: Incremental improvement</strong></p>
<pre><code class="language-toml">max_debt_density = 50.0  # Industry standard
</code></pre>
<p><strong>Month 5-6: Quality leadership</strong></p>
<pre><code class="language-toml">max_debt_density = 30.0  # Best-in-class
</code></pre>
<h3 id="project-specific-recommendations"><a class="header" href="#project-specific-recommendations">Project-Specific Recommendations</a></h3>
<p><strong>Greenfield projects:</strong></p>
<pre><code class="language-toml"># Start with high quality bar
max_debt_density = 20.0
max_average_complexity = 8.0
min_coverage_percentage = 80.0
</code></pre>
<p><strong>Active development:</strong></p>
<pre><code class="language-toml"># Balanced quality/velocity
max_debt_density = 50.0
max_average_complexity = 10.0
min_coverage_percentage = 70.0
</code></pre>
<p><strong>Legacy modernization:</strong></p>
<pre><code class="language-toml"># Prevent regression during refactoring
max_debt_density = 100.0
max_average_complexity = 15.0
min_coverage_percentage = 50.0
</code></pre>
<h3 id="pre-commit-hook-integration"><a class="header" href="#pre-commit-hook-integration">Pre-Commit Hook Integration</a></h3>
<p>Add validation as a pre-commit hook:</p>
<pre><code class="language-bash"># .git/hooks/pre-commit
#!/bin/bash
echo "Running debtmap validation..."
if debtmap validate . -v; then
    echo "‚úÖ Validation passed"
    exit 0
else
    echo "‚ùå Validation failed - commit blocked"
    exit 1
fi
</code></pre>
<p>Make it executable:</p>
<pre><code class="language-bash">chmod +x .git/hooks/pre-commit
</code></pre>
<h3 id="performance-optimization-2"><a class="header" href="#performance-optimization-2">Performance Optimization</a></h3>
<p><strong>Enable parallel processing:</strong>
Validation uses parallel processing by default for fast execution on multi-core systems.</p>
<p><strong>Disable for resource-constrained environments:</strong></p>
<pre><code class="language-bash"># Limit parallelism
debtmap validate . --jobs 2

# Disable completely
debtmap validate . --no-parallel
</code></pre>
<p><strong>Performance characteristics:</strong></p>
<ul>
<li>Parallel call graph construction</li>
<li>Multi-threaded file analysis</li>
<li>Same performance as <code>analyze</code> command</li>
</ul>
<h3 id="monitoring-trends"><a class="header" href="#monitoring-trends">Monitoring Trends</a></h3>
<p>Track validation metrics over time:</p>
<pre><code class="language-bash"># Generate timestamped reports
debtmap validate . --format json --output "reports/validation-$(date +%Y%m%d).json"

# Compare trends
jq -s 'map(.unified_analysis.debt_density)' reports/validation-*.json
</code></pre>
<h3 id="documentation"><a class="header" href="#documentation">Documentation</a></h3>
<p>Document your threshold decisions:</p>
<pre><code class="language-toml"># .debtmap.toml
[thresholds.validation]
# Rationale: Team agreed 50.0 density balances quality and velocity
# Review: Quarterly (next: 2025-04-01)
max_debt_density = 50.0

# Rationale: Enforces single-responsibility principle
# Review: After 3 months of metrics
max_average_complexity = 10.0
</code></pre>
<h2 id="summary-10"><a class="header" href="#summary-10">Summary</a></h2>
<p>The <code>validate</code> command provides automated quality gates for CI/CD integration:</p>
<ul>
<li><strong>Use density-based metrics</strong> for scale-independent quality measurement</li>
<li><strong>Configure in <code>.debtmap.toml</code></strong> for consistent, version-controlled thresholds</li>
<li><strong>Integrate with CI/CD</strong> using exit codes for automated enforcement</li>
<li><strong>Enable coverage and context</strong> for risk-based validation</li>
<li><strong>Migrate from deprecated metrics</strong> to density-based approach</li>
<li><strong>Debug with verbosity flags</strong> when validation fails unexpectedly</li>
<li><strong>Tighten thresholds progressively</strong> as code quality improves</li>
</ul>
<p>Next steps:</p>
<ul>
<li>Review <a href="./configuration.html">Configuration Reference</a> for detailed threshold options</li>
<li>See <a href="./examples.html">Examples</a> for more CI/CD integration patterns</li>
<li>Check <a href="./cli-reference.html">CLI Reference</a> for complete command documentation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="metrics-reference"><a class="header" href="#metrics-reference">Metrics Reference</a></h1>
<p>Comprehensive guide to all metrics calculated by Debtmap and how to interpret them.</p>
<h2 id="metric-categories-spec-118"><a class="header" href="#metric-categories-spec-118">Metric Categories (Spec 118)</a></h2>
<p>Debtmap distinguishes between two fundamental categories of metrics:</p>
<h3 id="measured-metrics"><a class="header" href="#measured-metrics">Measured Metrics</a></h3>
<p><strong>Definition</strong>: Metrics directly computed from the Abstract Syntax Tree (AST) through precise analysis.</p>
<p>These metrics are:</p>
<ul>
<li><strong>Deterministic</strong>: Same code always produces the same metric value</li>
<li><strong>Precise</strong>: Exact counts from syntax analysis, not estimates</li>
<li><strong>Suitable for thresholds</strong>: Reliable for CI/CD quality gates</li>
<li><strong>Language-specific</strong>: Computed using language parsers (syn for Rust, tree-sitter for others)</li>
</ul>
<p><strong>Measured metrics include:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>cyclomatic_complexity</code></td><td>Count of decision points (if, match, while, for, etc.)</td><td>Function with 3 if statements = complexity 4</td></tr>
<tr><td><code>cognitive_complexity</code></td><td>Weighted measure of code understandability</td><td>Nested loops increase cognitive load</td></tr>
<tr><td><code>nesting_depth</code></td><td>Maximum levels of nested control structures</td><td>3 nested if statements = depth 3</td></tr>
<tr><td><code>loc</code></td><td>Lines of code in the function</td><td>Physical line count</td></tr>
<tr><td><code>parameter_count</code></td><td>Number of function parameters</td><td><code>fn foo(a: i32, b: String)</code> = 2</td></tr>
</tbody></table>
</div>
<h3 id="estimated-metrics"><a class="header" href="#estimated-metrics">Estimated Metrics</a></h3>
<p><strong>Definition</strong>: Heuristic approximations calculated using formulas, not direct AST measurements.</p>
<p>These metrics are:</p>
<ul>
<li><strong>Heuristic</strong>: Based on mathematical formulas and assumptions</li>
<li><strong>Approximate</strong>: Close estimates, not exact counts</li>
<li><strong>Useful for prioritization</strong>: Help estimate effort and risk</li>
<li><strong>Not suitable for hard thresholds</strong>: Use for relative comparisons, not absolute gates</li>
</ul>
<p><strong>Estimated metrics include:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Formula</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>est_branches</code></td><td><code>max(nesting, 1) √ó cyclomatic √∑ 3</code></td><td>Estimate test cases needed for branch coverage</td><td>Complexity 12, nesting 3 ‚Üí ~12 branches</td></tr>
</tbody></table>
</div>
<p><strong>Important</strong>: The <code>est_branches</code> metric was previously called <code>branches</code>. It was renamed in Spec 118 to make it explicit that this is an <strong>estimate</strong>, not a precise count from the AST.</p>
<h2 id="why-the-distinction-matters"><a class="header" href="#why-the-distinction-matters">Why the Distinction Matters</a></h2>
<h3 id="for-code-quality-gates"><a class="header" href="#for-code-quality-gates">For Code Quality Gates</a></h3>
<pre><code class="language-bash"># GOOD: Use measured metrics for CI/CD thresholds
debtmap validate . --threshold-complexity 15

# AVOID: Don't use estimated metrics for hard gates
# (est_branches is not exposed as a threshold flag)
</code></pre>
<p><strong>Rationale</strong>: Measured metrics are deterministic and precise, making them suitable for build-breaking quality gates.</p>
<h3 id="for-prioritization"><a class="header" href="#for-prioritization">For Prioritization</a></h3>
<pre><code class="language-bash"># GOOD: Use est_branches for prioritization
debtmap analyze . --top 10  # Sorts by est_branches (among other factors)

# GOOD: Estimated metrics help understand testing effort
debtmap analyze . --lcov coverage.info --verbose
</code></pre>
<p><strong>Rationale</strong>: Estimated metrics provide useful heuristics for understanding where to focus testing and refactoring efforts.</p>
<h3 id="for-comparison-across-codebases"><a class="header" href="#for-comparison-across-codebases">For Comparison Across Codebases</a></h3>
<ul>
<li><strong>Measured metrics</strong>: Comparable across projects (cyclomatic 10 means the same everywhere)</li>
<li><strong>Estimated metrics</strong>: Project-specific heuristics (est_branches depends on nesting patterns)</li>
</ul>
<h2 id="detailed-metric-descriptions"><a class="header" href="#detailed-metric-descriptions">Detailed Metric Descriptions</a></h2>
<h3 id="cyclomatic-complexity-measured"><a class="header" href="#cyclomatic-complexity-measured">Cyclomatic Complexity (Measured)</a></h3>
<p><strong>What it measures</strong>: The number of linearly independent paths through a function‚Äôs control flow.</p>
<p><strong>How it‚Äôs calculated</strong>:</p>
<ul>
<li>Start with a base of 1</li>
<li>Add 1 for each decision point:
<ul>
<li><code>if</code>, <code>else if</code></li>
<li><code>match</code> arms</li>
<li><code>while</code>, <code>for</code>, <code>loop</code></li>
<li><code>&amp;&amp;</code>, <code>||</code> in conditions</li>
<li><code>?</code> operator (early return)</li>
</ul>
</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn example(x: i32, y: i32) -&gt; bool {
    if x &gt; 0 {        // +1
        if y &gt; 0 {    // +1
            true
        } else {      // implicit in if/else
            false
        }
    } else if x &lt; 0 { // +1
        false
    } else {
        y == 0        // no additional branches
    }
}
// Cyclomatic complexity = 1 + 3 = 4
<span class="boring">}</span></code></pre></pre>
<p><strong>Thresholds</strong>:</p>
<ul>
<li><strong>1-5</strong>: Simple, easy to test</li>
<li><strong>6-10</strong>: Moderate, manageable complexity</li>
<li><strong>11-20</strong>: Complex, consider refactoring</li>
<li><strong>21+</strong>: Very complex, high maintenance cost</li>
</ul>
<h3 id="cognitive-complexity-measured"><a class="header" href="#cognitive-complexity-measured">Cognitive Complexity (Measured)</a></h3>
<p><strong>What it measures</strong>: How difficult the code is for humans to understand.</p>
<p><strong>How it differs from cyclomatic</strong>:</p>
<ul>
<li>Weights nested structures more heavily (nested if is worse than sequential if)</li>
<li>Ignores shorthand structures (early returns, guard clauses)</li>
<li>Focuses on readability, not just logic paths</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn cyclomatic_low_cognitive_low(status: Status) -&gt; bool {
    match status {  // Cyclomatic: 4, Cognitive: 1
        Status::Active =&gt; true,
        Status::Pending =&gt; false,
        Status::Closed =&gt; false,
        Status::Error =&gt; false,
    }
}

fn cyclomatic_low_cognitive_high(x: i32, y: i32, z: i32) -&gt; bool {
    if x &gt; 0 {
        if y &gt; 0 {      // Nested: +2 cognitive penalty
            if z &gt; 0 {  // Deeply nested: +3 cognitive penalty
                return true;
            }
        }
    }
    false
}
// Cyclomatic: 4, Cognitive: 7 (nesting penalty applied)
<span class="boring">}</span></code></pre></pre>
<p><strong>Thresholds</strong>:</p>
<ul>
<li><strong>1-5</strong>: Easy to understand</li>
<li><strong>6-10</strong>: Moderate mental load</li>
<li><strong>11-15</strong>: Difficult to follow</li>
<li><strong>16+</strong>: Refactor recommended</li>
</ul>
<h3 id="estimated-branches-estimated"><a class="header" href="#estimated-branches-estimated">Estimated Branches (Estimated)</a></h3>
<p><strong>What it estimates</strong>: Approximate number of execution paths that would need test coverage.</p>
<p><strong>Formula</strong>:</p>
<pre><code>est_branches = max(nesting_depth, 1) √ó cyclomatic_complexity √∑ 3
</code></pre>
<p><strong>Why this formula</strong>:</p>
<ul>
<li><strong>Nesting multiplier</strong>: Deeper nesting creates more combinations</li>
<li><strong>Cyclomatic base</strong>: Higher complexity ‚Üí more paths</li>
<li><strong>√∑ 3 adjustment</strong>: Empirical factor to align with typical branch coverage needs</li>
</ul>
<p><strong>Example scenarios</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Cyclomatic</th><th>Nesting</th><th>est_branches</th><th>Interpretation</th></tr></thead><tbody>
<tr><td>3</td><td>1</td><td>1</td><td>Simple linear code</td></tr>
<tr><td>12</td><td>1</td><td>4</td><td>Multiple sequential branches</td></tr>
<tr><td>12</td><td>3</td><td>12</td><td>Nested conditions, many paths</td></tr>
<tr><td>20</td><td>5</td><td>33</td><td>Complex nested logic</td></tr>
</tbody></table>
</div>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Estimating test case requirements</li>
<li>Prioritizing untested complex code</li>
<li>Understanding coverage gaps</li>
</ul>
<p><strong>Limitations</strong>:</p>
<ul>
<li><strong>Not a precise count</strong>: This is a heuristic approximation</li>
<li><strong>Don‚Äôt use for coverage percentage calculation</strong>: Use actual coverage tools</li>
<li><strong>Varies by code style</strong>: Heavily nested code scores higher</li>
</ul>
<h2 id="terminology-change-spec-118"><a class="header" href="#terminology-change-spec-118">Terminology Change (Spec 118)</a></h2>
<h3 id="before-branches"><a class="header" href="#before-branches">Before: <code>branches</code></a></h3>
<p>Previously, this metric was displayed as <code>branches=X</code>, which was confusing because:</p>
<ol>
<li>Users thought it was a precise count from AST analysis</li>
<li>It was mistaken for cyclomatic complexity (actual branch count)</li>
<li>The estimation nature was not obvious</li>
</ol>
<h3 id="after-est_branches"><a class="header" href="#after-est_branches">After: <code>est_branches</code></a></h3>
<p>Now displayed as <code>est_branches=X</code> to:</p>
<ol>
<li><strong>Make estimation explicit</strong>: ‚Äúest_‚Äù prefix indicates this is approximate</li>
<li><strong>Avoid confusion</strong>: Clearly different from cyclomatic complexity</li>
<li><strong>Set correct expectations</strong>: Users know this is a heuristic, not a measurement</li>
</ol>
<h3 id="migration-guide-1"><a class="header" href="#migration-guide-1">Migration Guide</a></h3>
<p><strong>Terminal Output</strong>:</p>
<ul>
<li>Old: <code>COMPLEXITY: cyclomatic=12, branches=8, cognitive=15</code></li>
<li>New: <code>COMPLEXITY: cyclomatic=12, est_branches=8, cognitive=15</code></li>
</ul>
<p><strong>Code</strong>:</p>
<ul>
<li>Internal variable names updated from <code>branches</code> to <code>est_branches</code></li>
<li>Comments added explaining the estimation formula</li>
</ul>
<p><strong>JSON Output</strong>:</p>
<ul>
<li>No change: The ComplexityMetrics struct does not include this field</li>
<li><code>est_branches</code> is calculated on-demand for display purposes only</li>
</ul>
<h2 id="practical-usage-examples"><a class="header" href="#practical-usage-examples">Practical Usage Examples</a></h2>
<h3 id="example-1-code-quality-gate"><a class="header" href="#example-1-code-quality-gate">Example 1: Code Quality Gate</a></h3>
<pre><code class="language-bash"># Fail build if any function exceeds cyclomatic complexity 15
debtmap validate . --threshold-complexity 15 --max-high 0

# Why: Cyclomatic is measured, precise, and repeatable
</code></pre>
<h3 id="example-2-prioritize-testing-effort"><a class="header" href="#example-2-prioritize-testing-effort">Example 2: Prioritize Testing Effort</a></h3>
<pre><code class="language-bash"># Show top 10 functions by risk (uses est_branches in scoring)
debtmap analyze . --lcov coverage.info --top 10

# Functions with high est_branches and low coverage appear first
</code></pre>
<h3 id="example-3-understanding-test-requirements"><a class="header" href="#example-3-understanding-test-requirements">Example 3: Understanding Test Requirements</a></h3>
<pre><code class="language-bash"># Verbose output shows est_branches for each function
debtmap analyze . --verbose

# Output:
# ‚îî‚îÄ COMPLEXITY: cyclomatic=12, est_branches=8, cognitive=15, nesting=2
#
# Interpretation: ~8 test cases likely needed for good branch coverage
</code></pre>
<h3 id="example-4-explaining-metrics-to-team"><a class="header" href="#example-4-explaining-metrics-to-team">Example 4: Explaining Metrics to Team</a></h3>
<pre><code class="language-bash"># Display comprehensive metric definitions
debtmap analyze --explain-metrics

# Shows:
# - Measured vs Estimated categories
# - Formulas and thresholds
# - When to use each metric
</code></pre>
<h2 id="metric-selection-guide"><a class="header" href="#metric-selection-guide">Metric Selection Guide</a></h2>
<h3 id="when-to-use-cyclomatic-complexity"><a class="header" href="#when-to-use-cyclomatic-complexity">When to Use Cyclomatic Complexity</a></h3>
<p>‚úÖ <strong>Use for:</strong></p>
<ul>
<li>CI/CD quality gates</li>
<li>Code review guidelines</li>
<li>Consistent cross-project comparison</li>
<li>Identifying refactoring candidates</li>
</ul>
<p>‚ùå <strong>Don‚Äôt use for:</strong></p>
<ul>
<li>Estimating test effort (use est_branches)</li>
<li>Readability assessment (use cognitive complexity)</li>
</ul>
<h3 id="when-to-use-cognitive-complexity"><a class="header" href="#when-to-use-cognitive-complexity">When to Use Cognitive Complexity</a></h3>
<p>‚úÖ <strong>Use for:</strong></p>
<ul>
<li>Readability reviews</li>
<li>Identifying hard-to-maintain code</li>
<li>Onboarding difficulty assessment</li>
</ul>
<p>‚ùå <strong>Don‚Äôt use for:</strong></p>
<ul>
<li>Test coverage planning</li>
<li>Strict quality gates (more subjective than cyclomatic)</li>
</ul>
<h3 id="when-to-use-est_branches"><a class="header" href="#when-to-use-est_branches">When to Use est_branches</a></h3>
<p>‚úÖ <strong>Use for:</strong></p>
<ul>
<li>Estimating test case requirements</li>
<li>Prioritizing test coverage work</li>
<li>Understanding coverage gaps</li>
</ul>
<p>‚ùå <strong>Don‚Äôt use for:</strong></p>
<ul>
<li>CI/CD quality gates (it‚Äôs an estimate)</li>
<li>Calculating coverage percentages (use actual coverage data)</li>
<li>Cross-project comparison (formula is heuristic)</li>
</ul>
<h2 id="combining-metrics-for-insights"><a class="header" href="#combining-metrics-for-insights">Combining Metrics for Insights</a></h2>
<h3 id="high-complexity-low-coverage"><a class="header" href="#high-complexity-low-coverage">High Complexity, Low Coverage</a></h3>
<pre><code>cyclomatic=18, est_branches=12, coverage=0%
</code></pre>
<p><strong>Interpretation</strong>: High-risk code needing ~12 test cases for adequate coverage.</p>
<p><strong>Action</strong>: Prioritize writing tests, consider refactoring.</p>
<h3 id="high-cyclomatic-low-cognitive"><a class="header" href="#high-cyclomatic-low-cognitive">High Cyclomatic, Low Cognitive</a></h3>
<pre><code>cyclomatic=15, cognitive=5
</code></pre>
<p><strong>Interpretation</strong>: Many branches, but simple linear logic (e.g., validation checks).</p>
<p><strong>Action</strong>: Acceptable pattern, tests should be straightforward.</p>
<h3 id="low-cyclomatic-high-cognitive"><a class="header" href="#low-cyclomatic-high-cognitive">Low Cyclomatic, High Cognitive</a></h3>
<pre><code>cyclomatic=8, cognitive=18
</code></pre>
<p><strong>Interpretation</strong>: Deeply nested logic, hard to understand despite fewer branches.</p>
<p><strong>Action</strong>: Refactor to reduce nesting, extract functions.</p>
<h3 id="high-est_branches-low-cyclomatic"><a class="header" href="#high-est_branches-low-cyclomatic">High est_branches, Low Cyclomatic</a></h3>
<pre><code>cyclomatic=9, nesting=5, est_branches=15
</code></pre>
<p><strong>Interpretation</strong>: Deep nesting creates many path combinations.</p>
<p><strong>Action</strong>: Flatten nesting, use early returns, extract nested logic.</p>
<h2 id="frequently-asked-questions"><a class="header" href="#frequently-asked-questions">Frequently Asked Questions</a></h2>
<h3 id="q-why-is-est_branches-different-from-cyclomatic-complexity"><a class="header" href="#q-why-is-est_branches-different-from-cyclomatic-complexity">Q: Why is est_branches different from cyclomatic complexity?</a></h3>
<p><strong>A</strong>: Cyclomatic is the <strong>measured</strong> count of decision points. <code>est_branches</code> is an <strong>estimated</strong> number of execution paths, calculated using nesting depth to account for path combinations.</p>
<h3 id="q-can-i-use-est_branches-in-cicd-thresholds"><a class="header" href="#q-can-i-use-est_branches-in-cicd-thresholds">Q: Can I use est_branches in CI/CD thresholds?</a></h3>
<p><strong>A</strong>: No. Use measured metrics (cyclomatic_complexity, cognitive_complexity) for quality gates. <code>est_branches</code> is a heuristic for prioritization, not a precise measurement.</p>
<h3 id="q-why-did-the-metric-name-change-from-branches-to-est_branches"><a class="header" href="#q-why-did-the-metric-name-change-from-branches-to-est_branches">Q: Why did the metric name change from ‚Äúbranches‚Äù to ‚Äúest_branches‚Äù?</a></h3>
<p><strong>A</strong>: To make it explicit that this is an <strong>estimate</strong>, not a measured value. Users were confused, thinking it was a precise count from the AST.</p>
<h3 id="q-how-accurate-is-est_branches-for-estimating-test-cases"><a class="header" href="#q-how-accurate-is-est_branches-for-estimating-test-cases">Q: How accurate is est_branches for estimating test cases?</a></h3>
<p><strong>A</strong>: It‚Äôs a <strong>rough approximation</strong>. Actual test case requirements depend on:</p>
<ul>
<li>Business logic complexity</li>
<li>Edge cases</li>
<li>Error handling paths</li>
<li>Integration points</li>
</ul>
<p>Use <code>est_branches</code> as a starting point, not an exact requirement.</p>
<h3 id="q-should-i-refactor-code-with-high-est_branches"><a class="header" href="#q-should-i-refactor-code-with-high-est_branches">Q: Should I refactor code with high est_branches?</a></h3>
<p><strong>A</strong>: Not necessarily. High <code>est_branches</code> indicates complex logic that may need thorough testing. If the logic is unavoidable (e.g., state machines, complex business rules), focus on comprehensive test coverage rather than refactoring.</p>
<h2 id="further-reading-2"><a class="header" href="#further-reading-2">Further Reading</a></h2>
<ul>
<li><a href="why-debtmap.html#entropy-based-complexity-analysis">Why Debtmap? - Entropy Analysis</a></li>
<li><a href="configuration.html#thresholds">Configuration - Complexity Thresholds</a></li>
<li><a href="coverage-integration.html">Coverage Integration</a></li>
<li><a href="scoring-strategies.html">Scoring Strategies</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="examples-4"><a class="header" href="#examples-4">Examples</a></h1>
<p>This chapter provides practical, real-world examples of using Debtmap across different project types and workflows. All examples use current CLI syntax verified against the source code.</p>
<blockquote>
<p><strong>Quick Start</strong>: New to Debtmap? Start with <a href="examples.html#basic-rust-analysis">Basic Rust Analysis</a> for the simplest introduction, then explore <a href="examples.html#coverage-integration-with-cargo-tarpaulin">Coverage Integration</a> for risk-based prioritization.</p>
</blockquote>
<blockquote>
<p><strong>Quick Navigation</strong>: For detailed explanations of all CLI options, see the <a href="cli-reference.html">CLI Reference</a> chapter.</p>
</blockquote>
<h2 id="overview-17"><a class="header" href="#overview-17">Overview</a></h2>
<p>This chapter demonstrates:</p>
<ul>
<li><strong>Language-specific analysis</strong>: Rust, Python, JavaScript/TypeScript with their respective testing tools</li>
<li><strong>CI/CD integration</strong>: GitHub Actions, GitLab CI, CircleCI with validation gates</li>
<li><strong>Output formats</strong>: Terminal, JSON, and Markdown with interpretation guidance</li>
<li><strong>Advanced features</strong>: Context-aware analysis, multi-pass processing, cache management</li>
<li><strong>Configuration patterns</strong>: Tailored settings for different project types</li>
<li><strong>Progress tracking</strong>: Using the <code>compare</code> command to validate refactoring improvements</li>
</ul>
<p>All examples are copy-paste ready and tested against the current Debtmap implementation.</p>
<h2 id="table-of-contents-1"><a class="header" href="#table-of-contents-1">Table of Contents</a></h2>
<ul>
<li><a href="examples.html#analyzing-rust-projects">Analyzing Rust Projects</a></li>
<li><a href="examples.html#python-analysis">Python Analysis</a></li>
<li><a href="examples.html#javascripttypescript">JavaScript/TypeScript</a></li>
<li><a href="examples.html#ci-integration">CI Integration</a></li>
<li><a href="examples.html#output-formats">Output Formats</a></li>
<li><a href="examples.html#advanced-usage">Advanced Usage</a></li>
<li><a href="examples.html#configuration-examples">Configuration Examples</a></li>
<li><a href="examples.html#compare-command">Compare Command</a></li>
</ul>
<h2 id="analyzing-rust-projects"><a class="header" href="#analyzing-rust-projects">Analyzing Rust Projects</a></h2>
<h3 id="basic-rust-analysis"><a class="header" href="#basic-rust-analysis">Basic Rust Analysis</a></h3>
<p>Start with a simple analysis of your Rust project:</p>
<pre><code class="language-bash"># Analyze current directory (path defaults to '.')
debtmap analyze

# Same as above (explicit current directory)
debtmap analyze .

# Analyze specific directory
debtmap analyze ./src

# Analyze with custom complexity threshold
debtmap analyze ./src --threshold-complexity 15
</code></pre>
<h3 id="coverage-integration-with-cargo-tarpaulin"><a class="header" href="#coverage-integration-with-cargo-tarpaulin">Coverage Integration with cargo-tarpaulin</a></h3>
<p>Combine complexity analysis with test coverage for risk-based prioritization:</p>
<pre><code class="language-bash"># Generate LCOV coverage data
cargo tarpaulin --out lcov --output-dir target/coverage

# Analyze with coverage data
debtmap analyze . --lcov target/coverage/lcov.info

# Or use the shorter alias
debtmap analyze . --coverage-file target/coverage/lcov.info
</code></pre>
<blockquote>
<p><strong>Note</strong>: <code>--lcov</code> is an alias for <code>--coverage-file</code> - both work identically.</p>
</blockquote>
<p><strong>What this does:</strong></p>
<ul>
<li>Functions with 0% coverage and high complexity get marked as <code>[CRITICAL]</code></li>
<li>Well-tested functions (&gt;80% coverage) are deprioritized</li>
<li>Shows risk reduction potential for each untested function</li>
</ul>
<h3 id="custom-thresholds"><a class="header" href="#custom-thresholds">Custom Thresholds</a></h3>
<p>Configure thresholds to match your project standards:</p>
<pre><code class="language-bash"># Set both complexity and duplication thresholds
debtmap analyze . \
  --threshold-complexity 15 \
  --threshold-duplication 50

# Use preset configurations for quick setup
debtmap analyze . --threshold-preset strict    # Strict standards
debtmap analyze . --threshold-preset balanced  # Default balanced
debtmap analyze . --threshold-preset lenient   # Lenient for legacy code
</code></pre>
<p><strong>Preset configurations:</strong></p>
<ul>
<li><strong>Strict</strong>: Lower thresholds for high quality standards (good for new projects)</li>
<li><strong>Balanced</strong>: Default thresholds suitable for typical projects</li>
<li><strong>Lenient</strong>: Higher thresholds designed for legacy codebases with existing technical debt</li>
</ul>
<p><strong>Preset Threshold Values:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Preset</th><th>Complexity</th><th>Duplication</th><th>Max Function Lines</th><th>Max Nesting Depth</th></tr></thead><tbody>
<tr><td>Strict</td><td>8</td><td>30</td><td>30</td><td>3</td></tr>
<tr><td>Balanced</td><td>10</td><td>50</td><td>50</td><td>4</td></tr>
<tr><td>Lenient</td><td>15</td><td>75</td><td>80</td><td>5</td></tr>
</tbody></table>
</div>
<h3 id="god-object-detection-3"><a class="header" href="#god-object-detection-3">God Object Detection</a></h3>
<p>Identify classes and modules with too many responsibilities:</p>
<pre><code class="language-bash"># Standard analysis includes god object detection
debtmap analyze .

# Disable god object detection for specific run
debtmap analyze . --no-god-object
</code></pre>
<p>God objects are flagged with detailed metrics:</p>
<ul>
<li>Number of methods and fields</li>
<li>Responsibility count (grouped by naming patterns)</li>
<li>God object score (0-100%)</li>
<li>Recommendations for splitting</li>
</ul>
<h4 id="purity-weighted-god-object-scoring"><a class="header" href="#purity-weighted-god-object-scoring">Purity-Weighted God Object Scoring</a></h4>
<p>Debtmap uses purity analysis to distinguish functional programming patterns from actual god objects. Enable verbose mode to see purity distribution:</p>
<pre><code class="language-bash"># See purity distribution in god object analysis
debtmap analyze . -v
</code></pre>
<p><strong>Example Output:</strong></p>
<pre><code>GOD OBJECT ANALYSIS: src/core/processor.rs
  Total functions: 107
  PURITY DISTRIBUTION:
    Pure: 70 functions (65%) ‚Üí complexity weight: 6.3
    Impure: 37 functions (35%) ‚Üí complexity weight: 14.0
    Total weighted complexity: 20.3
  God object score: 12.0 (threshold: 70.0)
  Status: ‚úì Not a god object (functional design)
</code></pre>
<p>This shows:</p>
<ul>
<li><strong>Pure functions</strong> (no side effects, immutable) receive 0.3√ó weight</li>
<li><strong>Impure functions</strong> (I/O, mutations, side effects) receive 1.0√ó weight</li>
<li>Functional modules with many pure helpers avoid false positives</li>
<li>Focus shifts to modules with excessive stateful code</li>
</ul>
<p><strong>Why This Matters:</strong></p>
<p>Without purity weighting:</p>
<pre><code>Module with 100 pure helpers ‚Üí Flagged as god object ‚ùå
</code></pre>
<p>With purity weighting:</p>
<pre><code>Module with 100 pure helpers ‚Üí Normal (functional design) ‚úÖ
Module with 100 impure functions ‚Üí God object detected ‚úÖ
</code></pre>
<p><strong>Compare Two Modules:</strong></p>
<p>Functional module (70 pure, 30 impure):</p>
<pre><code>Pure:    70 √ó 0.3 = 21.0
Impure:  30 √ó 1.0 = 30.0
Score: 35.0 ‚Üí Not a god object ‚úì
</code></pre>
<p>Procedural module (100 impure):</p>
<pre><code>Impure: 100 √ó 1.0 = 100.0
Score: 125.0 ‚Üí God object detected ‚úó
</code></pre>
<h3 id="filtering-and-focusing"><a class="header" href="#filtering-and-focusing">Filtering and Focusing</a></h3>
<pre><code class="language-bash"># Analyze only Rust files
debtmap analyze . --languages rust

# Focus on architecture issues (god objects, complexity)
debtmap analyze . --filter Architecture

# Focus on testing gaps
debtmap analyze . --filter Testing

# Filter by multiple categories
debtmap analyze . --filter Architecture,Testing

# Show only top 10 issues
debtmap analyze . --top 10

# Show only high-priority items
debtmap analyze . --min-priority high
</code></pre>
<p><strong>Valid filter categories:</strong></p>
<ul>
<li><code>Architecture</code> - God objects, high complexity, structural issues</li>
<li><code>Testing</code> - Test coverage gaps, untested critical code</li>
<li><code>Duplication</code> - Code duplication and similar patterns</li>
<li><code>Maintainability</code> - Long functions, deep nesting, readability issues</li>
</ul>
<h3 id="output-formats-3"><a class="header" href="#output-formats-3">Output Formats</a></h3>
<pre><code class="language-bash"># JSON output for CI integration
debtmap analyze . --format json --output report.json

# Markdown report
debtmap analyze . --format markdown --output DEBT_REPORT.md

# Terminal output (default) - prettified
debtmap analyze .
</code></pre>
<h3 id="multi-pass-analysis-1"><a class="header" href="#multi-pass-analysis-1">Multi-Pass Analysis</a></h3>
<p>For deeper analysis with context awareness:</p>
<pre><code class="language-bash"># Enable context-aware analysis with multiple providers
debtmap analyze . \
  --context \
  --context-providers critical_path,dependency,git_history

# Multi-pass analysis with attribution
debtmap analyze . --multi-pass --attribution
</code></pre>
<h3 id="complete-ci-example"><a class="header" href="#complete-ci-example">Complete CI Example</a></h3>
<p>This is from Debtmap‚Äôs own <code>.github/workflows/debtmap.yml</code>:</p>
<pre><code class="language-bash"># 1. Install cargo-tarpaulin
cargo install cargo-tarpaulin

# 2. Build debtmap
cargo build --release

# 3. Generate coverage
cargo tarpaulin --config .tarpaulin.toml --out Lcov --timeout 300

# 4. Run validation with coverage
./target/release/debtmap validate . \
  --coverage-file target/coverage/lcov.info \
  --format json \
  --output debtmap-report.json
</code></pre>
<h2 id="python-analysis"><a class="header" href="#python-analysis">Python Analysis</a></h2>
<h3 id="basic-python-analysis"><a class="header" href="#basic-python-analysis">Basic Python Analysis</a></h3>
<pre><code class="language-bash"># Analyze Python files only
debtmap analyze . --languages python

# Analyze specific Python directory
debtmap analyze src --languages python
</code></pre>
<h3 id="coverage-integration-with-pytest"><a class="header" href="#coverage-integration-with-pytest">Coverage Integration with pytest</a></h3>
<p>Generate coverage and analyze risk:</p>
<pre><code class="language-bash"># Generate LCOV coverage with pytest
pytest --cov --cov-report=lcov

# Analyze with coverage data
debtmap analyze . \
  --languages python \
  --lcov coverage.lcov
</code></pre>
<h3 id="python-specific-patterns"><a class="header" href="#python-specific-patterns">Python-Specific Patterns</a></h3>
<pre><code class="language-bash"># Focus on testing gaps in Python code
debtmap analyze . \
  --languages python \
  --filter Testing

# Find god objects in Python modules
debtmap analyze . \
  --languages python \
  --filter Architecture
</code></pre>
<h3 id="example-configuration-for-python-projects"><a class="header" href="#example-configuration-for-python-projects">Example Configuration for Python Projects</a></h3>
<p>Create <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[languages]
enabled = ["python"]

[thresholds]
complexity = 12
max_function_lines = 40

[ignore]
patterns = [
  "**/*_test.py",
  "tests/**",
  ".venv/**",
  "**/__pycache__/**",
]

[god_object]
enabled = true
max_methods = 15
max_responsibilities = 4
</code></pre>
<h2 id="javascripttypescript-1"><a class="header" href="#javascripttypescript-1">JavaScript/TypeScript</a></h2>
<h3 id="analyzing-jsts-projects"><a class="header" href="#analyzing-jsts-projects">Analyzing JS/TS Projects</a></h3>
<pre><code class="language-bash"># Analyze JavaScript and TypeScript
debtmap analyze . --languages javascript,typescript

# TypeScript only
debtmap analyze . --languages typescript
</code></pre>
<h3 id="coverage-integration-with-jest"><a class="header" href="#coverage-integration-with-jest">Coverage Integration with Jest</a></h3>
<pre><code class="language-bash"># Generate LCOV with Jest
jest --coverage --coverageReporters=lcov

# Analyze with coverage
debtmap analyze . \
  --languages javascript,typescript \
  --lcov coverage/lcov.info
</code></pre>
<h3 id="nodejs-project-patterns"><a class="header" href="#nodejs-project-patterns">Node.js Project Patterns</a></h3>
<pre><code class="language-bash"># Exclude node_modules and focus on source
debtmap analyze src --languages javascript,typescript

# With custom complexity thresholds for JS
debtmap analyze . \
  --languages javascript,typescript \
  --threshold-complexity 10
</code></pre>
<h3 id="typescript-configuration-example"><a class="header" href="#typescript-configuration-example">TypeScript Configuration Example</a></h3>
<p>Create <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[languages]
enabled = ["typescript", "javascript"]

[thresholds]
complexity = 10
max_function_lines = 50

[ignore]
patterns = [
  "node_modules/**",
  "**/*.test.ts",
  "**/*.spec.ts",
  "dist/**",
  "build/**",
  "**/*.d.ts",
]
</code></pre>
<h3 id="monorepo-analysis"><a class="header" href="#monorepo-analysis">Monorepo Analysis</a></h3>
<pre><code class="language-bash"># Analyze specific package
debtmap analyze packages/api --languages typescript

# Analyze all packages, grouped by category
debtmap analyze packages \
  --languages typescript \
  --group-by-category
</code></pre>
<h2 id="ci-integration-1"><a class="header" href="#ci-integration-1">CI Integration</a></h2>
<h3 id="github-actions-3"><a class="header" href="#github-actions-3">GitHub Actions</a></h3>
<p>Complete workflow example (from <code>.github/workflows/debtmap.yml</code>):</p>
<pre><code class="language-yaml">name: Debtmap

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  validate:
    name: Technical Debt Validation
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        fetch-depth: 0

    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        components: rustfmt, clippy

    - name: Cache cargo dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-

    - name: Install cargo-tarpaulin
      run: |
        if ! command -v cargo-tarpaulin &amp;&gt; /dev/null; then
          cargo install cargo-tarpaulin
        else
          echo "cargo-tarpaulin already installed"
        fi

    - name: Build debtmap
      run: cargo build --release

    - name: Generate coverage data
      run: cargo tarpaulin --config .tarpaulin.toml --out Lcov --timeout 300

    - name: Run debtmap validation with coverage
      run: |
        if [ -f "target/coverage/lcov.info" ]; then
          ./target/release/debtmap validate . --coverage-file target/coverage/lcov.info --format json --output debtmap-report.json
        else
          echo "Warning: LCOV file not found, running validation without coverage data"
          ./target/release/debtmap validate . --format json --output debtmap-report.json
        fi

    - name: Upload debtmap report and coverage
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: debtmap-analysis-artifacts
        path: |
          debtmap-report.json
          target/coverage/lcov.info
        retention-days: 7
</code></pre>
<h3 id="gitlab-ci-3"><a class="header" href="#gitlab-ci-3">GitLab CI</a></h3>
<pre><code class="language-yaml">debtmap:
  stage: quality
  image: rust:latest
  script:
    # Install debtmap
    - cargo install debtmap

    # Run tests with coverage (generates LCOV format)
    - cargo install cargo-tarpaulin
    - cargo tarpaulin --out Lcov

    # Validate with debtmap (using LCOV format)
    - debtmap validate .
        --coverage-file lcov.info
        --format json
        --output debtmap-report.json
  artifacts:
    paths:
      - lcov.info
      - debtmap-report.json
    expire_in: 1 week
</code></pre>
<h3 id="circleci-1"><a class="header" href="#circleci-1">CircleCI</a></h3>
<pre><code class="language-yaml">version: 2.1

jobs:
  debtmap:
    docker:
      - image: cimg/rust:1.75
    steps:
      - checkout

      - run:
          name: Install debtmap
          command: cargo install debtmap

      - run:
          name: Generate coverage
          command: |
            cargo install cargo-tarpaulin
            cargo tarpaulin --out Lcov

      - run:
          name: Run debtmap
          command: |
            debtmap validate . \
              --coverage-file lcov.info \
              --format json \
              --output debtmap.json

      - store_artifacts:
          path: debtmap.json

workflows:
  version: 2
  build:
    jobs:
      - debtmap
</code></pre>
<h3 id="using-debtmap-validate-for-pr-gates"><a class="header" href="#using-debtmap-validate-for-pr-gates">Using debtmap validate for PR Gates</a></h3>
<pre><code class="language-bash"># Fail build if thresholds are exceeded
debtmap validate . --coverage-file lcov.info

# With custom thresholds
debtmap validate . \
  --coverage-file lcov.info \
  --threshold-complexity 15

# Exit code 0 if passing, 1 if failing
</code></pre>
<h3 id="compare-command-in-ci"><a class="header" href="#compare-command-in-ci">Compare Command in CI</a></h3>
<p>Track technical debt trends over time:</p>
<pre><code class="language-bash"># Generate baseline (on main branch)
debtmap analyze . --format json --output baseline.json

# After PR changes
debtmap analyze . --format json --output current.json

# Compare and fail if regressions detected
debtmap compare \
  --before baseline.json \
  --after current.json \
  --format json
</code></pre>
<h2 id="output-formats-4"><a class="header" href="#output-formats-4">Output Formats</a></h2>
<h3 id="terminal-output-default"><a class="header" href="#terminal-output-default">Terminal Output (Default)</a></h3>
<p>The default terminal output is prettified with colors and priorities:</p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.lcov --top 3
</code></pre>
<p>Example output:</p>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    PRIORITY TECHNICAL DEBT FIXES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéØ TOP 3 RECOMMENDATIONS (by unified priority)

#1 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/analyzers/rust.rs:38 parse_function()
‚îú‚îÄ ACTION: Add 6 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=6, cognitive=8, nesting=2, lines=32
‚îú‚îÄ DEPENDENCIES: 0 upstream, 11 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity

üìä TOTAL DEBT SCORE: 4907
üìà OVERALL COVERAGE: 67.12%
</code></pre>
<h3 id="json-output-3"><a class="header" href="#json-output-3">JSON Output</a></h3>
<p>Machine-readable format for CI/CD integration:</p>
<pre><code class="language-bash">debtmap analyze . --format json --output report.json
</code></pre>
<p><strong>Using JSON output programmatically:</strong></p>
<pre><code class="language-bash"># Extract total debt score
debtmap analyze . --format json | jq '.total_debt_score'

# Count critical items
debtmap analyze . --format json | jq '[.items[] | select(.unified_score.final_score &gt;= 8)] | length'

# Get top 5 functions by score
debtmap analyze . --format json | jq '.items | sort_by(-.unified_score.final_score) | .[0:5] | .[].location'

# Extract all test gap items
debtmap analyze . --format json | jq '[.items[] | select(.debt_type == "TestGap")]'
</code></pre>
<p>Structure:</p>
<pre><code class="language-json">{
  "items": [
    {
      "location": {
        "file": "src/main.rs",
        "function": "process_data",
        "line": 42
      },
      "debt_type": "TestGap",
      "unified_score": {
        "complexity_factor": 3.2,
        "coverage_factor": 10.0,
        "dependency_factor": 2.5,
        "role_multiplier": 1.2,
        "final_score": 9.4
      },
      "function_role": "BusinessLogic",
      "recommendation": {
        "action": "Add unit tests",
        "details": "Add 6 unit tests for full coverage",
        "effort_estimate": "2-3 hours"
      },
      "expected_impact": {
        "risk_reduction": 3.9,
        "complexity_reduction": 0,
        "coverage_improvement": 100
      }
    }
  ],
  "overall_coverage": 67.12,
  "total_debt_score": 4907
}
</code></pre>
<h3 id="markdown-report"><a class="header" href="#markdown-report">Markdown Report</a></h3>
<pre><code class="language-bash"># Standard markdown report
debtmap analyze . --format markdown --output DEBT_REPORT.md

# Summary level for executives (minimal detail)
debtmap analyze . --format markdown --detail-level summary --output SUMMARY.md

# Standard level for team review (default)
debtmap analyze . --format markdown --detail-level standard --output DEBT.md

# Comprehensive level for deep analysis
debtmap analyze . --format markdown --detail-level comprehensive --output DETAILED.md

# Debug level for troubleshooting
debtmap analyze . --format markdown --detail-level debug --output DEBUG.md
</code></pre>
<p><strong>Detail levels:</strong></p>
<ul>
<li><strong>summary</strong>: Executive summary with key metrics and top issues only</li>
<li><strong>standard</strong>: Balanced detail suitable for team reviews (default)</li>
<li><strong>comprehensive</strong>: Full details including all debt items and analysis</li>
<li><strong>debug</strong>: Maximum detail including AST information and parser internals</li>
</ul>
<p><strong>Use cases:</strong></p>
<ul>
<li>Summary: Management reports, PR comments</li>
<li>Standard: Regular team reviews</li>
<li>Comprehensive: Deep dives, refactoring planning</li>
<li>Debug: Troubleshooting debtmap behavior</li>
</ul>
<p>Great for documentation or PR comments.</p>
<h3 id="understanding-output-formats-1"><a class="header" href="#understanding-output-formats-1">Understanding Output Formats</a></h3>
<pre><code class="language-bash"># JSON output (default is legacy format)
debtmap analyze . --format json

# Unified JSON format (alternative to legacy)
debtmap analyze . --format json --output-format unified

# Legacy JSON format (default, for backward compatibility)
debtmap analyze . --format json --output-format legacy

# Output format options: terminal, json, markdown
debtmap analyze . --format terminal
</code></pre>
<p><strong>Unified vs Legacy JSON Formats:</strong></p>
<p>The unified format provides a consistent structure with a <code>type</code> field to distinguish between different item types, replacing the File/Function wrapper objects used in legacy format.</p>
<p><strong>Legacy format (default):</strong></p>
<pre><code class="language-json">{
  "items": [
    {"File": {"path": "src/main.rs", "score": 45.2}},
    {"Function": {"name": "process", "complexity": 12}}
  ]
}
</code></pre>
<p><strong>Unified format:</strong></p>
<pre><code class="language-json">{
  "items": [
    {"type": "file", "path": "src/main.rs", "score": 45.2},
    {"type": "function", "name": "process", "complexity": 12}
  ]
}
</code></pre>
<p><strong>Key differences:</strong></p>
<ul>
<li><strong>Unified format</strong>: Consistent structure with <code>type</code> discriminator field, easier to parse programmatically, better for new integrations</li>
<li><strong>Legacy format</strong>: Uses wrapper objects for backward compatibility with existing tooling and scripts</li>
</ul>
<p>Use unified format for new integrations and tools. Use legacy format when working with existing debtmap analysis pipelines.</p>
<h2 id="advanced-usage-1"><a class="header" href="#advanced-usage-1">Advanced Usage</a></h2>
<h3 id="design-pattern-detection-1"><a class="header" href="#design-pattern-detection-1">Design Pattern Detection</a></h3>
<p>Detect design patterns in your codebase to understand architectural choices and identify potential overuse of certain patterns:</p>
<pre><code class="language-bash"># Detect specific design patterns
debtmap analyze . --patterns observer,singleton,factory

# Adjust pattern confidence threshold (0.0-1.0, default: 0.7)
debtmap analyze . --pattern-threshold 0.8

# Show uncertain pattern matches with warnings
debtmap analyze . --show-pattern-warnings

# Disable pattern detection entirely
debtmap analyze . --no-pattern-detection
</code></pre>
<p><strong>Available patterns:</strong></p>
<ul>
<li><code>observer</code> - Event listener registrations, callback patterns</li>
<li><code>singleton</code> - Static instance management</li>
<li><code>factory</code> - Object creation methods</li>
<li><code>strategy</code> - Algorithm selection via traits/interfaces</li>
<li><code>callback</code> - Function passing and invocation</li>
<li><code>template_method</code> - Abstract methods with concrete implementations</li>
</ul>
<p><strong>Use cases:</strong></p>
<ul>
<li>Identify architectural patterns in unfamiliar codebases</li>
<li>Detect potential overuse of certain patterns (e.g., too many singletons)</li>
<li>Understand code organization and design decisions</li>
</ul>
<h3 id="dead-code-and-public-api-analysis"><a class="header" href="#dead-code-and-public-api-analysis">Dead Code and Public API Analysis</a></h3>
<p>Control how Debtmap detects public APIs to prevent false positives when analyzing libraries vs CLI tools:</p>
<pre><code class="language-bash"># Analyze with public API awareness (default for libraries)
debtmap analyze . --context

# Disable public API heuristics (useful for CLI tools)
debtmap analyze . --no-public-api-detection

# Adjust public API confidence threshold (default: 0.7)
debtmap analyze . --public-api-threshold 0.8
</code></pre>
<p><strong>When to use:</strong></p>
<ul>
<li><strong>Libraries</strong>: Keep default public API detection to avoid flagging exported functions as unused</li>
<li><strong>CLI tools</strong>: Use <code>--no-public-api-detection</code> since there‚Äôs no public API</li>
<li><strong>Mixed projects</strong>: Adjust threshold based on false positive rate</li>
</ul>
<p><strong>What it detects:</strong></p>
<ul>
<li>Functions exported in <code>lib.rs</code> or <code>api.rs</code></li>
<li>Public trait implementations</li>
<li>Functions matching API naming patterns</li>
<li>Prevents false positives for ‚Äúunused‚Äù library functions</li>
</ul>
<h3 id="context-aware-analysis-3"><a class="header" href="#context-aware-analysis-3">Context-Aware Analysis</a></h3>
<p>Enable advanced context providers for more accurate prioritization:</p>
<pre><code class="language-bash"># Enable all context providers for comprehensive analysis
debtmap analyze . \
  --context \
  --context-providers critical_path,dependency,git_history
</code></pre>
<p><strong>Context Providers:</strong></p>
<p><strong>critical_path</strong> - Identifies functions on critical execution paths</p>
<ul>
<li>Analyzes call graph to find frequently-called functions</li>
<li>Prioritizes functions that affect many code paths</li>
<li>Use for: Understanding impact of potential failures</li>
</ul>
<p><strong>dependency</strong> - Analyzes dependency impact and cascade effects</p>
<ul>
<li>Tracks caller/callee relationships</li>
<li>Calculates cascade impact of changes</li>
<li>Use for: Understanding change propagation and refactoring risk</li>
</ul>
<p><strong>git_history</strong> - Tracks change frequency and churn</p>
<ul>
<li>Analyzes git blame and commit history</li>
<li>Identifies frequently-changed functions</li>
<li>Use for: Finding volatile code that needs stabilization</li>
</ul>
<p><strong>Example workflows:</strong></p>
<pre><code class="language-bash"># Find volatile high-complexity code
debtmap analyze . --context --context-providers git_history

# Understand refactoring impact
debtmap analyze . --context --context-providers dependency

# Disable slow provider for faster analysis
debtmap analyze . --context --disable-context git_history
</code></pre>
<h3 id="multi-pass-analysis-2"><a class="header" href="#multi-pass-analysis-2">Multi-Pass Analysis</a></h3>
<pre><code class="language-bash"># Multi-pass with attribution tracking
debtmap analyze . --multi-pass --attribution

# Shows which functions contribute to which patterns
</code></pre>
<h3 id="cache-management-2"><a class="header" href="#cache-management-2">Cache Management</a></h3>
<pre><code class="language-bash"># Show cache statistics
debtmap analyze . --cache-stats

# Clear cache before analysis
debtmap analyze . --clear-cache

# Force cache rebuild
debtmap analyze . --force-cache-rebuild

# Use per-project cache (default)
debtmap analyze . --cache-location local

# Use shared system-wide cache for faster multi-project analysis
debtmap analyze . --cache-location shared

# Use custom cache directory
debtmap analyze . --cache-location /custom/path/to/cache
</code></pre>
<p><strong>Cache strategies:</strong></p>
<ul>
<li><strong>local</strong>: Per-project cache in <code>.debtmap-cache/</code> (default)</li>
<li><strong>shared</strong>: Shared cache directory for all projects (faster when analyzing multiple projects)</li>
<li><strong>custom path</strong>: Specify exact cache location</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Shared cache reduces analysis time when working on multiple projects</li>
<li>Custom path useful for CI systems with specific cache directories</li>
<li>Local cache isolates project-specific analysis results</li>
</ul>
<h3 id="aggregation-methods-1"><a class="header" href="#aggregation-methods-1">Aggregation Methods</a></h3>
<pre><code class="language-bash"># Use logarithmic sum for aggregation
debtmap analyze . --aggregation-method logarithmic_sum

# Standard sum (default)
debtmap analyze . --aggregation-method sum
</code></pre>
<h3 id="filtering-and-grouping"><a class="header" href="#filtering-and-grouping">Filtering and Grouping</a></h3>
<pre><code class="language-bash"># Group results by debt category
debtmap analyze . --group-by-category

# Filter specific categories
debtmap analyze . --filter Architecture,Testing

# Show only high-priority items
debtmap analyze . --min-priority high --top 10
</code></pre>
<h3 id="call-graph-debugging"><a class="header" href="#call-graph-debugging">Call Graph Debugging</a></h3>
<p>Debug and validate call graph construction for accurate dependency analysis:</p>
<pre><code class="language-bash"># Enable call graph debugging output
debtmap analyze . --debug-call-graph

# Trace specific function resolution
debtmap analyze . --trace-function my_function --trace-function another_fn

# Validate call graph structure (detect orphans and cycles)
debtmap analyze . --validate-call-graph

# Show detailed caller/callee relationships
debtmap analyze . --show-dependencies
</code></pre>
<p><strong>Use cases:</strong></p>
<p><strong>Troubleshooting resolution failures:</strong></p>
<pre><code class="language-bash"># When a function isn't being analyzed correctly
debtmap analyze . --debug-call-graph --trace-function problematic_function
</code></pre>
<p><strong>Understanding function relationships:</strong></p>
<pre><code class="language-bash"># See who calls what
debtmap analyze . --show-dependencies --top 10
</code></pre>
<p><strong>Validating call graph integrity:</strong></p>
<pre><code class="language-bash"># Detect cycles and orphaned nodes
debtmap analyze . --validate-call-graph
</code></pre>
<p>Output includes:</p>
<ul>
<li>Resolution statistics (success/failure rates)</li>
<li>DFS cycle detection results</li>
<li>Orphan node detection</li>
<li>Cross-module resolution details</li>
</ul>
<h3 id="verbosity-levels-1"><a class="header" href="#verbosity-levels-1">Verbosity Levels</a></h3>
<p>Control the level of diagnostic output for debugging and understanding analysis decisions:</p>
<pre><code class="language-bash"># Level 1: Show main score factors
debtmap analyze . -v

# Level 2: Show detailed calculations
debtmap analyze . -vv

# Level 3: Show all debug information
debtmap analyze . -vvv

# Long form also available
debtmap analyze . --verbose

# Show macro expansion details (Rust)
debtmap analyze . --verbose-macro-warnings --show-macro-stats
</code></pre>
<p><strong>What each level shows:</strong></p>
<ul>
<li><strong>-v</strong>: Score factor breakdowns and purity distribution in god object analysis</li>
<li><strong>-vv</strong>: Detailed calculations, coverage lookups, and metric computations</li>
<li><strong>-vvv</strong>: Full debug information including AST details and parser internals</li>
</ul>
<h3 id="understanding-metrics-2"><a class="header" href="#understanding-metrics-2">Understanding Metrics</a></h3>
<p>Learn how Debtmap calculates complexity metrics and scores:</p>
<pre><code class="language-bash"># Show metric definitions and formulas
debtmap analyze . --explain-metrics
</code></pre>
<p><strong>What it explains:</strong></p>
<p><strong>Measured metrics</strong> (counted from AST):</p>
<ul>
<li><code>cyclomatic_complexity</code> - Decision points (if, match, while, for, etc.)</li>
<li><code>cognitive_complexity</code> - Weighted readability measure</li>
<li><code>nesting_depth</code> - Maximum nested control structure levels</li>
<li><code>loc</code> - Lines of code in function</li>
<li><code>parameter_count</code> - Number of function parameters</li>
</ul>
<p><strong>Estimated metrics</strong> (formula-based approximations):</p>
<ul>
<li><code>est_branches</code> - Estimated execution paths
<ul>
<li>Formula: <code>max(nesting_depth, 1) √ó cyclomatic_complexity √∑ 3</code></li>
<li>Purpose: Estimate test cases needed for branch coverage</li>
<li>Note: This is an ESTIMATE, not a count from the AST</li>
</ul>
</li>
</ul>
<p><strong>Scoring formulas:</strong></p>
<ul>
<li>Complexity factor calculation</li>
<li>Coverage factor weight</li>
<li>Dependency factor impact</li>
<li>Role multiplier application</li>
<li>Final score aggregation</li>
</ul>
<p><strong>Use ‚Äìexplain-metrics when:</strong></p>
<ul>
<li>First learning debtmap</li>
<li>Questioning why something is flagged</li>
<li>Understanding score differences</li>
<li>Teaching team members about technical debt metrics</li>
</ul>
<h3 id="ast-functional-analysis"><a class="header" href="#ast-functional-analysis">AST Functional Analysis</a></h3>
<p>Enable AST-based functional composition analysis to detect functional programming patterns:</p>
<pre><code class="language-bash"># Enable AST-based functional composition analysis
debtmap analyze . --ast-functional-analysis

# Combine with verbose mode to see purity analysis
debtmap analyze . --ast-functional-analysis -v
</code></pre>
<p><strong>What it detects:</strong></p>
<ul>
<li>Pure functions (no side effects, immutable)</li>
<li>Impure functions (I/O, mutations, side effects)</li>
<li>Function composition patterns</li>
<li>Immutability patterns</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Distinguishes functional patterns from god objects (see purity weighting in God Object Detection section)</li>
<li>Identifies opportunities for better testability</li>
<li>Highlights side effect boundaries</li>
<li>Supports functional programming code reviews</li>
</ul>
<p><strong>Example output with -v:</strong></p>
<pre><code>PURITY DISTRIBUTION:
  Pure: 70 functions (65%) ‚Üí complexity weight: 6.3
  Impure: 37 functions (35%) ‚Üí complexity weight: 14.0
  Total weighted complexity: 20.3
</code></pre>
<h3 id="parallel-processing-control"><a class="header" href="#parallel-processing-control">Parallel Processing Control</a></h3>
<p>Control thread count for CPU-bound systems or to limit resource usage in CI environments. By default, Debtmap uses all available cores for optimal performance.</p>
<pre><code class="language-bash"># Use 8 parallel jobs
debtmap analyze . --jobs 8

# Disable parallel processing
debtmap analyze . --no-parallel
</code></pre>
<p><strong>When to adjust:</strong></p>
<ul>
<li><strong>CI environments</strong>: Limit thread count to avoid resource contention with other jobs</li>
<li><strong>CPU-bound systems</strong>: Reduce threads if machine is under load</li>
<li><strong>Large codebases</strong>: Default parallelism provides best performance</li>
<li><strong>Debugging</strong>: Use <code>--no-parallel</code> to simplify sequential execution when troubleshooting</li>
</ul>
<h2 id="configuration-examples-2"><a class="header" href="#configuration-examples-2">Configuration Examples</a></h2>
<h3 id="basic-configuration"><a class="header" href="#basic-configuration">Basic Configuration</a></h3>
<p>Create <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[thresholds]
complexity = 15
duplication = 25
max_function_lines = 50
max_nesting_depth = 4

[languages]
enabled = ["rust", "python"]

[ignore]
patterns = [
  "tests/**/*",
  "**/*.test.rs",
  "target/**",
]
</code></pre>
<h3 id="entropy-based-complexity-1"><a class="header" href="#entropy-based-complexity-1">Entropy-Based Complexity</a></h3>
<pre><code class="language-toml">[entropy]
enabled = true
weight = 0.5
use_classification = true
pattern_threshold = 0.7
entropy_threshold = 0.4
branch_threshold = 0.8
max_combined_reduction = 0.3
</code></pre>
<p>This reduces false positives for repetitive code patterns.</p>
<h3 id="custom-scoring-weights"><a class="header" href="#custom-scoring-weights">Custom Scoring Weights</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.40      # Test coverage gaps
complexity = 0.40    # Code complexity
dependency = 0.20    # Dependency criticality
</code></pre>
<h3 id="god-object-detection-tuning"><a class="header" href="#god-object-detection-tuning">God Object Detection Tuning</a></h3>
<pre><code class="language-toml">[god_object]
enabled = true

# Purity-based scoring reduces false positives for functional code
# Pure functions (no side effects) get lower weight in god object scoring
purity_weight_pure = 0.3    # Pure function complexity weight (default: 0.3)
purity_weight_impure = 1.0  # Impure function complexity weight (default: 1.0)

# Rust-specific thresholds
[god_object.rust]
max_methods = 25
max_fields = 15
max_traits = 5
max_lines = 400
max_complexity = 50

# Python-specific thresholds
[god_object.python]
max_methods = 20
max_fields = 12
max_lines = 350
max_complexity = 45

# JavaScript/TypeScript-specific thresholds
[god_object.javascript]
max_methods = 20
max_fields = 12
max_lines = 300
max_complexity = 40
</code></pre>
<p><strong>Why purity weighting matters:</strong>
See the Purity-Weighted God Object Scoring section for detailed explanation. In short:</p>
<ul>
<li>Modules with many pure helper functions avoid false god object flags</li>
<li>Focus shifts to modules with excessive stateful/impure code</li>
<li>Functional programming patterns are properly recognized</li>
</ul>
<p><strong>Example:</strong></p>
<ul>
<li>Module with 100 pure functions ‚Üí Normal (functional design) ‚úÖ</li>
<li>Module with 100 impure functions ‚Üí God object detected ‚úÖ</li>
</ul>
<h3 id="external-api-configuration-1"><a class="header" href="#external-api-configuration-1">External API Configuration</a></h3>
<p>For libraries (not CLI tools):</p>
<pre><code class="language-toml">[external_api]
detect_external_api = true

api_functions = [
  "parse",
  "Parser::new",
  "client::connect",
]

api_files = [
  "src/lib.rs",
  "src/api.rs",
  "src/public/*.rs",
]
</code></pre>
<h3 id="complete-multi-language-configuration"><a class="header" href="#complete-multi-language-configuration">Complete Multi-Language Configuration</a></h3>
<pre><code class="language-toml">[thresholds]
complexity = 12
duplication = 30
max_file_lines = 400
max_function_lines = 40
minimum_debt_score = 1.0
minimum_cyclomatic_complexity = 2

[entropy]
enabled = true
weight = 0.5

[scoring]
coverage = 0.40
complexity = 0.40
dependency = 0.20

[languages]
enabled = ["rust", "python", "javascript", "typescript"]

[ignore]
patterns = [
  # Tests
  "tests/**/*",
  "**/*.test.*",
  "**/*_test.*",

  # Build artifacts
  "target/**",
  "dist/**",
  "build/**",
  "node_modules/**",

  # Python
  ".venv/**",
  "**/__pycache__/**",

  # Generated code
  "*.generated.*",
  "*.pb.*",
]

[god_object]
enabled = true
max_methods = 18
max_fields = 12
</code></pre>
<h2 id="compare-command"><a class="header" href="#compare-command">Compare Command</a></h2>
<p>The <code>compare</code> command helps validate that refactoring achieved its goals.</p>
<h3 id="basic-comparison-workflow"><a class="header" href="#basic-comparison-workflow">Basic Comparison Workflow</a></h3>
<pre><code class="language-bash"># 1. Generate baseline before refactoring
debtmap analyze . --format json --output before.json

# 2. Make your code improvements
#    ... refactor, add tests, etc ...

# 3. Generate new analysis
debtmap analyze . --format json --output after.json

# 4. Compare and verify improvements
debtmap compare --before before.json --after after.json
</code></pre>
<h3 id="target-specific-comparison"><a class="header" href="#target-specific-comparison">Target-Specific Comparison</a></h3>
<p>Focus on whether a specific function improved:</p>
<pre><code class="language-bash"># Target format: file:function:line
debtmap compare \
  --before before.json \
  --after after.json \
  --target-location src/main.rs:process_data:100
</code></pre>
<h3 id="using-with-implementation-plans"><a class="header" href="#using-with-implementation-plans">Using with Implementation Plans</a></h3>
<p>Extract target automatically from plan files:</p>
<pre><code class="language-bash"># If IMPLEMENTATION_PLAN.md contains:
# **Target**: src/parser.rs:parse_expression:45

debtmap compare \
  --before before.json \
  --after after.json \
  --plan IMPLEMENTATION_PLAN.md
</code></pre>
<h3 id="output-formats-5"><a class="header" href="#output-formats-5">Output Formats</a></h3>
<pre><code class="language-bash"># JSON output (default)
debtmap compare --before before.json --after after.json

# Terminal output (explicit)
debtmap compare \
  --before before.json \
  --after after.json \
  --format terminal

# JSON for CI integration (explicit output file)
debtmap compare \
  --before before.json \
  --after after.json \
  --format json \
  --output comparison.json

# Markdown report
debtmap compare \
  --before before.json \
  --after after.json \
  --format markdown \
  --output COMPARISON.md
</code></pre>
<h3 id="interpreting-results-2"><a class="header" href="#interpreting-results-2">Interpreting Results</a></h3>
<p><strong>Target Status:</strong></p>
<ul>
<li><strong>Resolved</strong>: Function no longer appears (complexity reduced below threshold)</li>
<li><strong>Improved</strong>: Metrics improved (complexity down, coverage up)</li>
<li><strong>Unchanged</strong>: No significant change</li>
<li><strong>Regressed</strong>: Metrics got worse</li>
<li><strong>Not Found</strong>: Target not found in baseline</li>
</ul>
<p><strong>Overall Trend:</strong></p>
<ul>
<li><strong>Improving</strong>: More items resolved/improved than regressed</li>
<li><strong>Stable</strong>: No significant changes</li>
<li><strong>Regressing</strong>: New critical debt introduced</li>
</ul>
<p><strong>Example Output:</strong></p>
<pre><code>Target Status: Resolved ‚úÖ
- src/parser.rs:parse_expression:45 reduced from complexity 22 to 8
- Coverage improved from 0% to 85%

Overall Trend: Improving
- 3 items resolved
- 2 items improved
- 0 regressions
- Total debt score: 450 ‚Üí 285 (-37%)
</code></pre>
<h3 id="ci-integration-2"><a class="header" href="#ci-integration-2">CI Integration</a></h3>
<p>Use in pull request validation:</p>
<pre><code class="language-bash"># In CI script
debtmap compare \
  --before baseline.json \
  --after current.json \
  --format json | jq -e '.overall_trend == "Improving"'

# Exit code 0 if improving, 1 otherwise
</code></pre>
<h2 id="tips-and-best-practices"><a class="header" href="#tips-and-best-practices">Tips and Best Practices</a></h2>
<ol>
<li><strong>Start Simple</strong>: Begin with basic analysis, add coverage later</li>
<li><strong>Use Filters</strong>: Focus on one category at a time (Architecture, Testing)</li>
<li><strong>Iterate</strong>: Run analysis, fix top items, repeat</li>
<li><strong>CI Integration</strong>: Automate validation in your build pipeline</li>
<li><strong>Track Progress</strong>: Use <code>compare</code> command to validate improvements</li>
<li><strong>Configure Thresholds</strong>: Adjust to match your team‚Äôs standards</li>
<li><strong>Leverage Coverage</strong>: Always include coverage data for accurate risk assessment</li>
</ol>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ul>
<li><a href="cli-reference.html">CLI Reference</a> - Complete CLI documentation</li>
<li><a href="analysis-guide.html">Analysis Guide</a> - Understanding analysis results</li>
<li><a href="configuration.html">Configuration</a> - Advanced configuration options</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="frequently-asked-questions-1"><a class="header" href="#frequently-asked-questions-1">Frequently Asked Questions</a></h1>
<p>Common questions about debtmap‚Äôs features, usage, and comparison with other tools.</p>
<h2 id="features--capabilities"><a class="header" href="#features--capabilities">Features &amp; Capabilities</a></h2>
<h3 id="whats-the-difference-between-measured-and-estimated-metrics"><a class="header" href="#whats-the-difference-between-measured-and-estimated-metrics">What‚Äôs the difference between measured and estimated metrics?</a></h3>
<p>Debtmap distinguishes between two types of metrics (Spec 118):</p>
<p><strong>Measured Metrics</strong> - Precise values from AST analysis:</p>
<ul>
<li><code>cyclomatic_complexity</code>: Exact count of decision points</li>
<li><code>cognitive_complexity</code>: Weighted readability measure</li>
<li><code>nesting_depth</code>: Maximum nesting levels</li>
<li><code>loc</code>: Lines of code</li>
<li>These are suitable for CI/CD quality gates and thresholds</li>
</ul>
<p><strong>Estimated Metrics</strong> - Heuristic approximations:</p>
<ul>
<li><code>est_branches</code>: Estimated execution paths (formula-based)
<ul>
<li>Formula: <code>max(nesting, 1) √ó cyclomatic √∑ 3</code></li>
<li>Use for: Estimating test cases needed</li>
<li>Don‚Äôt use for: Hard quality gates</li>
</ul>
</li>
</ul>
<p><strong>Why it matters:</strong></p>
<ul>
<li>Use <strong>measured</strong> metrics for thresholds and gates (precise, repeatable)</li>
<li>Use <strong>estimated</strong> metrics for prioritization and effort estimation (heuristic, approximate)</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-bash"># GOOD: Use measured metric for quality gate
debtmap validate . --threshold-complexity 15

# GOOD: Use estimated metric for test prioritization
debtmap analyze . --top 10  # Considers est_branches for ranking
</code></pre>
<p>See <a href="metrics-reference.html">Metrics Reference</a> for complete details.</p>
<h3 id="what-is-entropy-based-complexity-analysis"><a class="header" href="#what-is-entropy-based-complexity-analysis">What is entropy-based complexity analysis?</a></h3>
<p>Entropy analysis uses information theory to distinguish between genuinely complex code and repetitive pattern-based code. Traditional cyclomatic complexity counts branches, but not all branches are equal in cognitive load.</p>
<p>For example, a function with 20 identical if/return validation checks has the same cyclomatic complexity as a function with 20 diverse conditional branches handling different business logic. Entropy analysis gives the validation function a much lower effective complexity score because it follows a simple, repetitive pattern.</p>
<p><strong>Result:</strong> 60-75% reduction in false positives compared to traditional complexity metrics.</p>
<p><a href="why-debtmap.html#entropy-based-complexity-analysis">Read more in Why Debtmap?</a></p>
<h3 id="how-does-coverage-integration-work"><a class="header" href="#how-does-coverage-integration-work">How does coverage integration work?</a></h3>
<p>Debtmap reads LCOV format coverage data (generated by tools like <code>cargo-tarpaulin</code>, <code>pytest-cov</code>, or <code>jest</code>) and maps it to specific functions and branches. It then combines coverage percentages with complexity metrics to calculate risk scores.</p>
<p><strong>Key insight:</strong> A complex function with good test coverage is lower risk than a moderately complex function with no tests.</p>
<p><strong>Example workflow:</strong></p>
<pre><code class="language-bash"># Generate coverage data
cargo tarpaulin --out lcov --output-dir target/coverage

# Analyze with coverage integration
debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<p><a href="analysis-guide.html#coverage-integrated-analysis">See examples in Analysis Guide</a></p>
<h3 id="what-languages-are-supported"><a class="header" href="#what-languages-are-supported">What languages are supported?</a></h3>
<p><strong>Full support:</strong></p>
<ul>
<li>Rust (via <code>syn</code> crate - complete AST analysis)</li>
<li>Python (via <code>rustpython</code> - full Python 3.x support)</li>
</ul>
<p><strong>Partial support:</strong></p>
<ul>
<li>JavaScript (via <code>tree-sitter</code> - ES6+, JSX)</li>
<li>TypeScript (via <code>tree-sitter</code> - basic support)</li>
</ul>
<p><strong>Planned:</strong></p>
<ul>
<li>Go (target: Q2 2025)</li>
<li>Java (target: Q3 2025)</li>
<li>C/C++ (target: Q4 2025)</li>
</ul>
<p>Language support means: AST parsing, metric extraction, complexity calculation, and pattern detection.</p>
<h3 id="why-was-branches-renamed-to-est_branches"><a class="header" href="#why-was-branches-renamed-to-est_branches">Why was ‚Äúbranches‚Äù renamed to ‚Äúest_branches‚Äù?</a></h3>
<p>The metric was renamed in Spec 118 to make it clear that this is an <strong>estimated</strong> value, not a precise measurement.</p>
<p><strong>Problem with old name (‚Äúbranches‚Äù):</strong></p>
<ul>
<li>Users thought it was a direct count from AST analysis (it‚Äôs not)</li>
<li>Caused confusion with cyclomatic complexity (which counts actual branches)</li>
<li>Unclear that the value was formula-based</li>
</ul>
<p><strong>Benefits of new name (‚Äúest_branches‚Äù):</strong></p>
<ul>
<li>The ‚Äúest_‚Äù prefix makes the estimation explicit</li>
<li>Clearly distinguishes it from measured metrics</li>
<li>Sets correct user expectations</li>
</ul>
<p><strong>What changed:</strong></p>
<ul>
<li>Terminal output: <code>branches=8</code> ‚Üí <code>est_branches=8</code></li>
<li>Internal variable names updated for clarity</li>
<li>Documentation updated to explain the distinction</li>
</ul>
<p><strong>What didn‚Äôt change:</strong></p>
<ul>
<li>The formula remains the same: <code>max(nesting, 1) √ó cyclomatic √∑ 3</code></li>
<li>JSON output (this field was never serialized to JSON)</li>
<li>Scoring and prioritization logic</li>
</ul>
<p>See <a href="metrics-reference.html#terminology-change-spec-118">Metrics Reference</a> for more details.</p>
<h3 id="can-i-customize-the-complexity-thresholds"><a class="header" href="#can-i-customize-the-complexity-thresholds">Can I customize the complexity thresholds?</a></h3>
<p>Yes! Configure thresholds in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[thresholds]
cyclomatic_complexity = 10      # Flag functions above this
nesting_depth = 3               # Maximum nesting levels
loc = 200                       # Maximum lines per function
parameter_count = 4             # Maximum parameters

[scoring]
critical_threshold = 8.0        # Risk score for Critical tier
high_threshold = 5.0            # Risk score for High tier
moderate_threshold = 2.0        # Risk score for Moderate tier
</code></pre>
<p>See <a href="configuration.html#thresholds">Configuration</a> for all available options.</p>
<h3 id="does-debtmap-integrate-with-cicd"><a class="header" href="#does-debtmap-integrate-with-cicd">Does debtmap integrate with CI/CD?</a></h3>
<p>Yes! Use the <code>validate</code> command to enforce quality gates:</p>
<pre><code class="language-bash"># Fail build if critical or high-tier debt detected
debtmap validate . --max-critical 0 --max-high 5

# Exit codes:
# 0 = validation passed
# 1 = validation failed (debt exceeds thresholds)
# 2 = analysis error
</code></pre>
<p><strong>GitHub Actions example:</strong></p>
<pre><code class="language-yaml">- name: Check technical debt
  run: |
    cargo tarpaulin --out lcov --output-dir target/coverage
    debtmap validate . --lcov target/coverage/lcov.info \
      --max-critical 0 --max-high 10 \
      --format json --output debt-report.json

- name: Comment on PR
  uses: actions/github-script@v6
  with:
    script: |
      const report = require('./debt-report.json');
      // Post report as PR comment
</code></pre>
<p>See <a href="prodigy-integration.html">Prodigy Integration</a> for more CI/CD patterns.</p>
<h2 id="comparison-with-other-tools"><a class="header" href="#comparison-with-other-tools">Comparison with Other Tools</a></h2>
<h3 id="how-is-debtmap-different-from-sonarqube"><a class="header" href="#how-is-debtmap-different-from-sonarqube">How is debtmap different from SonarQube?</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>Debtmap</th><th>SonarQube</th></tr></thead><tbody>
<tr><td><strong>Speed</strong></td><td>10-100x faster (Rust)</td><td>Slower (JVM overhead)</td></tr>
<tr><td><strong>Coverage Integration</strong></td><td>‚úÖ Built-in LCOV</td><td>‚ö†Ô∏è Enterprise only</td></tr>
<tr><td><strong>Entropy Analysis</strong></td><td>‚úÖ Unique feature</td><td>‚ùå No</td></tr>
<tr><td><strong>Language Support</strong></td><td>Rust, Python, JS/TS</td><td>25+ languages</td></tr>
<tr><td><strong>Setup</strong></td><td>Single binary</td><td>JVM + server setup</td></tr>
<tr><td><strong>Cost</strong></td><td>Free, open-source</td><td>Free (basic) / Paid (advanced)</td></tr>
<tr><td><strong>Use Case</strong></td><td>Fast local analysis</td><td>Enterprise dashboards</td></tr>
</tbody></table>
</div>
<p><strong>When to use SonarQube:</strong> Multi-language monorepos, enterprise compliance, centralized quality dashboards.</p>
<p><strong>When to use debtmap:</strong> Rust-focused projects, local development workflow, coverage-driven prioritization.</p>
<h3 id="how-is-debtmap-different-from-codeclimate"><a class="header" href="#how-is-debtmap-different-from-codeclimate">How is debtmap different from CodeClimate?</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>Debtmap</th><th>CodeClimate</th></tr></thead><tbody>
<tr><td><strong>Deployment</strong></td><td>Local binary</td><td>Cloud service</td></tr>
<tr><td><strong>Coverage</strong></td><td>Built-in integration</td><td>Separate tool</td></tr>
<tr><td><strong>Entropy</strong></td><td>‚úÖ Yes</td><td>‚ùå No</td></tr>
<tr><td><strong>Speed</strong></td><td>Seconds</td><td>Minutes (uploads code)</td></tr>
<tr><td><strong>Privacy</strong></td><td>Code stays local</td><td>Code uploaded to cloud</td></tr>
<tr><td><strong>Cost</strong></td><td>Free</td><td>Free (open source) / Paid</td></tr>
</tbody></table>
</div>
<p><strong>When to use CodeClimate:</strong> Multi-language projects, prefer SaaS solutions, want maintainability ratings.</p>
<p><strong>When to use debtmap:</strong> Rust projects, privacy-sensitive code, fast local analysis, entropy-based scoring.</p>
<h3 id="should-i-replace-clippy-with-debtmap"><a class="header" href="#should-i-replace-clippy-with-debtmap">Should I replace clippy with debtmap?</a></h3>
<p><strong>No‚Äîuse both!</strong> They serve different purposes:</p>
<p><strong>clippy:</strong></p>
<ul>
<li>Focuses on idiomatic Rust patterns</li>
<li>Catches common mistakes (e.g., unnecessary clones, inefficient iterators)</li>
<li>Suggests Rust-specific best practices</li>
<li>Runs in milliseconds</li>
</ul>
<p><strong>debtmap:</strong></p>
<ul>
<li>Focuses on technical debt prioritization</li>
<li>Identifies untested complex code</li>
<li>Combines complexity with test coverage</li>
<li>Provides quantified recommendations</li>
</ul>
<p><strong>Recommended workflow:</strong></p>
<pre><code class="language-bash"># Fix clippy issues first (quick wins)
cargo clippy --all-targets --all-features -- -D warnings

# Then prioritize debt with debtmap
debtmap analyze . --lcov coverage/lcov.info --top 10
</code></pre>
<h3 id="should-i-replace-cargo-audit-with-debtmap"><a class="header" href="#should-i-replace-cargo-audit-with-debtmap">Should I replace cargo-audit with debtmap?</a></h3>
<p><strong>No‚Äîdifferent focus.</strong> cargo-audit scans for security vulnerabilities in dependencies. Debtmap analyzes code complexity and test coverage.</p>
<p><strong>Use both:</strong></p>
<ul>
<li><code>cargo-audit</code> - Security vulnerabilities in dependencies</li>
<li><code>cargo-geiger</code> - Unsafe code detection</li>
<li><code>debtmap</code> - Technical debt and test gaps</li>
</ul>
<h3 id="how-does-debtmap-compare-to-traditional-code-coverage-tools"><a class="header" href="#how-does-debtmap-compare-to-traditional-code-coverage-tools">How does debtmap compare to traditional code coverage tools?</a></h3>
<p>Debtmap doesn‚Äôt replace coverage tools‚Äîit <strong>augments</strong> them.</p>
<p><strong>Coverage tools (tarpaulin, pytest-cov, jest):</strong></p>
<ul>
<li>Measure what % of code is executed by tests</li>
<li>Tell you ‚Äúyou have 75% coverage‚Äù</li>
</ul>
<p><strong>Debtmap:</strong></p>
<ul>
<li>Reads coverage data from these tools</li>
<li>Prioritizes gaps based on code complexity</li>
<li>Tells you ‚Äúfunction X has 0% coverage and complexity 12‚Äîfix this first‚Äù</li>
</ul>
<p><strong>Value:</strong> Debtmap answers ‚Äúwhich 25% should I test first?‚Äù instead of just ‚Äú75% is tested.‚Äù</p>
<h2 id="usage--configuration"><a class="header" href="#usage--configuration">Usage &amp; Configuration</a></h2>
<h3 id="why-dont-entry-points-need-100-coverage"><a class="header" href="#why-dont-entry-points-need-100-coverage">Why don‚Äôt entry points need 100% coverage?</a></h3>
<p>Entry points (main functions, CLI handlers, framework integration code) are typically tested via <strong>integration tests</strong>, not unit tests. Unit testing them would mean mocking the entire runtime environment, which is brittle and low-value.</p>
<p>Debtmap recognizes common entry point patterns and lowers their priority for unit test coverage:</p>
<pre><pre class="playground"><code class="language-rust">// Entry point - integration test coverage expected
fn main() {
    // Debtmap: LOW priority for unit tests
}

// HTTP handler - integration test coverage expected
async fn handle_request(req: Request) -&gt; Response {
    // Debtmap: LOW priority for unit tests
}

// Core business logic - unit test coverage expected
fn calculate_discount(cart: &amp;Cart) -&gt; Discount {
    // Debtmap: HIGH priority for unit tests if uncovered
}</code></pre></pre>
<p>You can configure entry point detection in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[analysis]
entry_point_patterns = [
    "main",
    "handle_*",
    "run_*",
    "*_handler",
]
</code></pre>
<h3 id="how-do-i-exclude-test-files-from-analysis"><a class="header" href="#how-do-i-exclude-test-files-from-analysis">How do I exclude test files from analysis?</a></h3>
<p>By default, debtmap excludes common test directories. To customize:</p>
<p><strong>.debtmap.toml:</strong></p>
<pre><code class="language-toml">[analysis]
exclude_patterns = [
    "**/tests/**",
    "**/*_test.rs",
    "**/test_*.py",
    "**/*.test.ts",
    "**/target/**",
    "**/node_modules/**",
]
</code></pre>
<p><strong>Command line:</strong></p>
<pre><code class="language-bash">debtmap analyze . --exclude '**/tests/**' --exclude '**/*_test.rs'
</code></pre>
<h3 id="can-i-analyze-only-specific-files-or-directories"><a class="header" href="#can-i-analyze-only-specific-files-or-directories">Can I analyze only specific files or directories?</a></h3>
<p>Yes! Use the <code>--include</code> flag:</p>
<pre><code class="language-bash"># Analyze only src/ directory
debtmap analyze . --include 'src/**'

# Analyze specific files
debtmap analyze . --include 'src/main.rs' --include 'src/lib.rs'

# Combine include and exclude
debtmap analyze . --include 'src/**' --exclude 'src/generated/**'
</code></pre>
<h3 id="how-do-i-configure-ignore-patterns-for-generated-code"><a class="header" href="#how-do-i-configure-ignore-patterns-for-generated-code">How do I configure ignore patterns for generated code?</a></h3>
<p>Add to <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[analysis]
exclude_patterns = [
    "**/generated/**",
    "**/*.g.rs",           # Generated Rust
    "**/*_pb.py",          # Protobuf generated Python
    "**/*.generated.ts",   # Generated TypeScript
]
</code></pre>
<p>Or use comments in source files:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore-file - entire file ignored

fn complex_function() {
    // debtmap:ignore-start
    // ... complex generated code ...
    // debtmap:ignore-end
}
<span class="boring">}</span></code></pre></pre>
<h3 id="what-if-debtmap-reports-false-positives"><a class="header" href="#what-if-debtmap-reports-false-positives">What if debtmap reports false positives?</a></h3>
<p><strong>1. Verify entropy analysis is enabled</strong> (default in v0.2.8+):</p>
<pre><code class="language-toml">[analysis]
enable_entropy_analysis = true
</code></pre>
<p><strong>2. Adjust thresholds</strong> for your project‚Äôs needs:</p>
<pre><code class="language-toml">[thresholds]
cyclomatic_complexity = 15  # Increase if you have many validation functions
</code></pre>
<p><strong>3. Use ignore comments</strong> for specific functions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// debtmap:ignore - explanation for why this is acceptable
fn complex_but_acceptable() {
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>4. Report false positives:</strong> If you believe debtmap‚Äôs analysis is incorrect, please <a href="https://github.com/prodigy-tools/debtmap/issues">open an issue</a> with a code example. This helps improve the tool!</p>
<h3 id="how-accurate-is-the-risk-scoring"><a class="header" href="#how-accurate-is-the-risk-scoring">How accurate is the risk scoring?</a></h3>
<p>Risk scores are <strong>relative prioritization metrics</strong>, not absolute measures. They help you answer ‚Äúwhich code should I focus on first?‚Äù rather than ‚Äúexactly how risky is this code?‚Äù</p>
<p><strong>Factors affecting accuracy:</strong></p>
<ul>
<li><strong>Coverage data quality:</strong> Accurate if your tests exercise realistic scenarios</li>
<li><strong>Entropy analysis:</strong> Effective for common patterns; may miss domain-specific patterns</li>
<li><strong>Call graph:</strong> More accurate within single files than across modules</li>
<li><strong>Context:</strong> Cannot account for business criticality (you know your domain best)</li>
</ul>
<p><strong>Best practice:</strong> Use risk scores for prioritization, but apply your domain knowledge when deciding what to actually refactor or test.</p>
<h3 id="can-i-run-debtmap-on-a-ci-server"><a class="header" href="#can-i-run-debtmap-on-a-ci-server">Can I run debtmap on a CI server?</a></h3>
<p>Yes! Debtmap is designed for CI/CD pipelines:</p>
<p><strong>Performance:</strong></p>
<ul>
<li>Statically linked binary (no runtime dependencies)</li>
<li>Fast analysis (seconds, not minutes)</li>
<li>Low memory footprint</li>
</ul>
<p><strong>Exit codes:</strong></p>
<ul>
<li><code>0</code> - Analysis succeeded, validation passed</li>
<li><code>1</code> - Analysis succeeded, validation failed (debt thresholds exceeded)</li>
<li><code>2</code> - Analysis error (parse failure, invalid config, etc.)</li>
</ul>
<p><strong>Example CI configuration:</strong></p>
<pre><code class="language-yaml"># .github/workflows/debt-check.yml
name: Technical Debt Check

on: [pull_request]

jobs:
  debt-analysis:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install debtmap
        run: cargo install debtmap

      - name: Generate coverage
        run: cargo tarpaulin --out lcov

      - name: Analyze debt
        run: debtmap validate . --lcov lcov.info --max-critical 0
</code></pre>
<h2 id="troubleshooting-21"><a class="header" href="#troubleshooting-21">Troubleshooting</a></h2>
<h3 id="analysis-is-slow-on-my-large-codebase"><a class="header" href="#analysis-is-slow-on-my-large-codebase">Analysis is slow on my large codebase</a></h3>
<p><strong>Optimization strategies:</strong></p>
<p><strong>1. Exclude unnecessary files:</strong></p>
<pre><code class="language-toml">[analysis]
exclude_patterns = [
    "**/target/**",
    "**/node_modules/**",
    "**/vendor/**",
    "**/.git/**",
]
</code></pre>
<p><strong>2. Use incremental mode</strong> (cache results for unchanged files):</p>
<pre><code class="language-bash">debtmap analyze . --incremental --cache-dir .debtmap-cache
</code></pre>
<p><strong>3. Analyze specific directories:</strong></p>
<pre><code class="language-bash"># Only analyze src/, skip examples and benches
debtmap analyze src/
</code></pre>
<p><strong>4. Reduce parallelism</strong> if memory-constrained:</p>
<pre><code class="language-bash">debtmap analyze . --jobs 4
</code></pre>
<p><strong>Expected performance:</strong></p>
<ul>
<li>50k LOC: 5-15 seconds</li>
<li>200k LOC: 30-90 seconds</li>
<li>1M+ LOC: 3-8 minutes</li>
</ul>
<p>If analysis is significantly slower, please <a href="https://github.com/prodigy-tools/debtmap/issues">report a performance issue</a>.</p>
<h3 id="debtmap-crashes-with-stack-overflow"><a class="header" href="#debtmap-crashes-with-stack-overflow">Debtmap crashes with ‚Äústack overflow‚Äù</a></h3>
<p>This typically happens with extremely deep call stacks or heavily nested code.</p>
<p><strong>Solutions:</strong></p>
<p><strong>1. Increase stack size:</strong></p>
<pre><code class="language-bash"># Linux/macOS
RUST_MIN_STACK=8388608 debtmap analyze .

# Windows PowerShell
$env:RUST_MIN_STACK=8388608; debtmap analyze .
</code></pre>
<p><strong>2. Exclude problematic files:</strong></p>
<pre><code class="language-bash">debtmap analyze . --exclude 'path/to/deeply/nested/file.rs'
</code></pre>
<p><strong>3. Report the issue:</strong> If you encounter stack overflows, please report with a minimal reproducible example.</p>
<h3 id="coverage-data-isnt-being-applied"><a class="header" href="#coverage-data-isnt-being-applied">Coverage data isn‚Äôt being applied</a></h3>
<p><strong>Check:</strong></p>
<p><strong>1. LCOV file path is correct:</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<p><strong>2. LCOV file contains data:</strong></p>
<pre><code class="language-bash">grep -c "^SF:" target/coverage/lcov.info  # Should be &gt; 0
</code></pre>
<p><strong>3. Source paths match:</strong>
LCOV file paths must match your source file paths. If you generate coverage in a different directory:</p>
<pre><code class="language-toml">[coverage]
source_root = "/path/to/project"  # Rewrite LCOV paths
</code></pre>
<p><strong>4. Enable debug logging:</strong></p>
<pre><code class="language-bash">RUST_LOG=debug debtmap analyze . --lcov lcov.info 2&gt;&amp;1 | grep -i coverage
</code></pre>
<h3 id="debtmap-reports-no-functions-found"><a class="header" href="#debtmap-reports-no-functions-found">Debtmap reports ‚ÄúNo functions found‚Äù</a></h3>
<p><strong>Common causes:</strong></p>
<p><strong>1. Wrong language detection:</strong></p>
<pre><code class="language-bash"># Verify file extensions are recognized
debtmap analyze . --verbose
</code></pre>
<p><strong>2. Syntax errors preventing parsing:</strong></p>
<pre><code class="language-bash"># Check for parse errors
RUST_LOG=warn debtmap analyze .
</code></pre>
<p><strong>3. All files excluded by ignore patterns:</strong></p>
<pre><code class="language-bash"># List files being analyzed
debtmap analyze . --dry-run
</code></pre>
<p><strong>4. Unsupported language features:</strong>
Some cutting-edge syntax may not parse correctly. Report parsing issues with code examples.</p>
<h3 id="how-do-i-report-a-bug-or-request-a-feature"><a class="header" href="#how-do-i-report-a-bug-or-request-a-feature">How do I report a bug or request a feature?</a></h3>
<p><strong>Bug reports:</strong></p>
<ol>
<li>Check <a href="https://github.com/prodigy-tools/debtmap/issues">existing issues</a></li>
<li>Provide minimal reproducible example</li>
<li>Include debtmap version: <code>debtmap --version</code></li>
<li>Include OS and Rust version: <code>rustc --version</code></li>
</ol>
<p><strong>Feature requests:</strong></p>
<ol>
<li>Describe the use case (what problem does it solve?)</li>
<li>Provide example of desired behavior</li>
<li>Explain why existing features don‚Äôt address the need</li>
</ol>
<p><strong>Contributions:</strong>
Debtmap is open-source and welcomes contributions! See <a href="https://github.com/prodigy-tools/debtmap/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a> for guidelines.</p>
<h2 id="advanced-topics"><a class="header" href="#advanced-topics">Advanced Topics</a></h2>
<h3 id="can-i-extend-debtmap-with-custom-analyzers"><a class="header" href="#can-i-extend-debtmap-with-custom-analyzers">Can I extend debtmap with custom analyzers?</a></h3>
<p>Not yet, but planned for v0.3.0. You‚Äôll be able to implement the <code>Analyzer</code> trait for custom language support or domain-specific pattern detection.</p>
<p><strong>Roadmap:</strong></p>
<ul>
<li>v0.3.0: Plugin API for custom analyzers</li>
<li>v0.4.0: Plugin API for custom scoring strategies</li>
<li>v0.5.0: Plugin API for custom output formatters</li>
</ul>
<p>Track progress in <a href="https://github.com/prodigy-tools/debtmap/issues/42">issue #42</a>.</p>
<h3 id="how-does-debtmap-handle-monorepos"><a class="header" href="#how-does-debtmap-handle-monorepos">How does debtmap handle monorepos?</a></h3>
<p><strong>Workspace support:</strong>
Debtmap analyzes each workspace member independently by default:</p>
<pre><code class="language-bash"># Analyze entire workspace
debtmap analyze .

# Analyze specific member
debtmap analyze packages/api

# Combined report for all members
debtmap analyze . --workspace-mode combined
</code></pre>
<p><strong>Configuration:</strong></p>
<pre><code class="language-toml">[workspace]
members = ["packages/*", "services/*"]
exclude = ["examples/*"]
</code></pre>
<h3 id="can-i-compare-debt-between-branches-or-commits"><a class="header" href="#can-i-compare-debt-between-branches-or-commits">Can I compare debt between branches or commits?</a></h3>
<p>Yes! Use the <code>compare</code> command:</p>
<pre><code class="language-bash"># Compare current branch with main
debtmap compare main

# Compare two specific commits
debtmap compare abc123..def456

# Show only new debt introduced
debtmap compare main --show-new-only
</code></pre>
<p>Output shows:</p>
<ul>
<li>New debt items (introduced since base)</li>
<li>Resolved debt items (fixed since base)</li>
<li>Changed debt items (score increased/decreased)</li>
</ul>
<p>See <a href="examples.html#comparing-branches">Examples - Comparing Branches</a> for details.</p>
<h3 id="how-do-i-integrate-debtmap-with-my-editor"><a class="header" href="#how-do-i-integrate-debtmap-with-my-editor">How do I integrate debtmap with my editor?</a></h3>
<p><strong>VS Code:</strong></p>
<ul>
<li>Install the ‚ÄúDebtmap‚Äù extension (planned for Q2 2025)</li>
<li>Inline warnings in editor for high-risk code</li>
<li>Quick fixes to generate test stubs</li>
</ul>
<p><strong>Vim/Neovim:</strong></p>
<ul>
<li>Use ALE or vim-lsp with debtmap‚Äôs LSP mode (planned)</li>
</ul>
<p><strong>IntelliJ/RustRover:</strong></p>
<ul>
<li>Use external tools integration:
<ul>
<li>Settings ‚Üí Tools ‚Üí External Tools</li>
<li>Add debtmap command</li>
<li>Configure keyboard shortcut</li>
</ul>
</li>
</ul>
<p>Track editor integration progress in <a href="https://github.com/prodigy-tools/debtmap/issues/38">issue #38</a>.</p>
<h2 id="need-more-help"><a class="header" href="#need-more-help">Need More Help?</a></h2>
<ul>
<li><strong>Documentation:</strong> <a href="https://debtmap.dev">debtmap.dev</a></li>
<li><strong>GitHub Issues:</strong> <a href="https://github.com/prodigy-tools/debtmap/issues">Report bugs or request features</a></li>
<li><strong>Discussions:</strong> <a href="https://github.com/prodigy-tools/debtmap/discussions">Ask questions</a></li>
<li><strong>Examples:</strong> See <a href="examples.html">Examples</a> for real-world use cases</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting-22"><a class="header" href="#troubleshooting-22">Troubleshooting</a></h1>
<p>Common issues and solutions for using debtmap effectively.</p>
<h2 id="quick-fixes-for-common-issues"><a class="header" href="#quick-fixes-for-common-issues">Quick Fixes for Common Issues</a></h2>
<p>If you‚Äôre experiencing problems, try these first:</p>
<ol>
<li><strong>Analysis is slow</strong>: Check <code>--cache-stats</code>, ensure caching is enabled, adjust threads with <code>--jobs</code></li>
<li><strong>Parse errors</strong>: Use <code>--semantic-off</code> for faster fallback mode or exclude problematic files</li>
<li><strong>No output</strong>: Increase verbosity with <code>-v</code> or lower <code>--min-priority</code></li>
<li><strong>Cache corruption</strong>: Run with <code>--clear-cache</code> to rebuild</li>
<li><strong>Inconsistent results</strong>: Check if coverage file changed or context providers are enabled</li>
</ol>
<h2 id="common-issues-3"><a class="header" href="#common-issues-3">Common Issues</a></h2>
<h3 id="parse-errors"><a class="header" href="#parse-errors">Parse Errors</a></h3>
<p><strong>Problem</strong>: Encountering ‚ÄúParse error in file:line:column‚Äù messages</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Unsupported language syntax or version</li>
<li>Complex macro expansions (Rust)</li>
<li>Type inference edge cases (Python, TypeScript)</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Try fallback mode without semantic analysis
debtmap --semantic-off

# For Rust macro issues, see detailed warnings
debtmap --verbose-macro-warnings --show-macro-stats

# Exclude specific problematic files
# Add to .debtmap/config.toml:
# exclude = ["path/to/problematic/file.rs"]
</code></pre>
<h3 id="out-of-memory-errors"><a class="header" href="#out-of-memory-errors">Out of Memory Errors</a></h3>
<p><strong>Problem</strong>: Analysis crashes or runs out of memory on large codebases</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Limit parallel processing
debtmap --jobs 2

# Disable parallel processing entirely
debtmap --no-parallel

# Test with limited files first
debtmap --max-files 100

# Analyze subdirectories separately
debtmap path/to/subset
</code></pre>
<h3 id="performance-issues-1"><a class="header" href="#performance-issues-1">Performance Issues</a></h3>
<p><strong>Problem</strong>: Analysis takes too long to complete</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Check cache statistics
debtmap --cache-stats

# Ensure caching is enabled (it is by default)
# If cache was disabled, remove --no-cache flag

# Use all available CPU cores
debtmap --jobs 0

# Try faster fallback mode (less accurate)
debtmap --semantic-off

# Use plain output for faster terminal rendering
debtmap --plain
</code></pre>
<p>See <a href="troubleshooting.html#performance-tips">Performance Tips</a> for detailed optimization strategies.</p>
<h3 id="cache-corruption"><a class="header" href="#cache-corruption">Cache Corruption</a></h3>
<p><strong>Problem</strong>: Getting ‚ÄúCache error‚Äù messages or stale results</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Clear cache and rebuild
debtmap --clear-cache

# Force cache rebuild
debtmap --force-cache-rebuild

# Check cache status
debtmap --cache-stats

# Use different cache location
debtmap --cache-location /path/to/cache
</code></pre>
<p>See <a href="troubleshooting.html#cache-troubleshooting">Cache Troubleshooting</a> for more details.</p>
<h3 id="file-permission-errors"><a class="header" href="#file-permission-errors">File Permission Errors</a></h3>
<p><strong>Problem</strong>: ‚ÄúFile system error‚Äù when accessing files</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Ensure you have read permissions for all source files</li>
<li>Check that the project directory is accessible</li>
<li>Verify cache directory is writable (default: <code>.debtmap/cache</code>)</li>
<li>Use <code>--cache-location</code> to specify an accessible cache directory</li>
</ul>
<h3 id="git-history-errors"><a class="header" href="#git-history-errors">Git History Errors</a></h3>
<p><strong>Problem</strong>: Errors when using <code>git_history</code> context provider</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Not running in a git repository</li>
<li>Git history not available for files</li>
<li>Insufficient git permissions</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable git_history context provider
debtmap --context --disable-context git_history

# Disable all context providers
debtmap --no-context-aware

# Check if in git repository
git status
</code></pre>
<h3 id="coverage-file-issues"><a class="header" href="#coverage-file-issues">Coverage File Issues</a></h3>
<p><strong>Problem</strong>: Coverage file not being processed or causing errors</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Non-LCOV format coverage file</li>
<li>Malformed coverage data</li>
<li>Path mismatches between coverage and source files</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Verify coverage file format (must be LCOV)
head coverage.info

# Check coverage file path
debtmap --coverage-file path/to/coverage.info -v

# Ensure paths in coverage file match source paths
# Coverage paths are relative to project root
</code></pre>
<h3 id="threshold-and-preset-confusion"><a class="header" href="#threshold-and-preset-confusion">Threshold and Preset Confusion</a></h3>
<p><strong>Problem</strong>: Unexpected filtering or priority levels</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Check what threshold preset does
debtmap --threshold-preset strict --help

# Override specific thresholds
debtmap --min-priority 3

# See all items regardless of thresholds
debtmap --min-priority 0

# Use category filters instead
debtmap --filter "complexity,debt"
</code></pre>
<h3 id="json-format-issues"><a class="header" href="#json-format-issues">JSON Format Issues</a></h3>
<p><strong>Problem</strong>: JSON output parsing errors or unexpected structure</p>
<p><strong>Understanding the Two Formats</strong>:</p>
<p><strong>Legacy format</strong> wraps items in variant-specific objects:</p>
<pre><code class="language-json">{"File": {"path": "src/main.rs", "score": 7.5, ...}}
{"Function": {"name": "parse", "score": 8.2, ...}}
</code></pre>
<p><strong>Unified format</strong> uses consistent structure with <code>type</code> field:</p>
<pre><code class="language-json">{"type": "File", "path": "src/main.rs", "score": 7.5, ...}
{"type": "Function", "name": "parse", "score": 8.2, ...}
</code></pre>
<p>The unified format is <strong>recommended</strong> for parsing and tool integration as it provides a consistent structure across all item types.</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use unified JSON format (consistent structure, recommended)
debtmap --format json --output-format unified

# Legacy format (default, uses {File: {...}} structure)
debtmap --format json --output-format legacy

# Validate JSON output
debtmap --format json | jq .

# Write to file for easier inspection
debtmap --format json --output results.json
</code></pre>
<p>See the <a href="./configuration.html#output-formats">Configuration/Output Formats</a> chapter for detailed JSON structure documentation.</p>
<h3 id="context-provider-errors"><a class="header" href="#context-provider-errors">Context Provider Errors</a></h3>
<p><strong>Problem</strong>: Errors with critical_path, dependency, or git_history providers</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Enable specific providers only
debtmap --context --context-providers critical_path,dependency

# Disable problematic provider
debtmap --context --disable-context git_history

# Disable context-aware filtering
debtmap --no-context-aware

# Check context provider details
debtmap --context -vvv
</code></pre>
<p>See <a href="troubleshooting.html#context-provider-troubleshooting">Context Provider Troubleshooting</a> for details.</p>
<h2 id="debug-mode"><a class="header" href="#debug-mode">Debug Mode</a></h2>
<p>Use verbosity flags to diagnose issues and understand analysis behavior.</p>
<h3 id="verbosity-levels-2"><a class="header" href="#verbosity-levels-2">Verbosity Levels</a></h3>
<pre><code class="language-bash"># Level 1: Show main score factors
debtmap -v

# Level 2: Show detailed calculations
debtmap -vv

# Level 3: Show all debug information
debtmap -vvv
</code></pre>
<p><strong>What each level shows</strong>:</p>
<ul>
<li><code>-v</code>: Score breakdowns, main contributing factors</li>
<li><code>-vv</code>: Detailed metric calculations, file processing</li>
<li><code>-vvv</code>: Full debug output, context provider details, cache operations</li>
</ul>
<h3 id="diagnostic-options"><a class="header" href="#diagnostic-options">Diagnostic Options</a></h3>
<pre><code class="language-bash"># Show macro parsing warnings (Rust)
debtmap --verbose-macro-warnings

# Show macro expansion statistics (Rust)
debtmap --show-macro-stats

# Disable semantic analysis (fallback mode)
debtmap --semantic-off

# Validate LOC consistency
debtmap --validate-loc

# Show cache statistics
debtmap --cache-stats
</code></pre>
<p><strong>Note</strong>: The <code>--explain-score</code> flag is deprecated and hidden. Use <code>-v</code>, <code>-vv</code>, or <code>-vvv</code> for verbosity levels instead to see score breakdowns.</p>
<h3 id="debugging-score-calculations"><a class="header" href="#debugging-score-calculations">Debugging Score Calculations</a></h3>
<pre><code class="language-bash"># Use verbosity levels to see score breakdown
debtmap -v    # Shows score factors

# See how coverage affects scores
debtmap --coverage-file coverage.info -v

# See how context affects scores
debtmap --context --context-providers critical_path -v
</code></pre>
<h3 id="example-debug-session"><a class="header" href="#example-debug-session">Example Debug Session</a></h3>
<pre><code class="language-bash"># Step 1: Run with verbosity to see what's happening
debtmap -vv

# Step 2: Check cache stats
debtmap --cache-stats

# Step 3: Try without semantic analysis
debtmap --semantic-off -v

# Step 4: Check specific file
debtmap path/to/file.rs -vvv

# Step 5: Validate results
debtmap --validate-loc
</code></pre>
<h2 id="performance-tips"><a class="header" href="#performance-tips">Performance Tips</a></h2>
<p>Optimize debtmap analysis speed and resource usage.</p>
<h3 id="parallel-processing-1"><a class="header" href="#parallel-processing-1">Parallel Processing</a></h3>
<pre><code class="language-bash"># Use all CPU cores (default)
debtmap --jobs 0

# Limit to 4 threads
debtmap --jobs 4

# Disable parallel processing (debugging)
# Note: --no-parallel is equivalent to --jobs 1 (single-threaded)
debtmap --no-parallel
</code></pre>
<p><strong>When to adjust parallelism</strong>:</p>
<ul>
<li><strong>Use <code>--jobs 0</code></strong> (default): Maximum performance on dedicated machine</li>
<li><strong>Use <code>--jobs N</code></strong>: Limit resource usage while other tasks run</li>
<li><strong>Use <code>--no-parallel</code></strong>: Debugging concurrency issues</li>
</ul>
<h3 id="caching-strategies"><a class="header" href="#caching-strategies">Caching Strategies</a></h3>
<p>Caching is <strong>enabled by default</strong> and provides the biggest performance improvement.</p>
<p><strong>Note</strong>: The <code>--cache</code> flag (to enable caching) is deprecated and hidden. Caching is now always enabled by default; use <code>--no-cache</code> to disable it.</p>
<pre><code class="language-bash"># Check cache effectiveness
debtmap --cache-stats

# Clear cache if corrupted
debtmap --clear-cache

# Force cache rebuild
debtmap --force-cache-rebuild

# Disable cache (not recommended)
debtmap --no-cache
</code></pre>
<p><strong>Cache locations</strong>:</p>
<pre><code class="language-bash"># Local cache (default): .debtmap/cache
debtmap

# Shared cache for multiple projects
debtmap --cache-location ~/.cache/debtmap

# Migrate existing cache to shared location
debtmap --migrate-cache

# Set via environment variable
export DEBTMAP_CACHE_DIR=~/.cache/debtmap
debtmap
</code></pre>
<p><strong>Cache best practices</strong>:</p>
<ol>
<li>Use shared cache for multiple similar projects</li>
<li>Monitor cache size with <code>--cache-stats</code> periodically</li>
<li>Clear cache after major refactorings</li>
<li>Use local cache for project-specific configurations</li>
</ol>
<h3 id="analysis-optimizations"><a class="header" href="#analysis-optimizations">Analysis Optimizations</a></h3>
<pre><code class="language-bash"># Fast mode: disable semantic analysis
debtmap --semantic-off

# Plain output: faster terminal rendering
debtmap --plain

# Limit files for testing
debtmap --max-files 100

# Analyze subdirectory only
debtmap src/specific/module

# Reduce output with filters
debtmap --min-priority 4 --top 20
</code></pre>
<h3 id="performance-comparison"><a class="header" href="#performance-comparison">Performance Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Speed</th><th>Accuracy</th></tr></thead><tbody>
<tr><td>Default (cached)</td><td>Fast</td><td>High</td></tr>
<tr><td><code>--no-cache</code></td><td>Slow</td><td>High</td></tr>
<tr><td><code>--semantic-off</code></td><td>Fastest</td><td>Medium</td></tr>
<tr><td><code>--no-parallel</code></td><td>Slowest</td><td>High</td></tr>
<tr><td><code>--jobs 4</code></td><td>Medium</td><td>High</td></tr>
</tbody></table>
</div>
<h3 id="monitoring-performance"><a class="header" href="#monitoring-performance">Monitoring Performance</a></h3>
<pre><code class="language-bash"># Time analysis
time debtmap

# Check cache hit rate
debtmap --cache-stats

# Profile with verbosity
debtmap -vv 2&gt;&amp;1 | grep "processed in"
</code></pre>
<h2 id="cache-troubleshooting"><a class="header" href="#cache-troubleshooting">Cache Troubleshooting</a></h2>
<p>Detailed guidance for cache-related issues.</p>
<h3 id="check-cache-status"><a class="header" href="#check-cache-status">Check Cache Status</a></h3>
<pre><code class="language-bash"># View cache statistics
debtmap --cache-stats

# Sample output:
# Cache location: .debtmap/cache
# Cache entries: 1,234
# Cache size: 45.2 MB
# Hit rate: 87.3%
</code></pre>
<h3 id="clear-corrupted-cache"><a class="header" href="#clear-corrupted-cache">Clear Corrupted Cache</a></h3>
<pre><code class="language-bash"># Clear all cache entries
debtmap --clear-cache

# Force rebuild on next run
debtmap --force-cache-rebuild

# Manual cache deletion
rm -rf .debtmap/cache
# or for shared cache:
rm -rf ~/.cache/debtmap
</code></pre>
<h3 id="cache-location-management"><a class="header" href="#cache-location-management">Cache Location Management</a></h3>
<pre><code class="language-bash"># Use local cache (default)
debtmap
# Cache at: .debtmap/cache

# Use shared cache
debtmap --cache-location ~/.cache/debtmap

# Set permanently via environment
export DEBTMAP_CACHE_DIR=~/.cache/debtmap
debtmap

# Migrate existing cache
debtmap --migrate-cache
</code></pre>
<h3 id="cache-pruning-configuration"><a class="header" href="#cache-pruning-configuration">Cache Pruning Configuration</a></h3>
<p>Debtmap automatically manages cache size and age to prevent unbounded growth:</p>
<p><strong>Environment Variables</strong>:</p>
<pre><code class="language-bash"># Enable/disable automatic cache pruning (default: true)
export DEBTMAP_CACHE_AUTO_PRUNE=true

# Maximum cache size in bytes (default: 1GB)
export DEBTMAP_CACHE_MAX_SIZE=1073741824

# Maximum cache entry age in days (default: 30)
export DEBTMAP_CACHE_MAX_AGE_DAYS=30

# Maximum number of cache entries (default: 10000)
export DEBTMAP_CACHE_MAX_ENTRIES=10000

# Percentage of entries to remove when pruning (default: 0.25)
export DEBTMAP_CACHE_PRUNE_PERCENTAGE=0.25

# Pruning strategy: lru, lfu, fifo, age_based (default: lru)
export DEBTMAP_CACHE_STRATEGY=lru
</code></pre>
<p><strong>Pruning Strategies</strong>:</p>
<ul>
<li><strong>LRU (Least Recently Used)</strong>: Removes oldest accessed entries (recommended for general use)</li>
<li><strong>LFU (Least Frequently Used)</strong>: Removes least accessed entries (best for stable workloads)</li>
<li><strong>FIFO (First In First Out)</strong>: Removes oldest created entries (simple, useful for testing)</li>
<li><strong>Age-based</strong>: Removes entries older than MAX_AGE_DAYS (useful for compliance requirements)</li>
</ul>
<p><strong>Performance Implications</strong>:</p>
<ul>
<li>LRU/LFU provide better cache hit rates than FIFO</li>
<li>Age-based strategy ensures data freshness but may reduce hit rate</li>
<li>Adjust MAX_SIZE based on available disk space and project count</li>
<li>Lower PRUNE_PERCENTAGE means more frequent but smaller cleanup operations</li>
</ul>
<h3 id="cache-strategies"><a class="header" href="#cache-strategies">Cache Strategies</a></h3>
<p><strong>Local cache</strong> (<code>.debtmap/cache</code>):</p>
<ul>
<li><strong>Pros</strong>: Isolated per project, automatically managed</li>
<li><strong>Cons</strong>: Duplicates across projects</li>
</ul>
<p><strong>Shared cache</strong> (<code>~/.cache/debtmap</code>):</p>
<ul>
<li><strong>Pros</strong>: Shared across projects, saves disk space</li>
<li><strong>Cons</strong>: Requires manual management, may mix unrelated projects</li>
</ul>
<h3 id="cache-consistency"><a class="header" href="#cache-consistency">Cache Consistency</a></h3>
<pre><code class="language-bash"># Validate LOC consistency
debtmap --validate-loc

# Cache automatically invalidates on file changes
# Uses file hashes to detect modifications

# Force fresh analysis
debtmap --no-cache
</code></pre>
<h3 id="cache-size-monitoring"><a class="header" href="#cache-size-monitoring">Cache Size Monitoring</a></h3>
<pre><code class="language-bash"># Check cache size
debtmap --cache-stats

# Clean up old entries (manual)
# No automatic cleanup - manage cache size manually
# Consider clearing cache periodically for large projects
</code></pre>
<h2 id="context-provider-troubleshooting"><a class="header" href="#context-provider-troubleshooting">Context Provider Troubleshooting</a></h2>
<p>Diagnose and fix issues with context providers (critical_path, dependency, git_history).</p>
<h3 id="enable-context-analysis"><a class="header" href="#enable-context-analysis">Enable Context Analysis</a></h3>
<pre><code class="language-bash"># Enable with default providers
debtmap --context

# Or use explicit flag
debtmap --enable-context

# Specify specific providers
debtmap --context --context-providers critical_path,dependency,git_history
</code></pre>
<h3 id="disable-specific-providers-1"><a class="header" href="#disable-specific-providers-1">Disable Specific Providers</a></h3>
<pre><code class="language-bash"># Disable git_history only
debtmap --context --disable-context git_history

# Disable multiple providers
debtmap --context --disable-context git_history,dependency

# Disable context-aware filtering
debtmap --no-context-aware
</code></pre>
<h3 id="git-history-provider-issues"><a class="header" href="#git-history-provider-issues">Git History Provider Issues</a></h3>
<p><strong>Problem</strong>: ‚ÄúGit history error‚Äù when running analysis</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Not in a git repository</li>
<li>No git history for files</li>
<li>Git not installed or accessible</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Verify in git repository
git status

# Disable git_history provider
debtmap --context --disable-context git_history

# Initialize git repo if needed
git init
</code></pre>
<h3 id="dependency-provider-issues"><a class="header" href="#dependency-provider-issues">Dependency Provider Issues</a></h3>
<p><strong>Problem</strong>: ‚ÄúDependency error‚Äù or incomplete dependency graph</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Complex import structures</li>
<li>Circular dependencies</li>
<li>Unsupported dependency patterns</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable dependency provider
debtmap --context --disable-context dependency

# Try with verbosity to see details
debtmap --context -vvv

# Use without context
debtmap
</code></pre>
<h3 id="critical-path-provider-issues"><a class="header" href="#critical-path-provider-issues">Critical Path Provider Issues</a></h3>
<p><strong>Problem</strong>: Critical path analysis fails or produces unexpected results</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Invalid call graph</li>
<li>Missing function definitions</li>
<li>Complex control flow</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable critical_path provider
debtmap --context --disable-context critical_path

# Try with semantic analysis disabled
debtmap --context --semantic-off

# Debug with verbosity
debtmap --context --context-providers critical_path -vvv
</code></pre>
<h3 id="context-impact-on-scoring"><a class="header" href="#context-impact-on-scoring">Context Impact on Scoring</a></h3>
<p>Context providers add additional risk factors to scoring:</p>
<pre><code class="language-bash"># See context contribution to scores
debtmap --context -v

# Compare with and without context
debtmap --output baseline.json
debtmap --context --output with_context.json
debtmap compare --before baseline.json --after with_context.json
</code></pre>
<h3 id="performance-impact-1"><a class="header" href="#performance-impact-1">Performance Impact</a></h3>
<p>Context analysis adds processing overhead:</p>
<pre><code class="language-bash"># Faster: no context
debtmap

# Slower: with all context providers
debtmap --context --context-providers critical_path,dependency,git_history

# Medium: selective providers
debtmap --context --context-providers dependency
</code></pre>
<h3 id="debug-context-providers"><a class="header" href="#debug-context-providers">Debug Context Providers</a></h3>
<pre><code class="language-bash"># See detailed context provider output
debtmap --context -vvv

# Check which providers are active
debtmap --context -v | grep "context provider"
</code></pre>
<h2 id="advanced-analysis-troubleshooting"><a class="header" href="#advanced-analysis-troubleshooting">Advanced Analysis Troubleshooting</a></h2>
<p>Advanced CLI flags for specialized analysis scenarios.</p>
<h3 id="multi-pass-analysis-3"><a class="header" href="#multi-pass-analysis-3">Multi-Pass Analysis</a></h3>
<p><strong>Flag</strong>: <code>--multi-pass</code></p>
<p>Multi-pass analysis performs multiple iterations to refine results.</p>
<pre><code class="language-bash"># Enable multi-pass analysis
debtmap --multi-pass

# Useful for complex projects with intricate dependencies
# May increase analysis time but improve accuracy
</code></pre>
<p><strong>When to use</strong>:</p>
<ul>
<li>Complex dependency graphs</li>
<li>Large codebases with deep nesting</li>
<li>When single-pass results seem incomplete</li>
</ul>
<h3 id="attribution-output"><a class="header" href="#attribution-output">Attribution Output</a></h3>
<p><strong>Flag</strong>: <code>--attribution</code></p>
<p>Shows attribution information for detected issues.</p>
<pre><code class="language-bash"># Enable attribution output
debtmap --attribution

# Combine with verbosity for details
debtmap --attribution -v
</code></pre>
<p><strong>Troubleshooting</strong>:</p>
<ul>
<li>Requires git history provider for author information</li>
<li>May slow down analysis</li>
<li>Use <code>--disable-context git_history</code> if causing errors</li>
</ul>
<h3 id="aggregation-methods-2"><a class="header" href="#aggregation-methods-2">Aggregation Methods</a></h3>
<p><strong>Flag</strong>: <code>--aggregation-method &lt;method&gt;</code></p>
<p>Controls how results are aggregated across files.</p>
<pre><code class="language-bash"># Available aggregation methods:
debtmap --aggregation-method weighted_sum  # (default)
debtmap --aggregation-method sum
debtmap --aggregation-method logarithmic_sum
debtmap --aggregation-method max_plus_average
</code></pre>
<p><strong>Common issues</strong>:</p>
<ul>
<li>Different methods produce different result structures</li>
<li>Choose method based on your reporting needs</li>
<li>Use consistent method for comparison over time</li>
</ul>
<h3 id="minimum-problematic-threshold"><a class="header" href="#minimum-problematic-threshold">Minimum Problematic Threshold</a></h3>
<p><strong>Flag</strong>: <code>--min-problematic &lt;number&gt;</code></p>
<p>Sets the minimum score for an item to be considered problematic.</p>
<pre><code class="language-bash"># Default threshold
debtmap --min-problematic 3

# More strict (show more issues)
debtmap --min-problematic 1

# Less strict (show only serious issues)
debtmap --min-problematic 5
</code></pre>
<p><strong>Relationship to other filters</strong>:</p>
<ul>
<li>Works alongside <code>--min-priority</code></li>
<li>Filters at analysis level vs display level</li>
<li>Lower values = more issues shown</li>
</ul>
<h3 id="god-object-detection-4"><a class="header" href="#god-object-detection-4">God Object Detection</a></h3>
<p><strong>Flag</strong>: <code>--no-god-object</code></p>
<p>Disables god object (large class/module) detection.</p>
<pre><code class="language-bash"># Disable god object detection
debtmap --no-god-object

# Useful if false positives on legitimately large modules
# Or if your architecture uses centralized classes
</code></pre>
<p><strong>When to use</strong>:</p>
<ul>
<li>False positives on framework files</li>
<li>Intentional large aggregator classes</li>
<li>Reducing noise in results</li>
</ul>
<h3 id="detail-level-control"><a class="header" href="#detail-level-control">Detail Level Control</a></h3>
<p><strong>Flag</strong>: <code>--detail-level &lt;level&gt;</code></p>
<p>Controls the level of detail in analysis output.</p>
<pre><code class="language-bash"># Available detail levels:
debtmap --detail-level summary        # High-level overview only
debtmap --detail-level standard       # (default) Balanced detail
debtmap --detail-level comprehensive  # Detailed analysis
debtmap --detail-level debug         # Full debug information
</code></pre>
<p><strong>When to use</strong>:</p>
<ul>
<li><code>summary</code>: Quick overview for large codebases</li>
<li><code>standard</code>: Default, appropriate for most use cases</li>
<li><code>comprehensive</code>: Deep dive into specific issues</li>
<li><code>debug</code>: Troubleshooting analysis behavior</li>
</ul>
<h3 id="aggregation-control"><a class="header" href="#aggregation-control">Aggregation Control</a></h3>
<p><strong>Flags</strong>: <code>--aggregate-only</code>, <code>--no-aggregation</code></p>
<p>Control file-level score aggregation.</p>
<pre><code class="language-bash"># Show only aggregated file-level scores
debtmap --aggregate-only

# Disable file-level aggregation entirely
debtmap --no-aggregation

# Default: show both individual items and file aggregates
debtmap
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li><code>--aggregate-only</code>: Focus on file-level technical debt</li>
<li><code>--no-aggregation</code>: See individual functions/classes only</li>
<li>Default: Full picture with both levels</li>
</ul>
<h3 id="tiered-prioritization-issues"><a class="header" href="#tiered-prioritization-issues">Tiered Prioritization Issues</a></h3>
<p><strong>Overview</strong>: Debtmap uses a 4-tier system to classify and <strong>sort</strong> technical debt items by architectural importance. Tiers affect result ordering but do not multiply scores.</p>
<p><strong>Tier Classification</strong>:</p>
<ul>
<li><strong>Tier 1 (Critical Architecture)</strong>: High complexity, low coverage, high dependencies, entry points, or file-level architectural debt</li>
<li><strong>Tier 2 (Complex Untested)</strong>: Significant complexity or coverage gaps</li>
<li><strong>Tier 3 (Testing Gaps)</strong>: Moderate issues that need attention</li>
<li><strong>Tier 4 (Maintenance)</strong>: Low-priority items, routine maintenance</li>
</ul>
<p><strong>Result Ordering</strong>:
Results are sorted first by tier (T1 &gt; T2 &gt; T3 &gt; T4), then by score within each tier. This ensures architecturally critical items appear at the top regardless of their absolute score.</p>
<p><strong>Note</strong>: Tier weights (1.5√ó, 1.0√ó, 0.7√ó, 0.3√ó) exist in the configuration but are currently not applied as score multipliers. Tiers control sort order instead.</p>
<p><strong>Configuration</strong>:</p>
<pre><code class="language-toml"># In .debtmap.toml
[tiers]
# Tier 2 requires EITHER high complexity OR high dependencies
t2_complexity_threshold = 15
t2_dependency_threshold = 10

# Tier 3 requires moderate complexity
t3_complexity_threshold = 8

# Control Tier 4 visibility in main report
show_t4_in_main_report = false
</code></pre>
<p><strong>Common Issues</strong>:</p>
<p><strong>Q: Why is my item in Tier 3 instead of Tier 2?</strong></p>
<p>A: Check if it meets Tier 2 thresholds:</p>
<pre><code class="language-bash"># See tier classification with verbosity
debtmap -v

# Check current thresholds
cat .debtmap.toml | grep -A 5 "\[tiers\]"

# Lower thresholds to promote more items to Tier 2
# In .debtmap.toml:
# t2_complexity_threshold = 10  (default: 15)
# t2_dependency_threshold = 5   (default: 10)
</code></pre>
<p><strong>Q: How do I hide Tier 4 items from the main report?</strong></p>
<p>A: Use the <code>show_t4_in_main_report</code> configuration:</p>
<pre><code class="language-toml"># In .debtmap.toml
[tiers]
show_t4_in_main_report = false
</code></pre>
<p>Tier 4 items will still appear in detailed output but won‚Äôt clutter the main summary.</p>
<h3 id="file-level-scoring-issues"><a class="header" href="#file-level-scoring-issues">File-Level Scoring Issues</a></h3>
<p><strong>Overview</strong>: Debtmap aggregates function/class scores into file-level scores using configurable aggregation methods.</p>
<p><strong>Note</strong>: The exact aggregation formula depends on the selected method (see <code>--aggregation-method</code> flag). File-level scores combine individual item scores with file-level characteristics.</p>
<p><strong>Aggregation Methods</strong>:</p>
<pre><code class="language-bash"># Weighted sum (default) - considers complexity weights
debtmap --aggregation-method weighted_sum

# Simple sum - adds all function scores
debtmap --aggregation-method sum

# Logarithmic sum - dampens very high scores
debtmap --aggregation-method logarithmic_sum

# Max plus average - highlights worst function + context
debtmap --aggregation-method max_plus_average
</code></pre>
<p><strong>When to use each method</strong>:</p>
<ul>
<li><strong>weighted_sum</strong>: Default, balances individual and collective impact</li>
<li><strong>sum</strong>: When you want raw cumulative debt</li>
<li><strong>logarithmic_sum</strong>: For very large files to prevent score explosion</li>
<li><strong>max_plus_average</strong>: Focus on worst offender while considering overall file health</li>
</ul>
<p><strong>Aggregation Control Flags</strong>:</p>
<pre><code class="language-bash"># Show only aggregated file-level scores
debtmap --aggregate-only

# Disable file-level aggregation entirely
debtmap --no-aggregation

# Default: show both individual items and file aggregates
debtmap
</code></pre>
<p><strong>Troubleshooting High File Scores</strong>:</p>
<p><strong>Q: Why does this file have such a high score?</strong></p>
<p>A: Check contributing factors with verbosity:</p>
<pre><code class="language-bash"># See file-level score breakdown
debtmap path/to/file.rs -vv

# Look for:
# - High function count (density_factor kicks in at 50+)
# - God object detection (1.5√ó multiplier)
# - Low coverage (high coverage_factor)
# - Large file size (size_factor)
# - Multiple high-complexity functions

# Disable god object detection if false positive
debtmap --no-god-object path/to/file.rs
</code></pre>
<h3 id="combining-advanced-flags"><a class="header" href="#combining-advanced-flags">Combining Advanced Flags</a></h3>
<pre><code class="language-bash"># Comprehensive analysis with all features
debtmap --multi-pass --attribution --context -vv

# Minimal filtering for exploration
debtmap --min-problematic 1 --min-priority 0 --no-god-object

# Performance-focused advanced analysis
debtmap --multi-pass --jobs 8 --cache-location ~/.cache/debtmap

# Summary view with aggregated scores
debtmap --detail-level summary --aggregate-only
</code></pre>
<h2 id="error-messages-reference"><a class="header" href="#error-messages-reference">Error Messages Reference</a></h2>
<p>Understanding common error messages and how to resolve them.</p>
<h3 id="file-system-errors"><a class="header" href="#file-system-errors">File System Errors</a></h3>
<p><strong>Message</strong>: <code>File system error: Permission denied</code></p>
<p><strong>Meaning</strong>: Cannot read file or directory due to permissions</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check file permissions: <code>ls -la &lt;file&gt;</code></li>
<li>Ensure user has read access</li>
<li>Verify cache directory is writable</li>
<li>Use <code>--cache-location</code> for accessible directory</li>
</ul>
<hr />
<p><strong>Message</strong>: <code>File system error: No such file or directory</code></p>
<p><strong>Meaning</strong>: File or directory does not exist</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify path is correct</li>
<li>Check current working directory: <code>pwd</code></li>
<li>Use absolute paths if needed</li>
<li>Ensure files weren‚Äôt moved or deleted</li>
</ul>
<h3 id="parse-errors-1"><a class="header" href="#parse-errors-1">Parse Errors</a></h3>
<p><strong>Message</strong>: <code>Parse error in file.rs:line:column: unexpected token</code></p>
<p><strong>Meaning</strong>: Syntax debtmap cannot parse</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Try fallback mode
debtmap --semantic-off

# For Rust macros
debtmap --verbose-macro-warnings --show-macro-stats

# Exclude problematic file
# In .debtmap/config.toml:
# exclude = ["path/to/file.rs"]
</code></pre>
<h3 id="analysis-errors"><a class="header" href="#analysis-errors">Analysis Errors</a></h3>
<p><strong>Message</strong>: <code>Analysis error: internal analysis failure</code></p>
<p><strong>Meaning</strong>: Internal error during analysis phase</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Try fallback mode
debtmap --semantic-off

# Report with debug info
debtmap -vvv 2&gt;&amp;1 | tee error.log

# Isolate problem file
debtmap --max-files 1 path/to/suspected/file
</code></pre>
<h3 id="configuration-errors"><a class="header" href="#configuration-errors">Configuration Errors</a></h3>
<p><strong>Message</strong>: <code>Configuration error: invalid config value</code></p>
<p><strong>Meaning</strong>: Invalid configuration in <code>.debtmap/config.toml</code> or CLI</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check <code>.debtmap/config.toml</code> syntax</li>
<li>Validate TOML format: <code>cat .debtmap/config.toml</code></li>
<li>Review CLI flag values</li>
<li>Check for typos in flag names</li>
</ul>
<h3 id="cache-errors"><a class="header" href="#cache-errors">Cache Errors</a></h3>
<p><strong>Message</strong>: <code>Cache error: corrupted cache entry</code></p>
<p><strong>Meaning</strong>: Cache data is invalid or corrupted</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Clear cache
debtmap --clear-cache

# Force rebuild
debtmap --force-cache-rebuild

# Use different cache location
debtmap --cache-location /tmp/debtmap-cache
</code></pre>
<h3 id="validation-errors"><a class="header" href="#validation-errors">Validation Errors</a></h3>
<p><strong>Message</strong>: <code>Validation error: threshold validation failed</code></p>
<p><strong>Meaning</strong>: Threshold configuration is invalid</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check threshold values in config</li>
<li>Ensure <code>--min-priority</code> is in valid range (0-10)</li>
<li>Verify threshold preset exists</li>
<li>Use <code>--threshold-preset</code> with valid preset name</li>
</ul>
<h3 id="dependency-errors"><a class="header" href="#dependency-errors">Dependency Errors</a></h3>
<p><strong>Message</strong>: <code>Dependency error: cannot resolve dependency graph</code></p>
<p><strong>Meaning</strong>: Cannot build dependency relationships</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable dependency provider
debtmap --context --disable-context dependency

# Try without context
debtmap

# Debug with verbosity
debtmap -vvv
</code></pre>
<h3 id="concurrency-errors"><a class="header" href="#concurrency-errors">Concurrency Errors</a></h3>
<p><strong>Message</strong>: <code>Concurrency error: parallel processing failure</code></p>
<p><strong>Meaning</strong>: Error during parallel execution</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable parallel processing
debtmap --no-parallel

# Reduce thread count
debtmap --jobs 1

# Report issue with debug output
debtmap -vvv 2&gt;&amp;1 | tee error.log
</code></pre>
<h3 id="unsupported-errors"><a class="header" href="#unsupported-errors">Unsupported Errors</a></h3>
<p><strong>Message</strong>: <code>Unsupported: feature not available for &lt;language&gt;</code></p>
<p><strong>Meaning</strong>: Language or construct not supported</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Use supported languages: Rust, Python, JavaScript, TypeScript</li>
<li>Check if language is enabled in config</li>
<li>Some advanced features may not be available for all languages</li>
<li>Try <code>--semantic-off</code> for basic analysis</li>
</ul>
<h3 id="pattern-errors"><a class="header" href="#pattern-errors">Pattern Errors</a></h3>
<p><strong>Message</strong>: <code>Pattern error: invalid glob pattern</code></p>
<p><strong>Meaning</strong>: Invalid glob pattern in configuration or CLI</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check glob pattern syntax</li>
<li>Escape special characters if needed</li>
<li>Test pattern with shell glob: <code>ls &lt;pattern&gt;</code></li>
<li>Use simpler patterns or path prefixes</li>
</ul>
<h2 id="language-specific-issues"><a class="header" href="#language-specific-issues">Language-Specific Issues</a></h2>
<h3 id="rust-1"><a class="header" href="#rust-1">Rust</a></h3>
<p><strong>Macro Expansion Issues</strong></p>
<pre><code class="language-bash"># See macro warnings
debtmap --verbose-macro-warnings

# Show macro statistics
debtmap --show-macro-stats

# Common issue: Complex macros may not expand correctly
# Solution: Use --semantic-off for faster fallback
</code></pre>
<p><strong>Trait and Generic Complexity</strong></p>
<p>Complex trait bounds and generic constraints may affect analysis accuracy:</p>
<pre><code class="language-bash"># Full semantic analysis (default)
debtmap

# Fallback mode for edge cases
debtmap --semantic-off
</code></pre>
<h3 id="python-1"><a class="header" href="#python-1">Python</a></h3>
<p><strong>Type Inference Limitations</strong></p>
<p>Dynamic typing makes some analysis challenging:</p>
<pre><code class="language-bash"># Best effort type inference (default)
debtmap

# Fallback mode if issues
debtmap --semantic-off
</code></pre>
<p><strong>Import Resolution</strong></p>
<p>Complex import structures may not resolve fully:</p>
<ul>
<li>Relative imports usually work</li>
<li>Dynamic imports may not be detected</li>
<li><code>__init__.py</code> packages are supported</li>
</ul>
<h3 id="javascripttypescript-2"><a class="header" href="#javascripttypescript-2">JavaScript/TypeScript</a></h3>
<p><strong>JSX/TSX Parsing</strong></p>
<p>Ensure files have correct extensions:</p>
<ul>
<li><code>.jsx</code> for JavaScript + JSX</li>
<li><code>.tsx</code> for TypeScript + JSX</li>
<li>Configure extensions in <code>.debtmap/config.toml</code> if needed</li>
</ul>
<p><strong>Type Resolution</strong></p>
<p>TypeScript type resolution in complex projects:</p>
<pre><code class="language-bash"># Full type checking (default for .ts files)
debtmap

# Fallback if type issues
debtmap --semantic-off
</code></pre>
<h3 id="mixed-language-projects"><a class="header" href="#mixed-language-projects">Mixed Language Projects</a></h3>
<pre><code class="language-bash"># Analyze all supported languages (default)
debtmap

# Filter specific languages
# In .debtmap/config.toml:
# languages = ["rust", "python"]
</code></pre>
<h3 id="unsupported-language-constructs"><a class="header" href="#unsupported-language-constructs">Unsupported Language Constructs</a></h3>
<p>Some advanced language features may show as ‚ÄúUnsupported‚Äù:</p>
<ul>
<li>Rust: Some macro patterns, const generics edge cases</li>
<li>Python: Some metaclass patterns, dynamic code generation</li>
<li>JavaScript: Some advanced AST manipulation</li>
</ul>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Use <code>--semantic-off</code> for basic analysis</li>
<li>Exclude problematic files if needed</li>
<li>Report unsupported patterns as feature requests</li>
</ul>
<h3 id="false-positives-1"><a class="header" href="#false-positives-1">False Positives</a></h3>
<p>Reduce false positives for validation functions and repetitive code patterns using entropy analysis:</p>
<p><strong>Enable and Configure Entropy Analysis</strong>:</p>
<pre><code class="language-toml"># In .debtmap.toml
[entropy]
enabled = true                    # Enable entropy-based dampening
weight = 0.3                      # Weight in complexity adjustment (0.0-1.0)
min_tokens = 50                   # Minimum tokens for entropy calculation
pattern_threshold = 0.7           # Pattern similarity threshold (0.0-1.0)
use_classification = true         # Enable advanced token classification
entropy_threshold = 0.5           # Entropy level for dampening (0.0-1.0)
branch_threshold = 0.8            # Branch similarity threshold (0.0-1.0)
max_combined_reduction = 0.5      # Max reduction percentage (0.0-1.0)
</code></pre>
<p><strong>When to Adjust Parameters</strong>:</p>
<ul>
<li><strong>Increase <code>pattern_threshold</code></strong> (e.g., 0.8-0.9): Be more strict, reduce dampening for truly unique code</li>
<li><strong>Decrease <code>entropy_threshold</code></strong> (e.g., 0.3-0.4): Apply dampening more broadly to catch more repetitive patterns</li>
<li><strong>Increase <code>weight</code></strong> (e.g., 0.4-0.5): Make entropy have stronger impact on final scores</li>
<li><strong>Increase <code>min_tokens</code></strong> (e.g., 100): Only apply entropy analysis to larger functions</li>
<li><strong>Increase <code>branch_threshold</code></strong> (e.g., 0.9): Be more strict about branching pattern similarity</li>
</ul>
<p>Entropy analysis can reduce false positives by up to 70% for validation functions, error handling, and other repetitive patterns.</p>
<p><strong>Other False Positive Reduction Strategies</strong>:</p>
<pre><code class="language-bash"># Use context-aware analysis
debtmap --context

# Adjust thresholds
debtmap --threshold-preset lenient

# Disable context-aware filtering if too aggressive
debtmap --no-context-aware
</code></pre>
<h3 id="missing-detections"><a class="header" href="#missing-detections">Missing Detections</a></h3>
<pre><code class="language-bash"># Ensure semantic analysis is enabled
debtmap  # (default, semantic ON)

# Increase verbosity to see what's detected
debtmap -vv

# Check if files are being analyzed
debtmap -v 2&gt;&amp;1 | grep "Processing"
</code></pre>
<h2 id="output-formatting-issues"><a class="header" href="#output-formatting-issues">Output Formatting Issues</a></h2>
<h3 id="choose-output-format"><a class="header" href="#choose-output-format">Choose Output Format</a></h3>
<pre><code class="language-bash"># Terminal format (default, human-readable)
debtmap

# JSON format
debtmap --format json

# Markdown format
debtmap --format markdown
</code></pre>
<h3 id="json-format-options"><a class="header" href="#json-format-options">JSON Format Options</a></h3>
<pre><code class="language-bash"># Legacy format (default): {File: {...}}
debtmap --format json --output-format legacy

# Unified format: consistent structure with 'type' field
debtmap --format json --output-format unified

# Validate JSON
debtmap --format json | jq .

# Write to file
debtmap --format json --output results.json
</code></pre>
<h3 id="plain-output-mode"><a class="header" href="#plain-output-mode">Plain Output Mode</a></h3>
<p>For environments without color/emoji support:</p>
<pre><code class="language-bash"># ASCII-only, no colors, no emoji
debtmap --plain

# Or set environment variable
export NO_EMOJI=1
debtmap
</code></pre>
<h3 id="terminal-color-issues"><a class="header" href="#terminal-color-issues">Terminal Color Issues</a></h3>
<p><strong>Problem</strong>: Colors not rendering or showing escape codes</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use plain mode
debtmap --plain

# Check TERM environment variable
echo $TERM

# Set appropriate TERM
export TERM=xterm-256color
</code></pre>
<h3 id="emoji-issues"><a class="header" href="#emoji-issues">Emoji Issues</a></h3>
<p><strong>Problem</strong>: Emojis showing as boxes or ??</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable emojis
debtmap --plain

# Or environment variable
export NO_EMOJI=1
debtmap
</code></pre>
<h3 id="markdown-rendering"><a class="header" href="#markdown-rendering">Markdown Rendering</a></h3>
<p>Ensure viewer supports GitHub-flavored markdown:</p>
<ul>
<li>Tables</li>
<li>Code blocks with syntax highlighting</li>
<li>Task lists</li>
</ul>
<h3 id="write-output-to-file"><a class="header" href="#write-output-to-file">Write Output to File</a></h3>
<pre><code class="language-bash"># JSON to file
debtmap --format json --output results.json

# Markdown to file
debtmap --format markdown --output report.md

# Terminal format to file (preserves colors)
debtmap --output results.txt

# Plain format to file
debtmap --plain --output results.txt
</code></pre>
<h3 id="summary-vs-full-output"><a class="header" href="#summary-vs-full-output">Summary vs Full Output</a></h3>
<pre><code class="language-bash"># Summary mode (compact)
debtmap --summary
debtmap -s

# Full output (default)
debtmap

# Limit number of items
debtmap --top 10       # Top 10 by priority
debtmap --tail 10      # Bottom 10 by priority
</code></pre>
<h3 id="filtering-output"><a class="header" href="#filtering-output">Filtering Output</a></h3>
<pre><code class="language-bash"># Minimum priority level
debtmap --min-priority 5

# Category filters
debtmap --filter "complexity,debt"

# Combine filters
debtmap --min-priority 3 --top 20 --filter complexity
</code></pre>
<h2 id="compare-command-issues"><a class="header" href="#compare-command-issues">Compare Command Issues</a></h2>
<p>The <code>compare</code> command helps track changes in technical debt over time.</p>
<h3 id="basic-usage-3"><a class="header" href="#basic-usage-3">Basic Usage</a></h3>
<p><strong>Note</strong>: The <code>compare</code> command defaults to JSON output format (unlike <code>analyze</code> which defaults to terminal). Use <code>--format terminal</code> or <code>--format markdown</code> if you need different output.</p>
<pre><code class="language-bash"># Save baseline results
debtmap --format json --output before.json

# Make code changes...

# Save new results
debtmap --format json --output after.json

# Compare results (outputs JSON by default)
debtmap compare --before before.json --after after.json

# Compare with terminal output
debtmap compare --before before.json --after after.json --format terminal
</code></pre>
<h3 id="targeted-comparison"><a class="header" href="#targeted-comparison">Targeted Comparison</a></h3>
<p>Use <code>--plan</code> and <code>--target-location</code> for focused debt analysis:</p>
<pre><code class="language-bash"># Compare based on implementation plan
debtmap compare --before before.json --after after.json --plan implementation-plan.json

# Compare specific code location
debtmap compare --before before.json --after after.json \
  --target-location src/main.rs:calculate_score:42

# Combine both for precise tracking
debtmap compare --before before.json --after after.json \
  --plan implementation-plan.json \
  --target-location src/analyzers/complexity.rs:analyze_function:128
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li><code>--plan</code>: Track debt changes for planned refactoring tasks</li>
<li><code>--target-location</code>: Focus on specific function or code location</li>
<li>Combine for granular technical debt tracking</li>
</ul>
<h3 id="incompatible-format-errors"><a class="header" href="#incompatible-format-errors">Incompatible Format Errors</a></h3>
<p><strong>Problem</strong>: ‚ÄúIncompatible formats‚Äù error when comparing files</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Mixing legacy and unified JSON formats</li>
<li>Files from different debtmap versions</li>
<li>Corrupted JSON files</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Ensure both files use same output format
debtmap --format json --output-format unified --output before.json
# ... make changes ...
debtmap --format json --output-format unified --output after.json
debtmap compare --before before.json --after after.json

# Validate JSON files are well-formed
jq . before.json &gt; /dev/null
jq . after.json &gt; /dev/null
</code></pre>
<h3 id="comparing-across-branches"><a class="header" href="#comparing-across-branches">Comparing Across Branches</a></h3>
<pre><code class="language-bash"># Save baseline on main branch
git checkout main
debtmap --format json --output main.json

# Switch to feature branch
git checkout feature-branch
debtmap --format json --output feature.json

# Compare branches
debtmap compare --before main.json --after feature.json
</code></pre>
<h3 id="missing-files-error"><a class="header" href="#missing-files-error">Missing Files Error</a></h3>
<p><strong>Problem</strong>: ‚ÄúFile not found‚Äù when running compare</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify file paths are correct (use absolute paths if needed)</li>
<li>Ensure JSON files weren‚Äôt moved or deleted</li>
<li>Check current working directory with <code>pwd</code></li>
</ul>
<h3 id="format-mismatch-issues"><a class="header" href="#format-mismatch-issues">Format Mismatch Issues</a></h3>
<p><strong>Problem</strong>: Compare shows unexpected differences or errors</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Regenerate both files with same debtmap version
debtmap --format json --output before.json
# ... make changes ...
debtmap --format json --output after.json

# Use same output format for both
debtmap --format json --output-format unified --output before.json
debtmap --format json --output-format unified --output after.json
</code></pre>
<h2 id="validate-command-issues"><a class="header" href="#validate-command-issues">Validate Command Issues</a></h2>
<p>The <code>validate</code> command checks if a codebase meets specified quality thresholds, useful for CI/CD pipelines.</p>
<h3 id="basic-validation"><a class="header" href="#basic-validation">Basic Validation</a></h3>
<pre><code class="language-bash"># Validate codebase passes default thresholds
debtmap validate /path/to/project

# Exit code 0 if passes, non-zero if validation fails
</code></pre>
<h3 id="debt-density-validation"><a class="header" href="#debt-density-validation">Debt Density Validation</a></h3>
<p><strong>Flag</strong>: <code>--max-debt-density &lt;number&gt;</code></p>
<p>Sets the maximum acceptable technical debt per 1000 lines of code.</p>
<pre><code class="language-bash"># Set maximum acceptable debt density (per 1000 LOC)
debtmap validate /path/to/project --max-debt-density 10.0

# Stricter threshold for critical projects
debtmap validate /path/to/project --max-debt-density 5.0

# Lenient threshold for legacy code
debtmap validate /path/to/project --max-debt-density 20.0
</code></pre>
<p><strong>Troubleshooting validation failures</strong>:</p>
<pre><code class="language-bash"># See which files exceed threshold with details
debtmap validate /path/to/project --max-debt-density 10.0 -v

# Get detailed breakdown of debt density calculations
debtmap validate /path/to/project --max-debt-density 10.0 -vv

# Analyze specific files that failed validation
debtmap /path/to/problematic/file.rs -v

# Understand debt density metric
# Debt density = (total_debt_score / total_lines_of_code) √ó 1000
# Example: 150 debt points across 10,000 LOC = 15.0 debt density
</code></pre>
<p><strong>Interpreting debt density values</strong>:</p>
<ul>
<li><strong>&lt; 5.0</strong>: Excellent code quality</li>
<li><strong>5.0 - 10.0</strong>: Good, manageable technical debt</li>
<li><strong>10.0 - 20.0</strong>: Moderate debt, consider cleanup</li>
<li><strong>&gt; 20.0</strong>: High debt, refactoring recommended</li>
</ul>
<h3 id="cicd-integration-4"><a class="header" href="#cicd-integration-4">CI/CD Integration</a></h3>
<pre><code class="language-bash"># In CI pipeline (fails build if validation fails)
debtmap validate . --max-debt-density 10.0 || exit 1

# With verbose output for debugging
debtmap validate . --max-debt-density 10.0 -v

# Save validation report
debtmap validate . --max-debt-density 10.0 --format json --output validation.json
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Enforce quality gates in CI/CD pipelines</li>
<li>Prevent accumulation of technical debt over time</li>
<li>Track debt density trends across releases</li>
<li>Set different thresholds for different parts of codebase</li>
</ul>
<h2 id="faq-1"><a class="header" href="#faq-1">FAQ</a></h2>
<h3 id="general-questions"><a class="header" href="#general-questions">General Questions</a></h3>
<p><strong>Q: Why is my analysis slow?</strong></p>
<p>A: Check several factors:</p>
<pre><code class="language-bash"># Check cache status
debtmap --cache-stats

# Ensure caching is enabled (default)
# Remove --no-cache if present

# Use all CPU cores
debtmap --jobs 0

# Check for large files or complex macros
debtmap -vv
</code></pre>
<p><strong>Q: What does ‚ÄòParse error‚Äô mean?</strong></p>
<p>A: File contains syntax debtmap cannot parse. Solutions:</p>
<ul>
<li>Try <code>--semantic-off</code> for fallback mode</li>
<li>Use <code>--verbose-macro-warnings</code> for Rust macros</li>
<li>Exclude problematic files in <code>.debtmap/config.toml</code></li>
<li>Report parse errors as potential bugs</li>
</ul>
<p><strong>Q: Why do scores differ between runs?</strong></p>
<p>A: Several factors affect scores:</p>
<ul>
<li>Coverage file changed (use <code>--coverage-file</code>)</li>
<li>Context providers enabled/disabled (<code>--context</code>)</li>
<li>Cache was cleared (<code>--clear-cache</code>)</li>
<li>Code changes (intended behavior)</li>
<li>Different threshold settings</li>
</ul>
<p><strong>Q: How do I reduce noise in results?</strong></p>
<p>A: Use filtering options:</p>
<pre><code class="language-bash"># Increase minimum priority
debtmap --min-priority 5

# Use threshold preset
debtmap --threshold-preset strict

# Filter categories
debtmap --filter "complexity,debt"

# Limit output
debtmap --top 20
</code></pre>
<h3 id="format-and-output"><a class="header" href="#format-and-output">Format and Output</a></h3>
<p><strong>Q: What‚Äôs the difference between legacy and unified JSON?</strong></p>
<p>A: Two JSON output formats:</p>
<ul>
<li><strong>Legacy</strong>: <code>{File: {...}}</code> - nested file-based structure</li>
<li><strong>Unified</strong>: Consistent structure with <code>type</code> field for each item</li>
</ul>
<pre><code class="language-bash"># Legacy (default)
debtmap --format json --output-format legacy

# Unified (recommended for parsing)
debtmap --format json --output-format unified
</code></pre>
<p><strong>Q: Can I analyze partial codebases?</strong></p>
<p>A: Yes, several approaches:</p>
<pre><code class="language-bash"># Limit file count
debtmap --max-files 100

# Analyze specific directory
debtmap src/specific/module

# Use filters in config
# .debtmap/config.toml:
# include = ["src/**/*.rs"]
</code></pre>
<p><strong>Q: How is the 0-10 priority score calculated?</strong></p>
<p>A: Debtmap uses a multiplicative risk-based scoring formula to compute priority scores:</p>
<p><strong>Core Formula</strong>:</p>
<pre><code>Final Score = base_risk √ó debt_factor √ó complexity_factor √ó
              coverage_penalty √ó coverage_factor
</code></pre>
<p><strong>Base Risk Calculation</strong>:</p>
<pre><code>complexity_component = (cyclomatic √ó 0.3 + cognitive √ó 0.45) / 50.0
coverage_component = (100 - coverage_percentage) / 100.0 √ó 0.5
base_risk = (complexity_component + coverage_component) √ó 5.0
</code></pre>
<p><strong>Coverage Penalty</strong> (tiered based on test coverage):</p>
<ul>
<li><strong>&lt; 20% coverage</strong>: 3.0√ó penalty (critical)</li>
<li><strong>20-40% coverage</strong>: 2.0√ó penalty (high risk)</li>
<li><strong>40-60% coverage</strong>: 1.5√ó penalty (moderate risk)</li>
<li><strong>60-80% coverage</strong>: 1.2√ó penalty (low risk)</li>
<li><strong>‚â• 80% coverage</strong>: 0.8√ó penalty (well tested - reduction)</li>
</ul>
<p><strong>Coverage Factor</strong> (additional reduction for well-tested code):</p>
<ul>
<li><strong>‚â• 90% coverage</strong>: 0.8 (20% score reduction)</li>
<li><strong>70-90% coverage</strong>: 0.9 (10% score reduction)</li>
<li><strong>&lt; 70% coverage</strong>: 1.0 (no reduction)</li>
</ul>
<p><strong>Role-Based Adjustments</strong> (Evidence-Based Calculator):</p>
<ul>
<li><strong>Pure logic</strong>: 1.2√ó (testable, maintainable code)</li>
<li><strong>Entry points</strong>: 1.1√ó (public API boundaries)</li>
<li><strong>I/O wrappers</strong>: 0.7√ó (thin delegation layers)</li>
</ul>
<p><strong>Default Weights</strong>:</p>
<ul>
<li>Coverage weight: 0.5</li>
<li>Cyclomatic complexity weight: 0.3</li>
<li>Cognitive complexity weight: 0.45</li>
<li>Debt factor weight: 0.2</li>
</ul>
<p><strong>Example</strong>:</p>
<ul>
<li>Function: cyclomatic=15, cognitive=20, coverage=10%, role=entry_point</li>
<li>Complexity component: (15 √ó 0.3 + 20 √ó 0.45) / 50 = 0.27</li>
<li>Coverage component: (100 - 10) / 100 √ó 0.5 = 0.45</li>
<li>Base risk: (0.27 + 0.45) √ó 5.0 = 3.6</li>
<li>Coverage penalty: 3.0 (&lt; 20% coverage)</li>
<li>Coverage factor: 1.0 (&lt; 70% coverage)</li>
<li>Debt factor: ~1.2 (moderate debt patterns)</li>
<li>Complexity factor: ~1.3 (pattern-adjusted)</li>
<li>Final score: 3.6 √ó 1.2 √ó 1.3 √ó 3.0 √ó 1.0 √ó 1.1 (role) ‚âà <strong>18.5</strong> (clamped to 10.0 scale)</li>
</ul>
<pre><code class="language-bash"># See score breakdown with verbosity
debtmap -v

# See detailed factor calculations including all multipliers
debtmap -vv
</code></pre>
<h3 id="coverage-and-testing"><a class="header" href="#coverage-and-testing">Coverage and Testing</a></h3>
<p><strong>Q: How does coverage affect scores?</strong></p>
<p>A: Coverage affects scores through two multiplicative factors in the risk calculation:</p>
<p><strong>1. Coverage Penalty</strong> (tiered multiplier based on test coverage):</p>
<ul>
<li><strong>&lt; 20% coverage</strong>: 3.0√ó penalty (untested code gets highest priority)</li>
<li><strong>20-40% coverage</strong>: 2.0√ó penalty</li>
<li><strong>40-60% coverage</strong>: 1.5√ó penalty</li>
<li><strong>60-80% coverage</strong>: 1.2√ó penalty</li>
<li><strong>‚â• 80% coverage</strong>: 0.8√ó reduction (well-tested code deprioritized)</li>
</ul>
<p><strong>2. Coverage Factor</strong> (additional reduction for well-tested code):</p>
<ul>
<li><strong>‚â• 90% coverage</strong>: 0.8 (20% score reduction)</li>
<li><strong>70-90% coverage</strong>: 0.9 (10% score reduction)</li>
<li><strong>&lt; 70% coverage</strong>: 1.0 (no additional reduction)</li>
</ul>
<p><strong>3. Base Risk Component</strong> (coverage weight: 0.5):</p>
<ul>
<li><code>coverage_component = (100 - coverage_percentage) / 100.0 √ó 0.5</code></li>
<li>Integrated into base risk calculation</li>
</ul>
<p><strong>Combined Effect</strong>:
Untested complex code (0% coverage) receives maximum penalties (3.0√ó coverage penalty), while well-tested code (‚â•90% coverage) receives both the 0.8√ó coverage penalty and 0.8√ó coverage factor, resulting in a 0.64√ó total reduction. This ensures untested code rises to the top of the priority list.</p>
<pre><code class="language-bash"># Use coverage file
debtmap --coverage-file coverage.info

# See coverage impact on scoring
debtmap --coverage-file coverage.info -v

# See detailed coverage penalty and factor breakdown
debtmap --coverage-file coverage.info -vv
</code></pre>
<p>See the FAQ entry ‚ÄúHow is the 0-10 priority score calculated?‚Äù for complete scoring formula details.</p>
<h3 id="context-and-analysis"><a class="header" href="#context-and-analysis">Context and Analysis</a></h3>
<p><strong>Q: What are context providers?</strong></p>
<p>A: Additional analysis for prioritization:</p>
<ul>
<li><strong>critical_path</strong>: Call graph analysis, entry point distance</li>
<li><strong>dependency</strong>: Dependency relationships and coupling</li>
<li><strong>git_history</strong>: Change frequency and authorship</li>
</ul>
<pre><code class="language-bash"># Enable all
debtmap --context

# Specific providers
debtmap --context --context-providers critical_path,dependency

# See context impact
debtmap --context -v
</code></pre>
<h3 id="results-and-comparison"><a class="header" href="#results-and-comparison">Results and Comparison</a></h3>
<p><strong>Q: Why no output?</strong></p>
<p>A: Check verbosity and filtering:</p>
<pre><code class="language-bash"># Increase verbosity
debtmap -v

# Lower priority threshold
debtmap --min-priority 0

# Check if files were analyzed
debtmap -vv 2&gt;&amp;1 | grep "Processed"

# Ensure not using strict threshold
debtmap --threshold-preset lenient
</code></pre>
<p><strong>Q: How to compare results over time?</strong></p>
<p>A: Use the <code>compare</code> command:</p>
<pre><code class="language-bash"># Save baseline
debtmap --format json --output before.json

# Make changes...

# Analyze again
debtmap --format json --output after.json

# Compare
debtmap compare --before before.json --after after.json
</code></pre>
<p><strong>Q: Why does compare fail with ‚Äòincompatible formats‚Äô?</strong></p>
<p>A: The JSON files must use the same output format:</p>
<pre><code class="language-bash"># Use unified format for both
debtmap --format json --output-format unified --output before.json
# ... make changes ...
debtmap --format json --output-format unified --output after.json
debtmap compare --before before.json --after after.json

# Or use legacy format for both (but unified is recommended)
debtmap --format json --output-format legacy --output before.json
debtmap --format json --output-format legacy --output after.json
</code></pre>
<p><strong>Q: How do I compare results from different branches?</strong></p>
<p>A: Generate JSON output on each branch and compare:</p>
<pre><code class="language-bash"># On main branch
git checkout main
debtmap --format json --output main.json

# On feature branch
git checkout feature-branch
debtmap --format json --output feature.json

# Compare (from either branch)
debtmap compare --before main.json --after feature.json
</code></pre>
<p><strong>Q: Can I compare legacy and unified JSON formats?</strong></p>
<p>A: No, both files must use the same format. Regenerate with matching formats:</p>
<pre><code class="language-bash"># Convert both to unified format
debtmap --format json --output-format unified --output before.json
debtmap --format json --output-format unified --output after.json
debtmap compare --before before.json --after after.json
</code></pre>
<h3 id="performance-and-optimization"><a class="header" href="#performance-and-optimization">Performance and Optimization</a></h3>
<p><strong>Q: How many threads should I use?</strong></p>
<p>A: Depends on your machine:</p>
<pre><code class="language-bash"># Use all cores (default, recommended)
debtmap --jobs 0

# Limit to 4 threads (if other work running)
debtmap --jobs 4

# Single threaded (debugging only)
debtmap --no-parallel
</code></pre>
<p><strong>Q: Should I use shared or local cache?</strong></p>
<p>A: Depends on your workflow:</p>
<ul>
<li><strong>Local cache</strong> (<code>.debtmap/cache</code>): Isolated, automatic</li>
<li><strong>Shared cache</strong> (<code>~/.cache/debtmap</code>): Saves space across projects</li>
</ul>
<pre><code class="language-bash"># Shared cache
debtmap --cache-location ~/.cache/debtmap

# Set permanently
export DEBTMAP_CACHE_DIR=~/.cache/debtmap
</code></pre>
<h2 id="when-to-file-bug-reports"><a class="header" href="#when-to-file-bug-reports">When to File Bug Reports</a></h2>
<p>File a bug report when:</p>
<p>‚úÖ <strong>These are bugs</strong>:</p>
<ul>
<li>Parse errors on valid syntax</li>
<li>Crashes or panics</li>
<li>Incorrect complexity calculations</li>
<li>Cache corruption</li>
<li>Concurrency errors</li>
<li>Incorrect error messages</li>
</ul>
<p>‚ùå <strong>These are not bugs</strong>:</p>
<ul>
<li>Unsupported language constructs (file feature request)</li>
<li>Disagreement with complexity scores (subjective)</li>
<li>Performance on very large codebases (optimization request)</li>
<li>Missing documentation (docs issue, not code bug)</li>
</ul>
<h3 id="how-to-report-issues"><a class="header" href="#how-to-report-issues">How to Report Issues</a></h3>
<ol>
<li><strong>Reproduce with minimal example</strong></li>
<li><strong>Include debug output</strong>: <code>debtmap -vvv 2&gt;&amp;1 | tee error.log</code></li>
<li><strong>Include version</strong>: <code>debtmap --version</code></li>
<li><strong>Include platform</strong>: OS, Rust version if relevant</li>
<li><strong>Include configuration</strong>: <code>.debtmap/config.toml</code> if used</li>
<li><strong>Expected vs actual behavior</strong></li>
</ol>
<h3 id="before-filing"><a class="header" href="#before-filing">Before Filing</a></h3>
<ol>
<li>Check this troubleshooting guide</li>
<li>Try <code>--semantic-off</code> fallback mode</li>
<li>Clear cache with <code>--clear-cache</code></li>
<li>Update to latest version</li>
<li>Search existing issues on GitHub</li>
</ol>
<h2 id="related-documentation-4"><a class="header" href="#related-documentation-4">Related Documentation</a></h2>
<ul>
<li><strong><a href="./configuration.html">Configuration Guide</a></strong>: Configure debtmap behavior</li>
<li><strong><a href="./cli-reference.html">CLI Reference</a></strong>: Complete CLI flag documentation</li>
<li><strong><a href="./analysis-guide.html">Analysis Guide</a></strong>: Understanding analysis results</li>
<li><strong><a href="./examples.html">Examples</a></strong>: Practical usage examples</li>
<li><strong><a href="./api/index.html">API Documentation</a></strong>: Rust API documentation</li>
</ul>
<h2 id="troubleshooting-checklist"><a class="header" href="#troubleshooting-checklist">Troubleshooting Checklist</a></h2>
<p>When debugging issues, work through this checklist:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Run with <code>-vv</code> to see detailed output</li>
<li><input disabled="" type="checkbox"/>
Check <code>--cache-stats</code> for cache issues</li>
<li><input disabled="" type="checkbox"/>
Try <code>--clear-cache</code> to rule out cache corruption</li>
<li><input disabled="" type="checkbox"/>
Try <code>--semantic-off</code> to use fallback mode</li>
<li><input disabled="" type="checkbox"/>
Check file permissions and paths</li>
<li><input disabled="" type="checkbox"/>
Verify configuration in <code>.debtmap/config.toml</code></li>
<li><input disabled="" type="checkbox"/>
Test with <code>--max-files 10</code> to isolate issues</li>
<li><input disabled="" type="checkbox"/>
Try <code>--no-parallel</code> to rule out concurrency</li>
<li><input disabled="" type="checkbox"/>
Check <code>debtmap --version</code> for updates</li>
<li><input disabled="" type="checkbox"/>
Review error messages in this guide</li>
<li><input disabled="" type="checkbox"/>
Search GitHub issues for similar problems</li>
<li><input disabled="" type="checkbox"/>
Create minimal reproduction case</li>
<li><input disabled="" type="checkbox"/>
File bug report with debug output</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
