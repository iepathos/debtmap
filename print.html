<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Debtmap Documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="Comprehensive guide to Debtmap code complexity and technical debt analyzer">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Debtmap Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/iepathos/debtmap" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<blockquote>
<p>üöß <strong>Early Prototype</strong> - This project is under active development and APIs may change</p>
</blockquote>
<p>Debtmap is a fast code complexity and technical debt analyzer written in Rust. Debtmap identifies which code to refactor for maximum cognitive debt reduction and which code to test for maximum risk reduction, providing data-driven prioritization for both.</p>
<h2 id="what-is-debtmap"><a class="header" href="#what-is-debtmap">What is Debtmap?</a></h2>
<p>Unlike traditional static analysis tools that simply flag complex code, Debtmap answers two critical questions:</p>
<ol>
<li><strong>‚ÄúWhat should I refactor to reduce cognitive burden?‚Äù</strong> - Identifies overly complex code that slows down development</li>
<li><strong>‚ÄúWhat should I test first to reduce the most risk?‚Äù</strong> - Pinpoints untested complex code that threatens stability</li>
</ol>
<p>Debtmap analyzes your codebase to identify complexity hotspots, technical debt patterns, and architectural risks. It supports Rust, Python, JavaScript, and TypeScript with full AST parsing and analysis capabilities. Rust includes additional advanced features like macro expansion and trait tracking.</p>
<p><strong>What Makes Debtmap Different:</strong></p>
<ul>
<li><strong>Entropy-Based Complexity Analysis</strong>: Uses information theory to distinguish genuinely complex code from pattern-based repetitive code, reducing false positives by up to 70%</li>
<li><strong>Coverage-Risk Correlation</strong>: The only tool that combines complexity metrics with test coverage to identify genuinely risky code (high complexity + low coverage = critical risk)</li>
<li><strong>Risk-Driven Prioritization</strong>: Prioritizes refactoring and testing efforts based on complexity, coverage, and dependency factors</li>
<li><strong>Actionable Guidance</strong>: Provides specific recommendations like ‚Äúextract nested conditions‚Äù or ‚Äúsplit this 80-line function‚Äù rather than just flagging issues</li>
<li><strong>Performance</strong>: 10-100x faster than Java/Python-based competitors (written in Rust with parallel processing)</li>
</ul>
<h2 id="why-use-debtmap"><a class="header" href="#why-use-debtmap">Why Use Debtmap?</a></h2>
<p>Debtmap helps you make data-driven decisions about where to focus your refactoring and testing efforts:</p>
<ul>
<li><strong>Identify Complexity</strong> - Find complex functions and modules that need refactoring, with concrete metrics showing which changes will have the most impact</li>
<li><strong>Detect Technical Debt</strong> - Discover 30+ debt patterns including code smells, security vulnerabilities, resource management issues, and architectural problems</li>
<li><strong>Assess Risk</strong> - Prioritize improvements based on sophisticated risk scoring that combines complexity, test coverage, and dependency impact</li>
<li><strong>Track Quality</strong> - Monitor code quality metrics over time with the <code>compare</code> command (which can track improvements against implementation plan targets) to verify that refactoring efforts achieved their goals</li>
<li><strong>Get Actionable Recommendations</strong> - Receive specific guidance like ‚Äúrefactoring this will reduce complexity by 60%‚Äù or ‚Äútesting this will reduce risk by 5%‚Äù</li>
<li><strong>Automated Debt Reduction</strong> - Integrates with Prodigy workflows for AI-driven automated refactoring with iterative validation and testing</li>
</ul>
<h2 id="key-features"><a class="header" href="#key-features">Key Features</a></h2>
<h3 id="analysis-capabilities"><a class="header" href="#analysis-capabilities">Analysis Capabilities</a></h3>
<ul>
<li><strong>Multi-language support</strong> - Full support for Rust, Python, JavaScript, and TypeScript with AST parsing, complexity analysis, and debt detection</li>
<li><strong>Entropy-based complexity analysis</strong> - Distinguishes between genuinely complex code and pattern-based repetitive code using information theory</li>
<li><strong>Token classification system</strong> - Advanced token categorization with weighted entropy for accurate complexity assessment</li>
<li><strong>Comprehensive debt detection</strong> - Identifies 30+ technical debt patterns across security (5 types), code organization (god objects, feature envy, magic values), resource management (5 types), testing quality (3 types), and error handling (4 types)</li>
<li><strong>Security vulnerability detection</strong> - Finds hardcoded secrets, weak crypto, SQL injection risks, and unsafe code patterns</li>
<li><strong>Resource management analysis</strong> - Identifies inefficient allocations, nested loops, and blocking I/O patterns</li>
<li><strong>Code organization analysis</strong> - Detects god objects, feature envy, primitive obsession, and magic values</li>
<li><strong>Testing quality assessment</strong> - Analyzes test complexity, flaky patterns, and assertion quality</li>
<li><strong>Context-aware analysis</strong> - Reduces false positives through intelligent context detection (enabled by default)</li>
</ul>
<h3 id="risk-analysis--prioritization"><a class="header" href="#risk-analysis--prioritization">Risk Analysis &amp; Prioritization</a></h3>
<ul>
<li><strong>Coverage-based risk analysis</strong> - Correlates complexity with test coverage to identify truly risky code</li>
<li><strong>Risk-driven testing recommendations</strong> - Prioritizes testing efforts based on complexity-coverage correlation and dependency impact</li>
<li><strong>Call graph analysis</strong> - Tracks upstream callers and downstream callees to understand dependency impact</li>
<li><strong>Tiered prioritization</strong> - Surfaces critical architectural issues above simple testing gaps</li>
<li><strong>Quantified impact</strong> - Shows concrete metrics like ‚Äúrefactoring this will reduce complexity by 60%‚Äù</li>
</ul>
<h3 id="performance--output"><a class="header" href="#performance--output">Performance &amp; Output</a></h3>
<ul>
<li><strong>Parallel processing</strong> - Built with Rust and Rayon for blazing-fast analysis of large codebases</li>
<li><strong>Multiple output formats</strong> - JSON, Markdown, and human-readable terminal formats</li>
<li><strong>Configurable thresholds</strong> - Customize complexity and duplication thresholds to match your standards</li>
<li><strong>Incremental analysis</strong> - Smart caching system for analyzing only changed files</li>
<li><strong>Intelligent caching</strong> - Smart cache system with automatic pruning, configurable strategies (LRU, LFU, FIFO), and environment-based configuration for fast repeated analysis</li>
<li><strong>Verbosity controls</strong> - Multiple verbosity levels (-v, -vv, -vvv) for progressive detail</li>
</ul>
<h3 id="configuration--customization"><a class="header" href="#configuration--customization">Configuration &amp; Customization</a></h3>
<ul>
<li><strong>Flexible suppression</strong> - Inline comment-based suppression for specific code sections</li>
<li><strong>Configuration file</strong> - <code>.debtmap.toml</code> for project-specific settings</li>
<li><strong>Test-friendly</strong> - Easily exclude test fixtures and example code from debt analysis</li>
<li><strong>Macro expansion support</strong> - Handles Rust macro expansions with configurable warnings</li>
</ul>
<h3 id="commands"><a class="header" href="#commands">Commands</a></h3>
<ul>
<li><strong><code>analyze</code></strong> - Comprehensive debt analysis with unified prioritization</li>
<li><strong><code>validate</code></strong> - Enforce quality thresholds in CI/CD pipelines</li>
<li><strong><code>compare</code></strong> - Track improvements over time and verify refactoring goals</li>
<li><strong><code>init</code></strong> - Generate configuration file with sensible defaults</li>
</ul>
<h2 id="target-audience"><a class="header" href="#target-audience">Target Audience</a></h2>
<p>Debtmap is designed for:</p>
<ul>
<li><strong>Development teams</strong> - Get concrete metrics for planning sprints. Know exactly which refactoring will reduce complexity by 60% or which function needs 6 unit tests for full coverage.</li>
<li><strong>Engineering managers</strong> - Track quality trends over time with the <code>compare</code> command. Monitor whether refactoring efforts are actually improving codebase health.</li>
<li><strong>Code reviewers</strong> - Focus reviews on high-risk areas identified by Debtmap. Prioritize reviewing untested complex code over simple utility functions.</li>
<li><strong>Developers refactoring legacy codebases</strong> - Receive actionable guidance like ‚Äúextract nested conditions‚Äù, ‚Äúsplit this 80-line function into 3 smaller functions‚Äù, or ‚Äúadd error handling for this catch block‚Äù.</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>Ready to analyze your codebase? Check out:</p>
<ul>
<li><a href="./installation.html">Installation</a> - Installing Debtmap on your system</li>
<li><a href="./getting-started.html">Getting Started</a> - Installation and first analysis</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Understanding the metrics and output</li>
<li><a href="./output-formats.html">Output Formats</a> - JSON, Markdown, and terminal formats</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h1>
<p>This guide will help you install Debtmap and run your first analysis in just a few minutes.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>Before installing Debtmap, you‚Äôll need:</p>
<ul>
<li><strong>For pre-built binaries</strong>: No prerequisites! The install script handles everything.</li>
<li><strong>For cargo install or building from source</strong>:
<ul>
<li>Rust toolchain (rustc and cargo)</li>
<li>Supported platforms: Linux, macOS, Windows</li>
<li>Rust edition 2021 or later</li>
</ul>
</li>
</ul>
<p><strong>Optional</strong> (for coverage-based risk analysis):</p>
<ul>
<li><strong>Rust projects</strong>: <code>cargo-tarpaulin</code> for coverage data</li>
<li><strong>JavaScript/TypeScript</strong>: Jest or other tools generating LCOV format</li>
<li><strong>Python</strong>: pytest with coverage plugin</li>
</ul>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<h3 id="quick-install-recommended"><a class="header" href="#quick-install-recommended">Quick Install (Recommended)</a></h3>
<p>Install the latest release with a single command:</p>
<pre><code class="language-bash">curl -sSL https://raw.githubusercontent.com/iepathos/debtmap/master/install.sh | bash
</code></pre>
<p>Or with wget:</p>
<pre><code class="language-bash">wget -qO- https://raw.githubusercontent.com/iepathos/debtmap/master/install.sh | bash
</code></pre>
<p>This will:</p>
<ul>
<li>Automatically detect your OS and architecture</li>
<li>Download the appropriate pre-built binary from the latest GitHub release</li>
<li>Install debtmap to <code>~/.cargo/bin</code> if it exists, otherwise <code>~/.local/bin</code></li>
<li>Offer to automatically add the install directory to your PATH if needed</li>
</ul>
<h3 id="using-cargo"><a class="header" href="#using-cargo">Using Cargo</a></h3>
<p>If you have Rust installed:</p>
<pre><code class="language-bash">cargo install debtmap
</code></pre>
<h3 id="from-source"><a class="header" href="#from-source">From Source</a></h3>
<p>For the latest development version:</p>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/iepathos/debtmap.git
cd debtmap

# Build and install
cargo install --path .
</code></pre>
<h3 id="verify-installation"><a class="header" href="#verify-installation">Verify Installation</a></h3>
<p>After installation, verify Debtmap is working:</p>
<pre><code class="language-bash"># Check version
debtmap --version

# See available commands
debtmap --help
</code></pre>
<p><strong>Common installation issues:</strong></p>
<ul>
<li><strong>Binary not in PATH</strong>: Add <code>~/.cargo/bin</code> or <code>~/.local/bin</code> to your PATH
<pre><code class="language-bash">export PATH="$HOME/.cargo/bin:$PATH"  # Add to ~/.bashrc or ~/.zshrc
</code></pre>
</li>
<li><strong>Permission issues</strong>: Run the install script with your current user (don‚Äôt use sudo)</li>
<li><strong>Cargo not found</strong>: Install Rust from https://rustup.rs</li>
</ul>
<h2 id="quick-start"><a class="header" href="#quick-start">Quick Start</a></h2>
<p>Here are the most common commands to get you started:</p>
<pre><code class="language-bash"># Analyze current directory (simplest command)
debtmap analyze .

# Analyze with coverage data for risk scoring (recommended)
# Note: --lcov is a shorthand alias for --coverage-file
debtmap analyze . --lcov target/coverage/lcov.info

# Generate coverage first (for Rust projects)
cargo tarpaulin --out lcov --output-dir target/coverage
debtmap analyze . --lcov target/coverage/lcov.info

# Analyze with custom thresholds
# Note: threshold-duplication specifies minimum lines of duplicated code to detect
debtmap analyze ./src --threshold-complexity 15 --threshold-duplication 50

# Output as JSON (for CI/CD integration)
debtmap analyze ./src --format json --output report.json

# Show only top 10 high-priority issues
debtmap analyze . --top 10

# Initialize configuration file for project-specific settings
debtmap init

# Validate against thresholds (CI/CD integration)
debtmap validate ./src --max-debt-density 5.0

# Compare before/after to track improvements
debtmap analyze . --format json --output before.json
# ... make improvements ...
debtmap analyze . --format json --output after.json
debtmap compare --before before.json --after after.json

# Advanced comparison: focus on specific function
debtmap compare --before before.json --after after.json --target-location src/main.rs:main:10

# Extract target from implementation plan
debtmap compare --before before.json --after after.json --plan IMPLEMENTATION_PLAN.md
</code></pre>
<h3 id="advanced-options"><a class="header" href="#advanced-options">Advanced Options</a></h3>
<p>Debtmap provides many powerful options to customize your analysis:</p>
<p><strong>Verbosity Levels:</strong></p>
<pre><code class="language-bash"># Show main factors contributing to scores
debtmap analyze . -v

# Show detailed calculations
debtmap analyze . -vv

# Show all debug information
debtmap analyze . -vvv
</code></pre>
<p><strong>Filtering and Prioritization:</strong></p>
<pre><code class="language-bash"># Only show high-priority items
debtmap analyze . --min-priority high

# Filter by specific categories
debtmap analyze . --filter Architecture,Testing

# Group results by debt category
debtmap analyze . --group-by-category
</code></pre>
<p><strong>Cache Management:</strong></p>
<pre><code class="language-bash"># Skip cache for fresh analysis
debtmap analyze . --no-cache

# Clear cache and rebuild
debtmap analyze . --clear-cache

# View cache statistics
debtmap analyze . --cache-stats

# Specify custom cache location
debtmap analyze . --cache-location /custom/path

# Migrate cache from local to shared location
debtmap analyze . --migrate-cache
</code></pre>
<p><strong>Performance Control:</strong></p>
<pre><code class="language-bash"># Limit parallel jobs
debtmap analyze . --jobs 4

# Disable parallel processing
debtmap analyze . --no-parallel
</code></pre>
<p><strong>Output Control:</strong></p>
<pre><code class="language-bash"># Plain output (no colors/emoji, for CI/CD)
debtmap analyze . --plain

# Compact summary output
debtmap analyze . --summary

# Control aggregation behavior
debtmap analyze . --aggregate-only          # Show only aggregated results
debtmap analyze . --no-aggregation          # Skip aggregation entirely
debtmap analyze . --aggregation-method sum  # Choose aggregation method

# Adjust detail level in output
debtmap analyze . --detail-level high       # More detailed output
</code></pre>
<p><strong>Expert Options:</strong></p>
<p>These advanced options are available for power users and specialized use cases:</p>
<pre><code class="language-bash"># Analysis behavior
--semantic-off              # Disable semantic analysis
--no-context-aware          # Disable context-aware analysis
--multi-pass                # Enable multi-pass analysis for deeper insights
--validate-loc              # Validate lines of code calculations

# Rust-specific options
--verbose-macro-warnings    # Show detailed macro expansion warnings
--show-macro-stats          # Display macro usage statistics

# Filtering and thresholds
--threshold-preset &lt;name&gt;   # Use predefined threshold preset
--min-problematic &lt;count&gt;   # Minimum problematic items to report
--max-files &lt;count&gt;         # Limit analysis to N files
--no-god-object             # Disable god object detection

# Advanced reporting
--attribution               # Include code attribution information
</code></pre>
<p>For detailed documentation of these options, run <code>debtmap analyze --help</code>.</p>
<h2 id="first-analysis"><a class="header" href="#first-analysis">First Analysis</a></h2>
<p>Let‚Äôs run your first analysis! Navigate to a project directory and run:</p>
<pre><code class="language-bash">debtmap analyze .
</code></pre>
<p><strong>What happens during analysis:</strong></p>
<ol>
<li><strong>File Discovery</strong> - Debtmap scans your project for supported source files (Rust, Python, JavaScript, TypeScript)</li>
<li><strong>Parsing</strong> - Each file is parsed into an Abstract Syntax Tree (AST)</li>
<li><strong>Metrics Calculation</strong> - Complexity, debt patterns, and risk scores are computed</li>
<li><strong>Prioritization</strong> - Results are ranked by priority (CRITICAL, HIGH, MEDIUM, LOW)</li>
<li><strong>Output</strong> - Results are displayed in your chosen format</li>
</ol>
<p><strong>Expected timing</strong>: Analyzing a 10,000 LOC project typically takes 2-5 seconds. The first run may be slightly slower as Debtmap builds its cache.</p>
<p><strong>About Caching:</strong>
Debtmap caches parsed ASTs and computed metrics to speed up subsequent analyses:</p>
<ul>
<li><strong>Cache location</strong>: <code>XDG_CACHE_HOME/debtmap</code> on Linux, <code>~/Library/Caches/debtmap</code> on macOS, <code>%LOCALAPPDATA%/debtmap</code> on Windows</li>
<li><strong>What‚Äôs cached</strong>: Parsed ASTs and computed metrics for each file</li>
<li><strong>Invalidation</strong>: Cache is automatically invalidated when files are modified</li>
<li><strong>Management</strong>: Use <code>--clear-cache</code> to clear, <code>--no-cache</code> to skip, or <code>--cache-stats</code> to view statistics</li>
</ul>
<p><strong>Language support</strong>:</p>
<ul>
<li><strong>Rust</strong>: Full support with advanced features (trait detection, purity analysis, call graphs)</li>
<li><strong>Python</strong>: Partial support (complexity metrics, basic debt detection)</li>
<li><strong>JavaScript/TypeScript</strong>: Partial support (complexity metrics, basic debt detection)</li>
</ul>
<h3 id="example-output"><a class="header" href="#example-output">Example Output</a></h3>
<p>When you run <code>debtmap analyze .</code>, you‚Äôll see output like this:</p>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    PRIORITY TECHNICAL DEBT FIXES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéØ TOP 3 RECOMMENDATIONS (by unified priority)

#1 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/analyzers/rust_call_graph.rs:38 add_function_to_graph()
‚îú‚îÄ ACTION: Add 6 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=6, branches=6, cognitive=8, nesting=2, lines=32
‚îú‚îÄ DEPENDENCIES: 0 upstream, 11 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=6, cog=8)

#2 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/debt/smells.rs:196 detect_data_clumps()
‚îú‚îÄ ACTION: Add 5 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=5, branches=5, cognitive=11, nesting=5, lines=31
‚îú‚îÄ DEPENDENCIES: 0 upstream, 4 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=5, cog=11)

#3 SCORE: 8.6 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/risk/context/dependency.rs:247 explain()
‚îú‚îÄ ACTION: Add 5 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.6 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=5, branches=5, cognitive=9, nesting=1, lines=24
‚îú‚îÄ DEPENDENCIES: 0 upstream, 1 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=5, cog=9)


üìä TOTAL DEBT SCORE: 4907
üìà OVERALL COVERAGE: 67.12%
</code></pre>
<h2 id="understanding-the-output"><a class="header" href="#understanding-the-output">Understanding the Output</a></h2>
<p>Let‚Äôs break down what this output means:</p>
<h3 id="priority-levels"><a class="header" href="#priority-levels">Priority Levels</a></h3>
<ul>
<li><strong>CRITICAL</strong> (9.0-10.0): Immediate action required - high complexity with no test coverage</li>
<li><strong>HIGH</strong> (7.0-8.9): Should be addressed soon - moderate-high complexity with poor coverage</li>
<li><strong>MEDIUM</strong> (5.0-6.9): Plan for next sprint - moderate complexity or partial coverage gaps</li>
<li><strong>LOW</strong> (3.0-4.9): Nice to have - well-tested or simple functions</li>
</ul>
<p><strong>Note:</strong> These are default priority thresholds. You can customize them in <code>.debtmap.toml</code> under the <code>[tiers]</code> section to match your team‚Äôs standards.</p>
<h3 id="key-metrics"><a class="header" href="#key-metrics">Key Metrics</a></h3>
<ul>
<li>
<p><strong>Unified Score</strong> (0-10 scale): Overall priority combining complexity, coverage, and dependencies</p>
<ul>
<li>Higher score = higher priority</li>
<li>Takes into account multiple risk factors</li>
</ul>
</li>
<li>
<p><strong>Debt Type</strong>: Category of the issue</p>
<ul>
<li><code>TestGap</code>: Missing test coverage</li>
<li><code>Complexity</code>: Exceeds complexity thresholds</li>
<li><code>Duplication</code>: Repeated code blocks</li>
<li><code>CodeSmell</code>: Anti-patterns and bad practices</li>
</ul>
</li>
<li>
<p><strong>Complexity Metrics</strong>:</p>
<ul>
<li><strong>Cyclomatic</strong>: Number of decision points (branches, loops)</li>
<li><strong>Cognitive</strong>: How difficult the code is to understand</li>
<li><strong>Nesting</strong>: Maximum indentation depth</li>
<li><strong>Lines</strong>: Function length</li>
</ul>
</li>
<li>
<p><strong>Dependencies</strong>:</p>
<ul>
<li><strong>Upstream callers</strong>: Functions that call this function</li>
<li><strong>Downstream callees</strong>: Functions this function calls</li>
<li>More dependencies = higher impact when this code breaks</li>
</ul>
</li>
</ul>
<h3 id="recommendation-structure"><a class="header" href="#recommendation-structure">Recommendation Structure</a></h3>
<p>Each recommendation shows:</p>
<ul>
<li><strong>ACTION</strong>: What you should do (e.g., ‚ÄúAdd 6 unit tests‚Äù)</li>
<li><strong>IMPACT</strong>: Expected improvement (e.g., ‚ÄúFull test coverage, -3.7 risk‚Äù)</li>
<li><strong>WHY</strong>: The reasoning behind this recommendation</li>
</ul>
<h3 id="organizing-results"><a class="header" href="#organizing-results">Organizing Results</a></h3>
<p>When analyzing large codebases, you can organize and filter results to focus on specific areas:</p>
<p><strong>Group by Debt Category:</strong></p>
<pre><code class="language-bash">debtmap analyze . --group-by-category
</code></pre>
<p>This organizes results by type: Architecture, Testing, Performance, CodeQuality</p>
<p><strong>Filter by Priority:</strong></p>
<pre><code class="language-bash"># Show only high and critical priority items
debtmap analyze . --min-priority high

# Combine with --top to limit results
debtmap analyze . --min-priority high --top 10
</code></pre>
<p><strong>Filter by Category:</strong></p>
<pre><code class="language-bash"># Focus on specific debt types
debtmap analyze . --filter Architecture,Testing

# Available categories: Architecture, Testing, Performance, CodeQuality
</code></pre>
<p>These filtering options help you focus on specific types of technical debt, making it easier to plan targeted improvements.</p>
<h3 id="summary-statistics"><a class="header" href="#summary-statistics">Summary Statistics</a></h3>
<ul>
<li>
<p><strong>Total Debt Score</strong>: Sum of all debt scores across your codebase</p>
<ul>
<li>Lower is better</li>
<li>Track over time to measure improvement</li>
</ul>
</li>
<li>
<p><strong>Overall Coverage</strong>: Percentage of code covered by tests</p>
<ul>
<li>Only shown when coverage data is provided</li>
</ul>
</li>
</ul>
<h3 id="output-formats"><a class="header" href="#output-formats">Output Formats</a></h3>
<p>Debtmap supports multiple output formats:</p>
<ul>
<li><strong>Terminal</strong> (default): Human-readable colored output with tables</li>
<li><strong>JSON</strong>: Machine-readable format for CI/CD integration</li>
<li><strong>Markdown</strong>: Documentation-friendly format for reports</li>
</ul>
<p>Example JSON output:</p>
<pre><code class="language-bash"># By default, JSON uses legacy format
debtmap analyze . --format json --output report.json

# For the new unified format (with consistent structure and type field):
debtmap analyze . --format json --output-format unified --output report.json
</code></pre>
<p><strong>JSON Format Options:</strong></p>
<ul>
<li><strong>legacy</strong> (default): Uses <code>{File: {...}}</code> and <code>{Function: {...}}</code> wrappers for backward compatibility with existing tools</li>
<li><strong>unified</strong>: New format (spec 108) with consistent structure and <code>type</code> field for all items</li>
</ul>
<p>Recommendation: Use <code>unified</code> for new integrations, <code>legacy</code> only for compatibility with existing tooling.</p>
<p>Example Markdown output:</p>
<pre><code class="language-bash">debtmap analyze . --format markdown --output report.md
</code></pre>
<h2 id="whats-next"><a class="header" href="#whats-next">What‚Äôs Next?</a></h2>
<p>Now that you‚Äôve run your first analysis, explore these topics:</p>
<ul>
<li><strong><a href="./analysis-guide.html">Analysis Guide</a></strong> - Deep dive into complexity metrics, debt patterns, and risk scoring</li>
<li><strong><a href="./output-formats.html">Output Formats</a></strong> - Detailed guide to JSON schema and integration options</li>
<li><strong>Configuration</strong> - Customize thresholds and filters with <code>.debtmap.toml</code></li>
<li><strong>CI/CD Integration</strong> - Use the <code>validate</code> command to enforce quality gates</li>
</ul>
<h3 id="generate-a-configuration-file"><a class="header" href="#generate-a-configuration-file">Generate a Configuration File</a></h3>
<p>Create a project-specific configuration:</p>
<pre><code class="language-bash">debtmap init
</code></pre>
<p>This creates a <code>.debtmap.toml</code> file with sensible defaults that you can customize for your project.</p>
<p><strong>Key Configuration Options:</strong></p>
<p>The configuration file allows you to customize:</p>
<ul>
<li><strong>Threshold customization</strong> - Adjust complexity, duplication, and file size thresholds</li>
<li><strong>Scoring weights</strong> - Fine-tune how coverage, complexity, and dependencies are weighted</li>
<li><strong>Language selection</strong> - Enable/disable specific language analyzers</li>
<li><strong>Ignore patterns</strong> - Exclude test files or generated code from analysis</li>
<li><strong>God object thresholds</strong> - Configure what constitutes a ‚Äúgod object‚Äù anti-pattern</li>
<li><strong>Entropy analysis</strong> - Control entropy-based complexity detection</li>
<li><strong>Priority tiers</strong> - Customize CRITICAL/HIGH/MEDIUM/LOW threshold ranges</li>
</ul>
<p>See the Configuration chapter for complete documentation of all available options.</p>
<h3 id="try-analysis-with-coverage"><a class="header" href="#try-analysis-with-coverage">Try Analysis with Coverage</a></h3>
<p>For more accurate risk assessment, run analysis with coverage data:</p>
<pre><code class="language-bash"># For Rust projects
cargo tarpaulin --out lcov --output-dir target/coverage
debtmap analyze . --lcov target/coverage/lcov.info

# For Python projects
pytest --cov --cov-report=lcov
debtmap analyze . --lcov coverage.lcov

# For JavaScript/TypeScript projects
jest --coverage --coverageReporters=lcov
debtmap analyze . --lcov coverage/lcov.info
</code></pre>
<p>Coverage data helps Debtmap identify <strong>truly risky code</strong> - functions that are both complex AND untested.</p>
<hr />
<p><strong>Need help?</strong> Report issues at https://github.com/iepathos/debtmap/issues</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cli-reference"><a class="header" href="#cli-reference">CLI Reference</a></h1>
<p>Complete reference for Debtmap command-line interface.</p>
<h2 id="quick-start-1"><a class="header" href="#quick-start-1">Quick Start</a></h2>
<pre><code class="language-bash"># Basic analysis
debtmap analyze src/

# With coverage integration
debtmap analyze src/ --coverage-file coverage.lcov

# Generate JSON report
debtmap analyze . --format json --output report.json

# Show top 10 priority items only
debtmap analyze . --top 10 --min-priority high

# Initialize configuration and validate
debtmap init
debtmap validate . --config debtmap.toml
</code></pre>
<h2 id="commands-1"><a class="header" href="#commands-1">Commands</a></h2>
<p>Debtmap provides four main commands:</p>
<h3 id="analyze"><a class="header" href="#analyze"><code>analyze</code></a></h3>
<p>Analyze code for complexity and technical debt.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap analyze &lt;PATH&gt; [OPTIONS]
</code></pre>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>&lt;PATH&gt;</code> - Path to analyze (file or directory)</li>
</ul>
<p><strong>Description:</strong>
Primary command for code analysis. Supports multiple output formats (json, markdown, terminal), coverage file integration, caching, parallel processing, context-aware risk analysis, and comprehensive filtering options.</p>
<p>See <a href="cli-reference.html#options">Options</a> section below for all available flags.</p>
<h3 id="init"><a class="header" href="#init"><code>init</code></a></h3>
<p>Initialize a Debtmap configuration file.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap init [OPTIONS]
</code></pre>
<p><strong>Options:</strong></p>
<ul>
<li><code>-f, --force</code> - Force overwrite existing config</li>
</ul>
<p><strong>Description:</strong>
Creates a <code>debtmap.toml</code> configuration file in the current directory with default settings. Use <code>--force</code> to overwrite an existing configuration file.</p>
<h3 id="validate"><a class="header" href="#validate"><code>validate</code></a></h3>
<p>Validate code against thresholds defined in configuration file.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap validate &lt;PATH&gt; [OPTIONS]
</code></pre>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>&lt;PATH&gt;</code> - Path to analyze</li>
</ul>
<p><strong>Options:</strong></p>
<p><em>Configuration &amp; Output:</em></p>
<ul>
<li><code>-c, --config &lt;CONFIG&gt;</code> - Configuration file path</li>
<li><code>-f, --format &lt;FORMAT&gt;</code> - Output format: json, markdown, terminal</li>
<li><code>-o, --output &lt;OUTPUT&gt;</code> - Output file path (defaults to stdout)</li>
</ul>
<p><em>Coverage &amp; Context:</em></p>
<ul>
<li><code>--coverage-file &lt;PATH&gt;</code> / <code>--lcov &lt;PATH&gt;</code> - LCOV coverage file for risk analysis</li>
<li><code>--context</code> / <code>--enable-context</code> - Enable context-aware risk analysis</li>
<li><code>--context-providers &lt;PROVIDERS&gt;</code> - Context providers to use (comma-separated)</li>
<li><code>--disable-context &lt;PROVIDERS&gt;</code> - Disable specific context providers</li>
</ul>
<p><em>Thresholds &amp; Validation:</em></p>
<ul>
<li><code>--max-debt-density &lt;N&gt;</code> - Maximum debt density allowed (per 1000 LOC)</li>
</ul>
<p><em>Display Filtering:</em></p>
<ul>
<li><code>--top &lt;N&gt;</code> / <code>--head &lt;N&gt;</code> - Show only top N priority items</li>
<li><code>--tail &lt;N&gt;</code> - Show only bottom N priority items</li>
<li><code>-s, --summary</code> - Use summary format with tiered priority display</li>
</ul>
<p><em>Analysis Control:</em></p>
<ul>
<li><code>--semantic-off</code> - Disable semantic analysis (fallback mode)</li>
</ul>
<p><em>Debugging &amp; Verbosity:</em></p>
<ul>
<li><code>-v, --verbose</code> - Increase verbosity level (can be repeated: -v, -vv, -vvv)</li>
</ul>
<p><strong>Description:</strong>
Similar to <code>analyze</code> but enforces thresholds defined in configuration file. Returns non-zero exit code if thresholds are exceeded, making it suitable for CI/CD integration.</p>
<p>The <code>validate</code> command supports a focused subset of <code>analyze</code> options, primarily for output control, coverage integration, context-aware analysis, and display filtering. The validate command does not support <code>--threshold-complexity</code>, <code>--threshold-duplication</code>, or <code>--threshold-preset</code> flags (these are analyze-only). Instead, configure thresholds in the <code>.debtmap.toml</code> config file. Performance options like <code>--jobs</code>, <code>--cache-*</code>, and <code>--languages</code> are also not available in validate.</p>
<p><strong>Exit Codes:</strong></p>
<ul>
<li><code>0</code> - Success (no errors, all thresholds passed)</li>
<li>Non-zero - Failure (errors occurred or thresholds exceeded)</li>
</ul>
<h3 id="compare"><a class="header" href="#compare"><code>compare</code></a></h3>
<p>Compare two analysis results and generate a diff report.</p>
<p><strong>Usage:</strong></p>
<pre><code class="language-bash">debtmap compare --before &lt;FILE&gt; --after &lt;FILE&gt; [OPTIONS]
</code></pre>
<p><strong>Required Options:</strong></p>
<ul>
<li><code>--before &lt;FILE&gt;</code> - Path to ‚Äúbefore‚Äù analysis JSON</li>
<li><code>--after &lt;FILE&gt;</code> - Path to ‚Äúafter‚Äù analysis JSON</li>
</ul>
<p><strong>Optional Target Location:</strong></p>
<ul>
<li><code>--plan &lt;FILE&gt;</code> - Path to implementation plan (to extract target location)</li>
<li><code>--target-location &lt;LOCATION&gt;</code> - Target location in format <code>file:function:line</code></li>
</ul>
<p><strong>Note:</strong> <code>--plan</code> and <code>--target-location</code> are mutually exclusive options. Using both together will cause a CLI error. Use one or the other to specify the target location.</p>
<p><strong>Output Options:</strong></p>
<ul>
<li><code>-f, --format &lt;FORMAT&gt;</code> - Output format: json, markdown, terminal (default: json)</li>
<li><code>-o, --output &lt;OUTPUT&gt;</code> - Output file (defaults to stdout)</li>
</ul>
<p><strong>Description:</strong>
Compares two analysis results and generates a diff showing improvements or regressions in code quality metrics.</p>
<h2 id="options"><a class="header" href="#options">Options</a></h2>
<p>Options are organized by category for clarity. Most options apply to the <code>analyze</code> command, with a subset available for <code>validate</code>.</p>
<h3 id="output-control"><a class="header" href="#output-control">Output Control</a></h3>
<p>Control how analysis results are formatted and displayed.</p>
<p><strong>Format Options:</strong></p>
<ul>
<li><code>-f, --format &lt;FORMAT&gt;</code> - Output format: json, markdown, terminal (default: terminal for analyze)</li>
<li><code>--output-format &lt;JSON_FORMAT&gt;</code> - JSON structure format: legacy or unified (default: legacy)
<ul>
<li><code>legacy</code> - Current format with <code>{File: {...}}</code> and <code>{Function: {...}}</code> wrappers</li>
<li><code>unified</code> - New format with consistent structure and ‚Äòtype‚Äô field</li>
</ul>
</li>
<li><code>-o, --output &lt;OUTPUT&gt;</code> - Output file path (defaults to stdout)</li>
<li><code>--plain</code> - Plain output mode: ASCII-only, no colors, no emoji, machine-parseable</li>
</ul>
<p><strong>Display Filtering:</strong></p>
<ul>
<li><code>--top &lt;N&gt;</code> / <code>--head &lt;N&gt;</code> - Show only top N priority items</li>
<li><code>--tail &lt;N&gt;</code> - Show only bottom N priority items (lowest priority)</li>
<li><code>-s, --summary</code> - Use summary format with tiered priority display (compact output)</li>
<li><code>--min-priority &lt;PRIORITY&gt;</code> - Minimum priority to display: low, medium, high, critical</li>
<li><code>--filter &lt;CATEGORIES&gt;</code> - Filter by debt categories (comma-separated)</li>
<li><code>--aggregate-only</code> - Show only aggregated file-level scores</li>
<li><code>--group-by-category</code> - Group output by debt category</li>
</ul>
<h3 id="analysis-control"><a class="header" href="#analysis-control">Analysis Control</a></h3>
<p>Configure analysis behavior, thresholds, and language selection.</p>
<p><strong>Thresholds:</strong></p>
<ul>
<li><code>--threshold-complexity &lt;N&gt;</code> - Complexity threshold (default: 10) [analyze command]</li>
<li><code>--threshold-duplication &lt;N&gt;</code> - Duplication threshold in lines (default: 50) [analyze command]</li>
<li><code>--threshold-preset &lt;PRESET&gt;</code> - Complexity threshold preset: strict, balanced, lenient [analyze command]
<ul>
<li><code>strict</code> - Strict thresholds for high code quality standards</li>
<li><code>balanced</code> - Balanced thresholds for typical projects (default)</li>
<li><code>lenient</code> - Lenient thresholds for legacy or complex domains</li>
</ul>
</li>
<li><code>--max-debt-density &lt;N&gt;</code> - Maximum debt density allowed per 1000 LOC [validate command]</li>
</ul>
<p><strong>Note:</strong> Threshold options (<code>--threshold-complexity</code>, <code>--threshold-duplication</code>, <code>--threshold-preset</code>) are command-line options for the <code>analyze</code> command. For the <code>validate</code> command, these thresholds are configured via the <code>--config</code> file (<code>debtmap.toml</code>) rather than as command-line flags.</p>
<p><strong>Language Selection:</strong></p>
<ul>
<li><code>--languages &lt;LANGS&gt;</code> - Comma-separated list of languages to analyze
<ul>
<li>Example: <code>--languages rust,python,javascript</code></li>
<li>Supported: rust, python, javascript, typescript</li>
</ul>
</li>
</ul>
<p><strong>Analysis Modes:</strong></p>
<ul>
<li><code>--semantic-off</code> - Disable semantic analysis (fallback mode)</li>
<li><code>--no-context-aware</code> - Disable context-aware false positive reduction (enabled by default)</li>
<li><code>--multi-pass</code> - Enable multi-pass analysis with attribution</li>
<li><code>--attribution</code> - Show complexity attribution details</li>
</ul>
<h3 id="context--coverage"><a class="header" href="#context--coverage">Context &amp; Coverage</a></h3>
<p>Enable context-aware risk analysis and integrate test coverage data.</p>
<p><strong>Context-Aware Risk Analysis:</strong></p>
<ul>
<li><code>--context</code> / <code>--enable-context</code> - Enable context-aware risk analysis</li>
<li><code>--context-providers &lt;PROVIDERS&gt;</code> - Context providers to use (comma-separated)
<ul>
<li>Available: <code>critical_path</code>, <code>dependency</code>, <code>git_history</code></li>
<li>Example: <code>--context-providers critical_path,git_history</code></li>
</ul>
</li>
<li><code>--disable-context &lt;PROVIDERS&gt;</code> - Disable specific context providers (comma-separated)</li>
</ul>
<p><strong>Coverage Integration:</strong></p>
<ul>
<li><code>--coverage-file &lt;PATH&gt;</code> / <code>--lcov &lt;PATH&gt;</code> - LCOV coverage file for risk analysis
<ul>
<li>Coverage data dampens debt scores for well-tested code (multiplier = 1.0 - coverage)</li>
<li>Surfaces untested complex functions as higher priority</li>
<li>Total debt score with coverage ‚â§ score without coverage</li>
</ul>
</li>
<li><code>--validate-loc</code> - Validate LOC consistency across analysis modes (with/without coverage)</li>
</ul>
<h3 id="performance--caching"><a class="header" href="#performance--caching">Performance &amp; Caching</a></h3>
<p>Optimize analysis performance through parallelization and caching.</p>
<p><strong>Parallel Processing:</strong></p>
<ul>
<li><code>--no-parallel</code> - Disable parallel call graph construction (enabled by default)</li>
<li><code>-j, --jobs &lt;N&gt;</code> - Number of threads for parallel processing
<ul>
<li><code>0</code> = use all available CPU cores (default)</li>
<li>Specify number to limit thread count</li>
</ul>
</li>
</ul>
<p><strong>Caching:</strong></p>
<ul>
<li><code>--no-cache</code> - Disable caching for this run (caching is enabled by default)</li>
<li><code>--clear-cache</code> - Clear cache before running analysis</li>
<li><code>--force-cache-rebuild</code> - Force cache rebuild (same as ‚Äìclear-cache)</li>
<li><code>--cache-stats</code> - Show cache statistics and location</li>
<li><code>--migrate-cache</code> - Migrate cache from local to shared location</li>
<li><code>--cache-location &lt;LOCATION&gt;</code> - Cache location strategy: local, shared, or path
<ul>
<li>Can also be set via <code>DEBTMAP_CACHE_DIR</code> environment variable</li>
<li>Affects where analysis results are cached for faster subsequent runs</li>
</ul>
</li>
</ul>
<p><strong>Other Performance:</strong></p>
<ul>
<li><code>--max-files &lt;N&gt;</code> - Maximum number of files to analyze (0 = no limit)</li>
</ul>
<h3 id="debugging--verbosity"><a class="header" href="#debugging--verbosity">Debugging &amp; Verbosity</a></h3>
<p>Control diagnostic output and debugging information.</p>
<p><strong>Verbosity Levels:</strong></p>
<ul>
<li><code>-v, --verbose</code> - Increase verbosity level (can be repeated: -v, -vv, -vvv)
<ul>
<li><code>-v</code> - Show main score factors</li>
<li><code>-vv</code> - Show detailed calculations</li>
<li><code>-vvv</code> - Show all debug information</li>
</ul>
</li>
</ul>
<p><strong>Specialized Debugging:</strong></p>
<ul>
<li><code>--verbose-macro-warnings</code> - Show verbose macro parsing warnings (Rust analysis)</li>
<li><code>--show-macro-stats</code> - Show macro expansion statistics at end of analysis</li>
<li><code>--detail-level &lt;LEVEL&gt;</code> - Detail level for diagnostic reports
<ul>
<li>Options: summary, standard, comprehensive, debug (default: standard)</li>
</ul>
</li>
</ul>
<h3 id="aggregation"><a class="header" href="#aggregation">Aggregation</a></h3>
<p>Control file-level aggregation and god object detection.</p>
<p><strong>File Aggregation:</strong></p>
<ul>
<li><code>--aggregate-only</code> - Show only aggregated file-level scores</li>
<li><code>--no-aggregation</code> - Disable file-level aggregation</li>
<li><code>--aggregation-method &lt;METHOD&gt;</code> - File aggregation method (default: weighted_sum)
<ul>
<li>Options: sum, weighted_sum, logarithmic_sum, max_plus_average</li>
</ul>
</li>
<li><code>--min-problematic &lt;N&gt;</code> - Minimum number of problematic functions for file aggregation</li>
<li><code>--no-god-object</code> - Disable god object detection</li>
</ul>
<h3 id="option-aliases"><a class="header" href="#option-aliases">Option Aliases</a></h3>
<p>Common option shortcuts and aliases for convenience:</p>
<ul>
<li><code>--lcov</code> is alias for <code>--coverage-file</code></li>
<li><code>--enable-context</code> is alias for <code>--context</code></li>
<li><code>--head</code> is alias for <code>--top</code></li>
<li><code>-s</code> is short form for <code>--summary</code></li>
<li><code>-v</code> is short form for <code>--verbose</code></li>
<li><code>-f</code> is short form for <code>--format</code></li>
<li><code>-o</code> is short form for <code>--output</code></li>
<li><code>-c</code> is short form for <code>--config</code></li>
<li><code>-j</code> is short form for <code>--jobs</code></li>
</ul>
<h3 id="deprecated-options"><a class="header" href="#deprecated-options">Deprecated Options</a></h3>
<p>The following options are deprecated and should be migrated:</p>
<ul>
<li><code>--cache</code> (hidden) - <strong>Deprecated:</strong> caching is now enabled by default
<ul>
<li><strong>Migration:</strong> Remove this flag, use <code>--no-cache</code> to disable if needed</li>
</ul>
</li>
<li><code>--explain-score</code> (hidden) - <strong>Deprecated:</strong> use <code>-v</code> instead
<ul>
<li><strong>Migration:</strong> Use <code>-v</code>, <code>-vv</code>, or <code>-vvv</code> for increasing verbosity levels</li>
</ul>
</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<h3 id="configuration-file"><a class="header" href="#configuration-file">Configuration File</a></h3>
<p>Created via <code>debtmap init</code> command. The configuration file (<code>debtmap.toml</code>) is used by the <code>validate</code> command for threshold enforcement and default settings.</p>
<p><strong>Creating Configuration:</strong></p>
<pre><code class="language-bash"># Create new config
debtmap init

# Overwrite existing config
debtmap init --force
</code></pre>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<ul>
<li><code>DEBTMAP_CACHE_DIR</code> - Override default cache directory location
<ul>
<li>Can also be set via <code>--cache-location</code> flag</li>
<li>Affects where analysis results are cached for faster subsequent runs</li>
</ul>
</li>
</ul>
<h3 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h3>
<p>Get help for any command:</p>
<pre><code class="language-bash"># General help
debtmap --help

# Command-specific help
debtmap analyze --help
debtmap validate --help
debtmap compare --help
debtmap init --help
</code></pre>
<h2 id="common-workflows"><a class="header" href="#common-workflows">Common Workflows</a></h2>
<h3 id="basic-analysis"><a class="header" href="#basic-analysis">Basic Analysis</a></h3>
<p>Analyze a project and view results in terminal:</p>
<pre><code class="language-bash">debtmap analyze src/
</code></pre>
<p>Generate JSON report for further processing:</p>
<pre><code class="language-bash">debtmap analyze . --format json --output report.json
</code></pre>
<p>Generate Markdown report:</p>
<pre><code class="language-bash">debtmap analyze . --format markdown --output report.md
</code></pre>
<h3 id="coverage-integrated-analysis"><a class="header" href="#coverage-integrated-analysis">Coverage-Integrated Analysis</a></h3>
<p>Analyze with test coverage to surface untested complex code:</p>
<pre><code class="language-bash"># Generate coverage file first (example for Rust)
cargo tarpaulin --out lcov

# Run analysis with coverage
debtmap analyze src/ --coverage-file lcov.info
</code></pre>
<p>Coverage dampens debt scores for well-tested code, making untested complex functions more visible.</p>
<h3 id="context-aware-analysis"><a class="header" href="#context-aware-analysis">Context-Aware Analysis</a></h3>
<p>Enable context providers for risk-aware prioritization:</p>
<pre><code class="language-bash"># Use all context providers
debtmap analyze . --context

# Use specific context providers
debtmap analyze . --context --context-providers critical_path,git_history
</code></pre>
<p>Context-aware analysis reduces false positives and prioritizes code based on:</p>
<ul>
<li>Critical execution paths</li>
<li>Dependency relationships</li>
<li>Git history (change frequency)</li>
</ul>
<h3 id="filtered--focused-analysis"><a class="header" href="#filtered--focused-analysis">Filtered &amp; Focused Analysis</a></h3>
<p>Show only top priority items:</p>
<pre><code class="language-bash">debtmap analyze . --top 10 --min-priority high
</code></pre>
<p>Filter by specific debt categories:</p>
<pre><code class="language-bash">debtmap analyze . --filter complexity,duplication
</code></pre>
<p>Use summary mode for compact output:</p>
<pre><code class="language-bash">debtmap analyze . --summary
</code></pre>
<p>Show only file-level aggregations:</p>
<pre><code class="language-bash">debtmap analyze . --aggregate-only
</code></pre>
<h3 id="performance-tuning"><a class="header" href="#performance-tuning">Performance Tuning</a></h3>
<p>Control parallelization:</p>
<pre><code class="language-bash"># Use 8 threads
debtmap analyze . --jobs 8

# Disable parallel processing
debtmap analyze . --no-parallel
</code></pre>
<p>Manage caching:</p>
<pre><code class="language-bash"># Use shared cache location
debtmap analyze . --cache-location shared

# Clear cache and rebuild
debtmap analyze . --clear-cache

# Show cache statistics
debtmap analyze . --cache-stats
</code></pre>
<p>Limit analysis scope:</p>
<pre><code class="language-bash"># Analyze maximum 100 files
debtmap analyze . --max-files 100

# Analyze specific languages only
debtmap analyze . --languages rust,python
</code></pre>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<p>Use the <code>validate</code> command in CI/CD pipelines:</p>
<pre><code class="language-bash"># Initialize configuration (one time)
debtmap init

# Edit debtmap.toml to set thresholds
# ...

# In CI pipeline: validate against thresholds
debtmap validate . --config debtmap.toml --max-debt-density 50
</code></pre>
<p>The <code>validate</code> command returns non-zero exit code if thresholds are exceeded, failing the build.</p>
<h3 id="comparison--tracking"><a class="header" href="#comparison--tracking">Comparison &amp; Tracking</a></h3>
<p>Compare analysis results before and after changes:</p>
<pre><code class="language-bash"># Before changes
debtmap analyze . --format json --output before.json

# Make code changes...

# After changes
debtmap analyze . --format json --output after.json

# Generate comparison report
debtmap compare --before before.json --after after.json --format markdown
</code></pre>
<p>With implementation plan:</p>
<pre><code class="language-bash">debtmap compare --before before.json --after after.json --plan IMPLEMENTATION_PLAN.md
</code></pre>
<h3 id="debugging-analysis"><a class="header" href="#debugging-analysis">Debugging Analysis</a></h3>
<p>Increase verbosity to understand scoring:</p>
<pre><code class="language-bash"># Show main score factors
debtmap analyze src/ -v

# Show detailed calculations
debtmap analyze src/ -vv

# Show all debug information
debtmap analyze src/ -vvv
</code></pre>
<p>Show macro expansion statistics (Rust):</p>
<pre><code class="language-bash">debtmap analyze . --show-macro-stats --verbose-macro-warnings
</code></pre>
<p>Use detailed diagnostic reports:</p>
<pre><code class="language-bash">debtmap analyze . --detail-level comprehensive
</code></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="basic-analysis-1"><a class="header" href="#basic-analysis-1">Basic Analysis</a></h3>
<pre><code class="language-bash"># Analyze current directory
debtmap analyze .

# Analyze specific directory
debtmap analyze src/

# Generate JSON output
debtmap analyze . --format json --output report.json
</code></pre>
<h3 id="with-coverage"><a class="header" href="#with-coverage">With Coverage</a></h3>
<pre><code class="language-bash"># Analyze with LCOV coverage file
debtmap analyze src/ --coverage-file coverage.lcov

# Alternative alias
debtmap analyze src/ --lcov coverage.lcov
</code></pre>
<h3 id="context-aware-analysis-1"><a class="header" href="#context-aware-analysis-1">Context-Aware Analysis</a></h3>
<pre><code class="language-bash"># Enable all context providers
debtmap analyze . --context

# Use specific context providers
debtmap analyze . --context --context-providers critical_path,git_history

# Disable specific providers
debtmap analyze . --context --disable-context dependency
</code></pre>
<h3 id="filtered-output"><a class="header" href="#filtered-output">Filtered Output</a></h3>
<pre><code class="language-bash"># Top 10 priority items only
debtmap analyze . --top 10

# High priority and above
debtmap analyze . --min-priority high

# Specific categories
debtmap analyze . --filter complexity,duplication

# Summary format
debtmap analyze . --summary

# Group by category
debtmap analyze . --group-by-category
</code></pre>
<h3 id="performance-tuning-1"><a class="header" href="#performance-tuning-1">Performance Tuning</a></h3>
<pre><code class="language-bash"># Use 8 threads
debtmap analyze . --jobs 8

# Disable parallelization
debtmap analyze . --no-parallel

# Limit file count
debtmap analyze . --max-files 100

# Shared cache
debtmap analyze . --cache-location shared

# Clear and rebuild cache
debtmap analyze . --clear-cache
</code></pre>
<h3 id="validation"><a class="header" href="#validation">Validation</a></h3>
<pre><code class="language-bash"># Initialize config
debtmap init --force

# Validate against config
debtmap validate . --config debtmap.toml

# With max debt density threshold
debtmap validate . --max-debt-density 50
</code></pre>
<h3 id="comparison"><a class="header" href="#comparison">Comparison</a></h3>
<pre><code class="language-bash"># Compare two analyses
debtmap compare --before before.json --after after.json

# With markdown output
debtmap compare --before before.json --after after.json --format markdown

# With implementation plan
debtmap compare --before before.json --after after.json --plan IMPLEMENTATION_PLAN.md

# With target location
debtmap compare --before before.json --after after.json --target-location "src/main.rs:process_file:42"
</code></pre>
<h3 id="language-selection"><a class="header" href="#language-selection">Language Selection</a></h3>
<pre><code class="language-bash"># Analyze only Rust files
debtmap analyze . --languages rust

# Multiple languages
debtmap analyze . --languages rust,python,javascript
</code></pre>
<h3 id="threshold-configuration"><a class="header" href="#threshold-configuration">Threshold Configuration</a></h3>
<pre><code class="language-bash"># Custom complexity threshold
debtmap analyze . --threshold-complexity 15

# Use preset
debtmap analyze . --threshold-preset strict

# Custom duplication threshold
debtmap analyze . --threshold-duplication 100
</code></pre>
<h3 id="plainmachine-readable-output"><a class="header" href="#plainmachine-readable-output">Plain/Machine-Readable Output</a></h3>
<pre><code class="language-bash"># Plain output (no colors, no emoji)
debtmap analyze . --plain

# Combine with JSON for CI
debtmap analyze . --format json --plain --output report.json
</code></pre>
<h2 id="command-compatibility-matrix"><a class="header" href="#command-compatibility-matrix">Command Compatibility Matrix</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Option</th><th>analyze</th><th>validate</th><th>compare</th><th>init</th></tr></thead><tbody>
<tr><td><code>&lt;PATH&gt;</code> argument</td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--format</code></td><td>‚úì</td><td>‚úì</td><td>‚úì</td><td>‚úó</td></tr>
<tr><td><code>--output</code></td><td>‚úì</td><td>‚úì</td><td>‚úì</td><td>‚úó</td></tr>
<tr><td><code>--coverage-file</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--context</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--threshold-*</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--top / --tail</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--cache-*</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--jobs</code></td><td>‚úì</td><td>‚úó</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--verbose</code></td><td>‚úì</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--config</code></td><td>‚úó</td><td>‚úì</td><td>‚úó</td><td>‚úó</td></tr>
<tr><td><code>--before / --after</code></td><td>‚úó</td><td>‚úó</td><td>‚úì</td><td>‚úó</td></tr>
<tr><td><code>--force</code></td><td>‚úó</td><td>‚úó</td><td>‚úó</td><td>‚úì</td></tr>
</tbody></table>
</div>
<p><strong>Note:</strong> The <code>validate</code> command supports output control (<code>--format</code>, <code>--output</code>), coverage integration (<code>--coverage-file</code>), context-aware analysis (<code>--context</code>), display filtering (<code>--top</code>, <code>--tail</code>, <code>--summary</code>), and verbosity options (<code>--verbose</code>) from the <code>analyze</code> command. Analysis thresholds (<code>--threshold-complexity</code>, <code>--threshold-duplication</code>, <code>--threshold-preset</code>) are configured via the <code>--config</code> file rather than as command-line options. Performance options like <code>--cache-*</code> and <code>--jobs</code> are specific to the <code>analyze</code> command.</p>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="performance-issues"><a class="header" href="#performance-issues">Performance Issues</a></h3>
<p><strong>Problem:</strong> Analysis is slow on large codebases</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Use more threads (if you have CPU cores available)
debtmap analyze . --jobs 16

# Enable caching (on by default, but ensure it's not disabled)
debtmap analyze . # caching is automatic

# Use shared cache for team
debtmap analyze . --cache-location shared

# Limit analysis scope
debtmap analyze . --max-files 500 --languages rust
</code></pre>
<h3 id="memory-issues"><a class="header" href="#memory-issues">Memory Issues</a></h3>
<p><strong>Problem:</strong> Analysis runs out of memory</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Disable parallelization
debtmap analyze . --no-parallel

# Limit file count
debtmap analyze . --max-files 100

# Analyze in batches by language
debtmap analyze . --languages rust
debtmap analyze . --languages python
</code></pre>
<h3 id="output-issues"><a class="header" href="#output-issues">Output Issues</a></h3>
<p><strong>Problem:</strong> Terminal output has garbled characters</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash"># Use plain mode
debtmap analyze . --plain
</code></pre>
<p><strong>Problem:</strong> Want machine-readable output</p>
<p><strong>Solution:</strong></p>
<pre><code class="language-bash"># Use JSON with plain mode
debtmap analyze . --format json --plain --output report.json
</code></pre>
<h3 id="cache-issues"><a class="header" href="#cache-issues">Cache Issues</a></h3>
<p><strong>Problem:</strong> Stale cached results</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Clear cache
debtmap analyze . --clear-cache

# Check cache statistics
debtmap analyze . --cache-stats

# Disable cache temporarily
debtmap analyze . --no-cache
</code></pre>
<h3 id="threshold-issues"><a class="header" href="#threshold-issues">Threshold Issues</a></h3>
<p><strong>Problem:</strong> Too many items flagged</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Use lenient preset
debtmap analyze . --threshold-preset lenient

# Increase threshold
debtmap analyze . --threshold-complexity 20

# Filter to high priority only
debtmap analyze . --min-priority high
</code></pre>
<p><strong>Problem:</strong> Not enough items flagged</p>
<p><strong>Solutions:</strong></p>
<pre><code class="language-bash"># Use strict preset
debtmap analyze . --threshold-preset strict

# Lower threshold
debtmap analyze . --threshold-complexity 5

# Show all items
debtmap analyze . --min-priority low
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="regular-analysis"><a class="header" href="#regular-analysis">Regular Analysis</a></h3>
<p>Run analysis regularly to track code quality trends:</p>
<pre><code class="language-bash"># Daily in CI
debtmap validate . --config debtmap.toml

# Weekly deep analysis with coverage
debtmap analyze . --coverage-file coverage.lcov --format json --output weekly-report.json
</code></pre>
<h3 id="team-workflows"><a class="header" href="#team-workflows">Team Workflows</a></h3>
<p>Use shared cache for consistent team experience:</p>
<pre><code class="language-bash"># Set environment variable for all team members
export DEBTMAP_CACHE_DIR=/shared/team/debtmap-cache

# Or use flag
debtmap analyze . --cache-location shared
</code></pre>
<h3 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h3>
<p>For large codebases:</p>
<pre><code class="language-bash"># Use maximum parallelization
debtmap analyze . --jobs 0  # 0 = all cores

# Cache aggressively
debtmap analyze . --cache-location shared

# Focus on changed files in CI
# (implement via custom scripts to analyze git diff)
</code></pre>
<h3 id="integration-with-coverage"><a class="header" href="#integration-with-coverage">Integration with Coverage</a></h3>
<p>Always analyze with coverage when available:</p>
<pre><code class="language-bash"># Rust example
cargo tarpaulin --out lcov
debtmap analyze src/ --coverage-file lcov.info

# Python example
pytest --cov --cov-report=lcov
debtmap analyze . --coverage-file coverage.lcov
</code></pre>
<p>Coverage integration helps prioritize untested complex code.</p>
<h2 id="additional-tools"><a class="header" href="#additional-tools">Additional Tools</a></h2>
<h3 id="prodigy-validate-debtmap-improvement"><a class="header" href="#prodigy-validate-debtmap-improvement">prodigy-validate-debtmap-improvement</a></h3>
<p>Specialized validation tool for Prodigy workflow integration.</p>
<p><strong>Description:</strong>
This binary is part of the Prodigy workflow system and provides specialized validation for Debtmap improvement workflows.</p>
<p><strong>Usage:</strong>
See Prodigy documentation for detailed usage instructions.</p>
<h2 id="see-also"><a class="header" href="#see-also">See Also</a></h2>
<ul>
<li><a href="./configuration.html">Configuration Format</a> - Detailed configuration file format</li>
<li><a href="./output-formats.html">Output Formats</a> - Understanding JSON, Markdown, and Terminal output</li>
<li><a href="./coverage.html">Coverage Integration</a> - Integrating test coverage data</li>
<li><a href="./context-providers.html">Context Providers</a> - Understanding context-aware analysis</li>
<li><a href="./examples.html">Examples</a> - More comprehensive usage examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="analysis-guide"><a class="header" href="#analysis-guide">Analysis Guide</a></h1>
<p>This guide explains Debtmap‚Äôs analysis capabilities, metrics, and methodologies in depth. Use this to understand what Debtmap measures, how it scores technical debt, and how to interpret analysis results for maximum impact.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Debtmap analyzes code through multiple lenses to provide a comprehensive view of technical health:</p>
<ul>
<li><strong>Complexity Metrics</strong> - Quantifies how difficult code is to understand and test</li>
<li><strong>Debt Patterns</strong> - Identifies 13 types of technical debt requiring attention</li>
<li><strong>Risk Scoring</strong> - Correlates complexity with test coverage to find truly risky code</li>
<li><strong>Prioritization</strong> - Ranks findings by impact to guide refactoring efforts</li>
</ul>
<p>The goal is to move beyond simple ‚Äúhere are your problems‚Äù to ‚Äúhere‚Äôs what to fix first and why.‚Äù</p>
<h2 id="complexity-metrics"><a class="header" href="#complexity-metrics">Complexity Metrics</a></h2>
<p>Debtmap measures complexity using multiple complementary approaches. Each metric captures a different aspect of code difficulty.</p>
<h3 id="cyclomatic-complexity"><a class="header" href="#cyclomatic-complexity">Cyclomatic Complexity</a></h3>
<p>Measures the number of linearly independent paths through code - essentially counting decision points.</p>
<p><strong>How it works:</strong></p>
<ul>
<li>Start with a base complexity of 1</li>
<li>Add 1 for each: <code>if</code>, <code>else if</code>, <code>match</code> arm, <code>while</code>, <code>for</code>, <code>&amp;&amp;</code>, <code>||</code>, <code>?</code> operator</li>
<li>Does NOT increase for <code>else</code> (it‚Äôs the alternate path, not a new decision)</li>
</ul>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>1-5</strong>: Simple, easy to test - typically needs 1-3 test cases</li>
<li><strong>6-10</strong>: Moderate complexity - needs 4-8 test cases</li>
<li><strong>11-20</strong>: Complex, consider refactoring - needs 9+ test cases</li>
<li><strong>20+</strong>: Very complex, high risk - difficult to test thoroughly</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn validate_user(age: u32, has_license: bool, country: &amp;str) -&gt; bool {
    // Complexity: 4
    // Base (1) + if (1) + &amp;&amp; (1) + match (1) = 4
    if age &gt;= 18 &amp;&amp; has_license {
        match country {
            "US" | "CA" =&gt; true,
            _ =&gt; false,
        }
    } else {
        false
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="cognitive-complexity"><a class="header" href="#cognitive-complexity">Cognitive Complexity</a></h3>
<p>Measures how difficult code is to understand by considering nesting depth and control flow interruptions.</p>
<p><strong>How it differs from cyclomatic:</strong></p>
<ul>
<li>Nesting increases weight (deeply nested code is harder to understand)</li>
<li>Linear sequences don‚Äôt increase complexity (easier to follow)</li>
<li>Breaks and continues add complexity (interrupt normal flow)</li>
</ul>
<p><strong>Calculation:</strong></p>
<ul>
<li>Each structure (if, loop, match) gets a base score</li>
<li>Nesting multiplies the weight (nested structures = harder to understand)</li>
<li>Break/continue/return in middle of function adds cognitive load</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cyclomatic: 5, Cognitive: 8
fn process_items(items: Vec&lt;Item&gt;) -&gt; Vec&lt;Result&gt; {
    let mut results = vec![];

    for item in items {                    // +1 cognitive
        if item.is_valid() {               // +2 (nested in loop)
            match item.type {              // +3 (nested 2 levels)
                Type::A =&gt; results.push(process_a(item)),
                Type::B =&gt; {
                    if item.priority &gt; 5 { // +4 (nested 3 levels)
                        results.push(process_b_priority(item));
                    }
                }
                _ =&gt; continue,             // +1 (control flow interruption)
            }
        }
    }

    results
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>0-5</strong>: Trivial - anyone can understand</li>
<li><strong>6-10</strong>: Simple - straightforward logic</li>
<li><strong>11-20</strong>: Moderate - requires careful reading</li>
<li><strong>21-40</strong>: Complex - difficult to understand</li>
<li><strong>40+</strong>: Very complex - needs refactoring</li>
</ul>
<h3 id="entropy-based-complexity-analysis"><a class="header" href="#entropy-based-complexity-analysis">Entropy-Based Complexity Analysis</a></h3>
<p>Uses information theory to distinguish genuinely complex code from pattern-based repetitive code. This dramatically reduces false positives for validation functions, dispatchers, and configuration parsers.</p>
<p><strong>How it works:</strong></p>
<ol>
<li>
<p><strong>Token Entropy</strong> (0.0-1.0): Measures variety in code tokens</p>
<ul>
<li>High entropy (0.7+): Diverse logic, genuinely complex</li>
<li>Low entropy (0.0-0.4): Repetitive patterns, less complex than it appears</li>
</ul>
</li>
<li>
<p><strong>Pattern Repetition</strong> (0.0-1.0): Detects repetitive structures in AST</p>
<ul>
<li>High repetition (0.7+): Similar blocks repeated (validation checks, case handlers)</li>
<li>Low repetition: Unique logic throughout</li>
</ul>
</li>
<li>
<p><strong>Branch Similarity</strong> (0.0-1.0): Analyzes similarity between conditional branches</p>
<ul>
<li>High similarity (0.8+): Branches do similar things (consistent handling)</li>
<li>Low similarity: Each branch has unique logic</li>
</ul>
</li>
<li>
<p><strong>Token Classification</strong>: Categorizes tokens by type with weighted importance</p>
<ul>
<li>Variables, methods, literals weighted differently</li>
<li>Focuses on structural complexity over superficial differences</li>
</ul>
</li>
</ol>
<p><strong>Dampening logic:</strong> Dampening is applied when multiple factors indicate repetitive patterns:</p>
<ul>
<li>Low token entropy (&lt; 0.4) indicates simple, repetitive patterns</li>
<li>High pattern repetition (&gt; 0.6) shows similar code blocks</li>
<li>High branch similarity (&gt; 0.7) indicates consistent branching logic</li>
</ul>
<p>When these conditions are met:</p>
<pre><code>effective_complexity = entropy √ó pattern_factor √ó similarity_factor
</code></pre>
<p><strong>Dampening cap:</strong> The dampening factor has a minimum of 0.7, ensuring no more than 30% reduction in complexity scores. This prevents over-correction of pattern-based code and maintains a baseline complexity floor for functions that still require understanding and maintenance.</p>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Without entropy: Cyclomatic = 15 (appears very complex)
// With entropy: Effective = 5 (pattern-based, dampened 67%)
fn validate_config(config: &amp;Config) -&gt; Result&lt;(), ValidationError&gt; {
    if config.name.is_empty() { return Err(ValidationError::EmptyName); }
    if config.port == 0 { return Err(ValidationError::InvalidPort); }
    if config.host.is_empty() { return Err(ValidationError::EmptyHost); }
    if config.timeout == 0 { return Err(ValidationError::InvalidTimeout); }
    // ... 11 more similar checks
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Enable in <code>.debtmap.toml</code>:</strong></p>
<pre><code class="language-toml">[entropy]
enabled = true                 # Enable entropy analysis (default: true)
weight = 0.5                  # Weight in adjustment (0.0-1.0)
use_classification = true     # Advanced token classification
pattern_threshold = 0.7       # Pattern detection threshold
entropy_threshold = 0.4       # Entropy below this triggers dampening
branch_threshold = 0.8        # Branch similarity threshold
max_combined_reduction = 0.3  # Maximum 30% reduction
</code></pre>
<p><strong>Output fields in EntropyScore:</strong></p>
<ul>
<li><code>unique_variables</code>: Count of distinct variables in the function (measures variable diversity)</li>
<li><code>max_nesting</code>: Maximum nesting depth detected (contributes to dampening calculation)</li>
<li><code>dampening_applied</code>: Actual dampening factor applied to the complexity score</li>
</ul>
<h3 id="nesting-depth"><a class="header" href="#nesting-depth">Nesting Depth</a></h3>
<p>Maximum level of indentation in a function. Deep nesting makes code hard to follow.</p>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>1-2</strong>: Flat, easy to read</li>
<li><strong>3-4</strong>: Moderate nesting</li>
<li><strong>5+</strong>: Deep nesting, consider extracting functions</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Nesting depth: 4 (difficult to follow)
fn process(data: Data) -&gt; Result&lt;Output&gt; {
    if data.is_valid() {                    // Level 1
        for item in data.items {            // Level 2
            if item.active {                // Level 3
                match item.type {           // Level 4
                    Type::A =&gt; { /* ... */ }
                    Type::B =&gt; { /* ... */ }
                }
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Refactored:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Nesting depth: 2 (much clearer)
fn process(data: Data) -&gt; Result&lt;Output&gt; {
    if !data.is_valid() {
        return Err(Error::Invalid);
    }

    data.items
        .iter()
        .filter(|item| item.active)
        .map(|item| process_item(item))     // Extract to separate function
        .collect()
}
<span class="boring">}</span></code></pre></pre>
<h3 id="function-length"><a class="header" href="#function-length">Function Length</a></h3>
<p>Number of lines in a function. Long functions often violate single responsibility principle.</p>
<p><strong>Thresholds:</strong></p>
<ul>
<li><strong>1-20 lines</strong>: Good - focused, single purpose</li>
<li><strong>21-50 lines</strong>: Acceptable - may have multiple steps</li>
<li><strong>51-100 lines</strong>: Long - consider breaking up</li>
<li><strong>100+ lines</strong>: Very long - definitely needs refactoring</li>
</ul>
<p><strong>Why length matters:</strong></p>
<ul>
<li>Harder to understand and remember</li>
<li>Harder to test thoroughly</li>
<li>Often violates single responsibility</li>
<li>Difficult to reuse</li>
</ul>
<h2 id="debt-patterns"><a class="header" href="#debt-patterns">Debt Patterns</a></h2>
<p>Debtmap detects 24 types of technical debt, organized into 4 strategic categories. Each debt type is mapped to a category that guides prioritization and remediation strategies.</p>
<h3 id="debt-type-enum"><a class="header" href="#debt-type-enum">Debt Type Enum</a></h3>
<p>The <code>DebtType</code> enum defines all specific debt patterns that Debtmap can detect:</p>
<p><strong>Testing Debt:</strong></p>
<ul>
<li><code>TestingGap</code> - Functions with insufficient test coverage</li>
<li><code>TestTodo</code> - TODO comments in test code</li>
<li><code>TestComplexity</code> - Test functions exceeding complexity thresholds</li>
<li><code>TestDuplication</code> - Duplicated code in test files</li>
<li><code>TestComplexityHotspot</code> - Complex test logic that‚Äôs hard to maintain</li>
<li><code>AssertionComplexity</code> - Complex test assertions</li>
<li><code>FlakyTestPattern</code> - Non-deterministic test behavior</li>
</ul>
<p><strong>Architecture Debt:</strong></p>
<ul>
<li><code>ComplexityHotspot</code> - Functions exceeding complexity thresholds</li>
<li><code>DeadCode</code> - Unreachable or unused code</li>
<li><code>GodObject</code> - Classes with too many responsibilities</li>
<li><code>GodModule</code> - Modules with too many responsibilities</li>
<li><code>FeatureEnvy</code> - Using more data from other objects than own</li>
<li><code>PrimitiveObsession</code> - Overusing basic types instead of domain objects</li>
<li><code>MagicValues</code> - Unexplained literal values</li>
</ul>
<p><strong>Performance Debt:</strong></p>
<ul>
<li><code>AllocationInefficiency</code> - Inefficient memory allocations</li>
<li><code>StringConcatenation</code> - Inefficient string building in loops</li>
<li><code>NestedLoops</code> - Multiple nested iterations (O(n¬≤) or worse)</li>
<li><code>BlockingIO</code> - Blocking I/O in async contexts</li>
<li><code>SuboptimalDataStructure</code> - Wrong data structure for access pattern</li>
<li><code>AsyncMisuse</code> - Improper async/await usage</li>
<li><code>ResourceLeak</code> - Resources not properly released</li>
<li><code>CollectionInefficiency</code> - Inefficient collection operations</li>
</ul>
<p><strong>Code Quality Debt:</strong></p>
<ul>
<li><code>Risk</code> - High-risk code (complex + poorly tested)</li>
<li><code>Duplication</code> - Duplicated code blocks</li>
<li><code>ErrorSwallowing</code> - Errors caught but ignored</li>
</ul>
<h3 id="debt-categories"><a class="header" href="#debt-categories">Debt Categories</a></h3>
<p>The <code>DebtCategory</code> enum groups debt types into strategic categories:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum DebtCategory {
    Architecture,  // Structure, design, complexity
    Testing,       // Coverage, test quality
    Performance,   // Speed, memory, efficiency
    CodeQuality,   // Maintainability, readability
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Category Mapping:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Debt Type</th><th>Category</th><th>Strategic Focus</th></tr></thead><tbody>
<tr><td>ComplexityHotspot, DeadCode, GodObject, GodModule, FeatureEnvy, PrimitiveObsession, MagicValues</td><td>Architecture</td><td>Structural improvements, design patterns</td></tr>
<tr><td>TestingGap, TestTodo, TestComplexity, TestDuplication, TestComplexityHotspot, AssertionComplexity, FlakyTestPattern</td><td>Testing</td><td>Test coverage, test quality</td></tr>
<tr><td>AllocationInefficiency, StringConcatenation, NestedLoops, BlockingIO, SuboptimalDataStructure, AsyncMisuse, ResourceLeak, CollectionInefficiency</td><td>Performance</td><td>Runtime efficiency, resource usage</td></tr>
<tr><td>Risk, Duplication, ErrorSwallowing</td><td>CodeQuality</td><td>Maintainability, reliability</td></tr>
</tbody></table>
</div>
<h3 id="examples-by-category"><a class="header" href="#examples-by-category">Examples by Category</a></h3>
<h4 id="architecture-debt"><a class="header" href="#architecture-debt">Architecture Debt</a></h4>
<p><strong>ComplexityHotspot</strong>: Functions exceeding complexity thresholds</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cyclomatic: 22, Cognitive: 35
fn process_transaction(tx: Transaction, account: &amp;mut Account) -&gt; Result&lt;Receipt&gt; {
    if tx.amount &lt;= 0 {
        return Err(Error::InvalidAmount);
    }
    // ... deeply nested logic with many branches
    Ok(receipt)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Cyclomatic &gt; 10 OR Cognitive &gt; 15 (configurable)
<strong>Action</strong>: Break into smaller functions, extract validation, simplify control flow</p>
<p><strong>GodObject / GodModule</strong>: Too many responsibilities</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// God module: handles parsing, validation, storage, notifications
mod user_service {
    fn parse_user() { /* ... */ }
    fn validate_user() { /* ... */ }
    fn save_user() { /* ... */ }
    fn send_email() { /* ... */ }
    fn log_activity() { /* ... */ }
    // ... 20+ more functions
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Pattern analysis for responsibility clustering
<strong>Action</strong>: Split into focused modules (parser, validator, repository, notifier)</p>
<p><strong>MagicValues</strong>: Unexplained literals</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Magic numbers
fn calculate_price(quantity: u32) -&gt; f64 {
    quantity as f64 * 19.99 + 5.0  // What are these numbers?
}

// Good: Named constants
const UNIT_PRICE: f64 = 19.99;
const SHIPPING_COST: f64 = 5.0;
fn calculate_price(quantity: u32) -&gt; f64 {
    quantity as f64 * UNIT_PRICE + SHIPPING_COST
}
<span class="boring">}</span></code></pre></pre>
<h4 id="testing-debt"><a class="header" href="#testing-debt">Testing Debt</a></h4>
<p><strong>TestingGap</strong>: Functions with insufficient test coverage</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 0% coverage - critical business logic untested
fn calculate_tax(amount: f64, region: &amp;str) -&gt; f64 {
    // Complex tax calculation logic
    // No tests exist for this function!
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Coverage data shows function has &lt; 80% line coverage
<strong>Action</strong>: Add unit tests to cover all branches and edge cases</p>
<p><strong>TestComplexity</strong>: Test functions too complex</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn complex_test() {
    // Cyclomatic: 12 (too complex for a test)
    for input in test_cases {
        if input.is_special() {
            match input.type {
                /* complex test logic */
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Test functions with cyclomatic &gt; 10 or cognitive &gt; 15
<strong>Action</strong>: Split into multiple focused tests, use test fixtures</p>
<p><strong>FlakyTestPattern</strong>: Non-deterministic tests</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn flaky_test() {
    let result = async_operation().await;  // Timing-dependent
    thread::sleep(Duration::from_millis(100));  // Race condition!
    assert_eq!(result.status, "complete");
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Pattern analysis for timing dependencies, random values
<strong>Action</strong>: Use mocks, deterministic test data, proper async test utilities</p>
<h4 id="performance-debt"><a class="header" href="#performance-debt">Performance Debt</a></h4>
<p><strong>AllocationInefficiency</strong>: Excessive allocations</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Allocates on every iteration
fn process_items(items: &amp;[Item]) -&gt; Vec&lt;String&gt; {
    let mut results = Vec::new();
    for item in items {
        results.push(item.name.clone());  // Unnecessary clone
    }
    results
}

// Good: Pre-allocate, avoid clones
fn process_items(items: &amp;[Item]) -&gt; Vec&lt;&amp;str&gt; {
    items.iter().map(|item| item.name.as_str()).collect()
}
<span class="boring">}</span></code></pre></pre>
<p><strong>BlockingIO</strong>: Blocking operations in async contexts</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Blocks async runtime
async fn load_data() -&gt; Result&lt;Data&gt; {
    let file = std::fs::read_to_string("data.json")?;  // Blocking!
    parse_json(&amp;file)
}

// Good: Async I/O
async fn load_data() -&gt; Result&lt;Data&gt; {
    let file = tokio::fs::read_to_string("data.json").await?;
    parse_json(&amp;file)
}
<span class="boring">}</span></code></pre></pre>
<p><strong>NestedLoops</strong>: O(n¬≤) or worse complexity</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: O(n¬≤) nested loops
fn find_duplicates(items: &amp;[Item]) -&gt; Vec&lt;(Item, Item)&gt; {
    let mut dupes = vec![];
    for i in 0..items.len() {
        for j in i+1..items.len() {
            if items[i] == items[j] {
                dupes.push((items[i].clone(), items[j].clone()));
            }
        }
    }
    dupes
}

// Good: O(n) with HashSet
fn find_duplicates(items: &amp;[Item]) -&gt; Vec&lt;Item&gt; {
    let mut seen = HashSet::new();
    items.iter().filter(|item| !seen.insert(item)).cloned().collect()
}
<span class="boring">}</span></code></pre></pre>
<h4 id="code-quality-debt"><a class="header" href="#code-quality-debt">Code Quality Debt</a></h4>
<p><strong>Duplication</strong>: Duplicated code blocks</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// File A:
fn process_user(user: User) -&gt; Result&lt;()&gt; {
    validate_email(&amp;user.email)?;
    validate_age(user.age)?;
    save_to_database(&amp;user)?;
    send_welcome_email(&amp;user.email)?;
    Ok(())
}

// File B: Duplicated validation
fn process_admin(admin: Admin) -&gt; Result&lt;()&gt; {
    validate_email(&amp;admin.email)?;  // Duplicated
    validate_age(admin.age)?;       // Duplicated
    save_to_database(&amp;admin)?;
    grant_admin_privileges(&amp;admin)?;
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Similar code blocks &gt; 50 lines (configurable)
<strong>Action</strong>: Extract shared code into reusable functions</p>
<p><strong>ErrorSwallowing</strong>: Errors caught but ignored</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Bad: Error swallowed, no context
match risky_operation() {
    Ok(result) =&gt; process(result),
    Err(_) =&gt; {}, // Silent failure!
}

// Good: Error handled with context
match risky_operation() {
    Ok(result) =&gt; process(result),
    Err(e) =&gt; {
        log::error!("Risky operation failed: {}", e);
        return Err(e.into());
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Empty catch blocks, ignored Results
<strong>Action</strong>: Add proper error logging and propagation</p>
<p><strong>Risk</strong>: High-risk code (complex + poorly tested)</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Cyclomatic: 18, Coverage: 20%, Risk Score: 47.6 (HIGH)
fn process_payment(tx: Transaction) -&gt; Result&lt;Receipt&gt; {
    // Complex payment logic with minimal testing
    // High risk of bugs in production
}
<span class="boring">}</span></code></pre></pre>
<p><strong>When detected</strong>: Combines complexity metrics with coverage data
<strong>Action</strong>: Either add comprehensive tests OR refactor to reduce complexity</p>
<h3 id="debt-scoring-formula"><a class="header" href="#debt-scoring-formula">Debt Scoring Formula</a></h3>
<p>Each debt item gets a score based on priority and type:</p>
<pre><code>debt_score = priority_weight √ó type_weight
</code></pre>
<p><strong>Priority weights:</strong></p>
<ul>
<li>Low = 1</li>
<li>Medium = 3</li>
<li>High = 5</li>
<li>Critical = 10</li>
</ul>
<p><strong>Combined examples:</strong></p>
<ul>
<li>Low Todo = 1 √ó 1 = 1</li>
<li>Medium Fixme = 3 √ó 2 = 6</li>
<li>High Complexity = 5 √ó 5 = 25</li>
<li>Critical Complexity = 10 √ó 5 = 50</li>
</ul>
<p><strong>Total debt score</strong> = Sum of all debt item scores</p>
<p>Lower is better. Track over time to measure improvement.</p>
<h2 id="risk-scoring"><a class="header" href="#risk-scoring">Risk Scoring</a></h2>
<p>Debtmap‚Äôs risk scoring identifies code that is both complex AND poorly tested - the true risk hotspots.</p>
<h3 id="unified-scoring-system"><a class="header" href="#unified-scoring-system">Unified Scoring System</a></h3>
<p>Debtmap uses a <strong>unified scoring system</strong> (0-10 scale) as the primary prioritization mechanism. This multi-factor approach balances complexity, test coverage, and dependency impact, adjusted by function role.</p>
<h4 id="score-scale-and-priority-classifications"><a class="header" href="#score-scale-and-priority-classifications">Score Scale and Priority Classifications</a></h4>
<p>Functions receive scores from 0 (minimal risk) to 10 (critical risk):</p>
<div class="table-wrapper"><table><thead><tr><th>Score Range</th><th>Priority</th><th>Description</th><th>Action</th></tr></thead><tbody>
<tr><td><strong>9.0-10.0</strong></td><td>Critical</td><td>Severe risk requiring immediate attention</td><td>Address immediately</td></tr>
<tr><td><strong>7.0-8.9</strong></td><td>High</td><td>Significant risk, should be addressed soon</td><td>Plan for this sprint</td></tr>
<tr><td><strong>5.0-6.9</strong></td><td>Medium</td><td>Moderate risk, plan for future work</td><td>Schedule for next sprint</td></tr>
<tr><td><strong>3.0-4.9</strong></td><td>Low</td><td>Minor risk, lower priority</td><td>Monitor and address as time permits</td></tr>
<tr><td><strong>0.0-2.9</strong></td><td>Minimal</td><td>Well-managed code</td><td>Continue monitoring</td></tr>
</tbody></table>
</div>
<h4 id="scoring-formula"><a class="header" href="#scoring-formula">Scoring Formula</a></h4>
<p>The unified score combines three weighted factors:</p>
<pre><code>Base Score = (Complexity Factor √ó 0.40) + (Coverage Factor √ó 0.40) + (Dependency Factor √ó 0.20)

Final Score = Base Score √ó Role Multiplier
</code></pre>
<p><strong>Factor Calculations:</strong></p>
<p><strong>Complexity Factor</strong> (0-10 scale):</p>
<pre><code>Complexity Factor = min(10, ((cyclomatic / 10) + (cognitive / 20)) √ó 5)
</code></pre>
<p>Normalized to 0-10 range based on cyclomatic and cognitive complexity.</p>
<p><strong>Coverage Factor</strong> (0-10 scale):</p>
<pre><code>Coverage Factor = 10 √ó (1 - coverage_percentage) √ó complexity_weight
</code></pre>
<p>Uncovered complex code scores higher than uncovered simple code. Coverage dampens the score - well-tested code gets lower scores.</p>
<p><strong>Dependency Factor</strong> (0-10 scale):
Based on call graph analysis:</p>
<ul>
<li>High upstream caller count (many functions depend on this): 8-10</li>
<li>On critical paths from entry points: 7-9</li>
<li>Moderate dependencies: 4-6</li>
<li>Isolated utilities: 1-3</li>
</ul>
<h4 id="default-weights"><a class="header" href="#default-weights">Default Weights</a></h4>
<p>The scoring formula uses configurable weights (default values shown):</p>
<ul>
<li><strong>Complexity: 40%</strong> - How difficult the code is to understand and test</li>
<li><strong>Coverage: 40%</strong> - How well the code is tested</li>
<li><strong>Dependency: 20%</strong> - How many other functions depend on this code</li>
</ul>
<p>These weights can be adjusted in <code>.debtmap.toml</code> to match your team‚Äôs priorities.</p>
<h4 id="role-based-prioritization"><a class="header" href="#role-based-prioritization">Role-Based Prioritization</a></h4>
<p>The unified score is multiplied by a <strong>role multiplier</strong> based on the function‚Äôs semantic classification:</p>
<div class="table-wrapper"><table><thead><tr><th>Role</th><th>Multiplier</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><strong>Entry Points</strong></td><td>1.5√ó</td><td>main(), HTTP handlers, API endpoints</td><td>User-facing code where bugs have immediate impact</td></tr>
<tr><td><strong>Business Logic</strong></td><td>1.2√ó</td><td>Core domain functions, algorithms</td><td>Critical functionality</td></tr>
<tr><td><strong>Data Access</strong></td><td>1.0√ó</td><td>Database queries, file I/O</td><td>Baseline importance</td></tr>
<tr><td><strong>Infrastructure</strong></td><td>0.8√ó</td><td>Logging, configuration, monitoring</td><td>Supporting code</td></tr>
<tr><td><strong>Utilities</strong></td><td>0.5√ó</td><td>Helpers, formatters, converters</td><td>Lower impact</td></tr>
<tr><td><strong>Test Code</strong></td><td>0.1√ó</td><td>Test functions, fixtures, mocks</td><td>Internal quality</td></tr>
</tbody></table>
</div>
<p><strong>How role classification works:</strong></p>
<p>Debtmap identifies function roles through pattern analysis:</p>
<ul>
<li><strong>Entry points</strong>: Functions named <code>main</code>, handlers with routing decorators, public API functions</li>
<li><strong>Business logic</strong>: Core domain operations, calculation functions, decision-making code</li>
<li><strong>Data access</strong>: Database queries, file operations, network calls</li>
<li><strong>Infrastructure</strong>: Logging, config parsing, monitoring, error handling</li>
<li><strong>Utilities</strong>: Helper functions, formatters, type converters, validators</li>
<li><strong>Test code</strong>: Functions in test modules, test functions, fixtures</li>
</ul>
<p><strong>Example: Same complexity, different priorities</strong></p>
<p>Consider a function with base score 8.0:</p>
<pre><code>If classified as Entry Point:
  Final Score = 8.0 √ó 1.5 = 12.0 (capped at 10.0) ‚Üí CRITICAL priority

If classified as Business Logic:
  Final Score = 8.0 √ó 1.2 = 9.6 ‚Üí CRITICAL priority

If classified as Data Access:
  Final Score = 8.0 √ó 1.0 = 8.0 ‚Üí HIGH priority

If classified as Utility:
  Final Score = 8.0 √ó 0.5 = 4.0 ‚Üí LOW priority
</code></pre>
<p>This ensures that complex code in critical paths gets higher priority than equally complex utility code.</p>
<h4 id="coverage-propagation"><a class="header" href="#coverage-propagation">Coverage Propagation</a></h4>
<p>Coverage impact flows through the call graph using <strong>transitive coverage</strong>:</p>
<pre><code>Transitive Coverage = Direct Coverage + Œ£(Caller Coverage √ó Weight)
</code></pre>
<p><strong>How it works:</strong></p>
<p>Functions called by well-tested code inherit some coverage benefit, reducing their urgency. This helps identify which untested functions are on critical paths versus safely isolated utilities.</p>
<p><strong>Example scenarios:</strong></p>
<p><strong>Scenario 1: Untested function with well-tested callers</strong></p>
<pre><code>Function A: 0% direct coverage
  Called by:
    - handle_request (95% coverage)
    - process_payment (90% coverage)
    - validate_order (88% coverage)

Transitive coverage: ~40% (inherits coverage benefit from callers)
Final priority: Lower than isolated 0% coverage function
</code></pre>
<p><strong>Scenario 2: Untested function on critical path</strong></p>
<pre><code>Function B: 0% direct coverage
  Called by:
    - main (0% coverage)
    - startup (10% coverage)

Transitive coverage: ~5% (minimal coverage benefit)
Final priority: Higher - on critical path with no safety net
</code></pre>
<p>Coverage propagation prevents false alarms about utility functions called only by well-tested code, while highlighting genuinely risky untested code on critical paths.</p>
<h4 id="unified-score-example"><a class="header" href="#unified-score-example">Unified Score Example</a></h4>
<pre><code>Function: process_payment
  Location: src/payments.rs:145

Metrics:
  - Cyclomatic complexity: 18
  - Cognitive complexity: 25
  - Test coverage: 20%
  - Upstream callers: 3 (high dependency)
  - Role: Business Logic

Calculation:
  Complexity Factor = min(10, ((18/10) + (25/20)) √ó 5) = min(10, 8.75) = 8.75
  Coverage Factor = 10 √ó (1 - 0.20) √ó 1.0 = 8.0
  Dependency Factor = 7.5 (3 upstream callers, moderate impact)

  Base Score = (8.75 √ó 0.40) + (8.0 √ó 0.40) + (7.5 √ó 0.20)
             = 3.5 + 3.2 + 1.5
             = 8.2

  Final Score = 8.2 √ó 1.2 (Business Logic multiplier)
              = 9.84 ‚Üí CRITICAL priority
</code></pre>
<h3 id="legacy-risk-scoring-pre-02x"><a class="header" href="#legacy-risk-scoring-pre-02x">Legacy Risk Scoring (Pre-0.2.x)</a></h3>
<p>Prior to the unified scoring system, Debtmap used a simpler additive risk formula. This is still available for compatibility but unified scoring is now the default and provides better prioritization.</p>
<h3 id="risk-categories"><a class="header" href="#risk-categories">Risk Categories</a></h3>
<p><strong>Note:</strong> The <code>RiskLevel</code> enum (Low, Medium, High, Critical) is used for <strong>legacy risk scoring compatibility</strong>. When using <strong>unified scoring</strong> (0-10 scale), refer to the priority classifications shown in the Unified Scoring System section above.</p>
<h4 id="legacy-risklevel-enum"><a class="header" href="#legacy-risklevel-enum">Legacy RiskLevel Enum</a></h4>
<p>For legacy risk scoring, Debtmap classifies functions into four risk levels:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum RiskLevel {
    Low,       // Score &lt; 10
    Medium,    // Score 10-24
    High,      // Score 25-49
    Critical,  // Score ‚â• 50
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Critical</strong> (legacy score ‚â• 50)</p>
<ul>
<li>High complexity (cyclomatic &gt; 15) AND low coverage (&lt; 30%)</li>
<li>Untested code that‚Äôs likely to break and hard to fix</li>
<li><strong>Action</strong>: Immediate attention required - add tests or refactor</li>
</ul>
<p><strong>High</strong> (legacy score 25-49)</p>
<ul>
<li>High complexity (cyclomatic &gt; 10) AND moderate coverage (&lt; 60%)</li>
<li>Risky code with incomplete testing</li>
<li><strong>Action</strong>: Should be addressed soon</li>
</ul>
<p><strong>Medium</strong> (legacy score 10-24)</p>
<ul>
<li>Moderate complexity (cyclomatic &gt; 5) AND low coverage (&lt; 50%)</li>
<li>OR: High complexity with good coverage</li>
<li><strong>Action</strong>: Plan for next sprint</li>
</ul>
<p><strong>Low</strong> (legacy score &lt; 10)</p>
<ul>
<li>Low complexity OR high coverage</li>
<li>Well-managed code</li>
<li><strong>Action</strong>: Monitor, low priority</li>
</ul>
<h4 id="unified-scoring-priority-levels"><a class="header" href="#unified-scoring-priority-levels">Unified Scoring Priority Levels</a></h4>
<p>When using unified scoring (default), functions are classified using the 0-10 scale:</p>
<ul>
<li><strong>Critical</strong> (9.0-10.0): Immediate attention</li>
<li><strong>High</strong> (7.0-8.9): Address this sprint</li>
<li><strong>Medium</strong> (5.0-6.9): Plan for next sprint</li>
<li><strong>Low</strong> (3.0-4.9): Monitor and address as time permits</li>
<li><strong>Minimal</strong> (0.0-2.9): Well-managed code</li>
</ul>
<p><strong>Well-tested complex code</strong> is an <strong>outcome</strong> in both systems, not a separate category:</p>
<ul>
<li>Complex function (cyclomatic 18, cognitive 25) with 95% coverage</li>
<li>Unified score: ~2.5 (Minimal priority due to coverage dampening)</li>
<li>Legacy risk score: ~8 (Low risk)</li>
<li>Falls into low-priority categories because good testing mitigates complexity</li>
<li>This is the desired state for inherently complex business logic</li>
</ul>
<h3 id="legacy-risk-calculation"><a class="header" href="#legacy-risk-calculation">Legacy Risk Calculation</a></h3>
<p><strong>Note:</strong> The legacy risk calculation is still supported for compatibility but has been superseded by the unified scoring system (see above). Unified scoring provides better prioritization through its multi-factor, weighted approach with role-based adjustments.</p>
<p>The legacy risk score uses a simpler additive formula:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>risk_score = complexity_factor + coverage_factor + debt_factor

where:
  complexity_factor = (cyclomatic / 5) + (cognitive / 10)
  coverage_factor = (1 - coverage_percentage) √ó 50
  debt_factor = debt_score / 10  // If debt data available
<span class="boring">}</span></code></pre></pre>
<p><strong>Example (legacy scoring):</strong></p>
<pre><code>Function: process_payment
  - Cyclomatic complexity: 18
  - Cognitive complexity: 25
  - Coverage: 20%
  - Debt score: 15

Calculation:
  complexity_factor = (18 / 5) + (25 / 10) = 3.6 + 2.5 = 6.1
  coverage_factor = (1 - 0.20) √ó 50 = 40
  debt_factor = 15 / 10 = 1.5

  risk_score = 6.1 + 40 + 1.5 = 47.6 (HIGH RISK)
</code></pre>
<p><strong>When to use legacy scoring:</strong></p>
<ul>
<li>Comparing with historical data from older Debtmap versions</li>
<li>Teams with existing workflows built around the old scale</li>
<li>Gradual migration to unified scoring</li>
</ul>
<p><strong>Why unified scoring is better:</strong></p>
<ul>
<li>Normalized 0-10 scale is more intuitive</li>
<li>Weighted factors (40% complexity, 40% coverage, 20% dependency) provide better balance</li>
<li>Role multipliers adjust priority based on function importance</li>
<li>Coverage propagation reduces false positives for utility functions</li>
</ul>
<h3 id="test-effort-assessment"><a class="header" href="#test-effort-assessment">Test Effort Assessment</a></h3>
<p>Debtmap estimates testing difficulty based on cognitive complexity:</p>
<p><strong>Difficulty Levels:</strong></p>
<ul>
<li><strong>Trivial</strong> (cognitive &lt; 5): 1-2 test cases, &lt; 1 hour</li>
<li><strong>Simple</strong> (cognitive 5-10): 3-5 test cases, 1-2 hours</li>
<li><strong>Moderate</strong> (cognitive 10-20): 6-10 test cases, 2-4 hours</li>
<li><strong>Complex</strong> (cognitive 20-40): 11-20 test cases, 4-8 hours</li>
<li><strong>VeryComplex</strong> (cognitive &gt; 40): 20+ test cases, 8+ hours</li>
</ul>
<p><strong>Test Effort includes:</strong></p>
<ul>
<li><strong>Cognitive load</strong>: How hard to understand the function</li>
<li><strong>Branch count</strong>: Number of paths to test</li>
<li><strong>Recommended test cases</strong>: Suggested number of tests</li>
</ul>
<h3 id="risk-distribution"><a class="header" href="#risk-distribution">Risk Distribution</a></h3>
<p>Debtmap provides codebase-wide risk metrics:</p>
<pre><code class="language-json">{
  "risk_distribution": {
    "critical_count": 12,
    "high_count": 45,
    "medium_count": 123,
    "low_count": 456,
    "minimal_count": 234,
    "total_functions": 870
  },
  "codebase_risk_score": 1247.5
}
</code></pre>
<p><strong>Interpreting distribution:</strong></p>
<ul>
<li><strong>Healthy codebase</strong>: Most functions in Low/Minimal priority (unified scoring) or Low/WellTested (legacy)</li>
<li><strong>Needs attention</strong>: Many Critical/High priority functions</li>
<li><strong>Technical debt</strong>: High codebase risk score</li>
</ul>
<p><strong>Note on well-tested functions:</strong>
In unified scoring, well-tested complex code simply scores low (0-2.9 Minimal or 3-4.9 Low) due to coverage dampening - it‚Äôs not a separate category. The <code>minimal_count</code> in the distribution represents functions with unified scores 0-2.9, which includes well-tested complex code.</p>
<h3 id="testing-recommendations"><a class="header" href="#testing-recommendations">Testing Recommendations</a></h3>
<p>When coverage data is provided, Debtmap generates prioritized testing recommendations with ROI analysis:</p>
<pre><code class="language-json">{
  "function": "process_transaction",
  "file": "src/payments.rs",
  "line": 145,
  "current_risk": 47.6,
  "potential_risk_reduction": 35.2,
  "test_effort_estimate": {
    "estimated_difficulty": "Complex",
    "cognitive_load": 25,
    "branch_count": 18,
    "recommended_test_cases": 12
  },
  "roi": 4.4,
  "rationale": "High complexity with low coverage (20%) and 3 downstream dependencies. Testing will reduce risk by 74%.",
  "dependencies": {
    "upstream_callers": ["handle_payment_request"],
    "downstream_callees": ["validate_amount", "check_balance", "record_transaction"]
  }
}
</code></pre>
<p><strong>ROI calculation:</strong></p>
<pre><code>roi = potential_risk_reduction / estimated_effort_hours
</code></pre>
<p>Higher ROI = better return on testing investment</p>
<h2 id="interpreting-results"><a class="header" href="#interpreting-results">Interpreting Results</a></h2>
<h3 id="understanding-output-formats"><a class="header" href="#understanding-output-formats">Understanding Output Formats</a></h3>
<p>Debtmap provides three output formats:</p>
<p><strong>Terminal</strong> (default): Human-readable with colors and tables</p>
<pre><code class="language-bash">debtmap analyze .
</code></pre>
<p><strong>JSON</strong>: Machine-readable for CI/CD integration</p>
<pre><code class="language-bash">debtmap analyze . --format json --output report.json
</code></pre>
<p><strong>Markdown</strong>: Documentation-friendly</p>
<pre><code class="language-bash">debtmap analyze . --format markdown --output report.md
</code></pre>
<h3 id="json-structure"><a class="header" href="#json-structure">JSON Structure</a></h3>
<pre><code class="language-json">{
  "timestamp": "2025-10-09T12:00:00Z",
  "project_path": "/path/to/project",
  "complexity": {
    "metrics": [
      {
        "name": "process_data",
        "file": "src/main.rs",
        "line": 42,
        "cyclomatic": 15,
        "cognitive": 22,
        "nesting": 4,
        "length": 68,
        "is_test": false,
        "visibility": "Public",
        "is_trait_method": false,
        "in_test_module": false,
        "entropy_score": {
          "token_entropy": 0.65,
          "pattern_repetition": 0.25,
          "branch_similarity": 0.30,
          "effective_complexity": 0.85
        },
        "is_pure": false,
        "purity_confidence": 0.8,
        "detected_patterns": ["validation_pattern"],
        "upstream_callers": ["main", "process_request"],
        "downstream_callees": ["validate", "save", "notify"]
      }
    ],
    "summary": {
      "total_functions": 150,
      "average_complexity": 5.3,
      "max_complexity": 22,
      "high_complexity_count": 8
    }
  },
  "technical_debt": {
    "items": [
      {
        "id": "complexity_src_main_rs_42",
        "debt_type": "Complexity",
        "priority": "High",
        "file": "src/main.rs",
        "line": 42,
        "column": 1,
        "message": "Function exceeds complexity threshold",
        "context": "Cyclomatic: 15, Cognitive: 22"
      }
    ],
    "by_type": {
      "Complexity": [...],
      "Duplication": [...],
      "Todo": [...]
    }
  }
}
</code></pre>
<h3 id="reading-function-metrics"><a class="header" href="#reading-function-metrics">Reading Function Metrics</a></h3>
<p><strong>Key fields:</strong></p>
<ul>
<li><code>cyclomatic</code>: Decision points - guides test case count</li>
<li><code>cognitive</code>: Understanding difficulty - guides refactoring priority</li>
<li><code>nesting</code>: Indentation depth - signals need for extraction</li>
<li><code>length</code>: Lines of code - signals SRP violations</li>
<li><code>visibility</code>: Function visibility (<code>"Private"</code>, <code>"Crate"</code>, or <code>"Public"</code> from FunctionVisibility enum)</li>
<li><code>is_pure</code>: No side effects - easier to test (Option type, may be None)</li>
<li><code>purity_confidence</code>: How certain we are about purity 0.0-1.0 (Option type, may be None)</li>
<li><code>is_trait_method</code>: Whether this function implements a trait method</li>
<li><code>in_test_module</code>: Whether function is inside a <code>#[cfg(test)]</code> module</li>
<li><code>detected_patterns</code>: Complexity adjustment patterns identified (e.g., ‚Äúvalidation_pattern‚Äù)</li>
<li><code>entropy_score</code>: Pattern analysis for false positive reduction</li>
<li><code>upstream_callers</code>: Impact radius if this function breaks</li>
<li><code>downstream_callees</code>: Functions this depends on</li>
</ul>
<p><strong>Entropy interpretation:</strong></p>
<ul>
<li><code>token_entropy &lt; 0.4</code>: Repetitive code, likely pattern-based</li>
<li><code>pattern_repetition &gt; 0.7</code>: High similarity between blocks</li>
<li><code>branch_similarity &gt; 0.8</code>: Similar conditional branches</li>
<li><code>effective_complexity &lt; 1.0</code>: Dampening applied</li>
</ul>
<h3 id="prioritizing-work"><a class="header" href="#prioritizing-work">Prioritizing Work</a></h3>
<p>Debtmap provides multiple prioritization strategies, with <strong>unified scoring (0-10 scale)</strong> as the recommended default for most workflows:</p>
<p><strong>1. By Unified Score (default - recommended)</strong></p>
<pre><code class="language-bash">debtmap analyze . --top 10
</code></pre>
<p>Shows top 10 items by <strong>combined complexity, coverage, and dependency factors</strong>, weighted and adjusted by function role.</p>
<p><strong>Why use unified scoring:</strong></p>
<ul>
<li>Balances complexity (40%), coverage (40%), and dependency impact (20%)</li>
<li>Adjusts for function importance (entry points prioritized over utilities)</li>
<li>Normalized 0-10 scale is intuitive and consistent</li>
<li>Reduces false positives through coverage propagation</li>
<li>Best for <strong>sprint planning</strong> and <strong>function-level refactoring decisions</strong></li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-bash"># Show top 20 critical items
debtmap analyze . --min-priority 7.0 --top 20

# Focus on high-impact functions (score &gt;= 7.0)
debtmap analyze . --format json | jq '.functions[] | select(.unified_score &gt;= 7.0)'
</code></pre>
<p><strong>2. By Risk Category (legacy compatibility)</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority high
</code></pre>
<p>Shows only HIGH and CRITICAL priority items using legacy risk scoring.</p>
<p><strong>Note:</strong> Legacy risk scoring uses additive formulas and unbounded scales. Prefer unified scoring for new workflows.</p>
<p><strong>3. By Debt Type</strong></p>
<pre><code class="language-bash">debtmap analyze . --filter Architecture,Testing
</code></pre>
<p>Focuses on specific categories:</p>
<ul>
<li><code>Architecture</code>: God objects, complexity, dead code</li>
<li><code>Testing</code>: Coverage gaps, test quality</li>
<li><code>Performance</code>: Resource leaks, inefficiencies</li>
<li><code>CodeQuality</code>: Code smells, maintainability</li>
</ul>
<p><strong>4. By ROI (with coverage)</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.lcov --top 20
</code></pre>
<p>Prioritizes by return on investment for testing/refactoring. Combines unified scoring with test effort estimates to identify high-value work.</p>
<p><strong>Choosing the right strategy:</strong></p>
<ul>
<li><strong>Sprint planning for developers</strong>: Use unified scoring (<code>--top N</code>)</li>
<li><strong>Architectural review</strong>: Use tiered prioritization (<code>--summary</code>)</li>
<li><strong>Category-focused work</strong>: Use debt type filtering (<code>--filter</code>)</li>
<li><strong>Testing priorities</strong>: Use ROI analysis with coverage data (<code>--lcov</code>)</li>
<li><strong>Historical comparisons</strong>: Use legacy risk scoring (for consistency with old reports)</li>
</ul>
<h3 id="tiered-prioritization"><a class="header" href="#tiered-prioritization">Tiered Prioritization</a></h3>
<p><strong>Note:</strong> Tiered prioritization uses <strong>traditional debt scoring</strong> (additive, higher = worse) and is complementary to the unified scoring system (0-10 scale). Both systems can be used together:</p>
<ul>
<li><strong>Unified scoring</strong> (0-10 scale): Best for <strong>function-level prioritization</strong> and sprint planning</li>
<li><strong>Tiered prioritization</strong> (debt tiers): Best for <strong>architectural focus</strong> and strategic debt planning</li>
</ul>
<p>Use <code>--summary</code> for tiered view focusing on architectural issues, or default output for function-level unified scores.</p>
<p>Debtmap uses a tier-based system to map debt scores to actionable priority levels. Each tier includes effort estimates and strategic guidance for efficient debt remediation.</p>
<h4 id="tier-levels"><a class="header" href="#tier-levels">Tier Levels</a></h4>
<p>The <code>Tier</code> enum defines four priority levels based on score thresholds:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum Tier {
    Critical,  // Score ‚â• 90
    High,      // Score 70-89.9
    Moderate,  // Score 50-69.9
    Low,       // Score &lt; 50
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Score-to-Tier Mapping:</strong></p>
<ul>
<li><strong>Critical</strong> (‚â• 90): Immediate action required - blocks progress</li>
<li><strong>High</strong> (70-89.9): Should be addressed this sprint</li>
<li><strong>Moderate</strong> (50-69.9): Plan for next sprint</li>
<li><strong>Low</strong> (&lt; 50): Background maintenance work</li>
</ul>
<h4 id="effort-estimates-per-tier"><a class="header" href="#effort-estimates-per-tier">Effort Estimates Per Tier</a></h4>
<p>Each tier includes estimated effort based on typical remediation patterns:</p>
<div class="table-wrapper"><table><thead><tr><th>Tier</th><th>Estimated Effort</th><th>Typical Work</th></tr></thead><tbody>
<tr><td><strong>Critical</strong></td><td>1-2 days</td><td>Major refactoring, comprehensive testing, architectural changes</td></tr>
<tr><td><strong>High</strong></td><td>2-4 hours</td><td>Extract functions, add test coverage, fix resource leaks</td></tr>
<tr><td><strong>Moderate</strong></td><td>1-2 hours</td><td>Simplify logic, reduce duplication, improve error handling</td></tr>
<tr><td><strong>Low</strong></td><td>30 minutes</td><td>Address TODOs, minor cleanup, documentation</td></tr>
</tbody></table>
</div>
<p><strong>Effort calculation considers:</strong></p>
<ul>
<li>Complexity metrics (cyclomatic, cognitive)</li>
<li>Test coverage gaps</li>
<li>Number of dependencies (upstream/downstream)</li>
<li>Debt category (Architecture debt takes longer than CodeQuality)</li>
</ul>
<h4 id="tiered-display-grouping"><a class="header" href="#tiered-display-grouping">Tiered Display Grouping</a></h4>
<p><code>TieredDisplay</code> groups similar debt items for batch action recommendations:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TieredDisplay {
    pub tier: Tier,
    pub items: Vec&lt;DebtItem&gt;,
    pub total_score: f64,
    pub estimated_total_effort_hours: f64,
    pub batch_recommendations: Vec&lt;String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Grouping strategy:</strong></p>
<ul>
<li>Groups items by tier and similarity pattern</li>
<li>Prevents grouping of god objects (always show individually)</li>
<li>Prevents grouping of Critical items (each needs individual attention)</li>
<li>Suggests batch actions for similar Low/Moderate items</li>
</ul>
<p><strong>Example batch recommendations:</strong></p>
<pre><code class="language-json">{
  "tier": "Moderate",
  "total_score": 245.8,
  "estimated_total_effort_hours": 12.5,
  "batch_recommendations": [
    "Extract 5 validation functions from similar patterns",
    "Add test coverage for 8 moderately complex functions (grouped by module)",
    "Refactor 3 functions with similar nested loop patterns"
  ]
}
</code></pre>
<h4 id="using-tiered-prioritization"><a class="header" href="#using-tiered-prioritization">Using Tiered Prioritization</a></h4>
<p><strong>1. Start with Critical tier:</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority critical
</code></pre>
<p>Focus on items with score ‚â• 90. These typically represent:</p>
<ul>
<li>Complex functions with 0% coverage</li>
<li>God objects blocking feature development</li>
<li>Critical resource leaks or security issues</li>
</ul>
<p><strong>2. Plan High tier work:</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority high --format json &gt; sprint-plan.json
</code></pre>
<p>Schedule 2-4 hours per item for this sprint. Look for:</p>
<ul>
<li>Functions approaching complexity thresholds</li>
<li>Moderate coverage gaps on important code paths</li>
<li>Performance bottlenecks with clear solutions</li>
</ul>
<p><strong>3. Batch Moderate tier items:</strong></p>
<pre><code class="language-bash">debtmap analyze . --min-priority moderate
</code></pre>
<p>Review batch recommendations. Examples:</p>
<ul>
<li>‚Äú10 validation functions detected - extract common pattern‚Äù</li>
<li>‚Äú5 similar test files with duplication - create shared fixtures‚Äù</li>
<li>‚Äú8 functions with magic values - create constants module‚Äù</li>
</ul>
<p><strong>4. Schedule Low tier background work:</strong>
Address during slack time or as warm-up tasks for new contributors.</p>
<h4 id="strategic-guidance-by-tier"><a class="header" href="#strategic-guidance-by-tier">Strategic Guidance by Tier</a></h4>
<p><strong>Critical Tier Strategy:</strong></p>
<ul>
<li><strong>Block new features</strong> until addressed</li>
<li><strong>Pair programming</strong> recommended for complex items</li>
<li><strong>Architectural review</strong> before major refactoring</li>
<li><strong>Comprehensive testing</strong> after changes</li>
</ul>
<p><strong>High Tier Strategy:</strong></p>
<ul>
<li><strong>Sprint planning priority</strong></li>
<li><strong>Impact analysis</strong> before changes</li>
<li><strong>Code review</strong> from senior developers</li>
<li><strong>Integration testing</strong> after changes</li>
</ul>
<p><strong>Moderate Tier Strategy:</strong></p>
<ul>
<li><strong>Batch similar items</strong> for efficiency</li>
<li><strong>Extract patterns</strong> across multiple files</li>
<li><strong>Incremental improvement</strong> over multiple PRs</li>
<li><strong>Regression testing</strong> for affected areas</li>
</ul>
<p><strong>Low Tier Strategy:</strong></p>
<ul>
<li><strong>Good first issues</strong> for new contributors</li>
<li><strong>Documentation improvements</strong></li>
<li><strong>Code cleanup</strong> during refactoring nearby code</li>
<li><strong>Technical debt gardening</strong> sessions</li>
</ul>
<h3 id="categorized-debt-analysis"><a class="header" href="#categorized-debt-analysis">Categorized Debt Analysis</a></h3>
<p>Debtmap provides <code>CategorizedDebt</code> analysis that groups debt items by category and identifies cross-category dependencies. This helps teams understand strategic relationships between different types of technical debt.</p>
<h4 id="categorysummary"><a class="header" href="#categorysummary">CategorySummary</a></h4>
<p>Each category gets a summary with metrics for planning:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CategorySummary {
    pub category: DebtCategory,
    pub total_score: f64,
    pub item_count: usize,
    pub estimated_effort_hours: f64,
    pub average_severity: f64,
    pub top_items: Vec&lt;DebtItem&gt;,  // Up to 5 highest priority
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Effort estimation formulas:</strong></p>
<ul>
<li><strong>Architecture debt</strong>: <code>complexity_score / 10 √ó 2</code> hours (structural changes take longer)</li>
<li><strong>Testing debt</strong>: <code>complexity_score / 10 √ó 1.5</code> hours (writing tests)</li>
<li><strong>Performance debt</strong>: <code>complexity_score / 10 √ó 1.8</code> hours (profiling + optimization)</li>
<li><strong>CodeQuality debt</strong>: <code>complexity_score / 10 √ó 1.2</code> hours (refactoring)</li>
</ul>
<p><strong>Example category summary:</strong></p>
<pre><code class="language-json">{
  "category": "Architecture",
  "total_score": 487.5,
  "item_count": 15,
  "estimated_effort_hours": 97.5,
  "average_severity": 32.5,
  "top_items": [
    {
      "debt_type": "GodObject",
      "file": "src/services/user_service.rs",
      "score": 95.0,
      "estimated_effort_hours": 16.0
    },
    {
      "debt_type": "ComplexityHotspot",
      "file": "src/payments/processor.rs",
      "score": 87.3,
      "estimated_effort_hours": 14.0
    }
  ]
}
</code></pre>
<h4 id="cross-category-dependencies"><a class="header" href="#cross-category-dependencies">Cross-Category Dependencies</a></h4>
<p><code>CrossCategoryDependency</code> identifies blocking relationships between different debt categories:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CrossCategoryDependency {
    pub from_category: DebtCategory,
    pub to_category: DebtCategory,
    pub blocking_items: Vec&lt;(DebtItem, DebtItem)&gt;,
    pub impact_level: ImpactLevel,  // Critical, High, Medium, Low
    pub recommendation: String,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Common dependency patterns:</strong></p>
<p><strong>1. Architecture blocks Testing:</strong></p>
<ul>
<li><strong>Pattern</strong>: God objects are too complex to test effectively</li>
<li><strong>Example</strong>: <code>UserService</code> has 50+ functions, making comprehensive testing impractical</li>
<li><strong>Impact</strong>: Critical - cannot improve test coverage without refactoring</li>
<li><strong>Recommendation</strong>: ‚ÄúSplit god object into 4-5 focused modules before adding tests‚Äù</li>
</ul>
<p><strong>2. Async issues require Architecture changes:</strong></p>
<ul>
<li><strong>Pattern</strong>: Blocking I/O in async contexts requires architectural redesign</li>
<li><strong>Example</strong>: Sync database calls in async handlers</li>
<li><strong>Impact</strong>: High - performance problems require design changes</li>
<li><strong>Recommendation</strong>: ‚ÄúIntroduce async database layer before optimizing handlers‚Äù</li>
</ul>
<p><strong>3. Complexity affects Testability:</strong></p>
<ul>
<li><strong>Pattern</strong>: High cyclomatic complexity makes thorough testing difficult</li>
<li><strong>Example</strong>: Function with 22 branches needs 22+ test cases</li>
<li><strong>Impact</strong>: High - testing effort grows exponentially with complexity</li>
<li><strong>Recommendation</strong>: ‚ÄúReduce complexity to &lt; 10 before writing comprehensive tests‚Äù</li>
</ul>
<p><strong>4. Performance requires Architecture:</strong></p>
<ul>
<li><strong>Pattern</strong>: O(n¬≤) nested loops need different data structures</li>
<li><strong>Example</strong>: Linear search in loops should use HashMap</li>
<li><strong>Impact</strong>: Medium - optimization requires structural changes</li>
<li><strong>Recommendation</strong>: ‚ÄúRefactor data structure before micro-optimizations‚Äù</li>
</ul>
<p><strong>Example cross-category dependency:</strong></p>
<pre><code class="language-json">{
  "from_category": "Architecture",
  "to_category": "Testing",
  "impact_level": "Critical",
  "blocking_items": [
    {
      "blocker": {
        "debt_type": "GodObject",
        "file": "src/services/user_service.rs",
        "functions": 52,
        "score": 95.0
      },
      "blocked": {
        "debt_type": "TestingGap",
        "file": "src/services/user_service.rs",
        "coverage": 15,
        "score": 78.0
      }
    }
  ],
  "recommendation": "Split UserService into focused modules (auth, profile, settings, notifications) before attempting to improve test coverage. Current structure makes comprehensive testing impractical.",
  "estimated_unblock_effort_hours": 16.0
}
</code></pre>
<h4 id="using-categorized-debt-analysis"><a class="header" href="#using-categorized-debt-analysis">Using Categorized Debt Analysis</a></h4>
<p><strong>View all category summaries:</strong></p>
<pre><code class="language-bash">debtmap analyze . --format json | jq '.categorized_debt.summaries'
</code></pre>
<p><strong>Focus on specific category:</strong></p>
<pre><code class="language-bash">debtmap analyze . --filter Architecture --top 10
</code></pre>
<p><strong>Identify blocking relationships:</strong></p>
<pre><code class="language-bash">debtmap analyze . --format json | jq '.categorized_debt.cross_category_dependencies[] | select(.impact_level == "Critical")'
</code></pre>
<p><strong>Strategic planning workflow:</strong></p>
<ol>
<li>
<p><strong>Review category summaries:</strong></p>
<ul>
<li>Identify which category has highest total score</li>
<li>Check estimated effort hours per category</li>
<li>Note average severity to gauge urgency</li>
</ul>
</li>
<li>
<p><strong>Check cross-category dependencies:</strong></p>
<ul>
<li>Find Critical and High impact blockers</li>
<li>Prioritize blockers before blocked items</li>
<li>Plan architectural changes before optimization</li>
</ul>
</li>
<li>
<p><strong>Plan remediation order:</strong></p>
<pre><code>Example decision tree:
- Architecture score &gt; 400? ‚Üí Address god objects first
- Testing gap with low complexity? ‚Üí Quick wins, add tests
- Performance issues + architecture debt? ‚Üí Refactor structure first
- High code quality debt but good architecture? ‚Üí Incremental cleanup
</code></pre>
</li>
<li>
<p><strong>Use category-specific strategies:</strong></p>
<ul>
<li><strong>Architecture</strong>: Pair programming, design reviews, incremental refactoring</li>
<li><strong>Testing</strong>: TDD for new code, characterization tests for legacy</li>
<li><strong>Performance</strong>: Profiling first, optimize hot paths, avoid premature optimization</li>
<li><strong>CodeQuality</strong>: Code review focus, linting rules, consistent patterns</li>
</ul>
</li>
</ol>
<h4 id="categorizeddebt-output-structure"><a class="header" href="#categorizeddebt-output-structure">CategorizedDebt Output Structure</a></h4>
<pre><code class="language-json">{
  "categorized_debt": {
    "summaries": [
      {
        "category": "Architecture",
        "total_score": 487.5,
        "item_count": 15,
        "estimated_effort_hours": 97.5,
        "average_severity": 32.5,
        "top_items": [...]
      },
      {
        "category": "Testing",
        "total_score": 356.2,
        "item_count": 23,
        "estimated_effort_hours": 53.4,
        "average_severity": 15.5,
        "top_items": [...]
      },
      {
        "category": "Performance",
        "total_score": 234.8,
        "item_count": 12,
        "estimated_effort_hours": 42.3,
        "average_severity": 19.6,
        "top_items": [...]
      },
      {
        "category": "CodeQuality",
        "total_score": 189.3,
        "item_count": 31,
        "estimated_effort_hours": 22.7,
        "average_severity": 6.1,
        "top_items": [...]
      }
    ],
    "cross_category_dependencies": [
      {
        "from_category": "Architecture",
        "to_category": "Testing",
        "impact_level": "Critical",
        "blocking_items": [...],
        "recommendation": "..."
      }
    ]
  }
}
</code></pre>
<h3 id="debt-density-metric"><a class="header" href="#debt-density-metric">Debt Density Metric</a></h3>
<p>Debt density normalizes technical debt scores across projects of different sizes, providing a per-1000-lines-of-code metric for fair comparison.</p>
<h4 id="formula"><a class="header" href="#formula">Formula</a></h4>
<pre><code>debt_density = (total_debt_score / total_lines_of_code) √ó 1000
</code></pre>
<p><strong>Example calculation:</strong></p>
<pre><code>Project A:
  - Total debt score: 1,250
  - Total lines of code: 25,000
  - Debt density: (1,250 / 25,000) √ó 1000 = 50

Project B:
  - Total debt score: 2,500
  - Total lines of code: 50,000
  - Debt density: (2,500 / 50,000) √ó 1000 = 50
</code></pre>
<p>Projects A and B have <strong>equal debt density</strong> (50) despite B having twice the absolute debt, because B is also twice as large. They have proportionally similar technical debt.</p>
<h4 id="interpretation-guidelines"><a class="header" href="#interpretation-guidelines">Interpretation Guidelines</a></h4>
<p>Use these thresholds to assess codebase health:</p>
<div class="table-wrapper"><table><thead><tr><th>Debt Density</th><th>Assessment</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>0-50</strong></td><td>Clean</td><td>Well-maintained codebase, minimal debt</td></tr>
<tr><td><strong>51-100</strong></td><td>Moderate</td><td>Typical technical debt, manageable</td></tr>
<tr><td><strong>101-150</strong></td><td>High</td><td>Significant debt, prioritize remediation</td></tr>
<tr><td><strong>150+</strong></td><td>Critical</td><td>Severe debt burden, may impede development</td></tr>
</tbody></table>
</div>
<p><strong>Context matters:</strong></p>
<ul>
<li><strong>Early-stage projects</strong>: Often have higher density (rapid iteration)</li>
<li><strong>Mature projects</strong>: Should trend toward lower density over time</li>
<li><strong>Legacy systems</strong>: May have high density, track trend over time</li>
<li><strong>Greenfield rewrites</strong>: Aim for density &lt; 50</li>
</ul>
<h4 id="using-debt-density"><a class="header" href="#using-debt-density">Using Debt Density</a></h4>
<p><strong>1. Compare projects fairly:</strong></p>
<pre><code class="language-bash"># Small microservice (5,000 LOC, debt = 250)
# Debt density: 50

# Large monolith (100,000 LOC, debt = 5,000)
# Debt density: 50

# Equal health despite size difference
</code></pre>
<p><strong>2. Track improvement over time:</strong></p>
<pre><code>Sprint 1: 50,000 LOC, debt = 7,500, density = 150 (High)
Sprint 5: 52,000 LOC, debt = 6,500, density = 125 (Improving)
Sprint 10: 54,000 LOC, debt = 4,860, density = 90 (Moderate)
</code></pre>
<p><strong>3. Set team goals:</strong></p>
<pre><code>Current density: 120
Target density: &lt; 80 (by Q4)
Reduction needed: 40 points

Strategy:
- Fix 2-3 Critical items per sprint
- Prevent new debt (enforce thresholds)
- Refactor before adding features in high-debt modules
</code></pre>
<p><strong>4. Benchmark across teams/projects:</strong></p>
<pre><code class="language-json">{
  "team_metrics": [
    {
      "project": "auth-service",
      "debt_density": 45,
      "assessment": "Clean",
      "trend": "stable"
    },
    {
      "project": "billing-service",
      "debt_density": 95,
      "assessment": "Moderate",
      "trend": "improving"
    },
    {
      "project": "legacy-api",
      "debt_density": 165,
      "assessment": "Critical",
      "trend": "worsening"
    }
  ]
}
</code></pre>
<h4 id="limitations"><a class="header" href="#limitations">Limitations</a></h4>
<p><strong>Debt density doesn‚Äôt account for:</strong></p>
<ul>
<li><strong>Code importance</strong>: 100 LOC in payment logic ‚â† 100 LOC in logging utils</li>
<li><strong>Complexity distribution</strong>: One 1000-line god object vs. 1000 simple functions</li>
<li><strong>Test coverage</strong>: 50% coverage on critical paths vs. low-priority features</li>
<li><strong>Team familiarity</strong>: New codebase vs. well-understood legacy system</li>
</ul>
<p><strong>Best practices:</strong></p>
<ul>
<li>Use density as <strong>one metric among many</strong></li>
<li>Combine with category analysis and tiered prioritization</li>
<li>Focus on <strong>trend</strong> (improving/stable/worsening) over absolute number</li>
<li>Consider <strong>debt per module</strong> for more granular insights</li>
</ul>
<h4 id="debt-density-in-cicd"><a class="header" href="#debt-density-in-cicd">Debt Density in CI/CD</a></h4>
<p><strong>Track density over time:</strong></p>
<pre><code class="language-bash"># Generate report with density
debtmap analyze . --format json --output debt-report.json

# Extract density for trending
DENSITY=$(jq '.debt_density' debt-report.json)

# Store in metrics database
echo "debtmap.density:${DENSITY}|g" | nc -u -w0 statsd 8125
</code></pre>
<p><strong>Set threshold gates:</strong></p>
<pre><code class="language-yaml"># .github/workflows/debt-check.yml
- name: Check debt density
  run: |
    DENSITY=$(debtmap analyze . --format json | jq '.debt_density')
    if (( $(echo "$DENSITY &gt; 150" | bc -l) )); then
      echo "‚ùå Debt density too high: $DENSITY (limit: 150)"
      exit 1
    fi
    echo "‚úÖ Debt density acceptable: $DENSITY"
</code></pre>
<h3 id="actionable-insights"><a class="header" href="#actionable-insights">Actionable Insights</a></h3>
<p>Each recommendation includes:</p>
<p><strong>ACTION</strong>: What to do</p>
<ul>
<li>‚ÄúAdd 6 unit tests for full coverage‚Äù</li>
<li>‚ÄúRefactor into 3 smaller functions‚Äù</li>
<li>‚ÄúExtract validation to separate function‚Äù</li>
</ul>
<p><strong>IMPACT</strong>: Expected improvement</p>
<ul>
<li>‚ÄúFull test coverage, -3.7 risk‚Äù</li>
<li>‚ÄúReduce complexity from 22 to 8‚Äù</li>
<li>‚ÄúEliminate 120 lines of duplication‚Äù</li>
</ul>
<p><strong>WHY</strong>: Rationale</p>
<ul>
<li>‚ÄúBusiness logic with 0% coverage, manageable complexity‚Äù</li>
<li>‚ÄúHigh complexity with low coverage threatens stability‚Äù</li>
<li>‚ÄúRepeated validation pattern across 5 files‚Äù</li>
</ul>
<p><strong>Example workflow:</strong></p>
<ol>
<li>Run analysis with coverage: <code>debtmap analyze . --lcov coverage.lcov</code></li>
<li>Filter to CRITICAL items: <code>--min-priority critical</code></li>
<li>Review top 5 recommendations</li>
<li>Start with highest ROI items</li>
<li>Rerun analysis to track progress</li>
</ol>
<h3 id="common-patterns-to-recognize"><a class="header" href="#common-patterns-to-recognize">Common Patterns to Recognize</a></h3>
<p><strong>Pattern 1: High Complexity, Well Tested</strong></p>
<pre><code>Complexity: 25, Coverage: 95%, Risk: LOW
</code></pre>
<p>This is actually good! Complex but thoroughly tested code. Learn from this approach.</p>
<p><strong>Pattern 2: Moderate Complexity, No Tests</strong></p>
<pre><code>Complexity: 12, Coverage: 0%, Risk: CRITICAL
</code></pre>
<p>Highest priority - manageable complexity, should be easy to test.</p>
<p><strong>Pattern 3: Low Complexity, No Tests</strong></p>
<pre><code>Complexity: 3, Coverage: 0%, Risk: LOW
</code></pre>
<p>Low priority - simple code, less risky without tests.</p>
<p><strong>Pattern 4: Repetitive High Complexity (Dampened)</strong></p>
<pre><code>Cyclomatic: 20, Effective: 7 (65% dampened), Risk: LOW
</code></pre>
<p>Validation or dispatch pattern - looks complex but is repetitive. Lower priority.</p>
<p><strong>Pattern 5: God Object</strong></p>
<pre><code>File: services.rs, Functions: 50+, Responsibilities: 15+
</code></pre>
<p>Architectural issue - split before adding features.</p>
<h2 id="analyzer-types"><a class="header" href="#analyzer-types">Analyzer Types</a></h2>
<p>Debtmap supports multiple programming languages with varying levels of analysis capability.</p>
<h3 id="supported-languages"><a class="header" href="#supported-languages">Supported Languages</a></h3>
<p><strong>Rust</strong> (Full Support)</p>
<ul>
<li><strong>Parser</strong>: syn (native Rust AST)</li>
<li><strong>Capabilities</strong>:
<ul>
<li>Full complexity metrics (cyclomatic, cognitive, entropy)</li>
<li>Trait implementation tracking</li>
<li>Purity detection with confidence scoring</li>
<li>Call graph analysis (upstream callers, downstream callees)</li>
<li>Semantic function classification (entry points, business logic, data access, infrastructure, utilities, test code)</li>
<li>Enhanced call graph with transitive relationships</li>
<li>Macro expansion support for accurate complexity analysis</li>
<li>Pattern-based adjustments for macros and code generation</li>
<li>Visibility tracking (pub, pub(crate), private)</li>
<li>Test module detection (#[cfg(test)])</li>
</ul>
</li>
</ul>
<p><strong>Semantic Classification:</strong></p>
<p>Debtmap automatically identifies function roles in Rust code to apply appropriate role multipliers in unified scoring:</p>
<ul>
<li><strong>Entry Points</strong>: Functions named <code>main</code>, <code>start</code>, or public functions in <code>bin/</code> modules</li>
<li><strong>Business Logic</strong>: Core domain functions with complex logic, algorithms, business rules</li>
<li><strong>Data Access</strong>: Functions performing database queries, file I/O, network operations</li>
<li><strong>Infrastructure</strong>: Logging, configuration, monitoring, error handling utilities</li>
<li><strong>Utilities</strong>: Helper functions, formatters, type converters, validation functions</li>
<li><strong>Test Code</strong>: Functions in <code>#[cfg(test)]</code> modules, functions with <code>#[test]</code> attribute</li>
</ul>
<p>This classification feeds directly into the unified scoring system‚Äôs role multiplier (see Risk Scoring section).</p>
<p><strong>Python</strong> (Partial Support)</p>
<ul>
<li><strong>Parser</strong>: rustpython-parser</li>
<li><strong>Capabilities</strong>:
<ul>
<li>Complexity metrics (cyclomatic, cognitive)</li>
<li>Python-specific error handling patterns</li>
<li>Purity detection for pure functions</li>
<li>Basic debt pattern detection</li>
<li>Limited call graph support</li>
</ul>
</li>
</ul>
<p><strong>JavaScript</strong> (Partial Support)</p>
<ul>
<li><strong>Parser</strong>: tree-sitter (JavaScript grammar)</li>
<li><strong>File extensions</strong>: .js, .jsx, .mjs, .cjs</li>
<li><strong>Capabilities</strong>:
<ul>
<li>ECMAScript complexity patterns</li>
<li>Basic complexity metrics</li>
<li>Function extraction</li>
<li>Limited pattern detection</li>
</ul>
</li>
</ul>
<p><strong>TypeScript</strong> (Partial Support)</p>
<ul>
<li><strong>Parser</strong>: tree-sitter (TypeScript grammar)</li>
<li><strong>File extensions</strong>: .ts, .tsx, .mts, .cts</li>
<li><strong>Capabilities</strong>:
<ul>
<li>Similar to JavaScript support</li>
<li>Type information currently not utilized</li>
<li>Basic complexity metrics</li>
<li>Limited pattern detection</li>
</ul>
</li>
</ul>
<p><strong>Unsupported Languages:</strong></p>
<p>Debtmap‚Äôs <code>Language</code> enum contains only the four supported languages: Rust, Python, JavaScript, and TypeScript. Files with unsupported extensions are filtered out during the file discovery phase and never reach the analysis stage.</p>
<p><strong>File filtering behavior:</strong></p>
<ul>
<li>Discovery scans project for files matching supported extensions</li>
<li>Unsupported files (<code>.cpp</code>, <code>.java</code>, <code>.go</code>, etc.) are skipped silently</li>
<li>No analysis, metrics, or debt patterns are generated for filtered files</li>
<li>Use <code>--languages</code> flag to explicitly control which languages to analyze</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-bash"># Only analyze Rust files (skip Python/JS/TS)
debtmap analyze . --languages rust

# Analyze Rust and Python only
debtmap analyze . --languages rust,python
</code></pre>
<h3 id="language-detection"><a class="header" href="#language-detection">Language Detection</a></h3>
<p>Automatic detection by file extension:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let language = Language::from_path(&amp;path);
<span class="boring">}</span></code></pre></pre>
<p>Explicit language selection:</p>
<pre><code class="language-bash">debtmap analyze . --languages rust,python
</code></pre>
<h3 id="extensibility"><a class="header" href="#extensibility">Extensibility</a></h3>
<p>Debtmap‚Äôs architecture allows adding new languages:</p>
<ol>
<li><strong>Implement Analyzer trait:</strong></li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Analyzer: Send + Sync {
    fn parse(&amp;self, content: &amp;str, path: PathBuf) -&gt; Result&lt;Ast&gt;;
    fn analyze(&amp;self, ast: &amp;Ast) -&gt; FileMetrics;
    fn language(&amp;self) -&gt; Language;
}
<span class="boring">}</span></code></pre></pre>
<ol start="2">
<li><strong>Register in get_analyzer():</strong></li>
</ol>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn get_analyzer(language: Language) -&gt; Box&lt;dyn Analyzer&gt; {
    match language {
        Language::Rust =&gt; Box::new(RustAnalyzer::new()),
        Language::YourLanguage =&gt; Box::new(YourAnalyzer::new()),
        // ...
    }
}
<span class="boring">}</span></code></pre></pre>
<p>See <code>src/analyzers/rust.rs</code> for a complete implementation example.</p>
<h2 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h2>
<h3 id="purity-detection"><a class="header" href="#purity-detection">Purity Detection</a></h3>
<p>Debtmap detects pure functions - those without side effects that always return the same output for the same input.</p>
<p><strong>What makes a function pure:</strong></p>
<ul>
<li>No I/O operations (file, network, database)</li>
<li>No mutable global state</li>
<li>No random number generation</li>
<li>No system calls</li>
<li>Deterministic output</li>
</ul>
<p><strong>Purity detection is optional:</strong></p>
<ul>
<li>Both <code>is_pure</code> and <code>purity_confidence</code> are <code>Option</code> types</li>
<li>May be <code>None</code> for some functions or languages where detection is not available</li>
<li>Rust has the most comprehensive purity detection support</li>
</ul>
<p><strong>Confidence scoring (when available):</strong></p>
<ul>
<li><strong>0.9-1.0</strong>: Very confident (no side effects detected)</li>
<li><strong>0.7-0.8</strong>: Likely pure (minimal suspicious patterns)</li>
<li><strong>0.5-0.6</strong>: Uncertain (some suspicious patterns)</li>
<li><strong>0.0-0.4</strong>: Likely impure (side effects detected)</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pure: confidence = 0.95
fn calculate_total(items: &amp;[Item]) -&gt; f64 {
    items.iter().map(|i| i.price).sum()
}

// Impure: confidence = 0.1 (I/O detected)
fn save_total(items: &amp;[Item]) -&gt; Result&lt;()&gt; {
    let total = items.iter().map(|i| i.price).sum();
    write_to_file(total)  // Side effect!
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Benefits:</strong></p>
<ul>
<li>Pure functions are easier to test</li>
<li>Can be safely cached or memoized</li>
<li>Safe to parallelize</li>
<li>Easier to reason about</li>
</ul>
<h3 id="data-flow-analysis"><a class="header" href="#data-flow-analysis">Data Flow Analysis</a></h3>
<p>Debtmap builds a comprehensive <code>DataFlowGraph</code> that extends basic call graph analysis with variable dependencies, data transformations, I/O operations, and purity tracking.</p>
<h4 id="call-graph-foundation"><a class="header" href="#call-graph-foundation">Call Graph Foundation</a></h4>
<p><strong>Upstream callers</strong> - Who calls this function</p>
<ul>
<li>Indicates impact radius</li>
<li>More callers = higher impact if it breaks</li>
</ul>
<p><strong>Downstream callees</strong> - What this function calls</p>
<ul>
<li>Indicates dependencies</li>
<li>More callees = more integration testing needed</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-json">{
  "name": "process_payment",
  "upstream_callers": [
    "handle_checkout",
    "process_subscription",
    "handle_refund"
  ],
  "downstream_callees": [
    "validate_payment_method",
    "calculate_fees",
    "record_transaction",
    "send_receipt"
  ]
}
</code></pre>
<h4 id="variable-dependency-tracking"><a class="header" href="#variable-dependency-tracking">Variable Dependency Tracking</a></h4>
<p><code>DataFlowGraph</code> tracks which variables each function depends on:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct DataFlowGraph {
    // Maps function_id -&gt; set of variable names used
    variable_dependencies: HashMap&lt;String, HashSet&lt;String&gt;&gt;,
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p><strong>What it tracks:</strong></p>
<ul>
<li>Local variables accessed in function body</li>
<li>Function parameters</li>
<li>Captured variables (closures)</li>
<li>Mutable vs immutable references</li>
</ul>
<p><strong>Benefits:</strong></p>
<ul>
<li>Identify functions coupled through shared state</li>
<li>Detect potential side effect chains</li>
<li>Guide refactoring to reduce coupling</li>
</ul>
<p><strong>Example output:</strong></p>
<pre><code class="language-json">{
  "function": "calculate_total",
  "variable_dependencies": ["items", "tax_rate", "discount", "total"],
  "parameter_count": 3,
  "local_var_count": 1
}
</code></pre>
<h4 id="data-transformation-patterns"><a class="header" href="#data-transformation-patterns">Data Transformation Patterns</a></h4>
<p><code>DataFlowGraph</code> identifies common functional programming patterns:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum TransformationType {
    Map,        // Transform each element
    Filter,     // Select subset of elements
    Reduce,     // Aggregate to single value
    FlatMap,    // Transform and flatten
    Unknown,    // Other transformations
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Pattern detection:</strong></p>
<ul>
<li>Recognizes iterator chains (<code>.map()</code>, <code>.filter()</code>, <code>.fold()</code>)</li>
<li>Identifies functional vs imperative data flow</li>
<li>Tracks input/output variable relationships</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected as: Filter ‚Üí Map ‚Üí Reduce pattern
fn total_active_users(users: &amp;[User]) -&gt; f64 {
    users.iter()
        .filter(|u| u.active)      // Filter transformation
        .map(|u| u.balance)        // Map transformation
        .sum()                      // Reduce transformation
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Transformation metadata:</strong></p>
<pre><code class="language-json">{
  "function": "total_active_users",
  "input_vars": ["users"],
  "output_vars": ["sum_result"],
  "transformation_type": "Reduce",
  "is_functional_style": true,
  "pipeline_length": 3
}
</code></pre>
<h4 id="io-operation-detection"><a class="header" href="#io-operation-detection">I/O Operation Detection</a></h4>
<p>Tracks functions performing I/O operations for purity and performance analysis:</p>
<p><strong>I/O categories tracked:</strong></p>
<ul>
<li><strong>File I/O</strong>: <code>std::fs</code>, <code>File::open</code>, <code>read_to_string</code></li>
<li><strong>Network I/O</strong>: HTTP requests, socket operations</li>
<li><strong>Database I/O</strong>: SQL queries, ORM operations</li>
<li><strong>System calls</strong>: Process spawning, environment access</li>
<li><strong>Blocking operations</strong>: <code>thread::sleep</code>, synchronous I/O in async</li>
</ul>
<p><strong>Example detection:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Detected I/O operations: FileRead, FileWrite
fn save_config(config: &amp;Config, path: &amp;Path) -&gt; Result&lt;()&gt; {
    let json = serde_json::to_string(config)?;  // No I/O
    std::fs::write(path, json)?;                 // FileWrite detected
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>I/O metadata:</strong></p>
<pre><code class="language-json">{
  "function": "save_config",
  "io_operations": ["FileWrite"],
  "is_blocking": true,
  "affects_purity": true,
  "async_safe": false
}
</code></pre>
<h4 id="purity-analysis-integration"><a class="header" href="#purity-analysis-integration">Purity Analysis Integration</a></h4>
<p><code>DataFlowGraph</code> integrates with purity detection to provide comprehensive side effect analysis:</p>
<p><strong>Side effect tracking:</strong></p>
<ul>
<li>I/O operations (file, network, console)</li>
<li>Global state mutations</li>
<li>Random number generation</li>
<li>System time access</li>
<li>Non-deterministic behavior</li>
</ul>
<p><strong>Purity confidence factors:</strong></p>
<ul>
<li><strong>1.0</strong>: Pure mathematical function, no side effects</li>
<li><strong>0.8</strong>: Pure with deterministic data transformations</li>
<li><strong>0.5</strong>: Mixed - some suspicious patterns</li>
<li><strong>0.2</strong>: Likely impure - I/O detected</li>
<li><strong>0.0</strong>: Definitely impure - multiple side effects</li>
</ul>
<p><strong>Example analysis:</strong></p>
<pre><code class="language-json">{
  "function": "calculate_discount",
  "is_pure": true,
  "purity_confidence": 0.95,
  "side_effects": [],
  "deterministic": true,
  "safe_to_parallelize": true,
  "safe_to_cache": true
}
</code></pre>
<h4 id="modification-impact-analysis"><a class="header" href="#modification-impact-analysis">Modification Impact Analysis</a></h4>
<p><code>DataFlowGraph</code> calculates the impact of modifying a function:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ModificationImpact {
    pub function_name: String,
    pub affected_functions: Vec&lt;String&gt;,  // Upstream callers
    pub dependency_count: usize,          // Downstream callees
    pub has_side_effects: bool,
    pub risk_level: RiskLevel,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Risk level calculation:</strong></p>
<ul>
<li><strong>Critical</strong>: Many upstream callers + side effects + low test coverage</li>
<li><strong>High</strong>: Many callers OR side effects with moderate coverage</li>
<li><strong>Medium</strong>: Few callers with side effects OR many callers with good coverage</li>
<li><strong>Low</strong>: Few callers, no side effects, or well-tested</li>
</ul>
<p><strong>Example impact analysis:</strong></p>
<pre><code class="language-json">{
  "function": "validate_payment_method",
  "modification_impact": {
    "affected_functions": [
      "process_payment",
      "refund_payment",
      "update_payment_method",
      "validate_subscription"
    ],
    "affected_count": 4,
    "dependency_count": 8,
    "has_side_effects": true,
    "io_operations": ["DatabaseRead", "NetworkCall"],
    "risk_level": "High",
    "recommendation": "Comprehensive testing required - 4 functions depend on this, performs I/O"
  }
}
</code></pre>
<p><strong>Using modification impact:</strong></p>
<pre><code class="language-bash"># Analyze impact before refactoring
debtmap analyze . --format json | jq '.functions[] | select(.name == "validate_payment_method") | .modification_impact'
</code></pre>
<p><strong>Impact analysis uses:</strong></p>
<ul>
<li><strong>Refactoring planning</strong>: Understand blast radius before changes</li>
<li><strong>Test prioritization</strong>: Focus tests on high-impact functions</li>
<li><strong>Code review</strong>: Flag high-risk changes for extra scrutiny</li>
<li><strong>Dependency management</strong>: Identify tightly coupled components</li>
</ul>
<h4 id="dataflowgraph-methods"><a class="header" href="#dataflowgraph-methods">DataFlowGraph Methods</a></h4>
<p>Key methods for data flow analysis:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Add function with its dependencies
pub fn add_function(&amp;mut self, function_id: String, callees: Vec&lt;String&gt;)

// Track variable dependencies
pub fn add_variable_dependency(&amp;mut self, function_id: String, var_name: String)

// Record I/O operations
pub fn add_io_operation(&amp;mut self, function_id: String, io_type: IoType)

// Calculate modification impact
pub fn calculate_modification_impact(&amp;self, function_id: &amp;str) -&gt; ModificationImpact

// Get all functions affected by a change
pub fn get_affected_functions(&amp;self, function_id: &amp;str) -&gt; Vec&lt;String&gt;

// Find functions with side effects
pub fn find_functions_with_side_effects(&amp;self) -&gt; Vec&lt;String&gt;
<span class="boring">}</span></code></pre></pre>
<p><strong>Integration in analysis pipeline:</strong></p>
<ol>
<li>Parser builds initial call graph</li>
<li>DataFlowGraph extends with variable/I/O tracking</li>
<li>Purity analyzer adds side effect information</li>
<li>Modification impact calculated for each function</li>
<li>Results used in prioritization and risk scoring</li>
</ol>
<p><strong>Connection to Unified Scoring:</strong></p>
<p>The dependency analysis from DataFlowGraph directly feeds into the <strong>unified scoring system‚Äôs dependency factor</strong> (20% weight):</p>
<ul>
<li><strong>Dependency Factor Calculation</strong>: Functions with high upstream caller count or on critical paths from entry points receive higher dependency scores (8-10)</li>
<li><strong>Isolated Utilities</strong>: Functions with few or no callers score lower (1-3) on dependency factor</li>
<li><strong>Impact Prioritization</strong>: This helps prioritize functions where bugs have wider impact across the codebase</li>
<li><strong>Modification Risk</strong>: The modification impact analysis uses dependency data to calculate blast radius when changes are made</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code>Function: validate_payment_method
  Upstream callers: 4 (high impact)
  ‚Üí Dependency Factor: 8.0

Function: format_currency_string
  Upstream callers: 0 (utility)
  ‚Üí Dependency Factor: 1.5

Both have same complexity, but validate_payment_method gets higher unified score
due to its critical role in the call graph.
</code></pre>
<p>This integration ensures that the unified scoring system considers not just internal function complexity and test coverage, but also the function‚Äôs importance in the broader codebase architecture.</p>
<h3 id="entropy-based-complexity"><a class="header" href="#entropy-based-complexity">Entropy-Based Complexity</a></h3>
<p>Advanced pattern detection to reduce false positives.</p>
<p><strong>Token Classification:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum TokenType {
    Variable,     // Weight: 1.0
    Method,       // Weight: 1.5 (more important)
    Literal,      // Weight: 0.5 (less important)
    Keyword,      // Weight: 0.8
    Operator,     // Weight: 0.6
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Shannon Entropy Calculation:</strong></p>
<pre><code>H(X) = -Œ£ p(x) √ó log‚ÇÇ(p(x))
</code></pre>
<p>where p(x) is the probability of each token type.</p>
<p><strong>Dampening Decision:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if entropy_score.token_entropy &lt; 0.4
   &amp;&amp; entropy_score.pattern_repetition &gt; 0.6
   &amp;&amp; entropy_score.branch_similarity &gt; 0.7
{
    // Apply dampening
    effective_complexity = base_complexity √ó (1 - dampening_factor);
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Output explanation:</strong></p>
<pre><code>Function: validate_input
  Cyclomatic: 15 ‚Üí Effective: 5
  Reasoning:
    - High pattern repetition detected (85%)
    - Low token entropy indicates simple patterns (0.32)
    - Similar branch structures found (92% similarity)
    - Complexity reduced by 67% due to pattern-based code
</code></pre>
<h3 id="entropy-analysis-caching"><a class="header" href="#entropy-analysis-caching">Entropy Analysis Caching</a></h3>
<p><code>EntropyAnalyzer</code> includes an LRU-style cache for performance optimization when analyzing large codebases or performing repeated analysis.</p>
<h4 id="cache-structure"><a class="header" href="#cache-structure">Cache Structure</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct CacheEntry {
    score: EntropyScore,
    timestamp: Instant,
    hit_count: usize,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Cache configuration:</strong></p>
<ul>
<li><strong>Default size</strong>: 1000 entries</li>
<li><strong>Eviction policy</strong>: LRU (Least Recently Used)</li>
<li><strong>Memory per entry</strong>: ~128 bytes</li>
<li><strong>Total memory overhead</strong>: ~128 KB for default size</li>
</ul>
<h4 id="cache-statistics"><a class="header" href="#cache-statistics">Cache Statistics</a></h4>
<p>The analyzer tracks cache performance:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct CacheStats {
    pub hits: usize,
    pub misses: usize,
    pub evictions: usize,
    pub hit_rate: f64,
    pub memory_bytes: usize,
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Example stats output:</strong></p>
<pre><code class="language-json">{
  "entropy_cache_stats": {
    "hits": 3427,
    "misses": 1573,
    "evictions": 573,
    "hit_rate": 0.685,
    "memory_bytes": 128000
  }
}
</code></pre>
<p><strong>Hit rate interpretation:</strong></p>
<ul>
<li><strong>&gt; 0.7</strong>: Excellent - many repeated analyses, cache is effective</li>
<li><strong>0.4-0.7</strong>: Good - moderate reuse, typical for incremental analysis</li>
<li><strong>&lt; 0.4</strong>: Low - mostly unique functions, cache less helpful</li>
</ul>
<h4 id="performance-benefits"><a class="header" href="#performance-benefits">Performance Benefits</a></h4>
<p><strong>Typical performance gains:</strong></p>
<ul>
<li><strong>Cold analysis</strong>: 100ms baseline (no cache benefit)</li>
<li><strong>Incremental analysis</strong>: 30-40ms (~60-70% faster) for unchanged functions</li>
<li><strong>Re-analysis</strong>: 15-20ms (~80-85% faster) for recently analyzed functions</li>
</ul>
<p><strong>Best for:</strong></p>
<ul>
<li><strong>Watch mode</strong>: Analyzing on file save (repeated analysis of same files)</li>
<li><strong>CI/CD</strong>: Comparing feature branch to main (overlap in functions)</li>
<li><strong>Large codebases</strong>: Many similar functions benefit from pattern caching</li>
</ul>
<p><strong>Memory estimation:</strong></p>
<pre><code>Total cache memory = entry_count √ó 128 bytes

Examples:
- 1,000 entries: ~128 KB (default)
- 5,000 entries: ~640 KB (large projects)
- 10,000 entries: ~1.25 MB (very large)
</code></pre>
<h4 id="cache-management"><a class="header" href="#cache-management">Cache Management</a></h4>
<p><strong>Automatic eviction:</strong></p>
<ul>
<li>When cache reaches size limit, oldest entries evicted</li>
<li>Hit count influences retention (frequently accessed stay longer)</li>
<li>Timestamp used for LRU ordering</li>
</ul>
<p><strong>Cache invalidation:</strong></p>
<ul>
<li>Function source changes invalidate entry</li>
<li>Cache cleared between major analysis runs</li>
<li>No manual invalidation needed</li>
</ul>
<p><strong>Configuration (if exposed in future):</strong></p>
<pre><code class="language-toml">[entropy.cache]
enabled = true
size = 1000           # Number of entries
ttl_seconds = 3600    # Optional: expire after 1 hour
</code></pre>
<h3 id="context-aware-analysis-2"><a class="header" href="#context-aware-analysis-2">Context-Aware Analysis</a></h3>
<p>Debtmap adjusts analysis based on code context:</p>
<p><strong>Pattern Recognition:</strong></p>
<ul>
<li>Validation patterns (repetitive checks)</li>
<li>Dispatcher patterns (routing logic)</li>
<li>Builder patterns (fluent APIs)</li>
<li>Configuration parsers (key-value processing)</li>
</ul>
<p><strong>Adjustment Strategies:</strong></p>
<ul>
<li>Reduce false positives for recognized patterns</li>
<li>Apply appropriate thresholds by pattern type</li>
<li>Consider pattern confidence in scoring</li>
</ul>
<p><strong>Example:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Recognized as "validation_pattern"
// Complexity dampening applied
fn validate_user_input(input: &amp;UserInput) -&gt; Result&lt;()&gt; {
    if input.name.is_empty() { return Err(Error::EmptyName); }
    if input.email.is_empty() { return Err(Error::EmptyEmail); }
    if input.age &lt; 13 { return Err(Error::TooYoung); }
    // ... more similar validations
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h3 id="coverage-integration"><a class="header" href="#coverage-integration">Coverage Integration</a></h3>
<p>Debtmap parses LCOV coverage data for risk analysis:</p>
<p><strong>LCOV Support:</strong></p>
<ul>
<li>Standard format from most coverage tools</li>
<li>Line-level coverage tracking</li>
<li>Function-level aggregation</li>
</ul>
<p><strong>Coverage Index:</strong></p>
<ul>
<li>O(1) exact name lookups (~0.5Œºs)</li>
<li>O(log n) line-based fallback (~5-8Œºs)</li>
<li>~200 bytes per function</li>
<li>Thread-safe (Arc<CoverageIndex>)</li>
</ul>
<h4 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h4>
<p><strong>Index Build Performance:</strong></p>
<ul>
<li>Index construction: O(n), approximately 20-30ms for 5,000 functions</li>
<li>Memory usage: ~200 bytes per record (~2MB for 5,000 functions)</li>
<li>Scales linearly with function count</li>
</ul>
<p><strong>Lookup Performance:</strong></p>
<ul>
<li>Exact match (function name): O(1) average, ~0.5Œºs per lookup</li>
<li>Line-based fallback: O(log n), ~5-8Œºs per lookup</li>
<li>Cache-friendly data structure for hot paths</li>
</ul>
<p><strong>Analysis Overhead:</strong></p>
<ul>
<li>Coverage integration overhead: ~2.5x baseline analysis time</li>
<li>Target overhead: ‚â§3x (maintained through optimizations)</li>
<li>Example timing: 53ms baseline ‚Üí 130ms with coverage (2.45x overhead)</li>
<li>Overhead includes index build + lookups + coverage propagation</li>
</ul>
<p><strong>Thread Safety:</strong></p>
<ul>
<li>Coverage index wrapped in <code>Arc&lt;CoverageIndex&gt;</code> for lock-free parallel access</li>
<li>Multiple analyzer threads can query coverage simultaneously</li>
<li>No contention on reads, suitable for parallel analysis pipelines</li>
</ul>
<p><strong>Memory Footprint:</strong></p>
<pre><code>Total memory = (function_count √ó 200 bytes) + index overhead

Examples:
- 1,000 functions: ~200 KB
- 5,000 functions: ~2 MB
- 10,000 functions: ~4 MB
</code></pre>
<p><strong>Scalability:</strong></p>
<ul>
<li>Tested with codebases up to 10,000 functions</li>
<li>Performance remains predictable and acceptable</li>
<li>Memory usage stays bounded and reasonable</li>
</ul>
<p><strong>Generating coverage:</strong></p>
<pre><code class="language-bash"># Rust
cargo tarpaulin --out lcov --output-dir target/coverage

# Python
pytest --cov --cov-report=lcov

# JavaScript/TypeScript
jest --coverage --coverageReporters=lcov

# Go
go test -coverprofile=coverage.out
gocover-cobertura &lt; coverage.out &gt; coverage.lcov
</code></pre>
<p><strong>Using with Debtmap:</strong></p>
<pre><code class="language-bash">debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<p><strong>Coverage dampening:</strong>
When coverage data is provided, debt scores are dampened for well-tested code:</p>
<pre><code>final_score = base_score √ó (1 - coverage_percentage)
</code></pre>
<p>This ensures well-tested complex code gets lower priority than untested simple code.</p>
<h2 id="example-outputs"><a class="header" href="#example-outputs">Example Outputs</a></h2>
<h3 id="high-complexity-function-needs-refactoring"><a class="header" href="#high-complexity-function-needs-refactoring">High Complexity Function (Needs Refactoring)</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>#1 SCORE: 9.2 [CRITICAL]
‚îú‚îÄ COMPLEXITY: ./src/payments/processor.rs:145 process_transaction()
‚îú‚îÄ ACTION: Refactor into 4 smaller functions
‚îú‚îÄ IMPACT: Reduce complexity from 25 to 8, improve testability
‚îú‚îÄ COMPLEXITY: cyclomatic=25, branches=25, cognitive=38, nesting=5, lines=120
‚îú‚îÄ DEPENDENCIES: 3 upstream, 8 downstream
‚îî‚îÄ WHY: Exceeds all complexity thresholds, difficult to test and maintain
</code></pre>
<p><strong>JSON Output:</strong></p>
<pre><code class="language-json">{
  "id": "complexity_src_payments_processor_rs_145",
  "debt_type": "Complexity",
  "priority": "Critical",
  "file": "src/payments/processor.rs",
  "line": 145,
  "message": "Function exceeds complexity threshold",
  "context": "Cyclomatic: 25, Cognitive: 38, Nesting: 5",
  "function_metrics": {
    "name": "process_transaction",
    "cyclomatic": 25,
    "cognitive": 38,
    "nesting": 5,
    "length": 120,
    "is_pure": false,
    "purity_confidence": 0.15,
    "upstream_callers": ["handle_payment", "handle_subscription", "handle_refund"],
    "downstream_callees": ["validate", "calculate_fees", "record_transaction", "send_receipt", "update_balance", "log_transaction", "check_fraud", "notify_user"]
  }
}
</code></pre>
<h3 id="well-tested-complex-function-good-example"><a class="header" href="#well-tested-complex-function-good-example">Well-Tested Complex Function (Good Example)</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>Function: calculate_tax (WELL TESTED - Good Example!)
  File: src/tax/calculator.rs:78
  Complexity: Cyclomatic=18, Cognitive=22
  Coverage: 98%
  Risk: LOW

  Why this is good:
  - High complexity is necessary (tax rules are complex)
  - Thoroughly tested with 45 test cases
  - Clear documentation of edge cases
  - Good example to follow for other complex logic
</code></pre>
<h3 id="test-gap-needs-testing"><a class="header" href="#test-gap-needs-testing">Test Gap (Needs Testing)</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>#2 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/analyzers/rust_call_graph.rs:38 add_function_to_graph()
‚îú‚îÄ ACTION: Add 6 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk reduction
‚îú‚îÄ COMPLEXITY: cyclomatic=6, branches=6, cognitive=8, nesting=2, lines=32
‚îú‚îÄ DEPENDENCIES: 0 upstream, 11 downstream
‚îú‚îÄ TEST EFFORT: Simple (2-3 hours)
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity (cyclo=6, cog=8)
    High impact - 11 functions depend on this
</code></pre>
<p><strong>JSON Output:</strong></p>
<pre><code class="language-json">{
  "function": "add_function_to_graph",
  "file": "src/analyzers/rust_call_graph.rs",
  "line": 38,
  "current_risk": 8.9,
  "potential_risk_reduction": 3.7,
  "recommendation": {
    "action": "Add unit tests",
    "details": "Add 6 unit tests for full coverage",
    "effort_estimate": "2-3 hours"
  },
  "test_effort": {
    "estimated_difficulty": "Simple",
    "cognitive_load": 8,
    "branch_count": 6,
    "recommended_test_cases": 6
  },
  "complexity": {
    "cyclomatic": 6,
    "cognitive": 8,
    "nesting": 2,
    "length": 32
  },
  "dependencies": {
    "upstream_callers": [],
    "downstream_callees": [
      "get_function_name", "extract_parameters", "parse_return_type",
      "add_to_registry", "update_call_sites", "resolve_types",
      "track_visibility", "record_location", "increment_counter",
      "validate_signature", "log_registration"
    ]
  },
  "roi": 4.5
}
</code></pre>
<h3 id="entropy-dampened-validation-function"><a class="header" href="#entropy-dampened-validation-function">Entropy-Dampened Validation Function</a></h3>
<p><strong>Terminal Output:</strong></p>
<pre><code>Function: validate_config
  File: src/config/validator.rs:23
  Cyclomatic: 20 ‚Üí Effective: 7 (65% dampened)
  Risk: LOW

  Entropy Analysis:
    ‚îú‚îÄ Token Entropy: 0.28 (low variety - repetitive patterns)
    ‚îú‚îÄ Pattern Repetition: 0.88 (high similarity between checks)
    ‚îú‚îÄ Branch Similarity: 0.91 (consistent validation structure)
    ‚îî‚îÄ Reasoning: Complexity reduced by 65% due to pattern-based code

  This appears complex but is actually a repetitive validation pattern.
  Lower priority for refactoring.
</code></pre>
<h3 id="beforeafter-refactoring-comparison"><a class="header" href="#beforeafter-refactoring-comparison">Before/After Refactoring Comparison</a></h3>
<p><strong>Before:</strong></p>
<pre><code>Function: process_order
  Cyclomatic: 22
  Cognitive: 35
  Coverage: 15%
  Risk Score: 52.3 (CRITICAL)
  Debt Score: 50 (Critical Complexity)
</code></pre>
<p><strong>After:</strong></p>
<pre><code>Function: process_order (refactored)
  Cyclomatic: 5
  Cognitive: 6
  Coverage: 92%
  Risk Score: 2.1 (LOW)
  Debt Score: 0 (no debt)

Extracted functions:
  - validate_order (Cyclomatic: 4, Coverage: 100%)
  - calculate_totals (Cyclomatic: 3, Coverage: 95%)
  - apply_discounts (Cyclomatic: 6, Coverage: 88%)
  - finalize_order (Cyclomatic: 4, Coverage: 90%)

Impact:
  ‚úì Complexity reduced by 77%
  ‚úì Coverage improved by 513%
  ‚úì Risk reduced by 96%
  ‚úì Created 4 focused, testable functions
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<ul>
<li><strong><a href="./output-formats.html">Output Formats</a></strong> - Detailed JSON schema and integration patterns</li>
<li><strong><a href="./configuration.html">Configuration</a></strong> - Customize thresholds and analysis behavior</li>
</ul>
<p>For questions or issues, visit <a href="https://github.com/iepathos/debtmap/issues">GitHub Issues</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h1>
<p>Debtmap is highly configurable through a <code>.debtmap.toml</code> file. This chapter explains how to customize Debtmap‚Äôs behavior for your project‚Äôs specific needs.</p>
<h2 id="config-files"><a class="header" href="#config-files">Config Files</a></h2>
<h3 id="creating-a-configuration-file"><a class="header" href="#creating-a-configuration-file">Creating a Configuration File</a></h3>
<p>Debtmap looks for a <code>.debtmap.toml</code> file in the current directory and up to 10 parent directories. To create an initial configuration:</p>
<pre><code class="language-bash">debtmap init
</code></pre>
<p>This command creates a <code>.debtmap.toml</code> file with sensible defaults.</p>
<h3 id="configuration-file-discovery"><a class="header" href="#configuration-file-discovery">Configuration File Discovery</a></h3>
<p>When you run <code>debtmap</code>, it searches for <code>.debtmap.toml</code> starting in your current directory and traversing up to 10 parent directories. The first configuration file found is used.</p>
<p>If no configuration file is found, Debtmap uses built-in defaults that work well for most projects.</p>
<h3 id="basic-example"><a class="header" href="#basic-example">Basic Example</a></h3>
<p>Here‚Äôs a minimal <code>.debtmap.toml</code> configuration:</p>
<pre><code class="language-toml">[scoring]
coverage = 0.50      # 50% weight for test coverage gaps
complexity = 0.35    # 35% weight for code complexity
dependency = 0.15    # 15% weight for dependency criticality

[thresholds]
complexity = 10
max_file_length = 500
max_function_length = 50

[languages]
enabled = ["rust", "python", "javascript", "typescript"]
</code></pre>
<h2 id="scoring-configuration"><a class="header" href="#scoring-configuration">Scoring Configuration</a></h2>
<h3 id="scoring-weights"><a class="header" href="#scoring-weights">Scoring Weights</a></h3>
<p>The <code>[scoring]</code> section controls how different factors contribute to the overall debt score. Debtmap uses a <strong>weighted sum model</strong> where weights must sum to 1.0.</p>
<pre><code class="language-toml">[scoring]
coverage = 0.50      # Weight for test coverage gaps (default: 0.50)
complexity = 0.35    # Weight for code complexity (default: 0.35)
dependency = 0.15    # Weight for dependency criticality (default: 0.15)
</code></pre>
<p><strong>Active weights</strong> (used in scoring):</p>
<ul>
<li><code>coverage</code> - Prioritizes untested code (default: 0.50)</li>
<li><code>complexity</code> - Identifies complex areas (default: 0.35)</li>
<li><code>dependency</code> - Considers impact radius (default: 0.15)</li>
</ul>
<p><strong>Unused weights</strong> (reserved for future features):</p>
<ul>
<li><code>semantic</code> - Not currently used (default: 0.00)</li>
<li><code>security</code> - Not currently used (default: 0.00)</li>
<li><code>organization</code> - Not currently used (default: 0.00)</li>
</ul>
<p><strong>Validation rules:</strong></p>
<ul>
<li>All weights must be between 0.0 and 1.0</li>
<li>Active weights (coverage + complexity + dependency) must sum to 1.0 (¬±0.001 tolerance)</li>
<li>If weights don‚Äôt sum to 1.0, they will be automatically normalized</li>
</ul>
<p><strong>Example - Prioritize complexity over coverage:</strong></p>
<pre><code class="language-toml">[scoring]
coverage = 0.30
complexity = 0.55
dependency = 0.15
</code></pre>
<h3 id="role-multipliers"><a class="header" href="#role-multipliers">Role Multipliers</a></h3>
<p>Role multipliers adjust complexity scores based on a function‚Äôs semantic role:</p>
<pre><code class="language-toml">[role_multipliers]
pure_logic = 1.2        # Prioritize pure computation (default: 1.2)
orchestrator = 0.8      # Reduce for delegation functions (default: 0.8)
io_wrapper = 0.7        # Reduce for I/O wrappers (default: 0.7)
entry_point = 0.9       # Slight reduction for main/CLI (default: 0.9)
pattern_match = 0.6     # Reduce for pattern matching (default: 0.6)
unknown = 1.0           # No adjustment (default: 1.0)
</code></pre>
<p>These multipliers help reduce false positives by recognizing that different function types have naturally different complexity levels.</p>
<h3 id="role-coverage-weights"><a class="header" href="#role-coverage-weights">Role Coverage Weights</a></h3>
<p>Adjust how coverage gaps are weighted based on function role:</p>
<pre><code class="language-toml">[role_coverage_weights]
entry_point = 0.6       # Reduce coverage penalty (often integration tested)
orchestrator = 0.8      # Reduce coverage penalty (tested via higher-level tests)
pure_logic = 1.0        # Full penalty (should have unit tests)
io_wrapper = 1.0        # Full penalty (should have unit tests)
pattern_match = 1.0     # Full penalty (should have unit tests)
unknown = 1.0           # Full penalty (default behavior)
</code></pre>
<p>Entry points and orchestrators get reduced coverage penalties since they‚Äôre often tested through integration tests rather than unit tests.</p>
<h2 id="thresholds-configuration"><a class="header" href="#thresholds-configuration">Thresholds Configuration</a></h2>
<h3 id="basic-thresholds"><a class="header" href="#basic-thresholds">Basic Thresholds</a></h3>
<p>Control when code is flagged as technical debt:</p>
<pre><code class="language-toml">[thresholds]
complexity = 10                      # Cyclomatic complexity threshold
duplication = 50                     # Duplication threshold
max_file_length = 500                # Maximum lines per file
max_function_length = 50             # Maximum lines per function
</code></pre>
<h3 id="minimum-thresholds"><a class="header" href="#minimum-thresholds">Minimum Thresholds</a></h3>
<p>Filter out trivial functions that aren‚Äôt really technical debt:</p>
<pre><code class="language-toml">[thresholds]
minimum_debt_score = 2.0              # Only show items with debt score ‚â• 2.0
minimum_cyclomatic_complexity = 3     # Ignore functions with cyclomatic &lt; 3
minimum_cognitive_complexity = 5      # Ignore functions with cognitive &lt; 5
minimum_risk_score = 2.0              # Only show Risk items with score ‚â• 2.0
</code></pre>
<p>These minimum thresholds help focus on significant issues by filtering out simple functions with minor complexity.</p>
<h3 id="validation-thresholds"><a class="header" href="#validation-thresholds">Validation Thresholds</a></h3>
<p>The <code>[thresholds.validation]</code> subsection configures limits for the <code>debtmap validate</code> command:</p>
<pre><code class="language-toml">[thresholds.validation]
max_average_complexity = 10.0         # Maximum allowed average complexity (default: 10.0)
max_high_complexity_count = 100       # Maximum high complexity functions (default: 100)
max_debt_items = 2000                 # Maximum technical debt items (default: 2000)
max_total_debt_score = 1000           # Maximum total debt score (default: 1000)
max_codebase_risk_score = 7.0         # Maximum codebase risk score (default: 7.0)
max_high_risk_functions = 50          # Maximum high-risk functions (default: 50)
min_coverage_percentage = 0.0         # Minimum required coverage % (default: 0.0)
max_debt_density = 50.0               # Maximum debt per 1000 LOC (default: 50.0)
</code></pre>
<p>Use <code>debtmap validate</code> in CI to enforce code quality standards:</p>
<pre><code class="language-bash"># Fail build if validation thresholds are exceeded
debtmap validate
</code></pre>
<h2 id="language-configuration"><a class="header" href="#language-configuration">Language Configuration</a></h2>
<h3 id="enabling-languages"><a class="header" href="#enabling-languages">Enabling Languages</a></h3>
<p>Specify which languages to analyze:</p>
<pre><code class="language-toml">[languages]
enabled = ["rust", "python", "javascript", "typescript"]
</code></pre>
<h3 id="language-specific-features"><a class="header" href="#language-specific-features">Language-Specific Features</a></h3>
<p>Configure features for individual languages:</p>
<pre><code class="language-toml">[languages.rust]
detect_dead_code = false        # Rust: disabled by default (compiler handles it)
detect_complexity = true
detect_duplication = true

[languages.python]
detect_dead_code = true
detect_complexity = true
detect_duplication = true

[languages.javascript]
detect_dead_code = true
detect_complexity = true
detect_duplication = true

[languages.typescript]
detect_dead_code = true
detect_complexity = true
detect_duplication = true
</code></pre>
<p><strong>Note:</strong> Rust‚Äôs dead code detection is disabled by default since the Rust compiler already provides excellent unused code warnings.</p>
<h2 id="exclusion-patterns"><a class="header" href="#exclusion-patterns">Exclusion Patterns</a></h2>
<h3 id="file-and-directory-exclusion"><a class="header" href="#file-and-directory-exclusion">File and Directory Exclusion</a></h3>
<p>Use glob patterns to exclude files and directories from analysis:</p>
<pre><code class="language-toml">[ignore]
patterns = [
    "target/**",              # Rust build output
    "venv/**",                # Python virtual environment
    "node_modules/**",        # JavaScript dependencies
    "*.min.js",               # Minified files
    "benches/**",             # Benchmark code
    "tests/**/*",             # Test files
    "**/test_*.rs",           # Test files (prefix)
    "**/*_test.rs",           # Test files (suffix)
    "**/fixtures/**",         # Test fixtures
    "**/mocks/**",            # Mock implementations
    "**/stubs/**",            # Stub implementations
    "**/examples/**",         # Example code
    "**/demo/**",             # Demo code
]
</code></pre>
<p><strong>Glob pattern syntax:</strong></p>
<ul>
<li><code>*</code> - Matches any characters except <code>/</code></li>
<li><code>**</code> - Matches any characters including <code>/</code> (recursive)</li>
<li><code>?</code> - Matches a single character</li>
<li><code>[abc]</code> - Matches any character in the set</li>
</ul>
<p><strong>Note:</strong> Function-level filtering (e.g., ignoring specific function name patterns) is handled by role detection and context-aware analysis rather than explicit ignore patterns. See the Context-Aware Detection section for function-level filtering options.</p>
<h2 id="display-configuration"><a class="header" href="#display-configuration">Display Configuration</a></h2>
<p>Control how results are displayed:</p>
<pre><code class="language-toml">[display]
tiered = true           # Use tiered priority display (default: true)
items_per_tier = 5      # Show 5 items per tier (default: 5)
</code></pre>
<p>When <code>tiered = true</code>, Debtmap groups results into priority tiers (Critical, High, Medium, Low) and shows the top items from each tier.</p>
<h2 id="output-configuration"><a class="header" href="#output-configuration">Output Configuration</a></h2>
<p>Set the default output format:</p>
<pre><code class="language-toml">[output]
default_format = "terminal"    # Options: "terminal", "json", "markdown"
</code></pre>
<p><strong>Supported formats:</strong></p>
<ul>
<li><code>"terminal"</code> - Human-readable colored output for the terminal (default)</li>
<li><code>"json"</code> - Machine-readable JSON for integration with other tools</li>
<li><code>"markdown"</code> - Markdown format for documentation and reports</li>
</ul>
<p>This can be overridden with the <code>--format</code> CLI flag:</p>
<pre><code class="language-bash">debtmap analyze --format json      # JSON output
debtmap analyze --format markdown  # Markdown output
</code></pre>
<h2 id="normalization-configuration"><a class="header" href="#normalization-configuration">Normalization Configuration</a></h2>
<p>Control how raw scores are normalized to a 0-10 scale:</p>
<pre><code class="language-toml">[normalization]
linear_threshold = 10.0         # Use linear scaling below this value
logarithmic_threshold = 100.0   # Use logarithmic scaling above this value
sqrt_multiplier = 3.33          # Multiplier for square root scaling
log_multiplier = 10.0           # Multiplier for logarithmic scaling
show_raw_scores = true          # Show both raw and normalized scores
</code></pre>
<p>Normalization ensures scores are comparable across different codebases and prevents extreme outliers from dominating the results.</p>
<h2 id="advanced-configuration"><a class="header" href="#advanced-configuration">Advanced Configuration</a></h2>
<h3 id="entropy-based-complexity-scoring"><a class="header" href="#entropy-based-complexity-scoring">Entropy-Based Complexity Scoring</a></h3>
<p>Entropy analysis helps identify repetitive code patterns (like large match statements) that inflate complexity metrics:</p>
<pre><code class="language-toml">[entropy]
enabled = true                      # Enable entropy analysis (default: true)
weight = 1.0                        # Weight in complexity adjustment (default: 1.0)
min_tokens = 20                     # Minimum tokens for analysis (default: 20)
pattern_threshold = 0.7             # Pattern similarity threshold (default: 0.7)
entropy_threshold = 0.4             # Low entropy threshold (default: 0.4)
branch_threshold = 0.8              # Branch similarity threshold (default: 0.8)
use_classification = false          # Use smarter token classification (default: false)

# Maximum reductions to prevent over-correction
max_repetition_reduction = 0.20     # Max 20% reduction for repetition (default: 0.20)
max_entropy_reduction = 0.15        # Max 15% reduction for low entropy (default: 0.15)
max_branch_reduction = 0.25         # Max 25% reduction for similar branches (default: 0.25)
max_combined_reduction = 0.30       # Max 30% total reduction (default: 0.30)
</code></pre>
<p>Entropy scoring reduces false positives from functions like parsers and state machines that have high cyclomatic complexity but are actually simple and maintainable.</p>
<h3 id="god-object-detection"><a class="header" href="#god-object-detection">God Object Detection</a></h3>
<p>Configure detection of classes/structs with too many responsibilities:</p>
<pre><code class="language-toml">[god_object_detection]
enabled = true

# Rust-specific thresholds
[god_object_detection.rust]
max_methods = 20        # Maximum methods before flagging (default: 20)
max_fields = 15         # Maximum fields before flagging (default: 15)
max_traits = 5          # Maximum implemented traits
max_lines = 1000        # Maximum lines of code
max_complexity = 200    # Maximum total complexity

# Python-specific thresholds
[god_object_detection.python]
max_methods = 15
max_fields = 10
max_traits = 3
max_lines = 500
max_complexity = 150

# JavaScript-specific thresholds
[god_object_detection.javascript]
max_methods = 15
max_fields = 20         # JavaScript classes often have more properties
max_traits = 3
max_lines = 500
max_complexity = 150
</code></pre>
<p><strong>Note:</strong> Different languages have different defaults. Rust allows more methods since trait implementations add methods, while JavaScript classes should be smaller.</p>
<h3 id="context-aware-detection"><a class="header" href="#context-aware-detection">Context-Aware Detection</a></h3>
<p>Enable context-aware pattern detection to reduce false positives:</p>
<pre><code class="language-toml">[context]
enabled = false         # Opt-in (default: false)

# Custom context rules
[[context.rules]]
name = "allow_blocking_in_main"
pattern = "blocking_io"
action = "allow"
priority = 100
reason = "Main function can use blocking I/O"

[context.rules.context]
role = "main"

# Function pattern configuration
[context.function_patterns]
test_patterns = ["test_*", "bench_*"]
config_patterns = ["load_*_config", "parse_*_config"]
handler_patterns = ["handle_*", "*_handler"]
init_patterns = ["initialize_*", "setup_*"]
</code></pre>
<p>Context-aware detection adjusts severity based on where code appears (main functions, test code, configuration loaders, etc.).</p>
<h3 id="error-handling-detection"><a class="header" href="#error-handling-detection">Error Handling Detection</a></h3>
<p>Configure detection of error handling anti-patterns:</p>
<pre><code class="language-toml">[error_handling]
detect_async_errors = true          # Detect async error issues (default: true)
detect_context_loss = true          # Detect error context loss (default: true)
detect_propagation = true           # Analyze error propagation (default: true)
detect_panic_patterns = true        # Detect panic/unwrap usage (default: true)
detect_swallowing = true            # Detect swallowed errors (default: true)

# Custom error patterns
[[error_handling.custom_patterns]]
name = "custom_panic"
pattern = "my_panic_macro"
pattern_type = "macro_name"
severity = "high"
description = "Custom panic macro usage"
remediation = "Replace with Result-based error handling"

# Severity overrides
[[error_handling.severity_overrides]]
pattern = "unwrap"
context = "test"
severity = "low"        # Unwrap is acceptable in test code
</code></pre>
<h3 id="external-api-configuration"><a class="header" href="#external-api-configuration">External API Configuration</a></h3>
<p>Mark functions as public API for enhanced testing recommendations:</p>
<pre><code class="language-toml">[external_api]
detect_external_api = false         # Auto-detect public APIs (default: false)
api_functions = []                  # Explicitly mark API functions
api_files = []                      # Explicitly mark API files
</code></pre>
<p>When enabled, public API functions receive higher priority for test coverage.</p>
<h3 id="additional-advanced-options"><a class="header" href="#additional-advanced-options">Additional Advanced Options</a></h3>
<p>Debtmap supports additional advanced configuration options:</p>
<ul>
<li>
<p><strong><code>[loc]</code></strong> - Lines of code counting configuration. Controls whether to include tests (<code>include_tests</code>), generated files (<code>include_generated</code>), comments (<code>count_comments</code>), and blank lines (<code>count_blank_lines</code>) in LOC counts. All default to false.</p>
</li>
<li>
<p><strong><code>[tiers]</code></strong> - Tier threshold configuration for prioritization. Allows customization of complexity and dependency thresholds for different priority tiers (T2, T3, T4). Used internally for tiered reporting.</p>
</li>
<li>
<p><strong><code>[complexity_thresholds]</code></strong> - Enhanced complexity detection thresholds. Configures minimum total, cyclomatic, and cognitive complexity thresholds for flagging functions. Supplements the basic <code>[thresholds]</code> section with more granular control.</p>
</li>
</ul>
<p>These options are advanced features with sensible defaults. Most users won‚Äôt need to configure them explicitly.</p>
<h2 id="cli-integration"><a class="header" href="#cli-integration">CLI Integration</a></h2>
<p>CLI flags can override configuration file settings:</p>
<pre><code class="language-bash"># Override complexity threshold
debtmap analyze --threshold-complexity 15

# Provide coverage file
debtmap analyze --coverage-file coverage.json

# Enable context-aware detection
debtmap analyze --context

# Override output format
debtmap analyze --format json
</code></pre>
<p>CLI flags take precedence over <code>.debtmap.toml</code> settings, allowing per-run customization.</p>
<h2 id="configuration-validation"><a class="header" href="#configuration-validation">Configuration Validation</a></h2>
<h3 id="automatic-validation"><a class="header" href="#automatic-validation">Automatic Validation</a></h3>
<p>Debtmap automatically validates your configuration when loading:</p>
<ul>
<li><strong>Scoring weights</strong> must sum to 1.0 (¬±0.001 tolerance)</li>
<li><strong>Individual weights</strong> must be between 0.0 and 1.0</li>
<li><strong>Invalid configurations</strong> fall back to defaults with a warning</li>
</ul>
<h3 id="normalization"><a class="header" href="#normalization">Normalization</a></h3>
<p>If scoring weights don‚Äôt sum exactly to 1.0, Debtmap automatically normalizes them:</p>
<pre><code class="language-toml"># Input (sums to 0.80)
[scoring]
coverage = 0.40
complexity = 0.30
dependency = 0.10

# Automatically normalized to:
# coverage = 0.50
# complexity = 0.375
# dependency = 0.125
</code></pre>
<h3 id="debug-validation"><a class="header" href="#debug-validation">Debug Validation</a></h3>
<p>To verify which configuration file is being loaded, check debug logs:</p>
<pre><code class="language-bash">RUST_LOG=debug debtmap analyze
</code></pre>
<p>Look for log messages like:</p>
<pre><code>DEBUG debtmap::config: Loaded config from /path/to/.debtmap.toml
</code></pre>
<h2 id="complete-configuration-example"><a class="header" href="#complete-configuration-example">Complete Configuration Example</a></h2>
<p>Here‚Äôs a comprehensive configuration showing all major sections:</p>
<pre><code class="language-toml"># Scoring configuration
[scoring]
coverage = 0.50
complexity = 0.35
dependency = 0.15

# Basic thresholds
[thresholds]
complexity = 10
duplication = 50
max_file_length = 500
max_function_length = 50
minimum_debt_score = 2.0
minimum_cyclomatic_complexity = 3
minimum_cognitive_complexity = 5
minimum_risk_score = 2.0

# Validation thresholds for CI
[thresholds.validation]
max_average_complexity = 10.0
max_high_complexity_count = 100
max_debt_items = 2000
max_total_debt_score = 1000
max_codebase_risk_score = 7.0
max_high_risk_functions = 50
min_coverage_percentage = 0.0
max_debt_density = 50.0

# Language configuration
[languages]
enabled = ["rust", "python", "javascript", "typescript"]

[languages.rust]
detect_dead_code = false
detect_complexity = true
detect_duplication = true

# Exclusion patterns
[ignore]
patterns = [
    "target/**",
    "node_modules/**",
    "tests/**/*",
    "**/*_test.rs",
]

# Display configuration
[display]
tiered = true
items_per_tier = 5

# Output configuration
[output]
default_format = "terminal"

# Entropy configuration
[entropy]
enabled = true
weight = 1.0
min_tokens = 20

# God object detection
[god_object_detection]
enabled = true

[god_object_detection.rust]
max_methods = 20
max_fields = 15
</code></pre>
<h2 id="configuration-best-practices"><a class="header" href="#configuration-best-practices">Configuration Best Practices</a></h2>
<h3 id="for-strict-quality-standards"><a class="header" href="#for-strict-quality-standards">For Strict Quality Standards</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.60         # Emphasize test coverage
complexity = 0.30
dependency = 0.10

[thresholds]
minimum_debt_score = 3.0        # Higher bar for flagging issues
max_function_length = 30        # Enforce smaller functions

[thresholds.validation]
max_average_complexity = 8.0    # Stricter complexity limits
max_debt_items = 500            # Stricter debt limits
min_coverage_percentage = 80.0  # Require 80% coverage
</code></pre>
<h3 id="for-legacy-codebases"><a class="header" href="#for-legacy-codebases">For Legacy Codebases</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.30         # Reduce coverage weight (legacy code often lacks tests)
complexity = 0.50       # Focus on complexity
dependency = 0.20

[thresholds]
minimum_debt_score = 5.0        # Only show highest priority items
minimum_cyclomatic_complexity = 10   # Filter out moderate complexity

[thresholds.validation]
max_debt_items = 10000          # Accommodate large debt
max_total_debt_score = 5000     # Higher limits for legacy code
</code></pre>
<h3 id="for-open-source-libraries"><a class="header" href="#for-open-source-libraries">For Open Source Libraries</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.55         # Prioritize test coverage (public API)
complexity = 0.30
dependency = 0.15

[external_api]
detect_external_api = true      # Flag untested public APIs

[thresholds.validation]
min_coverage_percentage = 90.0  # High coverage for public API
max_high_complexity_count = 20  # Keep complexity low
</code></pre>
<h2 id="troubleshooting-1"><a class="header" href="#troubleshooting-1">Troubleshooting</a></h2>
<h3 id="configuration-not-loading"><a class="header" href="#configuration-not-loading">Configuration Not Loading</a></h3>
<p><strong>Check file location:</strong></p>
<pre><code class="language-bash"># Ensure file is named .debtmap.toml (note the dot prefix)
ls -la .debtmap.toml

# Debtmap searches current directory + 10 parent directories
pwd
</code></pre>
<p><strong>Check file syntax:</strong></p>
<pre><code class="language-bash"># Verify TOML syntax is valid
debtmap analyze 2&gt;&amp;1 | grep -i "failed to parse"
</code></pre>
<h3 id="weights-dont-sum-to-10"><a class="header" href="#weights-dont-sum-to-10">Weights Don‚Äôt Sum to 1.0</a></h3>
<p><strong>Error message:</strong></p>
<pre><code>Warning: Invalid scoring weights: Active scoring weights must sum to 1.0, but sum to 0.800. Using defaults.
</code></pre>
<p><strong>Fix:</strong> Ensure coverage + complexity + dependency = 1.0</p>
<pre><code class="language-toml">[scoring]
coverage = 0.50
complexity = 0.35
dependency = 0.15    # Sum = 1.0 ‚úì
</code></pre>
<h3 id="no-results-shown"><a class="header" href="#no-results-shown">No Results Shown</a></h3>
<p><strong>Possible causes:</strong></p>
<ol>
<li>Minimum thresholds too high</li>
<li>All code excluded by ignore patterns</li>
<li>No supported languages in project</li>
</ol>
<p><strong>Solutions:</strong></p>
<pre><code class="language-toml"># Lower minimum thresholds
[thresholds]
minimum_debt_score = 1.0
minimum_cyclomatic_complexity = 1

# Check language configuration
[languages]
enabled = ["rust", "python", "javascript", "typescript"]

# Review ignore patterns
[ignore]
patterns = [
    # Make sure you're not excluding too much
]
</code></pre>
<h2 id="related-chapters"><a class="header" href="#related-chapters">Related Chapters</a></h2>
<ul>
<li><a href="./getting-started.html">Getting Started</a> - Initial setup and basic usage</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Understanding scoring and prioritization</li>
<li><a href="./output-formats.html">Output Formats</a> - Formatting and exporting results</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="output-formats-1"><a class="header" href="#output-formats-1">Output Formats</a></h1>
<p>Debtmap provides multiple output formats to suit different workflows, from interactive terminal reports to machine-readable JSON for CI/CD integration. This chapter covers all available formats and how to use them effectively.</p>
<h2 id="format-selection"><a class="header" href="#format-selection">Format Selection</a></h2>
<p>Select the output format using the <code>-f</code> or <code>--format</code> flag:</p>
<pre><code class="language-bash"># Terminal output (default) - human-readable with colors
debtmap analyze .

# JSON output - machine-readable for tooling
debtmap analyze . --format json

# Markdown output - documentation and reports
debtmap analyze . --format markdown
</code></pre>
<p>Available formats:</p>
<ul>
<li><strong>terminal</strong> (default): Interactive output with colors, emoji, and formatting</li>
<li><strong>json</strong>: Structured data for programmatic processing</li>
<li><strong>markdown</strong>: Reports suitable for documentation and PR comments</li>
</ul>
<h3 id="writing-to-files"><a class="header" href="#writing-to-files">Writing to Files</a></h3>
<p>By default, output goes to stdout. Use <code>-o</code> or <code>--output</code> to write to a file:</p>
<pre><code class="language-bash"># Write JSON to file
debtmap analyze . --format json -o report.json

# Write markdown report
debtmap analyze . --format markdown -o DEBT_REPORT.md

# Terminal output to file (preserves colors)
debtmap analyze . -o analysis.txt
</code></pre>
<h2 id="terminal-output"><a class="header" href="#terminal-output">Terminal Output</a></h2>
<p>The terminal format provides an interactive, color-coded report designed for developer workflows. It‚Äôs the default format and optimized for readability.</p>
<h3 id="output-structure"><a class="header" href="#output-structure">Output Structure</a></h3>
<p>Terminal output is organized into five main sections:</p>
<ol>
<li><strong>Header</strong> - Analysis report title</li>
<li><strong>Codebase Summary</strong> - High-level metrics and debt score</li>
<li><strong>Complexity Hotspots</strong> - Top 5 most complex functions with refactoring guidance</li>
<li><strong>Technical Debt</strong> - High-priority debt items requiring attention</li>
<li><strong>Pass/Fail Status</strong> - Overall quality assessment</li>
</ol>
<h3 id="example-terminal-output"><a class="header" href="#example-terminal-output">Example Terminal Output</a></h3>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
           DEBTMAP ANALYSIS REPORT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìä CODEBASE Summary
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Files analyzed:      42
  Total functions:     287
  Average complexity:  6.3
  Debt items:          15
  Total debt score:    156 (threshold: 100)

‚ö†Ô∏è  COMPLEXITY HOTSPOTS (Top 5)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  1. src/analyzers/rust.rs:245 parse_function() - Cyclomatic: 18, Cognitive: 24
     ACTION: Extract 3-5 pure functions using decompose-then-transform strategy
     PATTERNS: Decompose into logical units, then apply functional patterns
     BENEFIT: Pure functions are easily testable and composable

  2. src/debt/smells.rs:196 detect_data_clumps() - Cyclomatic: 15, Cognitive: 20
     ‚Üì Entropy: 0.32, Repetition: 85%, Effective: 0.6x
       High pattern repetition detected (85%)

üîß TECHNICAL DEBT (15 items)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  High Priority (5):
    - src/risk/scoring.rs:142 - TODO: Implement caching for score calculations
    - src/core/metrics.rs:89 - High complexity: cyclomatic=16
    - src/debt/patterns.rs:201 - Code duplication: 65 lines duplicated

‚úì Pass/Fail: PASS
</code></pre>
<h3 id="color-coding-and-symbols"><a class="header" href="#color-coding-and-symbols">Color Coding and Symbols</a></h3>
<p>The terminal output uses colors and symbols for quick visual scanning:</p>
<p><strong>Status Indicators:</strong></p>
<ul>
<li>‚úì Green: Passing, good, well-tested</li>
<li>‚ö†Ô∏è  Yellow: Warning, moderate complexity</li>
<li>‚úó Red: Failing, critical, high complexity</li>
<li>üìä Blue: Information, metrics</li>
<li>üîß Orange: Technical debt items</li>
<li>üéØ Cyan: Recommendations</li>
</ul>
<p><strong>Complexity Classification:</strong></p>
<ul>
<li><strong>LOW</strong> (0-5): Green - Simple, easy to maintain</li>
<li><strong>MODERATE</strong> (6-10): Yellow - Consider refactoring</li>
<li><strong>HIGH</strong> (11-15): Orange - Should refactor</li>
<li><strong>SEVERE</strong> (&gt;15): Red - Urgent refactoring needed</li>
</ul>
<blockquote>
<p><strong>Note:</strong> These levels match the <code>ComplexityLevel</code> enum in the implementation.</p>
</blockquote>
<p><strong>Debt Score Thresholds:</strong></p>
<p>The default debt threshold is <strong>100</strong>. Scores are colored based on this threshold:</p>
<ul>
<li><strong>Green (‚â§50)</strong>: Healthy - Below half threshold (score ‚â§ threshold/2)</li>
<li><strong>Yellow (51-100)</strong>: Attention needed - Between half and full threshold (threshold/2 &lt; score ‚â§ threshold)</li>
<li><strong>Red (&gt;100)</strong>: Action required - Exceeds threshold (score &gt; threshold)</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Boundary values use strict inequalities: 50 is Green, 100 is Yellow (not Red), 101+ is Red.</p>
</blockquote>
<h3 id="refactoring-guidance"><a class="header" href="#refactoring-guidance">Refactoring Guidance</a></h3>
<p>For complex functions (cyclomatic complexity &gt; 5), the terminal output provides actionable refactoring recommendations:</p>
<pre><code>ACTION: Extract 3-5 pure functions using decompose-then-transform strategy
PATTERNS: Decompose into logical units, then apply functional patterns
BENEFIT: Pure functions are easily testable and composable
</code></pre>
<p>Guidance levels:</p>
<ul>
<li><strong>Moderate</strong> (6-10): Extract 2-3 pure functions using direct functional transformation</li>
<li><strong>High</strong> (11-15): Extract 3-5 pure functions using decompose-then-transform strategy</li>
<li><strong>Severe</strong> (&gt;15): Extract 5+ pure functions into modules with functional core/imperative shell</li>
</ul>
<p>See the <a href="./analysis-guide.html">Analysis Guide</a> for metric explanations.</p>
<h3 id="plain-terminal-mode"><a class="header" href="#plain-terminal-mode">Plain Terminal Mode</a></h3>
<p>For environments without color support or when piping to tools, use <code>--plain</code>:</p>
<pre><code class="language-bash"># ASCII-only output, no colors, no emoji
debtmap analyze . --plain
</code></pre>
<p>Plain mode:</p>
<ul>
<li>Removes ANSI color codes</li>
<li>Replaces emoji with text labels</li>
<li>Uses ASCII box-drawing characters</li>
<li>Machine-parseable structure</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Terminal output formatting (colors, symbols, etc.) can be customized internally via <code>FormattingConfig</code>. These customization options are currently not exposed through the CLI interface.</p>
</blockquote>
<h3 id="verbosity-levels"><a class="header" href="#verbosity-levels">Verbosity Levels</a></h3>
<p>Control detail level with <code>-v</code> flags (can be repeated):</p>
<pre><code class="language-bash"># Standard output
debtmap analyze .

# Level 1: Show main score factors
debtmap analyze . -v

# Level 2: Show detailed calculations
debtmap analyze . -vv

# Level 3: Show all debug information
debtmap analyze . -vvv
</code></pre>
<p><strong>Verbosity features:</strong></p>
<ul>
<li><code>-v</code>: Show main score factors (complexity, coverage, dependency breakdown)</li>
<li><code>-vv</code>: Show detailed calculations with formulas and intermediate values</li>
<li><code>-vvv</code>: Show all debug information including entropy metrics, role detection, and cache hits</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Verbosity flags affect terminal output only. JSON and markdown formats include all data regardless of verbosity level.</p>
</blockquote>
<p>Each level includes all information from the previous levels, progressively adding more detail to help understand how scores are calculated.</p>
<p><strong>Example Output Differences:</strong></p>
<p>Standard output shows basic metrics:</p>
<pre><code>Total debt score: 156 (threshold: 100)
</code></pre>
<p>Level 1 (<code>-v</code>) adds score breakdowns:</p>
<pre><code>Total debt score: 156 (threshold: 100)
  Complexity contribution: 85 (54%)
  Coverage gaps: 45 (29%)
  Dependency issues: 26 (17%)
</code></pre>
<p>Level 2 (<code>-vv</code>) adds detailed calculations:</p>
<pre><code>Total debt score: 156 (threshold: 100)
  Complexity contribution: 85 (54%)
    Formula: sum(cyclomatic_weight * severity_multiplier)
    High complexity functions: 5 √ó 12 = 60
    Medium complexity: 8 √ó 3 = 24
    Base penalty: 1
  Coverage gaps: 45 (29%)
    Uncovered complex functions: 3 √ó 15 = 45
</code></pre>
<p>Level 3 (<code>-vvv</code>) adds all internal details:</p>
<pre><code>Total debt score: 156 (threshold: 100)
  ... (all level 2 output) ...
  Debug info:
    Entropy metrics cached: 42/50 functions
    Function role detection: BusinessLogic=12, Utility=8, TestHelper=5
    Cache hit rate: 84%
</code></pre>
<h3 id="risk-analysis-output"><a class="header" href="#risk-analysis-output">Risk Analysis Output</a></h3>
<p>When coverage data is provided via <code>--lcov</code>, terminal output includes a dedicated risk analysis section:</p>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
           RISK ANALYSIS REPORT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìà RISK Summary
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Codebase Risk Score: 45.5 (MEDIUM)
Complexity-Coverage Correlation: -0.65

Risk Distribution:
  Critical: 2 functions
  High: 5 functions
  Medium: 10 functions
  Low: 15 functions
  Well Tested: 20 functions

üéØ CRITICAL RISKS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1. src/core/parser.rs:142 parse_complex_ast()
   Risk: 85.0 | Complexity: 15 | Coverage: 0%
   Recommendation: Add 5 unit tests (est: 2-3 hours)
   Impact: -40 risk reduction

üí° RECOMMENDATIONS (by ROI)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1. test_me() - ROI: 5.0x
   Current Risk: 75 | Reduction: 40 | Effort: Moderate
   Rationale: High risk function with low coverage
</code></pre>
<p><strong>Risk Level Classification:</strong></p>
<ul>
<li><strong>LOW</strong> (&lt;30): Green - score &lt; 30.0</li>
<li><strong>MEDIUM</strong> (30-59): Yellow - 30.0 ‚â§ score &lt; 60.0</li>
<li><strong>HIGH</strong> (‚â•60): Red - score ‚â• 60.0</li>
</ul>
<blockquote>
<p><strong>Note:</strong> 60 is the start of HIGH risk level.</p>
</blockquote>
<h2 id="json-output"><a class="header" href="#json-output">JSON Output</a></h2>
<p>JSON output provides complete analysis results in a machine-readable format, ideal for CI/CD pipelines, custom tooling, and programmatic analysis.</p>
<h3 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h3>
<pre><code class="language-bash"># Generate JSON output
debtmap analyze . --format json

# Save to file
debtmap analyze . --format json -o report.json

# Pretty-printed by default for readability
debtmap analyze . --format json | jq .
</code></pre>
<blockquote>
<p><strong>Note:</strong> JSON output is automatically pretty-printed for readability.</p>
</blockquote>
<h3 id="json-schema-structure"><a class="header" href="#json-schema-structure">JSON Schema Structure</a></h3>
<p>Debtmap outputs a structured JSON document with the following top-level fields:</p>
<pre><code class="language-json">{
  "project_path": "/path/to/project",
  "timestamp": "2025-01-09T12:00:00Z",
  "complexity": { ... },
  "technical_debt": { ... },
  "dependencies": { ... },
  "duplications": [ ... ]
}
</code></pre>
<h3 id="full-schema-example"><a class="header" href="#full-schema-example">Full Schema Example</a></h3>
<p>Here‚Äôs a complete annotated JSON output example:</p>
<pre><code class="language-json">{
  // Project metadata
  "project_path": "/Users/dev/myproject",
  "timestamp": "2025-01-09T15:30:00Z",

  // Complexity analysis results
  "complexity": {
    "metrics": [
      {
        "name": "calculate_risk_score",
        "file": "src/risk/scoring.rs",
        "line": 142,
        "cyclomatic": 12,
        "cognitive": 18,
        "nesting": 4,
        "length": 85,
        "is_test": false,
        "visibility": "pub",
        "is_trait_method": false,
        "in_test_module": false,
        "entropy_score": {
          "token_entropy": 0.65,
          "pattern_repetition": 0.30,
          "branch_similarity": 0.45,
          "effective_complexity": 0.85
        },
        "is_pure": false,
        "purity_confidence": 0.75,
        "detected_patterns": ["nested_loops", "complex_conditionals"],
        "upstream_callers": ["analyze_codebase", "generate_report"],
        "downstream_callees": ["get_metrics", "apply_weights"]
      }
    ],
    "summary": {
      "total_functions": 287,
      "average_complexity": 6.3,
      "max_complexity": 24,
      "high_complexity_count": 12
    }
  },

  // Technical debt items
  "technical_debt": {
    "items": [
      {
        "id": "debt_001",
        "debt_type": "Complexity",
        "priority": "High",
        "file": "src/analyzers/rust.rs",
        "line": 245,
        "column": 5,
        "message": "High cyclomatic complexity: 18",
        "context": "Function parse_function has excessive branching"
      },
      {
        "id": "debt_002",
        "debt_type": "Todo",
        "priority": "Medium",
        "file": "src/core/cache.rs",
        "line": 89,
        "column": null,
        "message": "TODO: Implement LRU eviction policy",
        "context": null
      }
    ],
    "by_type": {
      "Complexity": [ /* same structure as items */ ],
      "Todo": [ /* ... */ ],
      "Duplication": [ /* ... */ ]
    },
    "priorities": ["Low", "Medium", "High", "Critical"]
  },

  // Dependency analysis
  "dependencies": {
    "modules": [
      {
        "module": "risk::scoring",
        "dependencies": ["core::metrics", "debt::patterns"],
        "dependents": ["commands::analyze", "io::output"]
      }
    ],
    "circular": [
      {
        "cycle": ["module_a", "module_b", "module_c", "module_a"]
      }
    ]
  },

  // Code duplication blocks
  "duplications": [
    {
      "hash": "abc123def456",
      "lines": 15,
      "locations": [
        {
          "file": "src/parser/rust.rs",
          "start_line": 42,
          "end_line": 57
        },
        {
          "file": "src/parser/python.rs",
          "start_line": 89,
          "end_line": 104
        }
      ]
    }
  ]
}
</code></pre>
<h3 id="field-descriptions"><a class="header" href="#field-descriptions">Field Descriptions</a></h3>
<p><strong>FunctionMetrics Fields:</strong></p>
<ul>
<li>
<p><code>name</code>: Function name</p>
</li>
<li>
<p><code>file</code>: Path to source file</p>
</li>
<li>
<p><code>line</code>: Line number where function is defined</p>
</li>
<li>
<p><code>cyclomatic</code>: Cyclomatic complexity score</p>
</li>
<li>
<p><code>cognitive</code>: Cognitive complexity score</p>
</li>
<li>
<p><code>nesting</code>: Maximum nesting depth</p>
</li>
<li>
<p><code>length</code>: Lines of code in function</p>
</li>
<li>
<p><code>is_test</code>: Whether this is a test function</p>
</li>
<li>
<p><code>visibility</code>: Rust visibility modifier (pub, pub(crate), or null)</p>
</li>
<li>
<p><code>is_trait_method</code>: Whether this implements a trait</p>
</li>
<li>
<p><code>in_test_module</code>: Whether inside #[cfg(test)]</p>
</li>
<li>
<p><code>entropy_score</code>: Optional entropy analysis with structure:</p>
<pre><code class="language-json">{
  "token_entropy": 0.65,        // Token distribution entropy (0-1): measures variety of tokens
  "pattern_repetition": 0.30,   // Pattern repetition score (0-1): detects repeated code patterns
  "branch_similarity": 0.45,    // Branch similarity metric (0-1): compares similarity between branches
  "effective_complexity": 0.85  // Adjusted complexity multiplier: complexity adjusted for entropy
}
</code></pre>
<p><strong>EntropyScore Fields:</strong></p>
<ul>
<li><code>token_entropy</code>: Measures the variety and distribution of tokens in the function (0-1, higher = more variety)</li>
<li><code>pattern_repetition</code>: Detects repeated code patterns within the function (0-1, higher = more repetition)</li>
<li><code>branch_similarity</code>: Measures similarity between different code branches (0-1, higher = more similar)</li>
<li><code>effective_complexity</code>: The overall complexity multiplier adjusted for entropy effects</li>
</ul>
</li>
<li>
<p><code>is_pure</code>: Whether function is pure (no side effects)</p>
</li>
<li>
<p><code>purity_confidence</code>: Confidence level (0.0-1.0)</p>
</li>
<li>
<p><code>detected_patterns</code>: List of detected code patterns</p>
</li>
<li>
<p><code>upstream_callers</code>: Functions that call this one</p>
</li>
<li>
<p><code>downstream_callees</code>: Functions this one calls</p>
</li>
</ul>
<p><strong>DebtItem Fields:</strong></p>
<ul>
<li><code>id</code>: Unique identifier</li>
<li><code>debt_type</code>: Type of debt (see DebtType enum below)</li>
<li><code>priority</code>: Priority level (Low, Medium, High, Critical)</li>
<li><code>file</code>: Path to file containing debt</li>
<li><code>line</code>: Line number</li>
<li><code>column</code>: Optional column number</li>
<li><code>message</code>: Human-readable description</li>
<li><code>context</code>: Optional additional context</li>
</ul>
<p><strong>DebtType Enum:</strong></p>
<ul>
<li><code>Todo</code>: TODO markers</li>
<li><code>Fixme</code>: FIXME markers</li>
<li><code>CodeSmell</code>: Code smell patterns</li>
<li><code>Duplication</code>: Duplicated code</li>
<li><code>Complexity</code>: Excessive complexity</li>
<li><code>Dependency</code>: Dependency issues</li>
<li><code>ErrorSwallowing</code>: Suppressed errors</li>
<li><code>ResourceManagement</code>: Resource management issues</li>
<li><code>CodeOrganization</code>: Organizational problems</li>
<li><code>TestComplexity</code>: Complex test code</li>
<li><code>TestTodo</code>: TODOs in tests</li>
<li><code>TestDuplication</code>: Duplicated test code</li>
<li><code>TestQuality</code>: Test quality issues</li>
</ul>
<h3 id="json-format-variants"><a class="header" href="#json-format-variants">JSON Format Variants</a></h3>
<p>Debtmap supports two JSON output formats:</p>
<pre><code class="language-bash"># Legacy format (default) - backward compatible
debtmap analyze . --format json --output-format legacy

# Unified format - new consistent structure
debtmap analyze . --format json --output-format unified
</code></pre>
<blockquote>
<p><strong>Note:</strong> The <code>--output-format</code> flag only applies when using <code>--format json</code>. It has no effect with markdown or terminal formats.</p>
</blockquote>
<p><strong>Legacy format:</strong> Uses <code>{File: {...}}</code> and <code>{Function: {...}}</code> wrappers for backward compatibility with existing tooling.</p>
<p><strong>Unified format:</strong> Consistent structure with a <code>type</code> field, making parsing simpler and more predictable. Recommended for new integrations.</p>
<h3 id="risk-insights-json"><a class="header" href="#risk-insights-json">Risk Insights JSON</a></h3>
<p>When using <code>--lcov</code>, debtmap also outputs risk analysis in JSON:</p>
<pre><code class="language-json">{
  "items": [
    {
      "location": {
        "file": "src/risk/scoring.rs",
        "function": "calculate_priority",
        "line": 66
      },
      "debt_type": "TestGap",
      "unified_score": {
        "complexity_factor": 3.2,
        "coverage_factor": 10.0,
        "dependency_factor": 2.5,
        "role_multiplier": 1.2,
        "final_score": 9.4
      },
      "function_role": "BusinessLogic",
      "recommendation": {
        "action": "Add unit tests",
        "details": "Add 6 unit tests for full coverage",
        "effort_estimate": "2-3 hours"
      },
      "expected_impact": {
        "risk_reduction": 3.9,
        "complexity_reduction": 0,
        "coverage_improvement": 100
      },
      "upstream_dependencies": 0,
      "downstream_dependencies": 3,
      "nesting_depth": 1,
      "function_length": 13
    }
  ],
  "call_graph": {
    "total_functions": 1523,
    "entry_points": 12,
    "test_functions": 456,
    "max_depth": 8
  },
  "overall_coverage": 82.3,
  "total_impact": {
    "risk_reduction": 45.2,
    "complexity_reduction": 12.3,
    "coverage_improvement": 18.5
  }
}
</code></pre>
<h2 id="markdown-output"><a class="header" href="#markdown-output">Markdown Output</a></h2>
<p>Markdown format generates documentation-friendly reports suitable for README files, PR comments, and technical documentation.</p>
<h3 id="basic-usage-1"><a class="header" href="#basic-usage-1">Basic Usage</a></h3>
<pre><code class="language-bash"># Generate markdown report
debtmap analyze . --format markdown

# Save to documentation
debtmap analyze . --format markdown -o docs/DEBT_REPORT.md
</code></pre>
<h3 id="markdown-structure"><a class="header" href="#markdown-structure">Markdown Structure</a></h3>
<p>Markdown output includes:</p>
<ol>
<li><strong>Executive Summary</strong> - High-level metrics and health dashboard</li>
<li><strong>Complexity Analysis</strong> - Detailed complexity breakdown by file</li>
<li><strong>Technical Debt</strong> - Categorized debt items with priorities</li>
<li><strong>Dependencies</strong> - Module dependencies and circular references</li>
<li><strong>Recommendations</strong> - Prioritized action items</li>
</ol>
<h3 id="example-markdown-output"><a class="header" href="#example-markdown-output">Example Markdown Output</a></h3>
<pre><code class="language-markdown"># Debtmap Analysis Report

**Generated:** 2025-01-09 15:30:00 UTC
**Project:** /Users/dev/myproject

## Executive Summary

- **Files Analyzed:** 42
- **Total Functions:** 287
- **Average Complexity:** 6.3
- **Total Debt Items:** 15
- **Debt Score:** 156/100 ‚ö†Ô∏è

### Health Dashboard

| Metric | Value | Status |
|--------|-------|--------|
| Complexity | 6.3 avg | ‚úÖ Good |
| Debt Score | 156 | ‚ö†Ô∏è Attention |
| High Priority Items | 5 | ‚ö†Ô∏è Action Needed |

## Complexity Analysis

### Top 5 Complex Functions

| Function | File | Cyclomatic | Cognitive | Priority |
|----------|------|-----------|-----------|----------|
| parse_function | src/analyzers/rust.rs:245 | 18 | 24 | High |
| detect_data_clumps | src/debt/smells.rs:196 | 15 | 20 | Medium |
| analyze_dependencies | src/core/deps.rs:89 | 14 | 18 | Medium |

### Refactoring Recommendations

**src/analyzers/rust.rs:245** - `parse_function()`
- **Complexity:** Cyclomatic: 18, Cognitive: 24
- **Action:** Extract 3-5 pure functions using decompose-then-transform strategy
- **Patterns:** Decompose into logical units, then apply functional patterns
- **Benefit:** Improved testability and maintainability

## Technical Debt

### High Priority (5 items)

- **src/risk/scoring.rs:142** - TODO: Implement caching for score calculations
- **src/core/metrics.rs:89** - High complexity: cyclomatic=16
- **src/debt/patterns.rs:201** - Code duplication: 65 lines duplicated

### Medium Priority (8 items)

...

## Dependencies

### Circular Dependencies

- `risk::scoring` ‚Üí `core::metrics` ‚Üí `risk::scoring`

## Recommendations

1. **Refactor parse_function** (High Priority)
   - Reduce complexity from 18 to &lt;10
   - Extract helper functions
   - Estimated effort: 4-6 hours

2. **Add tests for scoring module** (High Priority)
   - Current coverage: 35%
   - Target coverage: 80%
   - Estimated effort: 2-3 hours
</code></pre>
<h3 id="enhanced-markdown-features"><a class="header" href="#enhanced-markdown-features">Enhanced Markdown Features</a></h3>
<p>Debtmap can generate enhanced markdown reports with additional visualizations and insights:</p>
<ul>
<li><strong>Complexity distribution charts</strong> - Visual representation of complexity across codebase</li>
<li><strong>Risk heat maps</strong> - Color-coded risk matrices</li>
<li><strong>Dependency graphs</strong> - Module relationship diagrams</li>
<li><strong>Quick wins section</strong> - Low-effort, high-impact improvements</li>
<li><strong>Strategic priorities</strong> - Long-term architectural improvements</li>
<li><strong>Team guidance</strong> - Role-specific recommendations</li>
</ul>
<blockquote>
<p><strong>Note:</strong> Enhanced markdown features are implemented in the codebase (<code>src/io/writers/enhanced_markdown/</code> module) but the specific flags or configuration options to enable them are not currently documented. Refer to the source code or use <code>--help</code> to discover available options.</p>
</blockquote>
<h3 id="rendering-to-htmlpdf"><a class="header" href="#rendering-to-htmlpdf">Rendering to HTML/PDF</a></h3>
<p>Markdown reports can be converted to other formats:</p>
<pre><code class="language-bash"># Generate markdown
debtmap analyze . --format markdown -o report.md

# Convert to HTML with pandoc
pandoc report.md -o report.html --standalone --css style.css

# Convert to PDF
pandoc report.md -o report.pdf --pdf-engine=xelatex
</code></pre>
<h2 id="tool-integration"><a class="header" href="#tool-integration">Tool Integration</a></h2>
<h3 id="cicd-pipelines"><a class="header" href="#cicd-pipelines">CI/CD Pipelines</a></h3>
<p>Debtmap JSON output integrates seamlessly with CI/CD systems.</p>
<h4 id="github-actions"><a class="header" href="#github-actions">GitHub Actions</a></h4>
<pre><code class="language-yaml">name: Code Quality

on: [pull_request]

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install debtmap
        run: cargo install debtmap

      - name: Run analysis
        run: |
          debtmap analyze . \
            --format json \
            --output analysis.json \
            --lcov coverage/lcov.info

      - name: Check thresholds
        run: |
          DEBT_SCORE=$(jq '.technical_debt.items | length' analysis.json)
          if [ "$DEBT_SCORE" -gt 100 ]; then
            echo "‚ùå Debt score too high: $DEBT_SCORE"
            exit 1
          fi

      - name: Comment on PR
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const analysis = JSON.parse(fs.readFileSync('analysis.json'));
            const summary = `## Debtmap Analysis

            - **Debt Items:** ${analysis.technical_debt.items.length}
            - **Average Complexity:** ${analysis.complexity.summary.average_complexity}
            - **High Complexity Functions:** ${analysis.complexity.summary.high_complexity_count}
            `;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
</code></pre>
<h4 id="gitlab-ci"><a class="header" href="#gitlab-ci">GitLab CI</a></h4>
<pre><code class="language-yaml">code_quality:
  stage: test
  script:
    - cargo install debtmap
    - debtmap analyze . --format json --output gl-code-quality.json
    - |
      DEBT=$(jq '.technical_debt.items | length' gl-code-quality.json)
      if [ "$DEBT" -gt 50 ]; then
        echo "Debt threshold exceeded"
        exit 1
      fi
  artifacts:
    reports:
      codequality: gl-code-quality.json
</code></pre>
<h4 id="jenkins-pipeline"><a class="header" href="#jenkins-pipeline">Jenkins Pipeline</a></h4>
<pre><code class="language-groovy">pipeline {
    agent any

    stages {
        stage('Analyze') {
            steps {
                sh 'debtmap analyze . --format json -o report.json'

                script {
                    def json = readJSON file: 'report.json'
                    def debtScore = json.technical_debt.items.size()

                    if (debtScore &gt; 100) {
                        error("Debt score ${debtScore} exceeds threshold")
                    }
                }
            }
        }
    }

    post {
        always {
            archiveArtifacts artifacts: 'report.json'
        }
    }
}
</code></pre>
<h3 id="querying-json-with-jq"><a class="header" href="#querying-json-with-jq">Querying JSON with jq</a></h3>
<p>Common jq queries for analyzing debtmap output:</p>
<pre><code class="language-bash"># Get total debt items
jq '.technical_debt.items | length' report.json

# Get high-priority items only
jq '.technical_debt.items[] | select(.priority == "High")' report.json

# Get functions with complexity &gt; 10
jq '.complexity.metrics[] | select(.cyclomatic &gt; 10)' report.json

# Calculate average complexity
jq '.complexity.summary.average_complexity' report.json

# Get all TODO items
jq '.technical_debt.items[] | select(.debt_type == "Todo")' report.json

# Get top 5 complex functions
jq '.complexity.metrics | sort_by(-.cyclomatic) | .[0:5] | .[] | {name, file, cyclomatic}' report.json

# Get files with circular dependencies
jq '.dependencies.circular[] | .cycle' report.json

# Count debt items by type
jq '.technical_debt.items | group_by(.debt_type) | map({type: .[0].debt_type, count: length})' report.json

# Get functions with 0% coverage (when using --lcov)
jq '.complexity.metrics[] | select(.coverage == 0)' report.json

# Extract file paths with high debt
jq '.technical_debt.items[] | select(.priority == "High" or .priority == "Critical") | .file' report.json | sort -u
</code></pre>
<h3 id="filtering-and-transformation-examples"><a class="header" href="#filtering-and-transformation-examples">Filtering and Transformation Examples</a></h3>
<h4 id="python-script-to-parse-json"><a class="header" href="#python-script-to-parse-json">Python Script to Parse JSON</a></h4>
<pre><code class="language-python">#!/usr/bin/env python3
import json
import sys

def analyze_debtmap_output(json_file):
    with open(json_file) as f:
        data = json.load(f)

    # Get high-priority items
    high_priority = [
        item for item in data['technical_debt']['items']
        if item['priority'] in ['High', 'Critical']
    ]

    # Group by file
    by_file = {}
    for item in high_priority:
        file = item['file']
        if file not in by_file:
            by_file[file] = []
        by_file[file].append(item)

    # Print summary
    print(f"High-priority debt items: {len(high_priority)}")
    print(f"Files affected: {len(by_file)}")
    print("\nBy file:")
    for file, items in sorted(by_file.items(), key=lambda x: -len(x[1])):
        print(f"  {file}: {len(items)} items")

    return by_file

if __name__ == '__main__':
    analyze_debtmap_output(sys.argv[1])
</code></pre>
<h4 id="shell-script-for-threshold-checking"><a class="header" href="#shell-script-for-threshold-checking">Shell Script for Threshold Checking</a></h4>
<pre><code class="language-bash">#!/bin/bash
set -e

REPORT="$1"
DEBT_THRESHOLD=100
COMPLEXITY_THRESHOLD=10

# Check debt score
DEBT_SCORE=$(jq '.technical_debt.items | length' "$REPORT")
if [ "$DEBT_SCORE" -gt "$DEBT_THRESHOLD" ]; then
    echo "‚ùå Debt score $DEBT_SCORE exceeds threshold $DEBT_THRESHOLD"
    exit 1
fi

# Check average complexity
AVG_COMPLEXITY=$(jq '.complexity.summary.average_complexity' "$REPORT")
if (( $(echo "$AVG_COMPLEXITY &gt; $COMPLEXITY_THRESHOLD" | bc -l) )); then
    echo "‚ùå Average complexity $AVG_COMPLEXITY exceeds threshold $COMPLEXITY_THRESHOLD"
    exit 1
fi

echo "‚úÖ All quality checks passed"
echo "   Debt score: $DEBT_SCORE/$DEBT_THRESHOLD"
echo "   Avg complexity: $AVG_COMPLEXITY"
</code></pre>
<h3 id="editor-integration"><a class="header" href="#editor-integration">Editor Integration</a></h3>
<h4 id="vs-code-tasks"><a class="header" href="#vs-code-tasks">VS Code Tasks</a></h4>
<p>Create <code>.vscode/tasks.json</code>:</p>
<pre><code class="language-json">{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "Debtmap: Analyze",
      "type": "shell",
      "command": "debtmap",
      "args": [
        "analyze",
        ".",
        "--format",
        "terminal"
      ],
      "problemMatcher": [],
      "presentation": {
        "reveal": "always",
        "panel": "new"
      }
    },
    {
      "label": "Debtmap: Generate Report",
      "type": "shell",
      "command": "debtmap",
      "args": [
        "analyze",
        ".",
        "--format",
        "markdown",
        "-o",
        "DEBT_REPORT.md"
      ],
      "problemMatcher": []
    }
  ]
}
</code></pre>
<h4 id="problem-matcher-for-vs-code"><a class="header" href="#problem-matcher-for-vs-code">Problem Matcher for VS Code</a></h4>
<p>Parse debtmap output in VS Code‚Äôs Problems panel:</p>
<pre><code class="language-json">{
  "problemMatcher": {
    "owner": "debtmap",
    "fileLocation": "absolute",
    "pattern": {
      "regexp": "^(.+?):(\\d+):(\\d+)?\\s*-\\s*(.+)$",
      "file": 1,
      "line": 2,
      "column": 3,
      "message": 4
    }
  }
}
</code></pre>
<h3 id="webhook-integration"><a class="header" href="#webhook-integration">Webhook Integration</a></h3>
<p>Send debtmap results to webhooks for notifications:</p>
<pre><code class="language-bash">#!/bin/bash

# Run analysis
debtmap analyze . --format json -o report.json

# Send to Slack
DEBT_SCORE=$(jq '.technical_debt.items | length' report.json)
curl -X POST "$SLACK_WEBHOOK_URL" \
  -H 'Content-Type: application/json' \
  -d "{\"text\": \"Debtmap Analysis Complete\n‚Ä¢ Debt Score: $DEBT_SCORE\n‚Ä¢ High Priority: $(jq '[.technical_debt.items[] | select(.priority == "High")] | length' report.json)\"}"

# Send to custom webhook
curl -X POST "$CUSTOM_WEBHOOK_URL" \
  -H 'Content-Type: application/json' \
  -d @report.json
</code></pre>
<h2 id="output-filtering"><a class="header" href="#output-filtering">Output Filtering</a></h2>
<p>Debtmap provides several flags to filter and limit output:</p>
<blockquote>
<p><strong>Note:</strong> Filtering options (<code>--top</code>, <code>--tail</code>, <code>--summary</code>, <code>--filter</code>) apply to all output formats (terminal, JSON, and markdown). The filtered data is applied at the analysis level before formatting, ensuring consistent results across all output types.</p>
</blockquote>
<h3 id="limiting-results"><a class="header" href="#limiting-results">Limiting Results</a></h3>
<pre><code class="language-bash"># Show only top 10 priority items
debtmap analyze . --top 10

# Show bottom 5 lowest priority items
debtmap analyze . --tail 5
</code></pre>
<h3 id="priority-filtering"><a class="header" href="#priority-filtering">Priority Filtering</a></h3>
<pre><code class="language-bash"># Show only high and critical priority items
debtmap analyze . --min-priority high

# Filter by specific debt categories
debtmap analyze . --filter Architecture,Testing
</code></pre>
<p>Available categories:</p>
<ul>
<li><code>Architecture</code>: God objects, complexity hotspots, dead code</li>
<li><code>Testing</code>: Testing gaps, coverage issues</li>
<li><code>Performance</code>: Resource leaks, inefficient patterns</li>
<li><code>CodeQuality</code>: Code smells, maintainability</li>
</ul>
<h3 id="grouping-output"><a class="header" href="#grouping-output">Grouping Output</a></h3>
<pre><code class="language-bash"># Group results by debt category
debtmap analyze . --group-by-category

# Combine filters for focused analysis
debtmap analyze . --filter Architecture --min-priority high --top 5
</code></pre>
<h3 id="summary-mode"><a class="header" href="#summary-mode">Summary Mode</a></h3>
<pre><code class="language-bash"># Compact tiered priority display
debtmap analyze . --summary

# Combines well with filtering
debtmap analyze . --summary --min-priority medium
</code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="when-to-use-each-format"><a class="header" href="#when-to-use-each-format">When to Use Each Format</a></h3>
<p><strong>Use Terminal Format When:</strong></p>
<ul>
<li>Developing locally and reviewing code</li>
<li>Getting quick feedback on changes</li>
<li>Presenting results to team members</li>
<li>Exploring complexity hotspots interactively</li>
</ul>
<p><strong>Use JSON Format When:</strong></p>
<ul>
<li>Integrating with CI/CD pipelines</li>
<li>Building custom analysis tools</li>
<li>Tracking metrics over time</li>
<li>Programmatically processing results</li>
<li>Feeding into dashboards or monitoring systems</li>
</ul>
<p><strong>Use Markdown Format When:</strong></p>
<ul>
<li>Generating documentation</li>
<li>Creating PR comments</li>
<li>Sharing reports with stakeholders</li>
<li>Archiving analysis results</li>
<li>Producing executive summaries</li>
</ul>
<h3 id="quick-reference-table"><a class="header" href="#quick-reference-table">Quick Reference Table</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>Best For</th><th>Machine Readable</th><th>Human Readable</th><th>File Extension</th></tr></thead><tbody>
<tr><td>Terminal</td><td>Development</td><td>No</td><td>Yes</td><td>.txt</td></tr>
<tr><td>JSON</td><td>Automation</td><td>Yes</td><td>No</td><td>.json</td></tr>
<tr><td>Markdown</td><td>Documentation</td><td>Partially</td><td>Yes</td><td>.md</td></tr>
</tbody></table>
</div>
<h3 id="combining-formats"><a class="header" href="#combining-formats">Combining Formats</a></h3>
<p>Use multiple formats for comprehensive workflows:</p>
<pre><code class="language-bash"># Generate terminal output for review
debtmap analyze .

# Generate JSON for automation
debtmap analyze . --format json -o ci-report.json

# Generate markdown for documentation
debtmap analyze . --format markdown -o docs/DEBT.md
</code></pre>
<h3 id="performance-considerations"><a class="header" href="#performance-considerations">Performance Considerations</a></h3>
<ul>
<li><strong>Terminal format</strong>: Fastest, minimal overhead</li>
<li><strong>JSON format</strong>: Fast serialization, efficient for large codebases</li>
<li><strong>Markdown format</strong>: Slightly slower due to formatting, but still performant</li>
</ul>
<p>For very large codebases (&gt;10,000 files), use <code>--top</code> or <code>--filter</code> to limit output size.</p>
<h2 id="troubleshooting-2"><a class="header" href="#troubleshooting-2">Troubleshooting</a></h2>
<h3 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h3>
<p><strong>Colors not showing in terminal:</strong></p>
<ul>
<li>Check if terminal supports ANSI colors</li>
<li>Use <code>--plain</code> flag for ASCII-only output</li>
<li>Some CI systems may not support color codes</li>
</ul>
<p><strong>JSON parsing errors:</strong></p>
<ul>
<li>Ensure output is complete (check for errors during analysis)</li>
<li>Validate JSON with <code>jq</code> or online validators</li>
<li>Check for special characters in file paths</li>
</ul>
<p><strong>Markdown rendering issues:</strong></p>
<ul>
<li>Some markdown renderers don‚Äôt support all features</li>
<li>Use standard markdown for maximum compatibility</li>
<li>Test with pandoc or GitHub/GitLab preview</li>
</ul>
<p><strong>File encoding problems:</strong></p>
<ul>
<li>Ensure UTF-8 encoding for all output files</li>
<li>Use <code>--plain</code> for pure ASCII output</li>
<li>Check locale settings (LC_ALL, LANG environment variables)</li>
</ul>
<h3 id="exit-codes"><a class="header" href="#exit-codes">Exit Codes</a></h3>
<blockquote>
<p><strong>IMPORTANT:</strong> Exit codes 1 and 2 are NOT YET IMPLEMENTED. Current behavior: Always returns <code>0</code> on successful analysis, regardless of threshold violations.</p>
<p>Planned behavior includes:</p>
<ul>
<li><code>0</code>: Success, all checks passed</li>
<li><code>1</code>: Analysis completed, but validation thresholds exceeded</li>
<li><code>2</code>: Error during analysis (invalid path, parsing error, etc.)</li>
</ul>
</blockquote>
<p>For now, use the <code>validate</code> command with threshold checks to enforce quality gates:</p>
<pre><code class="language-bash"># Use validate command for threshold enforcement
debtmap validate . --config debtmap.toml

# Or parse JSON output for threshold checking
debtmap analyze . --format json -o report.json
DEBT_SCORE=$(jq '.technical_debt.items | length' report.json)
if [ "$DEBT_SCORE" -gt 100 ]; then
    echo "Debt threshold exceeded"
    exit 1
fi
</code></pre>
<h2 id="see-also-1"><a class="header" href="#see-also-1">See Also</a></h2>
<ul>
<li><a href="./getting-started.html">Getting Started</a> - Basic usage and examples</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Understanding metrics and scores</li>
<li><a href="./configuration.html">Configuration</a> - Customizing analysis behavior</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tiered-prioritization-1"><a class="header" href="#tiered-prioritization-1">Tiered Prioritization</a></h1>
<p>Debtmap uses a sophisticated tiered prioritization system to surface critical architectural issues above simple testing gaps. This chapter explains the tier strategy, how to interpret tier classifications, and how to customize tier thresholds for your project.</p>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>The tiered prioritization system organizes technical debt into four distinct tiers based on impact, urgency, and architectural significance. This prevents ‚Äúwalls of similar-scored items‚Äù and ensures critical issues don‚Äôt get lost among minor problems.</p>
<h2 id="the-four-tiers"><a class="header" href="#the-four-tiers">The Four Tiers</a></h2>
<h3 id="tier-1-critical-architecture"><a class="header" href="#tier-1-critical-architecture">Tier 1: Critical Architecture</a></h3>
<p><strong>Description</strong>: God Objects, God Modules, excessive complexity requiring immediate architectural attention</p>
<p><strong>Priority</strong>: Must address before adding new features</p>
<p><strong>Weight</strong>: 1.5x (highest priority multiplier)</p>
<p><strong>Impact</strong>: High impact on maintainability and team velocity</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Files with 15+ responsibilities</li>
<li>Modules with 50+ methods</li>
<li>God objects flagged by detection algorithms</li>
<li>Circular dependencies affecting core modules</li>
</ul>
<p><strong>When to Address</strong>: Immediately, before sprint work begins. These issues compound over time and block progress.</p>
<pre><code class="language-bash"># Focus on Tier 1 items
debtmap analyze . --filter Architecture --min-priority high
</code></pre>
<h3 id="tier-2-complex-untested"><a class="header" href="#tier-2-complex-untested">Tier 2: Complex Untested</a></h3>
<p><strong>Description</strong>: Untested code with high complexity or critical dependencies</p>
<p><strong>Priority</strong>: Risk of bugs in critical paths</p>
<p><strong>Weight</strong>: 1.0x (standard multiplier)</p>
<p><strong>Action</strong>: Should be tested before refactoring to prevent regressions</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Functions with cyclomatic complexity &gt; 15 and 0% coverage</li>
<li>Business logic entry points without tests</li>
<li>Complex error handling without validation</li>
</ul>
<p><strong>When to Address</strong>: Within current sprint. Add tests before making changes.</p>
<pre><code class="language-bash"># See Tier 2 testing gaps
debtmap analyze . --lcov coverage.lcov --filter Testing
</code></pre>
<h3 id="tier-3-testing-gaps"><a class="header" href="#tier-3-testing-gaps">Tier 3: Testing Gaps</a></h3>
<p><strong>Description</strong>: Untested code with moderate complexity</p>
<p><strong>Priority</strong>: Improve coverage to prevent future issues</p>
<p><strong>Weight</strong>: 0.7x (reduced multiplier)</p>
<p><strong>Action</strong>: Add tests opportunistically or during related changes</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Functions with cyclomatic complexity 10-15 and low coverage</li>
<li>Utility functions without edge case tests</li>
<li>Moderate complexity with partial coverage</li>
</ul>
<p><strong>When to Address</strong>: Next sprint or when touching related code.</p>
<h3 id="tier-4-maintenance"><a class="header" href="#tier-4-maintenance">Tier 4: Maintenance</a></h3>
<p><strong>Description</strong>: Low-complexity issues and code quality improvements</p>
<p><strong>Priority</strong>: Address opportunistically during other work</p>
<p><strong>Weight</strong>: 0.3x (lowest multiplier)</p>
<p><strong>Action</strong>: Fix when convenient, low urgency</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Simple functions with minor code quality issues</li>
<li>TODO markers in well-tested code</li>
<li>Minor duplication in test code</li>
</ul>
<p><strong>When to Address</strong>: During cleanup sprints or when refactoring nearby code.</p>
<h2 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h2>
<h3 id="default-tier-thresholds"><a class="header" href="#default-tier-thresholds">Default Tier Thresholds</a></h3>
<pre><code class="language-toml">[tiers]
# Tier 2 thresholds (Complex Untested)
t2_complexity_threshold = 15         # Cyclomatic complexity cutoff
t2_dependency_threshold = 10         # Dependency count cutoff

# Tier 3 thresholds (Testing Gaps)
t3_complexity_threshold = 10         # Lower complexity threshold

# Display options
show_t4_in_main_report = false      # Hide Tier 4 from main output

# Tier weights
[tiers.tier_weights]
t1 = 1.5    # Critical architecture
t2 = 1.0    # Complex untested
t3 = 0.7    # Testing gaps
t4 = 0.3    # Maintenance
</code></pre>
<h3 id="customizing-tier-thresholds"><a class="header" href="#customizing-tier-thresholds">Customizing Tier Thresholds</a></h3>
<p>Adjust thresholds to match your team‚Äôs standards:</p>
<pre><code class="language-toml"># Stricter thresholds for high-quality codebases
[tiers]
t2_complexity_threshold = 12
t3_complexity_threshold = 8

# More lenient for legacy codebases
[tiers]
t2_complexity_threshold = 20
t3_complexity_threshold = 15
</code></pre>
<h3 id="tier-weight-customization"><a class="header" href="#tier-weight-customization">Tier Weight Customization</a></h3>
<p>Adjust weights based on your priorities:</p>
<pre><code class="language-toml"># Emphasize testing over architecture
[tiers.tier_weights]
t1 = 1.2    # Reduce architecture weight
t2 = 1.3    # Increase testing weight
t3 = 0.8
t4 = 0.3

# Focus on architecture first
[tiers.tier_weights]
t1 = 2.0    # Maximize architecture weight
t2 = 1.0
t3 = 0.5
t4 = 0.2
</code></pre>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<h3 id="sprint-planning"><a class="header" href="#sprint-planning">Sprint Planning</a></h3>
<p>Use tiered prioritization to allocate work:</p>
<pre><code class="language-bash"># See Tier 1 items for architectural planning
debtmap analyze . --filter Architecture --top 5

# See Tier 2/3 for testing sprint work
debtmap analyze . --filter Testing --min-priority medium
</code></pre>
<h3 id="code-review-focus"><a class="header" href="#code-review-focus">Code Review Focus</a></h3>
<p>Prioritize review attention based on tiers:</p>
<ul>
<li><strong>Tier 1</strong>: Architectural review required, senior dev attention</li>
<li><strong>Tier 2</strong>: Test coverage validation critical</li>
<li><strong>Tier 3</strong>: Standard review process</li>
<li><strong>Tier 4</strong>: Quick review or automated checks</li>
</ul>
<h3 id="refactoring-strategy"><a class="header" href="#refactoring-strategy">Refactoring Strategy</a></h3>
<pre><code class="language-bash"># Phase 1: Address Tier 1 architectural issues
debtmap analyze . --filter Architecture

# Phase 2: Add tests for Tier 2 complex code
debtmap analyze . --lcov coverage.lcov --min-priority high

# Phase 3: Improve Tier 3 coverage
debtmap analyze . --lcov coverage.lcov --min-priority medium
</code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<ol>
<li><strong>Always address Tier 1 before feature work</strong> - Architectural issues compound</li>
<li><strong>Test Tier 2 items before refactoring</strong> - Avoid regressions</li>
<li><strong>Batch Tier 3 items</strong> - Address multiple in one sprint</li>
<li><strong>Defer Tier 4 items</strong> - Only fix during cleanup or when convenient</li>
<li><strong>Track tier distribution over time</strong> - Aim to reduce Tier 1/2 counts</li>
</ol>
<h2 id="interpreting-tier-output"><a class="header" href="#interpreting-tier-output">Interpreting Tier Output</a></h2>
<h3 id="terminal-output-1"><a class="header" href="#terminal-output-1">Terminal Output</a></h3>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    TIERED TECHNICAL DEBT REPORT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üî¥ TIER 1: CRITICAL ARCHITECTURE (3 items)
  1. src/services.rs - God Object (85% god score, 52 methods)
  2. src/core/engine.rs - Circular dependency with parsers module
  3. src/api/handlers.rs - God Module (15 responsibilities)

üü† TIER 2: COMPLEX UNTESTED (12 items)
  1. src/processing/transform.rs:145 - Complexity 18, Coverage 0%
  ...

üü° TIER 3: TESTING GAPS (45 items)
  ...

‚ö™ TIER 4: MAINTENANCE (120 items) [hidden]
  Use --show-t4 to display maintenance items
</code></pre>
<h3 id="json-output-1"><a class="header" href="#json-output-1">JSON Output</a></h3>
<pre><code class="language-json">{
  "tier_distribution": {
    "t1_count": 3,
    "t2_count": 12,
    "t3_count": 45,
    "t4_count": 120
  },
  "items": [
    {
      "tier": "T1_CriticalArchitecture",
      "priority_weight": 1.5,
      "base_score": 8.5,
      "final_score": 12.75
    }
  ]
}
</code></pre>
<h2 id="troubleshooting-3"><a class="header" href="#troubleshooting-3">Troubleshooting</a></h2>
<p><strong>Issue</strong>: Too many Tier 1 items</p>
<p><strong>Solution</strong>: Lower tier weights or increase thresholds temporarily:</p>
<pre><code class="language-toml">[tiers.tier_weights]
t1 = 1.2    # Reduce from 1.5
</code></pre>
<p><strong>Issue</strong>: Not enough items in Tier 1</p>
<p><strong>Solution</strong>: Check if god object detection is enabled:</p>
<pre><code class="language-toml">[god_object_detection]
enabled = true
</code></pre>
<p><strong>Issue</strong>: All items in Tier 4</p>
<p><strong>Solution</strong>: Lower minimum thresholds:</p>
<pre><code class="language-toml">[thresholds]
minimum_debt_score = 1.0
minimum_cyclomatic_complexity = 2
</code></pre>
<h2 id="see-also-2"><a class="header" href="#see-also-2">See Also</a></h2>
<ul>
<li><a href="./scoring-strategies.html">Scoring Strategies</a> - Understanding file-level vs function-level scoring</li>
<li><a href="./configuration.html">Configuration</a> - Complete configuration reference</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Detailed metric explanations</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scoring-strategies"><a class="header" href="#scoring-strategies">Scoring Strategies</a></h1>
<p>Debtmap provides two complementary scoring approaches: <strong>file-level</strong> and <strong>function-level</strong>. Understanding when to use each approach helps you make better refactoring decisions and prioritize work effectively.</p>
<h2 id="overview-2"><a class="header" href="#overview-2">Overview</a></h2>
<p>Different refactoring scenarios require different levels of granularity:</p>
<ul>
<li><strong>File-level scoring</strong>: Identifies architectural issues and planning major refactoring initiatives</li>
<li><strong>Function-level scoring</strong>: Pinpoints specific hot spots for targeted improvements</li>
</ul>
<p>This chapter explains both approaches, when to use each, and how to interpret the results.</p>
<h2 id="file-level-scoring"><a class="header" href="#file-level-scoring">File-Level Scoring</a></h2>
<p>File-level scoring aggregates metrics across all functions in a file to identify architectural problems and module-level refactoring opportunities.</p>
<h3 id="formula-1"><a class="header" href="#formula-1">Formula</a></h3>
<pre><code>File Score = Size √ó Complexity √ó Coverage √ó Density √ó GodObject √ó FunctionScores
</code></pre>
<p>Where each factor is calculated as:</p>
<ul>
<li><strong>Size</strong> = <code>sqrt(total_lines / 100)</code></li>
<li><strong>Complexity</strong> = <code>(avg_complexity / 5.0) √ó sqrt(total_complexity / 50.0)</code></li>
<li><strong>Coverage</strong> = <code>(1 - coverage_percent) √ó 2 + 1</code></li>
<li><strong>Density</strong> = <code>max(1.0, function_count / 50)</code> if function_count &gt; 50</li>
<li><strong>GodObject</strong> = <code>2.0 + god_object_score</code> if detected</li>
<li><strong>FunctionScores</strong> = <code>sum(function_scores) / 10</code></li>
</ul>
<h3 id="factors"><a class="header" href="#factors">Factors</a></h3>
<p><strong>Size Factor</strong>: <code>sqrt(total_lines / 100)</code></p>
<ul>
<li>Larger files have higher impact</li>
<li>Square root dampens the effect to avoid over-penalizing large files</li>
<li>Rationale: Refactoring a 1000-line file affects more code than a 100-line file</li>
</ul>
<p><strong>Complexity Factor</strong>: Combines average and total complexity</p>
<ul>
<li><code>(average_cyclomatic + total_cyclomatic / function_count) / 2</code></li>
<li>Balances per-function and aggregate complexity</li>
<li>Rationale: Both concentrated complexity and spread-out complexity matter</li>
</ul>
<p><strong>Coverage Factor</strong>: <code>(1 - coverage_percent) √ó 2 + 1</code></p>
<ul>
<li>Lower coverage increases score multiplicatively</li>
<li>Range: 1.0 (100% coverage) to 3.0 (0% coverage)</li>
<li>Rationale: Untested files are riskier to refactor</li>
</ul>
<p><strong>Density Factor</strong>: Penalizes files with excessive function count</p>
<ul>
<li>Triggers when function count &gt; 50</li>
<li><code>max(1.0, function_count / 50)</code></li>
<li>Rationale: Files with 100+ functions likely violate single responsibility</li>
</ul>
<p><strong>God Object Multiplier</strong>: <code>2.0 + god_object_score</code> when detected</p>
<ul>
<li>Applies when god object detection flags the file</li>
<li>Range: 2.0 (borderline) to 3.0 (severe god object)</li>
<li>Rationale: God objects need immediate architectural attention</li>
</ul>
<p><strong>Function Scores</strong>: <code>sum(all_function_scores) / 10</code></p>
<ul>
<li>Normalized sum of individual function debt scores</li>
<li>Provides baseline before modifiers</li>
</ul>
<h3 id="use-cases-1"><a class="header" href="#use-cases-1">Use Cases</a></h3>
<p><strong>1. Planning Major Refactoring Initiatives</strong></p>
<pre><code class="language-bash"># Show top 10 files needing architectural refactoring
debtmap analyze . --aggregate-only --top 10
</code></pre>
<p>Use when:</p>
<ul>
<li>Planning sprint or quarterly refactoring work</li>
<li>Deciding which modules to split</li>
<li>Prioritizing architectural improvements</li>
<li>Allocating team resources</li>
</ul>
<p><strong>Note</strong>: File-level scoring is enabled with the <code>--aggregate-only</code> flag, which changes output to show only file-level metrics instead of function-level details.</p>
<p><strong>2. Identifying Architectural Issues</strong></p>
<p>File-level scoring excels at finding:</p>
<ul>
<li>God objects with too many responsibilities</li>
<li>Files with poor cohesion</li>
<li>Modules that should be split</li>
<li>Files with too many functions</li>
</ul>
<pre><code class="language-bash"># Focus on architectural problems
debtmap analyze . --aggregate-only --filter Architecture
</code></pre>
<p><strong>3. Breaking Up Monolithic Modules</strong></p>
<pre><code class="language-bash"># Find files with excessive function counts
debtmap analyze . --aggregate-only --min-problematic 50
</code></pre>
<p><strong>4. Evaluating Overall Codebase Health</strong></p>
<pre><code class="language-bash"># Generate file-level report for executive summary
debtmap analyze . --aggregate-only --format markdown -o report.md
</code></pre>
<h3 id="aggregation-methods"><a class="header" href="#aggregation-methods">Aggregation Methods</a></h3>
<p>Debtmap supports multiple aggregation methods for file-level scores, configurable via CLI or configuration file.</p>
<p><strong>Weighted Sum (Default)</strong></p>
<pre><code class="language-bash">debtmap analyze . --aggregation-method weighted_sum
</code></pre>
<p>Or via configuration:</p>
<pre><code class="language-toml">[aggregation]
method = "weighted_sum"
</code></pre>
<ul>
<li>Weights functions by complexity and coverage</li>
<li>Emphasizes high-impact functions</li>
<li>Best for most use cases</li>
</ul>
<p><strong>Simple Sum</strong></p>
<pre><code class="language-toml">[aggregation]
method = "sum"
</code></pre>
<ul>
<li>Adds all function scores directly</li>
<li>Treats all functions equally</li>
<li>Useful for broad overview</li>
</ul>
<p><strong>Logarithmic Sum</strong></p>
<pre><code class="language-toml">[aggregation]
method = "logarithmic_sum"
</code></pre>
<ul>
<li>Dampens impact of many small issues</li>
<li><code>log(1 + sum_of_scores)</code></li>
<li>Useful for legacy codebases with many minor issues</li>
</ul>
<p><strong>Max Plus Average</strong></p>
<pre><code class="language-toml">[aggregation]
method = "max_plus_average"
</code></pre>
<ul>
<li>Considers worst function plus average of others</li>
<li><code>max_score √ó 0.6 + average_score √ó 0.4</code></li>
<li>Balances worst-case and typical-case analysis</li>
</ul>
<h3 id="configuration-3"><a class="header" href="#configuration-3">Configuration</a></h3>
<pre><code class="language-toml">[aggregation]
method = "weighted_sum"
min_problematic = 3              # Need 3+ problematic functions for file-level score

[god_object_detection]
enabled = true
max_methods = 20
max_fields = 15
max_responsibilities = 5
</code></pre>
<h2 id="function-level-scoring"><a class="header" href="#function-level-scoring">Function-Level Scoring</a></h2>
<p>Function-level scoring identifies specific functions needing attention for targeted improvements.</p>
<h3 id="formula-2"><a class="header" href="#formula-2">Formula</a></h3>
<pre><code>Function Score = (Complexity √ó 0.35) + (Coverage √ó 0.50) + (Dependency √ó 0.15)
Final Score = Base Score √ó Role Multiplier
</code></pre>
<p><strong>Note</strong>: These weights are configurable via the <code>[scoring]</code> section in <code>.debtmap.toml</code>. See <a href="scoring-strategies.html#configuration">Configuration</a> below.</p>
<h3 id="metrics"><a class="header" href="#metrics">Metrics</a></h3>
<p><strong>Cyclomatic Complexity</strong></p>
<ul>
<li>Counts decision points (if, match, loops)</li>
<li>Guides test case count</li>
</ul>
<p><strong>Cognitive Complexity</strong></p>
<ul>
<li>Measures understanding difficulty</li>
<li>Accounts for nesting depth</li>
</ul>
<p><strong>Coverage Percentage</strong></p>
<ul>
<li>Direct line coverage from LCOV</li>
<li>0% coverage = maximum urgency</li>
</ul>
<p><strong>Dependency Count</strong></p>
<ul>
<li>Upstream callers + downstream callees</li>
<li>Higher dependencies = higher impact</li>
</ul>
<p><strong>Role Multiplier</strong></p>
<p>Functions are classified by role, and each role receives a multiplier based on its architectural importance:</p>
<ul>
<li><strong>Entry points</strong>: 1.5x - Public APIs, main functions, HTTP handlers</li>
<li><strong>Pure logic / Business logic</strong>: 1.2x-1.3x - Core business rules and algorithms (multiplier increases with complexity)</li>
<li><strong>Orchestrator</strong>: 0.8x - Functions that coordinate other functions</li>
<li><strong>IO wrapper</strong>: 0.5x - Simple file/network I/O wrappers</li>
<li><strong>Pattern match</strong>: 0.6x - Functions primarily doing pattern matching</li>
<li><strong>Utility</strong>: 0.5x - Helper functions and utilities</li>
</ul>
<p><strong>Note</strong>: Role multipliers are configurable via the <code>[role_multipliers]</code> section in <code>.debtmap.toml</code>.</p>
<h3 id="use-cases-2"><a class="header" href="#use-cases-2">Use Cases</a></h3>
<p><strong>1. Identifying Specific Hot Spots</strong></p>
<pre><code class="language-bash"># Show top 20 functions needing attention
debtmap analyze . --top 20
</code></pre>
<p>Use when:</p>
<ul>
<li>Planning individual developer tasks</li>
<li>Assigning specific refactoring work</li>
<li>Identifying functions to test first</li>
<li>Code review focus</li>
</ul>
<p><strong>2. Sprint Planning for Developers</strong></p>
<pre><code class="language-bash"># Get function-level tasks for this sprint
debtmap analyze . --top 10 --format json -o sprint-tasks.json
</code></pre>
<p><strong>3. Writing Unit Tests</strong></p>
<pre><code class="language-bash"># Find untested complex functions
debtmap analyze . --lcov coverage.lcov --filter Testing --top 15
</code></pre>
<p><strong>4. Targeted Performance Optimization</strong></p>
<pre><code class="language-bash"># Find complex hot paths
debtmap analyze . --filter Performance --context --top 10
</code></pre>
<h3 id="configuration-4"><a class="header" href="#configuration-4">Configuration</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.50              # Weight for coverage gaps (default)
complexity = 0.35            # Weight for complexity (default)
dependency = 0.15            # Weight for dependency impact (default)

[role_multipliers]
entry_point = 1.5
business_logic = 1.2
pure_logic = 1.2
orchestrator = 0.8
io_wrapper = 0.7
utility = 0.5
</code></pre>
<h2 id="when-to-use-each-approach"><a class="header" href="#when-to-use-each-approach">When to Use Each Approach</a></h2>
<h3 id="use-file-level-scoring-when"><a class="header" href="#use-file-level-scoring-when">Use File-Level Scoring When:</a></h3>
<p>‚úÖ Planning architectural refactoring
‚úÖ Quarterly or annual planning
‚úÖ Deciding which modules to split
‚úÖ Executive summaries and high-level reports
‚úÖ Team capacity planning
‚úÖ Identifying god objects
‚úÖ Module reorganization</p>
<p><strong>Command:</strong></p>
<pre><code class="language-bash">debtmap analyze . --aggregate-only
</code></pre>
<h3 id="use-function-level-scoring-when"><a class="header" href="#use-function-level-scoring-when">Use Function-Level Scoring When:</a></h3>
<p>‚úÖ Sprint planning
‚úÖ Individual developer task assignment
‚úÖ Writing specific unit tests
‚úÖ Code review preparation
‚úÖ Pair programming sessions
‚úÖ Daily or weekly development work
‚úÖ Targeted hot spot fixes</p>
<p><strong>Command:</strong></p>
<pre><code class="language-bash">debtmap analyze . --top 20
</code></pre>
<h3 id="use-both-together"><a class="header" href="#use-both-together">Use Both Together:</a></h3>
<p>Many workflows benefit from both views:</p>
<pre><code class="language-bash"># Step 1: Identify problematic files
debtmap analyze . --aggregate-only --top 5 -o files.json

# Step 2: Drill into specific file
debtmap analyze src/problematic/module.rs --format terminal
</code></pre>
<h2 id="comparison-examples"><a class="header" href="#comparison-examples">Comparison Examples</a></h2>
<h3 id="example-1-god-object-detection"><a class="header" href="#example-1-god-object-detection">Example 1: God Object Detection</a></h3>
<p><strong>File-Level View:</strong></p>
<pre><code>src/services/user_service.rs - Score: 245.8
  - 850 lines, 45 methods
  - God Object: 78% score
  - Action: Split into UserAuth, UserProfile, UserNotifications
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>src/services/user_service.rs:142 - authenticate_user() - Score: 8.5
src/services/user_service.rs:298 - update_profile() - Score: 7.2
src/services/user_service.rs:456 - send_notification() - Score: 6.8
</code></pre>
<p><strong>Decision</strong>: File-level score (245.8) correctly identifies architectural issue. Individual functions aren‚Äôt exceptionally complex, but the file has too many responsibilities. <strong>Solution</strong>: Split the file.</p>
<h3 id="example-2-targeted-function-fix"><a class="header" href="#example-2-targeted-function-fix">Example 2: Targeted Function Fix</a></h3>
<p><strong>File-Level View:</strong></p>
<pre><code>src/parsers/expression.rs - Score: 45.2
  - 320 lines, 12 functions
  - No god object detected
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>src/parsers/expression.rs:89 - parse_complex_expression() - Score: 9.1
  - Cyclomatic: 22, Cognitive: 35
  - Coverage: 0%
  - Action: Add tests and refactor
</code></pre>
<p><strong>Decision</strong>: File as a whole is acceptable, but one function needs attention. <strong>Solution</strong>: Focus on that specific function.</p>
<h3 id="example-3-balanced-refactoring"><a class="header" href="#example-3-balanced-refactoring">Example 3: Balanced Refactoring</a></h3>
<p><strong>File-Level View:</strong></p>
<pre><code>src/analysis/scoring.rs - Score: 125.6
  - 580 lines, 18 functions
  - High complexity, low coverage
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>calculate_score() - Score: 8.8 (15% coverage)
apply_weights() - Score: 8.2 (10% coverage)
normalize_results() - Score: 7.5 (0% coverage)
</code></pre>
<p><strong>Decision</strong>: Both file and functions need work. <strong>Solution</strong>: Add tests first (function-level), then consider splitting if complexity persists (file-level).</p>
<h2 id="score-normalization"><a class="header" href="#score-normalization">Score Normalization</a></h2>
<p>Both scoring approaches normalize to a 0-10 scale for consistency.</p>
<h3 id="normalization-strategy"><a class="header" href="#normalization-strategy">Normalization Strategy</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>score_normalized = if raw_score &lt; 10.0 {
    raw_score  // Linear below 10
} else if raw_score &lt; 100.0 {
    sqrt(raw_score) √ó 3.33  // Square root 10-100
} else {
    log10(raw_score) √ó 10.0  // Logarithmic above 100
}
<span class="boring">}</span></code></pre></pre>
<h3 id="configuration-5"><a class="header" href="#configuration-5">Configuration</a></h3>
<pre><code class="language-toml">[normalization]
linear_threshold = 10.0       # Scores below this use linear scaling (1:1 mapping)
logarithmic_threshold = 100.0 # Scores above this use logarithmic dampening
sqrt_multiplier = 3.33        # Applied to scores between linear and log thresholds
log_multiplier = 10.0         # Applied to scores above logarithmic threshold
show_raw_scores = true        # Display both normalized (0-10) and raw scores in output
</code></pre>
<p><strong>Explanation</strong>:</p>
<ul>
<li><strong>linear_threshold</strong>: Scores below this value are mapped 1:1 (no scaling)</li>
<li><strong>logarithmic_threshold</strong>: Scores above this value are dampened logarithmically to prevent extreme values</li>
<li><strong>sqrt_multiplier</strong>: Square root scaling applied to mid-range scores (between linear and logarithmic thresholds)</li>
<li><strong>log_multiplier</strong>: Logarithmic dampening factor for very high scores</li>
<li><strong>show_raw_scores</strong>: When enabled, output includes both the normalized 0-10 score and the raw calculated score</li>
</ul>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="workflow-integration"><a class="header" href="#workflow-integration">Workflow Integration</a></h3>
<p><strong>Week 1: File-Level Assessment</strong></p>
<pre><code class="language-bash"># Identify architectural problems
debtmap analyze . --aggregate-only --top 10
</code></pre>
<p><strong>Week 2-4: Function-Level Work</strong></p>
<pre><code class="language-bash"># Work through specific functions
debtmap analyze src/target/module.rs
</code></pre>
<p><strong>Monthly: Compare Progress</strong></p>
<pre><code class="language-bash">debtmap compare --before baseline.json --after current.json
</code></pre>
<h3 id="team-collaboration"><a class="header" href="#team-collaboration">Team Collaboration</a></h3>
<ul>
<li><strong>Architects</strong>: Use file-level scores for strategic planning</li>
<li><strong>Tech Leads</strong>: Use both for sprint planning</li>
<li><strong>Developers</strong>: Use function-level for daily work</li>
<li><strong>QA</strong>: Use function-level for test prioritization</li>
</ul>
<h3 id="cicd-integration-1"><a class="header" href="#cicd-integration-1">CI/CD Integration</a></h3>
<pre><code class="language-bash"># Gate: No new file-level regressions
debtmap analyze . --aggregate-only --format json -o file-scores.json

# Gate: No new critical function-level issues
debtmap analyze . --min-priority critical --format json -o critical-items.json
</code></pre>
<h2 id="troubleshooting-4"><a class="header" href="#troubleshooting-4">Troubleshooting</a></h2>
<p><strong>Issue</strong>: File-level scores seem too high</p>
<p><strong>Solution</strong>: Check aggregation method:</p>
<pre><code class="language-toml">[aggregation]
method = "logarithmic_sum"  # Dampen scores
</code></pre>
<p><strong>Issue</strong>: Function-level scores all similar</p>
<p><strong>Solution</strong>: Adjust scoring weights to emphasize different factors:</p>
<pre><code class="language-toml">[scoring]
coverage = 0.60    # Emphasize testing gaps more
complexity = 0.30
dependency = 0.10
</code></pre>
<p><strong>Issue</strong>: Too many low-priority items</p>
<p><strong>Solution</strong>: Use minimum thresholds:</p>
<pre><code class="language-toml">[thresholds]
minimum_debt_score = 3.0
</code></pre>
<h2 id="see-also-3"><a class="header" href="#see-also-3">See Also</a></h2>
<ul>
<li><a href="./tiered-prioritization.html">Tiered Prioritization</a> - Understanding tier-based classification</li>
<li><a href="./configuration.html">Configuration</a> - Scoring and aggregation configuration</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Detailed metric explanations</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prodigy-integration"><a class="header" href="#prodigy-integration">Prodigy Integration</a></h1>
<p>Debtmap integrates with <a href="https://github.com/iepathos/prodigy">Prodigy</a> to provide fully automated technical debt reduction through AI-driven workflows. This chapter explains how to set up and use Prodigy workflows to automatically refactor code, add tests, and improve codebase quality.</p>
<h2 id="what-is-prodigy"><a class="header" href="#what-is-prodigy">What is Prodigy?</a></h2>
<p>Prodigy is an AI-powered workflow automation system that uses Claude to execute complex multi-step tasks. When integrated with Debtmap, it can:</p>
<ul>
<li><strong>Automatically refactor</strong> high-complexity functions identified by Debtmap</li>
<li><strong>Add unit tests</strong> for untested code</li>
<li><strong>Fix code duplication</strong> by extracting shared logic</li>
<li><strong>Improve code organization</strong> by addressing architectural issues</li>
<li><strong>Validate improvements</strong> with automated testing</li>
</ul>
<p>All changes are made in isolated git worktrees, validated with tests and linting, and only committed if all checks pass.</p>
<h2 id="benefits"><a class="header" href="#benefits">Benefits</a></h2>
<h3 id="automated-debt-reduction"><a class="header" href="#automated-debt-reduction">Automated Debt Reduction</a></h3>
<p>Instead of manually addressing each technical debt item, Prodigy can:</p>
<ol>
<li>Analyze Debtmap‚Äôs output</li>
<li>Select high-priority items</li>
<li>Generate refactoring plans</li>
<li>Execute refactorings automatically</li>
<li>Validate with tests</li>
<li>Commit clean changes</li>
</ol>
<h3 id="iterative-improvement"><a class="header" href="#iterative-improvement">Iterative Improvement</a></h3>
<p>Prodigy supports <strong>iterative workflows</strong>:</p>
<ul>
<li>Run analysis ‚Üí fix top items ‚Üí re-analyze ‚Üí fix more</li>
<li>Configurable iteration count (default: 5 iterations)</li>
<li>Each iteration focuses on highest-priority remaining items</li>
</ul>
<h3 id="safe-experimentation"><a class="header" href="#safe-experimentation">Safe Experimentation</a></h3>
<p>All changes happen in <strong>isolated git worktrees</strong>:</p>
<ul>
<li>Original branch remains untouched</li>
<li>Failed attempts don‚Äôt affect main codebase</li>
<li>Easy to review before merging</li>
<li>Automatic cleanup after workflow</li>
</ul>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<h3 id="install-prodigy"><a class="header" href="#install-prodigy">Install Prodigy</a></h3>
<pre><code class="language-bash"># Install Prodigy CLI
cargo install prodigy

# Verify installation
prodigy --version
</code></pre>
<h3 id="configure-claude-api"><a class="header" href="#configure-claude-api">Configure Claude API</a></h3>
<pre><code class="language-bash"># Set Claude API key
export ANTHROPIC_API_KEY="your-api-key-here"

# Or in ~/.prodigy/config.toml:
[api]
anthropic_key = "your-api-key-here"
</code></pre>
<h3 id="ensure-debtmap-is-installed"><a class="header" href="#ensure-debtmap-is-installed">Ensure Debtmap is Installed</a></h3>
<pre><code class="language-bash"># Install Debtmap
cargo install debtmap

# Verify installation
debtmap --version
</code></pre>
<h2 id="quick-start-2"><a class="header" href="#quick-start-2">Quick Start</a></h2>
<h3 id="1-initialize-workflow"><a class="header" href="#1-initialize-workflow">1. Initialize Workflow</a></h3>
<p>Create a workflow file <code>workflows/debtmap.yml</code>:</p>
<pre><code class="language-yaml"># Sequential workflow. Fix top technical debt item

# Phase 1: Generate coverage data
- shell: "just coverage-lcov"

# Phase 2: Analyze tech debt and capture baseline
- shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-before.json --format json"

# Phase 3: Create implementation plan (PLANNING PHASE)
- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"
  capture_output: true
  validate:
    commands:
      - claude: "/prodigy-validate-debtmap-plan --before .prodigy/debtmap-before.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/plan-validation.json"
    result_file: ".prodigy/plan-validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-revise-debtmap-plan --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
      max_attempts: 3
      fail_workflow: false

# Phase 4: Execute the plan (IMPLEMENTATION PHASE)
- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
  validate:
    commands:
      - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
      - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      - claude: "/prodigy-validate-debtmap-improvement --comparison .prodigy/comparison.json --output .prodigy/debtmap-validation.json"
    result_file: ".prodigy/debtmap-validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
          commit_required: true
        - shell: "just coverage-lcov"
        - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
        - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      max_attempts: 5
      fail_workflow: true

# Phase 5: Run tests with automatic fixing
- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true

# Phase 6: Run linting and formatting
- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<h3 id="2-run-workflow"><a class="header" href="#2-run-workflow">2. Run Workflow</a></h3>
<pre><code class="language-bash"># Run with worktree, auto-confirm, 5 iterations
prodigy cook workflows/debtmap.yml -wyn 5

# Run with custom iteration count
prodigy cook workflows/debtmap.yml -wyn 10

# Run single iteration for testing
prodigy cook workflows/debtmap.yml -wyn 1
</code></pre>
<p><strong>Command Flags:</strong></p>
<ul>
<li><code>-w</code> - Create an isolated git worktree for changes</li>
<li><code>-y</code> - Auto-confirm workflow steps (skip prompts)</li>
<li><code>-n 5</code> - Run workflow for up to 5 iterations</li>
</ul>
<h3 id="3-review-results"><a class="header" href="#3-review-results">3. Review Results</a></h3>
<p>Prodigy creates a detailed report:</p>
<pre><code>üìä WORKFLOW SUMMARY
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Iterations: 5
Items Fixed: 12
Tests Added: 8
Complexity Reduced: 145 ‚Üí 78 (-46%)
Coverage Improved: 45% ‚Üí 72% (+27%)

‚úÖ All validations passed
</code></pre>
<h2 id="workflow-configuration"><a class="header" href="#workflow-configuration">Workflow Configuration</a></h2>
<p>Prodigy workflows are defined as YAML lists of steps. Each step can be either a <code>shell</code> command or a <code>claude</code> slash command.</p>
<h3 id="workflow-step-types"><a class="header" href="#workflow-step-types">Workflow Step Types</a></h3>
<h4 id="shell-commands"><a class="header" href="#shell-commands">Shell Commands</a></h4>
<p>Execute shell commands directly:</p>
<pre><code class="language-yaml">- shell: "cargo test"
</code></pre>
<p>With error handling:</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<h4 id="claude-commands"><a class="header" href="#claude-commands">Claude Commands</a></h4>
<p>Execute Claude Code slash commands:</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"
  capture_output: true
  commit_required: true
</code></pre>
<h3 id="step-level-validation"><a class="header" href="#step-level-validation">Step-Level Validation</a></h3>
<p>Steps can include validation that must pass:</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
  validate:
    commands:
      - shell: "cargo test"
      - shell: "cargo clippy -- -D warnings"
    result_file: ".prodigy/validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
          commit_required: true
      max_attempts: 5
      fail_workflow: true
</code></pre>
<p><strong>Validation Options:</strong></p>
<ul>
<li><code>commands</code>: List of commands to run for validation</li>
<li><code>result_file</code>: JSON file containing validation results</li>
<li><code>threshold</code>: Minimum score (0-100) required to pass</li>
<li><code>on_incomplete</code>: Actions to take if validation score &lt; threshold</li>
<li><code>max_attempts</code>: Maximum retry attempts</li>
<li><code>fail_workflow</code>: Whether to fail entire workflow if validation never passes</li>
</ul>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<p>Use <code>on_failure</code> to handle command failures:</p>
<pre><code class="language-yaml">- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<p><strong>Error Handling Options:</strong></p>
<ul>
<li><code>claude</code>: Slash command to fix the failure</li>
<li><code>max_attempts</code>: Maximum fix attempts</li>
<li><code>fail_workflow</code>: If true, workflow fails after max_attempts; if false, continues to next step</li>
</ul>
<h3 id="coverage-integration-1"><a class="header" href="#coverage-integration-1">Coverage Integration</a></h3>
<p>Generate and use coverage data in workflows:</p>
<pre><code class="language-yaml"># Generate coverage
- shell: "just coverage-lcov"

# Use coverage in analysis
- shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-before.json --format json"
</code></pre>
<h2 id="claude-slash-commands"><a class="header" href="#claude-slash-commands">Claude Slash Commands</a></h2>
<p>Prodigy workflows use Claude Code slash commands to perform analysis, planning, and implementation. The key commands used in the debtmap workflow are:</p>
<h3 id="planning-commands"><a class="header" href="#planning-commands">Planning Commands</a></h3>
<h4 id="prodigy-debtmap-plan"><a class="header" href="#prodigy-debtmap-plan"><code>/prodigy-debtmap-plan</code></a></h4>
<p>Creates an implementation plan for the top priority debt item.</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"
  capture_output: true
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--before</code>: Path to debtmap analysis JSON file</li>
<li><code>--output</code>: Path to write implementation plan</li>
</ul>
<h4 id="prodigy-validate-debtmap-plan"><a class="header" href="#prodigy-validate-debtmap-plan"><code>/prodigy-validate-debtmap-plan</code></a></h4>
<p>Validates that the implementation plan is complete and addresses the debt item.</p>
<pre><code class="language-yaml">- claude: "/prodigy-validate-debtmap-plan --before .prodigy/debtmap-before.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/plan-validation.json"
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--before</code>: Original debtmap analysis</li>
<li><code>--plan</code>: Implementation plan to validate</li>
<li><code>--output</code>: Validation results JSON (with score 0-100)</li>
</ul>
<h4 id="prodigy-revise-debtmap-plan"><a class="header" href="#prodigy-revise-debtmap-plan"><code>/prodigy-revise-debtmap-plan</code></a></h4>
<p>Revises an incomplete plan based on validation gaps.</p>
<pre><code class="language-yaml">- claude: "/prodigy-revise-debtmap-plan --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--gaps</code>: List of missing items from validation</li>
<li><code>--plan</code>: Plan file to update</li>
</ul>
<h3 id="implementation-commands"><a class="header" href="#implementation-commands">Implementation Commands</a></h3>
<h4 id="prodigy-debtmap-implement"><a class="header" href="#prodigy-debtmap-implement"><code>/prodigy-debtmap-implement</code></a></h4>
<p>Executes the implementation plan.</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--plan</code>: Path to implementation plan</li>
</ul>
<h4 id="prodigy-validate-debtmap-improvement-1"><a class="header" href="#prodigy-validate-debtmap-improvement-1"><code>/prodigy-validate-debtmap-improvement</code></a></h4>
<p>Validates that the implementation successfully addressed the debt item.</p>
<pre><code class="language-yaml">- claude: "/prodigy-validate-debtmap-improvement --comparison .prodigy/comparison.json --output .prodigy/debtmap-validation.json"
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--comparison</code>: Debtmap comparison results (before vs after)</li>
<li><code>--output</code>: Validation results JSON (with score 0-100)</li>
</ul>
<h4 id="prodigy-complete-debtmap-fix"><a class="header" href="#prodigy-complete-debtmap-fix"><code>/prodigy-complete-debtmap-fix</code></a></h4>
<p>Completes a partial fix based on validation gaps.</p>
<pre><code class="language-yaml">- claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--gaps</code>: Validation gaps to address</li>
<li><code>--plan</code>: Original implementation plan</li>
</ul>
<h3 id="testing-and-quality-commands"><a class="header" href="#testing-and-quality-commands">Testing and Quality Commands</a></h3>
<h4 id="prodigy-debug-test-failure"><a class="header" href="#prodigy-debug-test-failure"><code>/prodigy-debug-test-failure</code></a></h4>
<p>Automatically fixes failing tests.</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>--output</code>: Test failure output from shell command</li>
</ul>
<h4 id="prodigy-lint"><a class="header" href="#prodigy-lint"><code>/prodigy-lint</code></a></h4>
<p>Fixes linting and formatting issues.</p>
<pre><code class="language-yaml">- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
</code></pre>
<p><strong>Parameters:</strong></p>
<ul>
<li>Shell output with linting errors</li>
</ul>
<h2 id="target-selection"><a class="header" href="#target-selection">Target Selection</a></h2>
<p>Target selection happens through the debtmap analysis and slash commands, not through workflow configuration:</p>
<h3 id="how-targets-are-selected"><a class="header" href="#how-targets-are-selected">How Targets Are Selected</a></h3>
<ol>
<li><strong>Debtmap analyzes</strong> the codebase and scores all items by complexity, coverage, and risk</li>
<li><strong>Planning command</strong> (<code>/prodigy-debtmap-plan</code>) selects the highest priority item</li>
<li><strong>Implementation command</strong> (<code>/prodigy-debtmap-implement</code>) fixes that specific item</li>
<li><strong>Next iteration</strong> re-analyzes and selects the next highest priority item</li>
</ol>
<h3 id="factors-in-prioritization"><a class="header" href="#factors-in-prioritization">Factors in Prioritization</a></h3>
<ul>
<li><strong>Complexity score</strong>: Functions with cyclomatic complexity &gt; 10</li>
<li><strong>Coverage percentage</strong>: Lower coverage increases priority</li>
<li><strong>Risk score</strong>: Complexity √ó (100 - coverage%)</li>
<li><strong>Debt type</strong>: Complexity, TestGap, Duplication, GodObject, DeepNesting</li>
</ul>
<h3 id="customizing-target-selection"><a class="header" href="#customizing-target-selection">Customizing Target Selection</a></h3>
<p>To focus on specific debt types or modules, modify the slash commands or create custom commands in <code>.claude/commands/</code></p>
<h2 id="map-reduce-workflows"><a class="header" href="#map-reduce-workflows">Map-Reduce Workflows</a></h2>
<p>Prodigy supports map-reduce workflows for processing multiple items in parallel. This is useful for large-scale refactoring tasks.</p>
<h3 id="when-to-use-map-reduce"><a class="header" href="#when-to-use-map-reduce">When to Use Map-Reduce</a></h3>
<ul>
<li>Processing multiple independent debt items simultaneously</li>
<li>Applying the same fix pattern across many files</li>
<li>Large-scale codebase cleanup tasks</li>
</ul>
<h3 id="map-reduce-structure"><a class="header" href="#map-reduce-structure">Map-Reduce Structure</a></h3>
<p>The exact syntax for map-reduce workflows in Prodigy may differ from sequential workflows. Consult the Prodigy documentation for current map-reduce syntax and examples.</p>
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Map phase</strong>: Process items in parallel using multiple agents</li>
<li><strong>Reduce phase</strong>: Aggregate results and ensure consistency</li>
<li><strong>Isolation</strong>: Each map agent works in its own worktree</li>
<li><strong>Validation</strong>: All changes must pass validation before merging</li>
</ul>
<h2 id="iteration-strategy"><a class="header" href="#iteration-strategy">Iteration Strategy</a></h2>
<h3 id="how-iterations-work"><a class="header" href="#how-iterations-work">How Iterations Work</a></h3>
<p>When you run <code>prodigy cook workflows/debtmap.yml -wyn 5</code>, the workflow executes up to 5 times:</p>
<ol>
<li>
<p><strong>Iteration 1</strong>:</p>
<ul>
<li>Analyze codebase with debtmap</li>
<li>Select highest priority item</li>
<li>Create implementation plan</li>
<li>Execute plan and validate</li>
<li>Run tests and linting</li>
</ul>
</li>
<li>
<p><strong>Iteration 2</strong>:</p>
<ul>
<li>Re-analyze codebase (scores updated based on Iteration 1 changes)</li>
<li>Select next highest priority item</li>
<li>Repeat plan/implement/validate cycle</li>
</ul>
</li>
<li>
<p><strong>Continue</strong> until iteration limit reached or workflow completes without finding issues</p>
</li>
</ol>
<h3 id="controlling-iterations"><a class="header" href="#controlling-iterations">Controlling Iterations</a></h3>
<p>Iterations are controlled via the <code>-n</code> flag:</p>
<pre><code class="language-bash"># Single iteration (testing)
prodigy cook workflows/debtmap.yml -wyn 1

# Standard run (5 iterations)
prodigy cook workflows/debtmap.yml -wyn 5

# Deep cleanup (10+ iterations)
prodigy cook workflows/debtmap.yml -wyn 20
</code></pre>
<h3 id="what-happens-each-iteration"><a class="header" href="#what-happens-each-iteration">What Happens Each Iteration</a></h3>
<p>Each iteration runs the <strong>entire workflow from start to finish</strong>:</p>
<ol>
<li>Generate coverage data</li>
<li>Analyze technical debt</li>
<li>Create implementation plan</li>
<li>Execute plan</li>
<li>Validate improvement</li>
<li>Run tests (with auto-fixing)</li>
<li>Run linting (with auto-fixing)</li>
</ol>
<p>The workflow continues to the next iteration automatically if all steps succeed.</p>
<h3 id="example-output-1"><a class="header" href="#example-output-1">Example Output</a></h3>
<pre><code>Iteration 1:
  - Fixed: parse_expression() (9.2 ‚Üí 5.1)
  - Fixed: calculate_score() (8.8 ‚Üí 4.2)
  - Fixed: apply_weights() (8.5 ‚Üí 5.8)
  ‚úì Tests pass

Iteration 2:
  - Fixed: normalize_results() (7.5 ‚Üí 3.9)
  - Fixed: aggregate_data() (7.2 ‚Üí 4.1)
  ‚úì Tests pass

Iteration 3:
  - No items above threshold (6.0)
  ‚úì Early stop

Final Results:
  Items fixed: 5
  Average complexity: 15.2 ‚Üí 8.6
</code></pre>
<h2 id="validation-1"><a class="header" href="#validation-1">Validation</a></h2>
<p>Prodigy validates changes at the workflow step level, not as a standalone configuration.</p>
<h3 id="step-level-validation-1"><a class="header" href="#step-level-validation-1">Step-Level Validation</a></h3>
<p>Validation is attached to specific workflow steps:</p>
<pre><code class="language-yaml">- claude: "/prodigy-debtmap-implement --plan .prodigy/IMPLEMENTATION_PLAN.md"
  commit_required: true
  validate:
    commands:
      - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
      - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      - claude: "/prodigy-validate-debtmap-improvement --comparison .prodigy/comparison.json --output .prodigy/debtmap-validation.json"
    result_file: ".prodigy/debtmap-validation.json"
    threshold: 75
    on_incomplete:
      commands:
        - claude: "/prodigy-complete-debtmap-fix --gaps ${validation.gaps} --plan .prodigy/IMPLEMENTATION_PLAN.md"
          commit_required: true
        - shell: "just coverage-lcov"
        - shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-after.json --format json"
        - shell: "debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json --plan .prodigy/IMPLEMENTATION_PLAN.md --output .prodigy/comparison.json --format json"
      max_attempts: 5
      fail_workflow: true
</code></pre>
<h3 id="validation-process"><a class="header" href="#validation-process">Validation Process</a></h3>
<ol>
<li><strong>Commands run</strong>: Execute validation commands (shell or claude)</li>
<li><strong>Check result file</strong>: Read JSON file specified in <code>result_file</code></li>
<li><strong>Compare to threshold</strong>: Score must be &gt;= threshold (0-100 scale)</li>
<li><strong>On incomplete</strong>: If score &lt; threshold, run <code>on_incomplete</code> commands</li>
<li><strong>Retry</strong>: Repeat up to <code>max_attempts</code> times</li>
<li><strong>Fail or continue</strong>: If <code>fail_workflow: true</code>, stop workflow; otherwise continue</li>
</ol>
<h3 id="validation-result-format"><a class="header" href="#validation-result-format">Validation Result Format</a></h3>
<p>The <code>result_file</code> JSON should contain:</p>
<pre><code class="language-json">{
  "score": 85,
  "passed": true,
  "gaps": [],
  "details": "All debt improvement criteria met"
}
</code></pre>
<h3 id="test-validation-with-auto-fix"><a class="header" href="#test-validation-with-auto-fix">Test Validation with Auto-Fix</a></h3>
<p>Tests are validated with automatic fixing on failure:</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<p>If tests fail, Prodigy automatically attempts to fix them up to 5 times before failing the workflow.</p>
<h2 id="output-and-metrics"><a class="header" href="#output-and-metrics">Output and Metrics</a></h2>
<h3 id="workflow-report"><a class="header" href="#workflow-report">Workflow Report</a></h3>
<pre><code class="language-json">{
  "workflow": "debtmap-debt-reduction",
  "iterations": 5,
  "items_processed": 12,
  "items_fixed": 10,
  "items_failed": 2,
  "metrics": {
    "complexity_before": 145,
    "complexity_after": 78,
    "complexity_reduction": -46.2,
    "coverage_before": 45.3,
    "coverage_after": 72.1,
    "coverage_improvement": 26.8
  },
  "changes": [
    {
      "file": "src/parser.rs",
      "function": "parse_expression",
      "before_score": 9.2,
      "after_score": 5.1,
      "improvements": ["Reduced complexity", "Added tests"]
    }
  ]
}
</code></pre>
<h3 id="commit-messages"><a class="header" href="#commit-messages">Commit Messages</a></h3>
<p>Prodigy generates descriptive commit messages:</p>
<pre><code>refactor(parser): reduce complexity in parse_expression

- Extract nested conditionals to helper functions
- Add unit tests for edge cases
- Coverage: 0% ‚Üí 85%
- Complexity: 22 ‚Üí 8

Generated by Prodigy workflow: debtmap-debt-reduction
Iteration: 1/5
</code></pre>
<h2 id="integration-with-cicd"><a class="header" href="#integration-with-cicd">Integration with CI/CD</a></h2>
<h3 id="github-actions-1"><a class="header" href="#github-actions-1">GitHub Actions</a></h3>
<pre><code class="language-yaml">name: Prodigy Debt Reduction

on:
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday
  workflow_dispatch:

jobs:
  reduce-debt:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable

      - name: Install Prodigy
        run: cargo install prodigy

      - name: Install dependencies
        run: |
          cargo install debtmap
          cargo install just

      - name: Run Prodigy workflow
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: prodigy cook workflows/debtmap.yml -wyn 5

      - name: Create PR
        uses: peter-evans/create-pull-request@v5
        with:
          title: "chore: automated debt reduction via Prodigy"
          body: |
            Automated technical debt reduction using Prodigy workflow.

            This PR was generated by the weekly debt reduction workflow.
            Review changes carefully before merging.
          branch: prodigy-debt-reduction
</code></pre>
<h3 id="gitlab-ci-1"><a class="header" href="#gitlab-ci-1">GitLab CI</a></h3>
<pre><code class="language-yaml">prodigy-debt-reduction:
  stage: quality
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  script:
    - cargo install prodigy
    - cargo install debtmap
    - cargo install just
    - prodigy cook workflows/debtmap.yml -wyn 5
  artifacts:
    paths:
      - .prodigy/debtmap-*.json
      - .prodigy/comparison.json
</code></pre>
<h3 id="important-ci-considerations"><a class="header" href="#important-ci-considerations">Important CI Considerations</a></h3>
<ul>
<li><strong>API Keys</strong>: Store <code>ANTHROPIC_API_KEY</code> as a secret</li>
<li><strong>Worktrees</strong>: The <code>-w</code> flag creates isolated worktrees automatically</li>
<li><strong>Dependencies</strong>: Install <code>prodigy</code>, <code>debtmap</code>, and <code>just</code> (or your build tool)</li>
<li><strong>Timeout</strong>: CI jobs may need extended timeout for multiple iterations</li>
<li><strong>Review</strong>: Always create a PR for human review before merging automated changes</li>
</ul>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="1-start-small"><a class="header" href="#1-start-small">1. Start Small</a></h3>
<p>Begin with low iteration counts:</p>
<pre><code class="language-bash"># First run: 1 iteration to test workflow
prodigy cook workflows/debtmap.yml -wyn 1

# Standard run: 3-5 iterations
prodigy cook workflows/debtmap.yml -wyn 5
</code></pre>
<h3 id="2-focus-on-high-priority-items"><a class="header" href="#2-focus-on-high-priority-items">2. Focus on High-Priority Items</a></h3>
<p>The debtmap analysis automatically prioritizes by:</p>
<ul>
<li>Complexity score (cyclomatic complexity)</li>
<li>Coverage percentage (lower coverage = higher priority)</li>
<li>Risk score (complexity √ó (100 - coverage%))</li>
</ul>
<p>To focus on specific areas, create custom slash commands in <code>.claude/commands/</code> that filter by:</p>
<ul>
<li>Module/file patterns</li>
<li>Specific debt types (Complexity, TestGap, Duplication)</li>
<li>Score thresholds</li>
</ul>
<h3 id="3-validate-thoroughly"><a class="header" href="#3-validate-thoroughly">3. Validate Thoroughly</a></h3>
<p>Use comprehensive validation in your workflow:</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true

- shell: "just fmt-check &amp;&amp; just lint"
  on_failure:
    claude: "/prodigy-lint ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<h3 id="4-review-before-merging"><a class="header" href="#4-review-before-merging">4. Review Before Merging</a></h3>
<p>Always review Prodigy‚Äôs changes:</p>
<pre><code class="language-bash"># Find your worktree
ls ~/.prodigy/worktrees/

# Check changes
cd ~/.prodigy/worktrees/session-xxx
git diff main

# Review commit history
git log --oneline

# Run full test suite
cargo test --all-features
</code></pre>
<h3 id="5-monitor-progress"><a class="header" href="#5-monitor-progress">5. Monitor Progress</a></h3>
<p>Track debt reduction over iterations:</p>
<pre><code class="language-bash"># Compare before and after
debtmap compare --before .prodigy/debtmap-before.json --after .prodigy/debtmap-after.json

# View detailed metrics
cat .prodigy/comparison.json | jq
</code></pre>
<h2 id="troubleshooting-5"><a class="header" href="#troubleshooting-5">Troubleshooting</a></h2>
<h3 id="workflow-fails-to-start"><a class="header" href="#workflow-fails-to-start">Workflow Fails to Start</a></h3>
<p><strong>Issue</strong>: ‚ÄúProdigy not found‚Äù or ‚ÄúAPI key missing‚Äù</p>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Install Prodigy
cargo install prodigy

# Set API key
export ANTHROPIC_API_KEY="your-key"

# Verify installation
prodigy --version
</code></pre>
<h3 id="validation-failures"><a class="header" href="#validation-failures">Validation Failures</a></h3>
<p><strong>Issue</strong>: Validation score below threshold</p>
<p><strong>Solution</strong>: Check validation results:</p>
<pre><code class="language-bash"># View validation details
cat .prodigy/debtmap-validation.json

# Check what gaps remain
cat .prodigy/debtmap-validation.json | jq '.gaps'

# Review comparison results
cat .prodigy/comparison.json
</code></pre>
<p>The workflow will automatically retry up to <code>max_attempts</code> times with <code>/prodigy-complete-debtmap-fix</code>.</p>
<h3 id="test-failures"><a class="header" href="#test-failures">Test Failures</a></h3>
<p><strong>Issue</strong>: Tests fail after implementation</p>
<p><strong>Solution</strong>: The workflow includes automatic test fixing:</p>
<pre><code class="language-yaml">- shell: "just test"
  on_failure:
    claude: "/prodigy-debug-test-failure --output ${shell.output}"
    max_attempts: 5
    fail_workflow: true
</code></pre>
<p>If tests still fail after 5 attempts, review manually:</p>
<pre><code class="language-bash"># Check test output
just test

# Review recent changes
git diff HEAD~1
</code></pre>
<h3 id="no-items-processed"><a class="header" href="#no-items-processed">No Items Processed</a></h3>
<p><strong>Issue</strong>: Workflow completes but doesn‚Äôt find debt to fix</p>
<p><strong>Possible Causes</strong>:</p>
<ol>
<li>Codebase has very low debt scores (below selection threshold)</li>
<li>Coverage data not generated properly</li>
<li>Debtmap analysis found no high-priority items</li>
</ol>
<p><strong>Solution</strong>:</p>
<pre><code class="language-bash"># Check debtmap analysis results
cat .prodigy/debtmap-before.json | jq '.items | sort_by(-.unified_score.final_score) | .[0:5]'

# Verify coverage was generated
ls -lh target/coverage/lcov.info

# Run debtmap manually to see what's detected
debtmap analyze . --lcov target/coverage/lcov.info
</code></pre>
<h3 id="workflow-hangs-or-times-out"><a class="header" href="#workflow-hangs-or-times-out">Workflow Hangs or Times Out</a></h3>
<p><strong>Issue</strong>: Workflow takes too long or appears stuck</p>
<p><strong>Possible Causes</strong>:</p>
<ul>
<li>Large codebase with many files</li>
<li>Complex refactoring requiring extensive analysis</li>
<li>Network issues with Claude API</li>
</ul>
<p><strong>Solution</strong>:</p>
<ul>
<li>Reduce iteration count for testing (<code>-n 1</code>)</li>
<li>Check Claude API connectivity</li>
<li>Monitor worktree for progress: <code>cd ~/.prodigy/worktrees/session-xxx &amp;&amp; git log</code></li>
</ul>
<h2 id="example-workflows"><a class="header" href="#example-workflows">Example Workflows</a></h2>
<h3 id="full-repository-cleanup"><a class="header" href="#full-repository-cleanup">Full Repository Cleanup</a></h3>
<p>For comprehensive debt reduction, use a higher iteration count:</p>
<pre><code class="language-bash"># Run 10 iterations for deeper cleanup
prodigy cook workflows/debtmap.yml -wyn 10

# Run 20 iterations for major refactoring
prodigy cook workflows/debtmap.yml -wyn 20
</code></pre>
<p>The workflow automatically:</p>
<ol>
<li>Selects highest priority items each iteration</li>
<li>Addresses different debt types (Complexity, TestGap, Duplication)</li>
<li>Validates all changes with tests and linting</li>
<li>Commits only successful improvements</li>
</ol>
<h3 id="custom-workflow-for-specific-focus"><a class="header" href="#custom-workflow-for-specific-focus">Custom Workflow for Specific Focus</a></h3>
<p>Create a custom workflow file for focused improvements:</p>
<p><strong><code>workflows/add-tests.yml</code></strong> - Focus on test coverage:</p>
<pre><code class="language-yaml"># Generate coverage
- shell: "just coverage-lcov"

# Analyze with focus on test gaps
- shell: "debtmap analyze . --lcov target/coverage/lcov.info --output .prodigy/debtmap-before.json --format json"

# Create plan (slash command will prioritize TestGap items)
- claude: "/prodigy-debtmap-plan --before .prodigy/debtmap-before.json --output .prodigy/IMPLEMENTATION_PLAN.md"

# ... rest of standard workflow steps
</code></pre>
<p>Run with:</p>
<pre><code class="language-bash">prodigy cook workflows/add-tests.yml -wyn 5
</code></pre>
<h3 id="targeted-module-cleanup"><a class="header" href="#targeted-module-cleanup">Targeted Module Cleanup</a></h3>
<p>Create a custom slash command to focus on specific modules:</p>
<p><strong><code>.claude/commands/refactor-module.md</code></strong>:</p>
<pre><code class="language-markdown"># /refactor-module

Refactor the highest complexity item in the specified module.

Arguments: --module &lt;module_name&gt;

... implementation details ...
</code></pre>
<p>Then create a workflow using this command for targeted refactoring.</p>
<h2 id="see-also-4"><a class="header" href="#see-also-4">See Also</a></h2>
<ul>
<li><a href="./cli-reference.html">Debtmap CLI Reference</a> - Debtmap command options</li>
<li><a href="./configuration.html">Configuration</a> - Debtmap configuration</li>
<li><a href="./tiered-prioritization.html">Tiered Prioritization</a> - Understanding priority tiers</li>
<li><a href="https://github.com/iepathos/prodigy">Prodigy Documentation</a> - Full Prodigy reference</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="examples-1"><a class="header" href="#examples-1">Examples</a></h1>
<p>This chapter provides practical, real-world examples of using Debtmap across different project types and workflows. All examples use current CLI syntax verified against the source code.</p>
<blockquote>
<p><strong>Quick Start</strong>: New to Debtmap? Start with <a href="examples.html#basic-rust-analysis">Basic Rust Analysis</a> for the simplest introduction, then explore <a href="examples.html#coverage-integration-with-cargo-tarpaulin">Coverage Integration</a> for risk-based prioritization.</p>
</blockquote>
<blockquote>
<p><strong>Quick Navigation</strong>: For detailed explanations of all CLI options, see the <a href="cli-reference.html">CLI Reference</a> chapter.</p>
</blockquote>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>This chapter demonstrates:</p>
<ul>
<li><strong>Language-specific analysis</strong>: Rust, Python, JavaScript/TypeScript with their respective testing tools</li>
<li><strong>CI/CD integration</strong>: GitHub Actions, GitLab CI, CircleCI with validation gates</li>
<li><strong>Output formats</strong>: Terminal, JSON, and Markdown with interpretation guidance</li>
<li><strong>Advanced features</strong>: Context-aware analysis, multi-pass processing, cache management</li>
<li><strong>Configuration patterns</strong>: Tailored settings for different project types</li>
<li><strong>Progress tracking</strong>: Using the <code>compare</code> command to validate refactoring improvements</li>
</ul>
<p>All examples are copy-paste ready and tested against the current Debtmap implementation.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="examples.html#analyzing-rust-projects">Analyzing Rust Projects</a></li>
<li><a href="examples.html#python-analysis">Python Analysis</a></li>
<li><a href="examples.html#javascripttypescript">JavaScript/TypeScript</a></li>
<li><a href="examples.html#ci-integration">CI Integration</a></li>
<li><a href="examples.html#output-formats">Output Formats</a></li>
<li><a href="examples.html#advanced-usage">Advanced Usage</a></li>
<li><a href="examples.html#configuration-examples">Configuration Examples</a></li>
<li><a href="examples.html#compare-command">Compare Command</a></li>
</ul>
<h2 id="analyzing-rust-projects"><a class="header" href="#analyzing-rust-projects">Analyzing Rust Projects</a></h2>
<h3 id="basic-rust-analysis"><a class="header" href="#basic-rust-analysis">Basic Rust Analysis</a></h3>
<p>Start with a simple analysis of your Rust project:</p>
<pre><code class="language-bash"># Analyze all Rust files in current directory
debtmap analyze .

# Analyze specific directory
debtmap analyze ./src

# Analyze with custom complexity threshold
debtmap analyze ./src --threshold-complexity 15
</code></pre>
<h3 id="coverage-integration-with-cargo-tarpaulin"><a class="header" href="#coverage-integration-with-cargo-tarpaulin">Coverage Integration with cargo-tarpaulin</a></h3>
<p>Combine complexity analysis with test coverage for risk-based prioritization:</p>
<pre><code class="language-bash"># Generate LCOV coverage data
cargo tarpaulin --out lcov --output-dir target/coverage

# Analyze with coverage data
debtmap analyze . --lcov target/coverage/lcov.info

# Or use the shorter alias
debtmap analyze . --coverage-file target/coverage/lcov.info
</code></pre>
<p><strong>What this does:</strong></p>
<ul>
<li>Functions with 0% coverage and high complexity get marked as <code>[CRITICAL]</code></li>
<li>Well-tested functions (&gt;80% coverage) are deprioritized</li>
<li>Shows risk reduction potential for each untested function</li>
</ul>
<h3 id="custom-thresholds"><a class="header" href="#custom-thresholds">Custom Thresholds</a></h3>
<p>Configure thresholds to match your project standards:</p>
<pre><code class="language-bash"># Set both complexity and duplication thresholds
debtmap analyze . \
  --threshold-complexity 15 \
  --threshold-duplication 50

# Use preset configurations for quick setup
debtmap analyze . --threshold-preset strict    # Strict standards
debtmap analyze . --threshold-preset balanced  # Default balanced
debtmap analyze . --threshold-preset lenient   # Lenient for legacy code
</code></pre>
<h3 id="god-object-detection-1"><a class="header" href="#god-object-detection-1">God Object Detection</a></h3>
<p>Identify classes and modules with too many responsibilities:</p>
<pre><code class="language-bash"># Standard analysis includes god object detection
debtmap analyze .

# Disable god object detection for specific run
debtmap analyze . --no-god-object
</code></pre>
<p>God objects are flagged with detailed metrics:</p>
<ul>
<li>Number of methods and fields</li>
<li>Responsibility count (grouped by naming patterns)</li>
<li>God object score (0-100%)</li>
<li>Recommendations for splitting</li>
</ul>
<h3 id="filtering-and-focusing"><a class="header" href="#filtering-and-focusing">Filtering and Focusing</a></h3>
<pre><code class="language-bash"># Analyze only Rust files
debtmap analyze . --languages rust

# Focus on architecture issues (god objects, complexity)
debtmap analyze . --filter Architecture

# Focus on testing gaps
debtmap analyze . --filter Testing

# Filter by multiple categories
debtmap analyze . --filter Architecture,Testing

# Show only top 10 issues
debtmap analyze . --top 10

# Show only high-priority items
debtmap analyze . --min-priority high
</code></pre>
<p><strong>Valid filter categories:</strong></p>
<ul>
<li><code>Architecture</code> - God objects, high complexity, structural issues</li>
<li><code>Testing</code> - Test coverage gaps, untested critical code</li>
<li><code>Duplication</code> - Code duplication and similar patterns</li>
<li><code>Maintainability</code> - Long functions, deep nesting, readability issues</li>
</ul>
<h3 id="output-formats-2"><a class="header" href="#output-formats-2">Output Formats</a></h3>
<pre><code class="language-bash"># JSON output for CI integration
debtmap analyze . --format json --output report.json

# Markdown report
debtmap analyze . --format markdown --output DEBT_REPORT.md

# Terminal output (default) - prettified
debtmap analyze .
</code></pre>
<h3 id="multi-pass-analysis"><a class="header" href="#multi-pass-analysis">Multi-Pass Analysis</a></h3>
<p>For deeper analysis with context awareness:</p>
<pre><code class="language-bash"># Enable context-aware analysis with multiple providers
debtmap analyze . \
  --context \
  --context-providers critical_path,dependency,git_history

# Multi-pass analysis with attribution
debtmap analyze . --multi-pass --attribution
</code></pre>
<h3 id="complete-ci-example"><a class="header" href="#complete-ci-example">Complete CI Example</a></h3>
<p>This is from Debtmap‚Äôs own <code>.github/workflows/debtmap.yml</code>:</p>
<pre><code class="language-bash"># 1. Install cargo-tarpaulin
cargo install cargo-tarpaulin

# 2. Build debtmap
cargo build --release

# 3. Generate coverage
cargo tarpaulin --config .tarpaulin.toml --out Lcov --timeout 300

# 4. Run validation with coverage
./target/release/debtmap validate . \
  --coverage-file target/coverage/lcov.info \
  --format json \
  --output debtmap-report.json
</code></pre>
<h2 id="python-analysis"><a class="header" href="#python-analysis">Python Analysis</a></h2>
<h3 id="basic-python-analysis"><a class="header" href="#basic-python-analysis">Basic Python Analysis</a></h3>
<pre><code class="language-bash"># Analyze Python files only
debtmap analyze . --languages python

# Analyze specific Python directory
debtmap analyze src --languages python
</code></pre>
<h3 id="coverage-integration-with-pytest"><a class="header" href="#coverage-integration-with-pytest">Coverage Integration with pytest</a></h3>
<p>Generate coverage and analyze risk:</p>
<pre><code class="language-bash"># Generate LCOV coverage with pytest
pytest --cov --cov-report=lcov

# Analyze with coverage data
debtmap analyze . \
  --languages python \
  --lcov coverage.lcov
</code></pre>
<h3 id="python-specific-patterns"><a class="header" href="#python-specific-patterns">Python-Specific Patterns</a></h3>
<pre><code class="language-bash"># Focus on testing gaps in Python code
debtmap analyze . \
  --languages python \
  --filter Testing

# Find god objects in Python modules
debtmap analyze . \
  --languages python \
  --filter Architecture
</code></pre>
<h3 id="example-configuration-for-python-projects"><a class="header" href="#example-configuration-for-python-projects">Example Configuration for Python Projects</a></h3>
<p>Create <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[languages]
enabled = ["python"]

[thresholds]
complexity = 12
max_function_lines = 40

[ignore]
patterns = [
  "**/*_test.py",
  "tests/**",
  ".venv/**",
  "**/__pycache__/**",
]

[god_object]
enabled = true
max_methods = 15
max_responsibilities = 4
</code></pre>
<h2 id="javascripttypescript"><a class="header" href="#javascripttypescript">JavaScript/TypeScript</a></h2>
<h3 id="analyzing-jsts-projects"><a class="header" href="#analyzing-jsts-projects">Analyzing JS/TS Projects</a></h3>
<pre><code class="language-bash"># Analyze JavaScript and TypeScript
debtmap analyze . --languages javascript,typescript

# TypeScript only
debtmap analyze . --languages typescript
</code></pre>
<h3 id="coverage-integration-with-jest"><a class="header" href="#coverage-integration-with-jest">Coverage Integration with Jest</a></h3>
<pre><code class="language-bash"># Generate LCOV with Jest
jest --coverage --coverageReporters=lcov

# Analyze with coverage
debtmap analyze . \
  --languages javascript,typescript \
  --lcov coverage/lcov.info
</code></pre>
<h3 id="nodejs-project-patterns"><a class="header" href="#nodejs-project-patterns">Node.js Project Patterns</a></h3>
<pre><code class="language-bash"># Exclude node_modules and focus on source
debtmap analyze src --languages javascript,typescript

# With custom complexity thresholds for JS
debtmap analyze . \
  --languages javascript,typescript \
  --threshold-complexity 10
</code></pre>
<h3 id="typescript-configuration-example"><a class="header" href="#typescript-configuration-example">TypeScript Configuration Example</a></h3>
<p>Create <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[languages]
enabled = ["typescript", "javascript"]

[thresholds]
complexity = 10
max_function_lines = 50

[ignore]
patterns = [
  "node_modules/**",
  "**/*.test.ts",
  "**/*.spec.ts",
  "dist/**",
  "build/**",
  "**/*.d.ts",
]
</code></pre>
<h3 id="monorepo-analysis"><a class="header" href="#monorepo-analysis">Monorepo Analysis</a></h3>
<pre><code class="language-bash"># Analyze specific package
debtmap analyze packages/api --languages typescript

# Analyze all packages, grouped by category
debtmap analyze packages \
  --languages typescript \
  --group-by-category
</code></pre>
<h2 id="ci-integration"><a class="header" href="#ci-integration">CI Integration</a></h2>
<h3 id="github-actions-2"><a class="header" href="#github-actions-2">GitHub Actions</a></h3>
<p>Complete workflow example (from <code>.github/workflows/debtmap.yml</code>):</p>
<pre><code class="language-yaml">name: Debtmap

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  validate:
    name: Technical Debt Validation
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        fetch-depth: 0

    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        components: rustfmt, clippy

    - name: Cache cargo dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ runner.os }}-cargo-

    - name: Install cargo-tarpaulin
      run: |
        if ! command -v cargo-tarpaulin &amp;&gt; /dev/null; then
          cargo install cargo-tarpaulin
        else
          echo "cargo-tarpaulin already installed"
        fi

    - name: Build debtmap
      run: cargo build --release

    - name: Generate coverage data
      run: cargo tarpaulin --config .tarpaulin.toml --out Lcov --timeout 300

    - name: Run debtmap validation with coverage
      run: |
        if [ -f "target/coverage/lcov.info" ]; then
          ./target/release/debtmap validate . --coverage-file target/coverage/lcov.info --format json --output debtmap-report.json
        else
          echo "Warning: LCOV file not found, running validation without coverage data"
          ./target/release/debtmap validate . --format json --output debtmap-report.json
        fi

    - name: Upload debtmap report and coverage
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: debtmap-analysis-artifacts
        path: |
          debtmap-report.json
          target/coverage/lcov.info
        retention-days: 7
</code></pre>
<h3 id="gitlab-ci-2"><a class="header" href="#gitlab-ci-2">GitLab CI</a></h3>
<pre><code class="language-yaml">debtmap:
  stage: quality
  image: rust:latest
  script:
    # Install debtmap
    - cargo install debtmap

    # Run tests with coverage
    - cargo install cargo-tarpaulin
    - cargo tarpaulin --out Lcov

    # Validate with debtmap
    - debtmap validate .
        --coverage-file cobertura.xml
        --format json
        --output debtmap-report.json
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: cobertura.xml
    paths:
      - debtmap-report.json
    expire_in: 1 week
</code></pre>
<h3 id="circleci"><a class="header" href="#circleci">CircleCI</a></h3>
<pre><code class="language-yaml">version: 2.1

jobs:
  debtmap:
    docker:
      - image: cimg/rust:1.75
    steps:
      - checkout

      - run:
          name: Install debtmap
          command: cargo install debtmap

      - run:
          name: Generate coverage
          command: |
            cargo install cargo-tarpaulin
            cargo tarpaulin --out Lcov

      - run:
          name: Run debtmap
          command: |
            debtmap validate . \
              --coverage-file lcov.info \
              --format json \
              --output debtmap.json

      - store_artifacts:
          path: debtmap.json

workflows:
  version: 2
  build:
    jobs:
      - debtmap
</code></pre>
<h3 id="using-debtmap-validate-for-pr-gates"><a class="header" href="#using-debtmap-validate-for-pr-gates">Using debtmap validate for PR Gates</a></h3>
<pre><code class="language-bash"># Fail build if thresholds are exceeded
debtmap validate . --coverage-file lcov.info

# With custom thresholds
debtmap validate . \
  --coverage-file lcov.info \
  --threshold-complexity 15

# Exit code 0 if passing, 1 if failing
</code></pre>
<h3 id="compare-command-in-ci"><a class="header" href="#compare-command-in-ci">Compare Command in CI</a></h3>
<p>Track technical debt trends over time:</p>
<pre><code class="language-bash"># Generate baseline (on main branch)
debtmap analyze . --format json --output baseline.json

# After PR changes
debtmap analyze . --format json --output current.json

# Compare and fail if regressions detected
debtmap compare \
  --before baseline.json \
  --after current.json \
  --format json
</code></pre>
<h2 id="output-formats-3"><a class="header" href="#output-formats-3">Output Formats</a></h2>
<h3 id="terminal-output-default"><a class="header" href="#terminal-output-default">Terminal Output (Default)</a></h3>
<p>The default terminal output is prettified with colors and priorities:</p>
<pre><code class="language-bash">debtmap analyze . --lcov coverage.lcov --top 3
</code></pre>
<p>Example output:</p>
<pre><code>‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    PRIORITY TECHNICAL DEBT FIXES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üéØ TOP 3 RECOMMENDATIONS (by unified priority)

#1 SCORE: 8.9 [CRITICAL]
‚îú‚îÄ TEST GAP: ./src/analyzers/rust.rs:38 parse_function()
‚îú‚îÄ ACTION: Add 6 unit tests for full coverage
‚îú‚îÄ IMPACT: Full test coverage, -3.7 risk
‚îú‚îÄ COMPLEXITY: cyclomatic=6, cognitive=8, nesting=2, lines=32
‚îú‚îÄ DEPENDENCIES: 0 upstream, 11 downstream
‚îî‚îÄ WHY: Business logic with 0% coverage, manageable complexity

üìä TOTAL DEBT SCORE: 4907
üìà OVERALL COVERAGE: 67.12%
</code></pre>
<h3 id="json-output-2"><a class="header" href="#json-output-2">JSON Output</a></h3>
<p>Machine-readable format for CI/CD integration:</p>
<pre><code class="language-bash">debtmap analyze . --format json --output report.json
</code></pre>
<p><strong>Using JSON output programmatically:</strong></p>
<pre><code class="language-bash"># Extract total debt score
debtmap analyze . --format json | jq '.total_debt_score'

# Count critical items
debtmap analyze . --format json | jq '[.items[] | select(.unified_score.final_score &gt;= 8)] | length'

# Get top 5 functions by score
debtmap analyze . --format json | jq '.items | sort_by(-.unified_score.final_score) | .[0:5] | .[].location'

# Extract all test gap items
debtmap analyze . --format json | jq '[.items[] | select(.debt_type == "TestGap")]'
</code></pre>
<p>Structure:</p>
<pre><code class="language-json">{
  "items": [
    {
      "location": {
        "file": "src/main.rs",
        "function": "process_data",
        "line": 42
      },
      "debt_type": "TestGap",
      "unified_score": {
        "complexity_factor": 3.2,
        "coverage_factor": 10.0,
        "dependency_factor": 2.5,
        "role_multiplier": 1.2,
        "final_score": 9.4
      },
      "function_role": "BusinessLogic",
      "recommendation": {
        "action": "Add unit tests",
        "details": "Add 6 unit tests for full coverage",
        "effort_estimate": "2-3 hours"
      },
      "expected_impact": {
        "risk_reduction": 3.9,
        "complexity_reduction": 0,
        "coverage_improvement": 100
      }
    }
  ],
  "overall_coverage": 67.12,
  "total_debt_score": 4907
}
</code></pre>
<h3 id="markdown-report"><a class="header" href="#markdown-report">Markdown Report</a></h3>
<pre><code class="language-bash">debtmap analyze . --format markdown --output DEBT_REPORT.md
</code></pre>
<p>Great for documentation or PR comments.</p>
<h3 id="understanding-output-formats-1"><a class="header" href="#understanding-output-formats-1">Understanding Output Formats</a></h3>
<pre><code class="language-bash"># JSON output (default is legacy format)
debtmap analyze . --format json

# Unified JSON format (alternative to legacy)
debtmap analyze . --format json --output-format unified

# Legacy JSON format (default, for backward compatibility)
debtmap analyze . --format json --output-format legacy

# Output format options: terminal, json, markdown
debtmap analyze . --format terminal
</code></pre>
<h2 id="advanced-usage"><a class="header" href="#advanced-usage">Advanced Usage</a></h2>
<h3 id="context-aware-analysis-3"><a class="header" href="#context-aware-analysis-3">Context-Aware Analysis</a></h3>
<p>Enable advanced context providers for more accurate prioritization:</p>
<pre><code class="language-bash"># Enable all context providers
debtmap analyze . \
  --context \
  --context-providers critical_path,dependency,git_history

# Disable specific providers
debtmap analyze . \
  --context \
  --disable-context git_history
</code></pre>
<h3 id="multi-pass-analysis-1"><a class="header" href="#multi-pass-analysis-1">Multi-Pass Analysis</a></h3>
<pre><code class="language-bash"># Multi-pass with attribution tracking
debtmap analyze . --multi-pass --attribution

# Shows which functions contribute to which patterns
</code></pre>
<h3 id="cache-management-1"><a class="header" href="#cache-management-1">Cache Management</a></h3>
<pre><code class="language-bash"># Show cache statistics
debtmap cache stats

# Clear cache for current project
debtmap cache clear

# Prune old cache entries
debtmap cache prune --max-age-days 7
</code></pre>
<h3 id="aggregation-methods-1"><a class="header" href="#aggregation-methods-1">Aggregation Methods</a></h3>
<pre><code class="language-bash"># Use logarithmic sum for aggregation
debtmap analyze . --aggregation-method logarithmic_sum

# Standard sum (default)
debtmap analyze . --aggregation-method sum
</code></pre>
<h3 id="filtering-and-grouping"><a class="header" href="#filtering-and-grouping">Filtering and Grouping</a></h3>
<pre><code class="language-bash"># Group results by debt category
debtmap analyze . --group-by-category

# Filter specific categories
debtmap analyze . --filter Architecture,Testing

# Show only high-priority items
debtmap analyze . --min-priority high --top 10
</code></pre>
<h3 id="verbosity-levels-1"><a class="header" href="#verbosity-levels-1">Verbosity Levels</a></h3>
<pre><code class="language-bash"># Level 1: Show main score factors
debtmap analyze . -v

# Level 2: Show detailed calculations
debtmap analyze . -vv

# Level 3: Show all debug information
debtmap analyze . -vvv

# Long form also available
debtmap analyze . --verbose

# Show macro expansion details (Rust)
debtmap analyze . --verbose-macro-warnings --show-macro-stats
</code></pre>
<h3 id="parallel-processing-control"><a class="header" href="#parallel-processing-control">Parallel Processing Control</a></h3>
<pre><code class="language-bash"># Use 8 parallel jobs
debtmap analyze . --jobs 8

# Disable parallel processing
debtmap analyze . --no-parallel
</code></pre>
<h2 id="configuration-examples"><a class="header" href="#configuration-examples">Configuration Examples</a></h2>
<h3 id="basic-configuration"><a class="header" href="#basic-configuration">Basic Configuration</a></h3>
<p>Create <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[thresholds]
complexity = 15
duplication = 25
max_function_lines = 50
max_nesting_depth = 4

[languages]
enabled = ["rust", "python"]

[ignore]
patterns = [
  "tests/**/*",
  "**/*.test.rs",
  "target/**",
]
</code></pre>
<h3 id="entropy-based-complexity-1"><a class="header" href="#entropy-based-complexity-1">Entropy-Based Complexity</a></h3>
<pre><code class="language-toml">[entropy]
enabled = true
weight = 0.5
use_classification = true
pattern_threshold = 0.7
entropy_threshold = 0.4
branch_threshold = 0.8
max_combined_reduction = 0.3
</code></pre>
<p>This reduces false positives for repetitive code patterns.</p>
<h3 id="custom-scoring-weights"><a class="header" href="#custom-scoring-weights">Custom Scoring Weights</a></h3>
<pre><code class="language-toml">[scoring]
coverage = 0.40      # Test coverage gaps
complexity = 0.40    # Code complexity
dependency = 0.20    # Dependency criticality
</code></pre>
<h3 id="god-object-detection-tuning"><a class="header" href="#god-object-detection-tuning">God Object Detection Tuning</a></h3>
<pre><code class="language-toml">[god_object]
enabled = true
max_methods = 20
max_fields = 15
max_responsibilities = 5
</code></pre>
<h3 id="external-api-configuration-1"><a class="header" href="#external-api-configuration-1">External API Configuration</a></h3>
<p>For libraries (not CLI tools):</p>
<pre><code class="language-toml">[external_api]
detect_external_api = true

api_functions = [
  "parse",
  "Parser::new",
  "client::connect",
]

api_files = [
  "src/lib.rs",
  "src/api.rs",
  "src/public/*.rs",
]
</code></pre>
<h3 id="complete-multi-language-configuration"><a class="header" href="#complete-multi-language-configuration">Complete Multi-Language Configuration</a></h3>
<pre><code class="language-toml">[thresholds]
complexity = 12
duplication = 30
max_file_lines = 400
max_function_lines = 40
minimum_debt_score = 1.0
minimum_cyclomatic_complexity = 2

[entropy]
enabled = true
weight = 0.5

[scoring]
coverage = 0.40
complexity = 0.40
dependency = 0.20

[languages]
enabled = ["rust", "python", "javascript", "typescript"]

[ignore]
patterns = [
  # Tests
  "tests/**/*",
  "**/*.test.*",
  "**/*_test.*",

  # Build artifacts
  "target/**",
  "dist/**",
  "build/**",
  "node_modules/**",

  # Python
  ".venv/**",
  "**/__pycache__/**",

  # Generated code
  "*.generated.*",
  "*.pb.*",
]

[god_object]
enabled = true
max_methods = 18
max_fields = 12
</code></pre>
<h2 id="compare-command"><a class="header" href="#compare-command">Compare Command</a></h2>
<p>The <code>compare</code> command helps validate that refactoring achieved its goals.</p>
<h3 id="basic-comparison-workflow"><a class="header" href="#basic-comparison-workflow">Basic Comparison Workflow</a></h3>
<pre><code class="language-bash"># 1. Generate baseline before refactoring
debtmap analyze . --format json --output before.json

# 2. Make your code improvements
#    ... refactor, add tests, etc ...

# 3. Generate new analysis
debtmap analyze . --format json --output after.json

# 4. Compare and verify improvements
debtmap compare --before before.json --after after.json
</code></pre>
<h3 id="target-specific-comparison"><a class="header" href="#target-specific-comparison">Target-Specific Comparison</a></h3>
<p>Focus on whether a specific function improved:</p>
<pre><code class="language-bash"># Target format: file:function:line
debtmap compare \
  --before before.json \
  --after after.json \
  --target-location src/main.rs:process_data:100
</code></pre>
<h3 id="using-with-implementation-plans"><a class="header" href="#using-with-implementation-plans">Using with Implementation Plans</a></h3>
<p>Extract target automatically from plan files:</p>
<pre><code class="language-bash"># If IMPLEMENTATION_PLAN.md contains:
# **Target**: src/parser.rs:parse_expression:45

debtmap compare \
  --before before.json \
  --after after.json \
  --plan IMPLEMENTATION_PLAN.md
</code></pre>
<h3 id="output-formats-4"><a class="header" href="#output-formats-4">Output Formats</a></h3>
<pre><code class="language-bash"># JSON output (default)
debtmap compare --before before.json --after after.json

# Terminal output (explicit)
debtmap compare \
  --before before.json \
  --after after.json \
  --format terminal

# JSON for CI integration (explicit output file)
debtmap compare \
  --before before.json \
  --after after.json \
  --format json \
  --output comparison.json

# Markdown report
debtmap compare \
  --before before.json \
  --after after.json \
  --format markdown \
  --output COMPARISON.md
</code></pre>
<h3 id="interpreting-results-1"><a class="header" href="#interpreting-results-1">Interpreting Results</a></h3>
<p><strong>Target Status:</strong></p>
<ul>
<li><strong>Resolved</strong>: Function no longer appears (complexity reduced below threshold)</li>
<li><strong>Improved</strong>: Metrics improved (complexity down, coverage up)</li>
<li><strong>Unchanged</strong>: No significant change</li>
<li><strong>Regressed</strong>: Metrics got worse</li>
<li><strong>Not Found</strong>: Target not found in baseline</li>
</ul>
<p><strong>Overall Trend:</strong></p>
<ul>
<li><strong>Improving</strong>: More items resolved/improved than regressed</li>
<li><strong>Stable</strong>: No significant changes</li>
<li><strong>Regressing</strong>: New critical debt introduced</li>
</ul>
<p><strong>Example Output:</strong></p>
<pre><code>Target Status: Resolved ‚úÖ
- src/parser.rs:parse_expression:45 reduced from complexity 22 to 8
- Coverage improved from 0% to 85%

Overall Trend: Improving
- 3 items resolved
- 2 items improved
- 0 regressions
- Total debt score: 450 ‚Üí 285 (-37%)
</code></pre>
<h3 id="ci-integration-1"><a class="header" href="#ci-integration-1">CI Integration</a></h3>
<p>Use in pull request validation:</p>
<pre><code class="language-bash"># In CI script
debtmap compare \
  --before baseline.json \
  --after current.json \
  --format json | jq -e '.overall_trend == "Improving"'

# Exit code 0 if improving, 1 otherwise
</code></pre>
<h2 id="tips-and-best-practices"><a class="header" href="#tips-and-best-practices">Tips and Best Practices</a></h2>
<ol>
<li><strong>Start Simple</strong>: Begin with basic analysis, add coverage later</li>
<li><strong>Use Filters</strong>: Focus on one category at a time (Architecture, Testing)</li>
<li><strong>Iterate</strong>: Run analysis, fix top items, repeat</li>
<li><strong>CI Integration</strong>: Automate validation in your build pipeline</li>
<li><strong>Track Progress</strong>: Use <code>compare</code> command to validate improvements</li>
<li><strong>Configure Thresholds</strong>: Adjust to match your team‚Äôs standards</li>
<li><strong>Leverage Coverage</strong>: Always include coverage data for accurate risk assessment</li>
</ol>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<ul>
<li><a href="cli-reference.html">CLI Reference</a> - Complete CLI documentation</li>
<li><a href="analysis-guide.html">Analysis Guide</a> - Understanding analysis results</li>
<li><a href="configuration.html">Configuration</a> - Advanced configuration options</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="troubleshooting-6"><a class="header" href="#troubleshooting-6">Troubleshooting</a></h1>
<p>Common issues and solutions for using debtmap effectively.</p>
<h2 id="quick-fixes-for-common-issues"><a class="header" href="#quick-fixes-for-common-issues">Quick Fixes for Common Issues</a></h2>
<p>If you‚Äôre experiencing problems, try these first:</p>
<ol>
<li><strong>Analysis is slow</strong>: Check <code>--cache-stats</code>, ensure caching is enabled, adjust threads with <code>-j</code></li>
<li><strong>Parse errors</strong>: Use <code>--semantic-off</code> for faster fallback mode or exclude problematic files</li>
<li><strong>No output</strong>: Increase verbosity with <code>-v</code> or lower <code>--min-priority</code></li>
<li><strong>Cache corruption</strong>: Run with <code>--clear-cache</code> to rebuild</li>
<li><strong>Inconsistent results</strong>: Check if coverage file changed or context providers are enabled</li>
</ol>
<h2 id="common-issues-1"><a class="header" href="#common-issues-1">Common Issues</a></h2>
<h3 id="parse-errors"><a class="header" href="#parse-errors">Parse Errors</a></h3>
<p><strong>Problem</strong>: Encountering ‚ÄúParse error in file:line:column‚Äù messages</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Unsupported language syntax or version</li>
<li>Complex macro expansions (Rust)</li>
<li>Type inference edge cases (Python, TypeScript)</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Try fallback mode without semantic analysis
debtmap --semantic-off

# For Rust macro issues, see detailed warnings
debtmap --verbose-macro-warnings --show-macro-stats

# Exclude specific problematic files
# Add to .debtmap/config.toml:
# exclude = ["path/to/problematic/file.rs"]
</code></pre>
<h3 id="out-of-memory-errors"><a class="header" href="#out-of-memory-errors">Out of Memory Errors</a></h3>
<p><strong>Problem</strong>: Analysis crashes or runs out of memory on large codebases</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Limit parallel processing
debtmap --jobs 2

# Disable parallel processing entirely
debtmap --no-parallel

# Test with limited files first
debtmap --max-files 100

# Analyze subdirectories separately
debtmap path/to/subset
</code></pre>
<h3 id="performance-issues-1"><a class="header" href="#performance-issues-1">Performance Issues</a></h3>
<p><strong>Problem</strong>: Analysis takes too long to complete</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Check cache statistics
debtmap --cache-stats

# Ensure caching is enabled (it is by default)
# If cache was disabled, remove --no-cache flag

# Use all available CPU cores
debtmap --jobs 0

# Try faster fallback mode (less accurate)
debtmap --semantic-off

# Use plain output for faster terminal rendering
debtmap --plain
</code></pre>
<p>See <a href="troubleshooting.html#performance-tips">Performance Tips</a> for detailed optimization strategies.</p>
<h3 id="cache-corruption"><a class="header" href="#cache-corruption">Cache Corruption</a></h3>
<p><strong>Problem</strong>: Getting ‚ÄúCache error‚Äù messages or stale results</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Clear cache and rebuild
debtmap --clear-cache

# Force cache rebuild
debtmap --force-cache-rebuild

# Check cache status
debtmap --cache-stats

# Use different cache location
debtmap --cache-location /path/to/cache
</code></pre>
<p>See <a href="troubleshooting.html#cache-troubleshooting">Cache Troubleshooting</a> for more details.</p>
<h3 id="file-permission-errors"><a class="header" href="#file-permission-errors">File Permission Errors</a></h3>
<p><strong>Problem</strong>: ‚ÄúFile system error‚Äù when accessing files</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Ensure you have read permissions for all source files</li>
<li>Check that the project directory is accessible</li>
<li>Verify cache directory is writable (default: <code>.debtmap/cache</code>)</li>
<li>Use <code>--cache-location</code> to specify an accessible cache directory</li>
</ul>
<h3 id="git-history-errors"><a class="header" href="#git-history-errors">Git History Errors</a></h3>
<p><strong>Problem</strong>: Errors when using <code>git_history</code> context provider</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Not running in a git repository</li>
<li>Git history not available for files</li>
<li>Insufficient git permissions</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable git_history context provider
debtmap --context --disable-context git_history

# Disable all context providers
debtmap --no-context-aware

# Check if in git repository
git status
</code></pre>
<h3 id="coverage-file-issues"><a class="header" href="#coverage-file-issues">Coverage File Issues</a></h3>
<p><strong>Problem</strong>: Coverage file not being processed or causing errors</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Non-LCOV format coverage file</li>
<li>Malformed coverage data</li>
<li>Path mismatches between coverage and source files</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Verify coverage file format (must be LCOV)
head coverage.info

# Check coverage file path
debtmap --coverage-file path/to/coverage.info -v

# Ensure paths in coverage file match source paths
# Coverage paths are relative to project root
</code></pre>
<h3 id="threshold-and-preset-confusion"><a class="header" href="#threshold-and-preset-confusion">Threshold and Preset Confusion</a></h3>
<p><strong>Problem</strong>: Unexpected filtering or priority levels</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Check what threshold preset does
debtmap --threshold-preset strict --help

# Override specific thresholds
debtmap --min-priority 3

# See all items regardless of thresholds
debtmap --min-priority 0

# Use category filters instead
debtmap --filter "complexity,debt"
</code></pre>
<h3 id="json-format-issues"><a class="header" href="#json-format-issues">JSON Format Issues</a></h3>
<p><strong>Problem</strong>: JSON output parsing errors or unexpected structure</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use unified JSON format (consistent structure)
debtmap --format json --output-format unified

# Legacy format (default, uses {File: {...}} structure)
debtmap --format json --output-format legacy

# Validate JSON output
debtmap --format json | jq .

# Write to file for easier inspection
debtmap --format json --output results.json
</code></pre>
<h3 id="context-provider-errors"><a class="header" href="#context-provider-errors">Context Provider Errors</a></h3>
<p><strong>Problem</strong>: Errors with critical_path, dependency, or git_history providers</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Enable specific providers only
debtmap --context --context-providers critical_path,dependency

# Disable problematic provider
debtmap --context --disable-context git_history

# Disable context-aware filtering
debtmap --no-context-aware

# Check context provider details
debtmap --context -vvv
</code></pre>
<p>See <a href="troubleshooting.html#context-provider-troubleshooting">Context Provider Troubleshooting</a> for details.</p>
<h2 id="debug-mode"><a class="header" href="#debug-mode">Debug Mode</a></h2>
<p>Use verbosity flags to diagnose issues and understand analysis behavior.</p>
<h3 id="verbosity-levels-2"><a class="header" href="#verbosity-levels-2">Verbosity Levels</a></h3>
<pre><code class="language-bash"># Level 1: Show main score factors
debtmap -v

# Level 2: Show detailed calculations
debtmap -vv

# Level 3: Show all debug information
debtmap -vvv
</code></pre>
<p><strong>What each level shows</strong>:</p>
<ul>
<li><code>-v</code>: Score breakdowns, main contributing factors</li>
<li><code>-vv</code>: Detailed metric calculations, file processing</li>
<li><code>-vvv</code>: Full debug output, context provider details, cache operations</li>
</ul>
<h3 id="diagnostic-options"><a class="header" href="#diagnostic-options">Diagnostic Options</a></h3>
<pre><code class="language-bash"># Show macro parsing warnings (Rust)
debtmap --verbose-macro-warnings

# Show macro expansion statistics (Rust)
debtmap --show-macro-stats

# Disable semantic analysis (fallback mode)
debtmap --semantic-off

# Validate LOC consistency
debtmap --validate-loc

# Show cache statistics
debtmap --cache-stats
</code></pre>
<h3 id="debugging-score-calculations"><a class="header" href="#debugging-score-calculations">Debugging Score Calculations</a></h3>
<pre><code class="language-bash"># Use verbosity levels to see score breakdown
debtmap -v    # Shows score factors

# See how coverage affects scores
debtmap --coverage-file coverage.info -v

# See how context affects scores
debtmap --context --context-providers critical_path -v
</code></pre>
<h3 id="example-debug-session"><a class="header" href="#example-debug-session">Example Debug Session</a></h3>
<pre><code class="language-bash"># Step 1: Run with verbosity to see what's happening
debtmap -vv

# Step 2: Check cache stats
debtmap --cache-stats

# Step 3: Try without semantic analysis
debtmap --semantic-off -v

# Step 4: Check specific file
debtmap path/to/file.rs -vvv

# Step 5: Validate results
debtmap --validate-loc
</code></pre>
<h2 id="performance-tips"><a class="header" href="#performance-tips">Performance Tips</a></h2>
<p>Optimize debtmap analysis speed and resource usage.</p>
<h3 id="parallel-processing"><a class="header" href="#parallel-processing">Parallel Processing</a></h3>
<pre><code class="language-bash"># Use all CPU cores (default)
debtmap --jobs 0

# Limit to 4 threads
debtmap --jobs 4

# Disable parallel processing (debugging)
# Note: --no-parallel is equivalent to --jobs 1 (single-threaded)
debtmap --no-parallel
</code></pre>
<p><strong>When to adjust parallelism</strong>:</p>
<ul>
<li><strong>Use <code>--jobs 0</code></strong> (default): Maximum performance on dedicated machine</li>
<li><strong>Use <code>--jobs N</code></strong>: Limit resource usage while other tasks run</li>
<li><strong>Use <code>--no-parallel</code></strong>: Debugging concurrency issues</li>
</ul>
<h3 id="caching-strategies"><a class="header" href="#caching-strategies">Caching Strategies</a></h3>
<p>Caching is <strong>enabled by default</strong> and provides the biggest performance improvement.</p>
<p><strong>Note</strong>: The <code>--cache</code> flag (to enable caching) is deprecated and hidden. Caching is now always enabled by default; use <code>--no-cache</code> to disable it.</p>
<pre><code class="language-bash"># Check cache effectiveness
debtmap --cache-stats

# Clear cache if corrupted
debtmap --clear-cache

# Force cache rebuild
debtmap --force-cache-rebuild

# Disable cache (not recommended)
debtmap --no-cache
</code></pre>
<p><strong>Cache locations</strong>:</p>
<pre><code class="language-bash"># Local cache (default): .debtmap/cache
debtmap

# Shared cache for multiple projects
debtmap --cache-location ~/.cache/debtmap

# Migrate existing cache to shared location
debtmap --migrate-cache

# Set via environment variable
export DEBTMAP_CACHE_DIR=~/.cache/debtmap
debtmap
</code></pre>
<p><strong>Cache best practices</strong>:</p>
<ol>
<li>Use shared cache for multiple similar projects</li>
<li>Monitor cache size with <code>--cache-stats</code> periodically</li>
<li>Clear cache after major refactorings</li>
<li>Use local cache for project-specific configurations</li>
</ol>
<h3 id="analysis-optimizations"><a class="header" href="#analysis-optimizations">Analysis Optimizations</a></h3>
<pre><code class="language-bash"># Fast mode: disable semantic analysis
debtmap --semantic-off

# Plain output: faster terminal rendering
debtmap --plain

# Limit files for testing
debtmap --max-files 100

# Analyze subdirectory only
debtmap src/specific/module

# Reduce output with filters
debtmap --min-priority 4 --top 20
</code></pre>
<h3 id="performance-comparison"><a class="header" href="#performance-comparison">Performance Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Configuration</th><th>Speed</th><th>Accuracy</th></tr></thead><tbody>
<tr><td>Default (cached)</td><td>Fast</td><td>High</td></tr>
<tr><td><code>--no-cache</code></td><td>Slow</td><td>High</td></tr>
<tr><td><code>--semantic-off</code></td><td>Fastest</td><td>Medium</td></tr>
<tr><td><code>--no-parallel</code></td><td>Slowest</td><td>High</td></tr>
<tr><td><code>--jobs 4</code></td><td>Medium</td><td>High</td></tr>
</tbody></table>
</div>
<h3 id="monitoring-performance"><a class="header" href="#monitoring-performance">Monitoring Performance</a></h3>
<pre><code class="language-bash"># Time analysis
time debtmap

# Check cache hit rate
debtmap --cache-stats

# Profile with verbosity
debtmap -vv 2&gt;&amp;1 | grep "processed in"
</code></pre>
<h2 id="cache-troubleshooting"><a class="header" href="#cache-troubleshooting">Cache Troubleshooting</a></h2>
<p>Detailed guidance for cache-related issues.</p>
<h3 id="check-cache-status"><a class="header" href="#check-cache-status">Check Cache Status</a></h3>
<pre><code class="language-bash"># View cache statistics
debtmap --cache-stats

# Sample output:
# Cache location: .debtmap/cache
# Cache entries: 1,234
# Cache size: 45.2 MB
# Hit rate: 87.3%
</code></pre>
<h3 id="clear-corrupted-cache"><a class="header" href="#clear-corrupted-cache">Clear Corrupted Cache</a></h3>
<pre><code class="language-bash"># Clear all cache entries
debtmap --clear-cache

# Force rebuild on next run
debtmap --force-cache-rebuild

# Manual cache deletion
rm -rf .debtmap/cache
# or for shared cache:
rm -rf ~/.cache/debtmap
</code></pre>
<h3 id="cache-location-management"><a class="header" href="#cache-location-management">Cache Location Management</a></h3>
<pre><code class="language-bash"># Use local cache (default)
debtmap
# Cache at: .debtmap/cache

# Use shared cache
debtmap --cache-location ~/.cache/debtmap

# Set permanently via environment
export DEBTMAP_CACHE_DIR=~/.cache/debtmap
debtmap

# Migrate existing cache
debtmap --migrate-cache
</code></pre>
<h3 id="cache-strategies"><a class="header" href="#cache-strategies">Cache Strategies</a></h3>
<p><strong>Local cache</strong> (<code>.debtmap/cache</code>):</p>
<ul>
<li><strong>Pros</strong>: Isolated per project, automatically managed</li>
<li><strong>Cons</strong>: Duplicates across projects</li>
</ul>
<p><strong>Shared cache</strong> (<code>~/.cache/debtmap</code>):</p>
<ul>
<li><strong>Pros</strong>: Shared across projects, saves disk space</li>
<li><strong>Cons</strong>: Requires manual management, may mix unrelated projects</li>
</ul>
<h3 id="cache-consistency"><a class="header" href="#cache-consistency">Cache Consistency</a></h3>
<pre><code class="language-bash"># Validate LOC consistency
debtmap --validate-loc

# Cache automatically invalidates on file changes
# Uses file hashes to detect modifications

# Force fresh analysis
debtmap --no-cache
</code></pre>
<h3 id="cache-size-monitoring"><a class="header" href="#cache-size-monitoring">Cache Size Monitoring</a></h3>
<pre><code class="language-bash"># Check cache size
debtmap --cache-stats

# Clean up old entries (manual)
# No automatic cleanup - manage cache size manually
# Consider clearing cache periodically for large projects
</code></pre>
<h2 id="context-provider-troubleshooting"><a class="header" href="#context-provider-troubleshooting">Context Provider Troubleshooting</a></h2>
<p>Diagnose and fix issues with context providers (critical_path, dependency, git_history).</p>
<h3 id="enable-context-analysis"><a class="header" href="#enable-context-analysis">Enable Context Analysis</a></h3>
<pre><code class="language-bash"># Enable with default providers
debtmap --context

# Or use explicit flag
debtmap --enable-context

# Specify specific providers
debtmap --context --context-providers critical_path,dependency,git_history
</code></pre>
<h3 id="disable-specific-providers"><a class="header" href="#disable-specific-providers">Disable Specific Providers</a></h3>
<pre><code class="language-bash"># Disable git_history only
debtmap --context --disable-context git_history

# Disable multiple providers
debtmap --context --disable-context git_history,dependency

# Disable context-aware filtering
debtmap --no-context-aware
</code></pre>
<h3 id="git-history-provider-issues"><a class="header" href="#git-history-provider-issues">Git History Provider Issues</a></h3>
<p><strong>Problem</strong>: ‚ÄúGit history error‚Äù when running analysis</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Not in a git repository</li>
<li>No git history for files</li>
<li>Git not installed or accessible</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Verify in git repository
git status

# Disable git_history provider
debtmap --context --disable-context git_history

# Initialize git repo if needed
git init
</code></pre>
<h3 id="dependency-provider-issues"><a class="header" href="#dependency-provider-issues">Dependency Provider Issues</a></h3>
<p><strong>Problem</strong>: ‚ÄúDependency error‚Äù or incomplete dependency graph</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Complex import structures</li>
<li>Circular dependencies</li>
<li>Unsupported dependency patterns</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable dependency provider
debtmap --context --disable-context dependency

# Try with verbosity to see details
debtmap --context -vvv

# Use without context
debtmap
</code></pre>
<h3 id="critical-path-provider-issues"><a class="header" href="#critical-path-provider-issues">Critical Path Provider Issues</a></h3>
<p><strong>Problem</strong>: Critical path analysis fails or produces unexpected results</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Invalid call graph</li>
<li>Missing function definitions</li>
<li>Complex control flow</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable critical_path provider
debtmap --context --disable-context critical_path

# Try with semantic analysis disabled
debtmap --context --semantic-off

# Debug with verbosity
debtmap --context --context-providers critical_path -vvv
</code></pre>
<h3 id="context-impact-on-scoring"><a class="header" href="#context-impact-on-scoring">Context Impact on Scoring</a></h3>
<p>Context providers add additional risk factors to scoring:</p>
<pre><code class="language-bash"># See context contribution to scores
debtmap --context -v

# Compare with and without context
debtmap --output baseline.json
debtmap --context --output with_context.json
debtmap compare --before baseline.json --after with_context.json
</code></pre>
<h3 id="performance-impact"><a class="header" href="#performance-impact">Performance Impact</a></h3>
<p>Context analysis adds processing overhead:</p>
<pre><code class="language-bash"># Faster: no context
debtmap

# Slower: with all context providers
debtmap --context --context-providers critical_path,dependency,git_history

# Medium: selective providers
debtmap --context --context-providers dependency
</code></pre>
<h3 id="debug-context-providers"><a class="header" href="#debug-context-providers">Debug Context Providers</a></h3>
<pre><code class="language-bash"># See detailed context provider output
debtmap --context -vvv

# Check which providers are active
debtmap --context -v | grep "context provider"
</code></pre>
<h2 id="advanced-analysis-troubleshooting"><a class="header" href="#advanced-analysis-troubleshooting">Advanced Analysis Troubleshooting</a></h2>
<p>Advanced CLI flags for specialized analysis scenarios.</p>
<h3 id="multi-pass-analysis-2"><a class="header" href="#multi-pass-analysis-2">Multi-Pass Analysis</a></h3>
<p><strong>Flag</strong>: <code>--multi-pass</code></p>
<p>Multi-pass analysis performs multiple iterations to refine results.</p>
<pre><code class="language-bash"># Enable multi-pass analysis
debtmap --multi-pass

# Useful for complex projects with intricate dependencies
# May increase analysis time but improve accuracy
</code></pre>
<p><strong>When to use</strong>:</p>
<ul>
<li>Complex dependency graphs</li>
<li>Large codebases with deep nesting</li>
<li>When single-pass results seem incomplete</li>
</ul>
<h3 id="attribution-output"><a class="header" href="#attribution-output">Attribution Output</a></h3>
<p><strong>Flag</strong>: <code>--attribution</code></p>
<p>Shows attribution information for detected issues.</p>
<pre><code class="language-bash"># Enable attribution output
debtmap --attribution

# Combine with verbosity for details
debtmap --attribution -v
</code></pre>
<p><strong>Troubleshooting</strong>:</p>
<ul>
<li>Requires git history provider for author information</li>
<li>May slow down analysis</li>
<li>Use <code>--disable-context git_history</code> if causing errors</li>
</ul>
<h3 id="aggregation-methods-2"><a class="header" href="#aggregation-methods-2">Aggregation Methods</a></h3>
<p><strong>Flag</strong>: <code>--aggregation-method &lt;method&gt;</code></p>
<p>Controls how results are aggregated across files.</p>
<pre><code class="language-bash"># Available aggregation methods:
debtmap --aggregation-method weighted_sum  # (default)
debtmap --aggregation-method sum
debtmap --aggregation-method logarithmic_sum
debtmap --aggregation-method max_plus_average
</code></pre>
<p><strong>Common issues</strong>:</p>
<ul>
<li>Different methods produce different result structures</li>
<li>Choose method based on your reporting needs</li>
<li>Use consistent method for comparison over time</li>
</ul>
<h3 id="minimum-problematic-threshold"><a class="header" href="#minimum-problematic-threshold">Minimum Problematic Threshold</a></h3>
<p><strong>Flag</strong>: <code>--min-problematic &lt;number&gt;</code></p>
<p>Sets the minimum score for an item to be considered problematic.</p>
<pre><code class="language-bash"># Default threshold
debtmap --min-problematic 3

# More strict (show more issues)
debtmap --min-problematic 1

# Less strict (show only serious issues)
debtmap --min-problematic 5
</code></pre>
<p><strong>Relationship to other filters</strong>:</p>
<ul>
<li>Works alongside <code>--min-priority</code></li>
<li>Filters at analysis level vs display level</li>
<li>Lower values = more issues shown</li>
</ul>
<h3 id="god-object-detection-2"><a class="header" href="#god-object-detection-2">God Object Detection</a></h3>
<p><strong>Flag</strong>: <code>--no-god-object</code></p>
<p>Disables god object (large class/module) detection.</p>
<pre><code class="language-bash"># Disable god object detection
debtmap --no-god-object

# Useful if false positives on legitimately large modules
# Or if your architecture uses centralized classes
</code></pre>
<p><strong>When to use</strong>:</p>
<ul>
<li>False positives on framework files</li>
<li>Intentional large aggregator classes</li>
<li>Reducing noise in results</li>
</ul>
<h3 id="detail-level-control"><a class="header" href="#detail-level-control">Detail Level Control</a></h3>
<p><strong>Flag</strong>: <code>--detail-level &lt;level&gt;</code></p>
<p>Controls the level of detail in analysis output.</p>
<pre><code class="language-bash"># Available detail levels:
debtmap --detail-level summary        # High-level overview only
debtmap --detail-level standard       # (default) Balanced detail
debtmap --detail-level comprehensive  # Detailed analysis
debtmap --detail-level debug         # Full debug information
</code></pre>
<p><strong>When to use</strong>:</p>
<ul>
<li><code>summary</code>: Quick overview for large codebases</li>
<li><code>standard</code>: Default, appropriate for most use cases</li>
<li><code>comprehensive</code>: Deep dive into specific issues</li>
<li><code>debug</code>: Troubleshooting analysis behavior</li>
</ul>
<h3 id="aggregation-control"><a class="header" href="#aggregation-control">Aggregation Control</a></h3>
<p><strong>Flags</strong>: <code>--aggregate-only</code>, <code>--no-aggregation</code></p>
<p>Control file-level score aggregation.</p>
<pre><code class="language-bash"># Show only aggregated file-level scores
debtmap --aggregate-only

# Disable file-level aggregation entirely
debtmap --no-aggregation

# Default: show both individual items and file aggregates
debtmap
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li><code>--aggregate-only</code>: Focus on file-level technical debt</li>
<li><code>--no-aggregation</code>: See individual functions/classes only</li>
<li>Default: Full picture with both levels</li>
</ul>
<h3 id="combining-advanced-flags"><a class="header" href="#combining-advanced-flags">Combining Advanced Flags</a></h3>
<pre><code class="language-bash"># Comprehensive analysis with all features
debtmap --multi-pass --attribution --context -vv

# Minimal filtering for exploration
debtmap --min-problematic 1 --min-priority 0 --no-god-object

# Performance-focused advanced analysis
debtmap --multi-pass --jobs 8 --cache-location ~/.cache/debtmap

# Summary view with aggregated scores
debtmap --detail-level summary --aggregate-only
</code></pre>
<h2 id="error-messages-reference"><a class="header" href="#error-messages-reference">Error Messages Reference</a></h2>
<p>Understanding common error messages and how to resolve them.</p>
<h3 id="file-system-errors"><a class="header" href="#file-system-errors">File System Errors</a></h3>
<p><strong>Message</strong>: <code>File system error: Permission denied</code></p>
<p><strong>Meaning</strong>: Cannot read file or directory due to permissions</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check file permissions: <code>ls -la &lt;file&gt;</code></li>
<li>Ensure user has read access</li>
<li>Verify cache directory is writable</li>
<li>Use <code>--cache-location</code> for accessible directory</li>
</ul>
<hr />
<p><strong>Message</strong>: <code>File system error: No such file or directory</code></p>
<p><strong>Meaning</strong>: File or directory does not exist</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify path is correct</li>
<li>Check current working directory: <code>pwd</code></li>
<li>Use absolute paths if needed</li>
<li>Ensure files weren‚Äôt moved or deleted</li>
</ul>
<h3 id="parse-errors-1"><a class="header" href="#parse-errors-1">Parse Errors</a></h3>
<p><strong>Message</strong>: <code>Parse error in file.rs:line:column: unexpected token</code></p>
<p><strong>Meaning</strong>: Syntax debtmap cannot parse</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Try fallback mode
debtmap --semantic-off

# For Rust macros
debtmap --verbose-macro-warnings --show-macro-stats

# Exclude problematic file
# In .debtmap/config.toml:
# exclude = ["path/to/file.rs"]
</code></pre>
<h3 id="analysis-errors"><a class="header" href="#analysis-errors">Analysis Errors</a></h3>
<p><strong>Message</strong>: <code>Analysis error: internal analysis failure</code></p>
<p><strong>Meaning</strong>: Internal error during analysis phase</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Try fallback mode
debtmap --semantic-off

# Report with debug info
debtmap -vvv 2&gt;&amp;1 | tee error.log

# Isolate problem file
debtmap --max-files 1 path/to/suspected/file
</code></pre>
<h3 id="configuration-errors"><a class="header" href="#configuration-errors">Configuration Errors</a></h3>
<p><strong>Message</strong>: <code>Configuration error: invalid config value</code></p>
<p><strong>Meaning</strong>: Invalid configuration in <code>.debtmap/config.toml</code> or CLI</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check <code>.debtmap/config.toml</code> syntax</li>
<li>Validate TOML format: <code>cat .debtmap/config.toml</code></li>
<li>Review CLI flag values</li>
<li>Check for typos in flag names</li>
</ul>
<h3 id="cache-errors"><a class="header" href="#cache-errors">Cache Errors</a></h3>
<p><strong>Message</strong>: <code>Cache error: corrupted cache entry</code></p>
<p><strong>Meaning</strong>: Cache data is invalid or corrupted</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Clear cache
debtmap --clear-cache

# Force rebuild
debtmap --force-cache-rebuild

# Use different cache location
debtmap --cache-location /tmp/debtmap-cache
</code></pre>
<h3 id="validation-errors"><a class="header" href="#validation-errors">Validation Errors</a></h3>
<p><strong>Message</strong>: <code>Validation error: threshold validation failed</code></p>
<p><strong>Meaning</strong>: Threshold configuration is invalid</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check threshold values in config</li>
<li>Ensure <code>--min-priority</code> is in valid range (0-10)</li>
<li>Verify threshold preset exists</li>
<li>Use <code>--threshold-preset</code> with valid preset name</li>
</ul>
<h3 id="dependency-errors"><a class="header" href="#dependency-errors">Dependency Errors</a></h3>
<p><strong>Message</strong>: <code>Dependency error: cannot resolve dependency graph</code></p>
<p><strong>Meaning</strong>: Cannot build dependency relationships</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable dependency provider
debtmap --context --disable-context dependency

# Try without context
debtmap

# Debug with verbosity
debtmap -vvv
</code></pre>
<h3 id="concurrency-errors"><a class="header" href="#concurrency-errors">Concurrency Errors</a></h3>
<p><strong>Message</strong>: <code>Concurrency error: parallel processing failure</code></p>
<p><strong>Meaning</strong>: Error during parallel execution</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable parallel processing
debtmap --no-parallel

# Reduce thread count
debtmap --jobs 1

# Report issue with debug output
debtmap -vvv 2&gt;&amp;1 | tee error.log
</code></pre>
<h3 id="unsupported-errors"><a class="header" href="#unsupported-errors">Unsupported Errors</a></h3>
<p><strong>Message</strong>: <code>Unsupported: feature not available for &lt;language&gt;</code></p>
<p><strong>Meaning</strong>: Language or construct not supported</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Use supported languages: Rust, Python, JavaScript, TypeScript</li>
<li>Check if language is enabled in config</li>
<li>Some advanced features may not be available for all languages</li>
<li>Try <code>--semantic-off</code> for basic analysis</li>
</ul>
<h3 id="pattern-errors"><a class="header" href="#pattern-errors">Pattern Errors</a></h3>
<p><strong>Message</strong>: <code>Pattern error: invalid glob pattern</code></p>
<p><strong>Meaning</strong>: Invalid glob pattern in configuration or CLI</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Check glob pattern syntax</li>
<li>Escape special characters if needed</li>
<li>Test pattern with shell glob: <code>ls &lt;pattern&gt;</code></li>
<li>Use simpler patterns or path prefixes</li>
</ul>
<h2 id="language-specific-issues"><a class="header" href="#language-specific-issues">Language-Specific Issues</a></h2>
<h3 id="rust"><a class="header" href="#rust">Rust</a></h3>
<p><strong>Macro Expansion Issues</strong></p>
<pre><code class="language-bash"># See macro warnings
debtmap --verbose-macro-warnings

# Show macro statistics
debtmap --show-macro-stats

# Common issue: Complex macros may not expand correctly
# Solution: Use --semantic-off for faster fallback
</code></pre>
<p><strong>Trait and Generic Complexity</strong></p>
<p>Complex trait bounds and generic constraints may affect analysis accuracy:</p>
<pre><code class="language-bash"># Full semantic analysis (default)
debtmap

# Fallback mode for edge cases
debtmap --semantic-off
</code></pre>
<h3 id="python"><a class="header" href="#python">Python</a></h3>
<p><strong>Type Inference Limitations</strong></p>
<p>Dynamic typing makes some analysis challenging:</p>
<pre><code class="language-bash"># Best effort type inference (default)
debtmap

# Fallback mode if issues
debtmap --semantic-off
</code></pre>
<p><strong>Import Resolution</strong></p>
<p>Complex import structures may not resolve fully:</p>
<ul>
<li>Relative imports usually work</li>
<li>Dynamic imports may not be detected</li>
<li><code>__init__.py</code> packages are supported</li>
</ul>
<h3 id="javascripttypescript-1"><a class="header" href="#javascripttypescript-1">JavaScript/TypeScript</a></h3>
<p><strong>JSX/TSX Parsing</strong></p>
<p>Ensure files have correct extensions:</p>
<ul>
<li><code>.jsx</code> for JavaScript + JSX</li>
<li><code>.tsx</code> for TypeScript + JSX</li>
<li>Configure extensions in <code>.debtmap/config.toml</code> if needed</li>
</ul>
<p><strong>Type Resolution</strong></p>
<p>TypeScript type resolution in complex projects:</p>
<pre><code class="language-bash"># Full type checking (default for .ts files)
debtmap

# Fallback if type issues
debtmap --semantic-off
</code></pre>
<h3 id="mixed-language-projects"><a class="header" href="#mixed-language-projects">Mixed Language Projects</a></h3>
<pre><code class="language-bash"># Analyze all supported languages (default)
debtmap

# Filter specific languages
# In .debtmap/config.toml:
# languages = ["rust", "python"]
</code></pre>
<h3 id="unsupported-language-constructs"><a class="header" href="#unsupported-language-constructs">Unsupported Language Constructs</a></h3>
<p>Some advanced language features may show as ‚ÄúUnsupported‚Äù:</p>
<ul>
<li>Rust: Some macro patterns, const generics edge cases</li>
<li>Python: Some metaclass patterns, dynamic code generation</li>
<li>JavaScript: Some advanced AST manipulation</li>
</ul>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Use <code>--semantic-off</code> for basic analysis</li>
<li>Exclude problematic files if needed</li>
<li>Report unsupported patterns as feature requests</li>
</ul>
<h3 id="false-positives"><a class="header" href="#false-positives">False Positives</a></h3>
<pre><code class="language-bash"># Reduce false positives with context
debtmap --context

# Adjust thresholds
debtmap --threshold-preset lenient

# Disable context-aware filtering if too aggressive
debtmap --no-context-aware
</code></pre>
<h3 id="missing-detections"><a class="header" href="#missing-detections">Missing Detections</a></h3>
<pre><code class="language-bash"># Ensure semantic analysis is enabled
debtmap  # (default, semantic ON)

# Increase verbosity to see what's detected
debtmap -vv

# Check if files are being analyzed
debtmap -v 2&gt;&amp;1 | grep "Processing"
</code></pre>
<h2 id="output-formatting-issues"><a class="header" href="#output-formatting-issues">Output Formatting Issues</a></h2>
<h3 id="choose-output-format"><a class="header" href="#choose-output-format">Choose Output Format</a></h3>
<pre><code class="language-bash"># Terminal format (default, human-readable)
debtmap

# JSON format
debtmap --format json

# Markdown format
debtmap --format markdown
</code></pre>
<h3 id="json-format-options"><a class="header" href="#json-format-options">JSON Format Options</a></h3>
<pre><code class="language-bash"># Legacy format (default): {File: {...}}
debtmap --format json --output-format legacy

# Unified format: consistent structure with 'type' field
debtmap --format json --output-format unified

# Validate JSON
debtmap --format json | jq .

# Write to file
debtmap --format json --output results.json
</code></pre>
<h3 id="plain-output-mode"><a class="header" href="#plain-output-mode">Plain Output Mode</a></h3>
<p>For environments without color/emoji support:</p>
<pre><code class="language-bash"># ASCII-only, no colors, no emoji
debtmap --plain

# Or set environment variable
export NO_EMOJI=1
debtmap
</code></pre>
<h3 id="terminal-color-issues"><a class="header" href="#terminal-color-issues">Terminal Color Issues</a></h3>
<p><strong>Problem</strong>: Colors not rendering or showing escape codes</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Use plain mode
debtmap --plain

# Check TERM environment variable
echo $TERM

# Set appropriate TERM
export TERM=xterm-256color
</code></pre>
<h3 id="emoji-issues"><a class="header" href="#emoji-issues">Emoji Issues</a></h3>
<p><strong>Problem</strong>: Emojis showing as boxes or ??</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Disable emojis
debtmap --plain

# Or environment variable
export NO_EMOJI=1
debtmap
</code></pre>
<h3 id="markdown-rendering"><a class="header" href="#markdown-rendering">Markdown Rendering</a></h3>
<p>Ensure viewer supports GitHub-flavored markdown:</p>
<ul>
<li>Tables</li>
<li>Code blocks with syntax highlighting</li>
<li>Task lists</li>
</ul>
<h3 id="write-output-to-file"><a class="header" href="#write-output-to-file">Write Output to File</a></h3>
<pre><code class="language-bash"># JSON to file
debtmap --format json --output results.json

# Markdown to file
debtmap --format markdown --output report.md

# Terminal format to file (preserves colors)
debtmap --output results.txt

# Plain format to file
debtmap --plain --output results.txt
</code></pre>
<h3 id="summary-vs-full-output"><a class="header" href="#summary-vs-full-output">Summary vs Full Output</a></h3>
<pre><code class="language-bash"># Summary mode (compact)
debtmap --summary
debtmap -s

# Full output (default)
debtmap

# Limit number of items
debtmap --top 10       # Top 10 by priority
debtmap --tail 10      # Bottom 10 by priority
</code></pre>
<h3 id="filtering-output"><a class="header" href="#filtering-output">Filtering Output</a></h3>
<pre><code class="language-bash"># Minimum priority level
debtmap --min-priority 5

# Category filters
debtmap --filter "complexity,debt"

# Combine filters
debtmap --min-priority 3 --top 20 --filter complexity
</code></pre>
<h2 id="compare-command-issues"><a class="header" href="#compare-command-issues">Compare Command Issues</a></h2>
<p>The <code>compare</code> command helps track changes in technical debt over time.</p>
<h3 id="basic-usage-2"><a class="header" href="#basic-usage-2">Basic Usage</a></h3>
<p><strong>Note</strong>: The <code>compare</code> command defaults to JSON output format (unlike <code>analyze</code> which defaults to terminal). Use <code>--format terminal</code> or <code>--format markdown</code> if you need different output.</p>
<pre><code class="language-bash"># Save baseline results
debtmap --format json --output before.json

# Make code changes...

# Save new results
debtmap --format json --output after.json

# Compare results (outputs JSON by default)
debtmap compare --before before.json --after after.json

# Compare with terminal output
debtmap compare --before before.json --after after.json --format terminal
</code></pre>
<h3 id="targeted-comparison"><a class="header" href="#targeted-comparison">Targeted Comparison</a></h3>
<p>Use <code>--plan</code> and <code>--target-location</code> for focused debt analysis:</p>
<pre><code class="language-bash"># Compare based on implementation plan
debtmap compare --before before.json --after after.json --plan implementation-plan.json

# Compare specific code location
debtmap compare --before before.json --after after.json \
  --target-location src/main.rs:calculate_score:42

# Combine both for precise tracking
debtmap compare --before before.json --after after.json \
  --plan implementation-plan.json \
  --target-location src/analyzers/complexity.rs:analyze_function:128
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li><code>--plan</code>: Track debt changes for planned refactoring tasks</li>
<li><code>--target-location</code>: Focus on specific function or code location</li>
<li>Combine for granular technical debt tracking</li>
</ul>
<h3 id="incompatible-format-errors"><a class="header" href="#incompatible-format-errors">Incompatible Format Errors</a></h3>
<p><strong>Problem</strong>: ‚ÄúIncompatible formats‚Äù error when comparing files</p>
<p><strong>Causes</strong>:</p>
<ul>
<li>Mixing legacy and unified JSON formats</li>
<li>Files from different debtmap versions</li>
<li>Corrupted JSON files</li>
</ul>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Ensure both files use same output format
debtmap --format json --output-format unified --output before.json
# ... make changes ...
debtmap --format json --output-format unified --output after.json
debtmap compare --before before.json --after after.json

# Validate JSON files are well-formed
jq . before.json &gt; /dev/null
jq . after.json &gt; /dev/null
</code></pre>
<h3 id="comparing-across-branches"><a class="header" href="#comparing-across-branches">Comparing Across Branches</a></h3>
<pre><code class="language-bash"># Save baseline on main branch
git checkout main
debtmap --format json --output main.json

# Switch to feature branch
git checkout feature-branch
debtmap --format json --output feature.json

# Compare branches
debtmap compare --before main.json --after feature.json
</code></pre>
<h3 id="missing-files-error"><a class="header" href="#missing-files-error">Missing Files Error</a></h3>
<p><strong>Problem</strong>: ‚ÄúFile not found‚Äù when running compare</p>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Verify file paths are correct (use absolute paths if needed)</li>
<li>Ensure JSON files weren‚Äôt moved or deleted</li>
<li>Check current working directory with <code>pwd</code></li>
</ul>
<h3 id="format-mismatch-issues"><a class="header" href="#format-mismatch-issues">Format Mismatch Issues</a></h3>
<p><strong>Problem</strong>: Compare shows unexpected differences or errors</p>
<p><strong>Solutions</strong>:</p>
<pre><code class="language-bash"># Regenerate both files with same debtmap version
debtmap --format json --output before.json
# ... make changes ...
debtmap --format json --output after.json

# Use same output format for both
debtmap --format json --output-format unified --output before.json
debtmap --format json --output-format unified --output after.json
</code></pre>
<h2 id="validate-command-issues"><a class="header" href="#validate-command-issues">Validate Command Issues</a></h2>
<p>The <code>validate</code> command checks if a codebase meets specified quality thresholds, useful for CI/CD pipelines.</p>
<h3 id="basic-validation"><a class="header" href="#basic-validation">Basic Validation</a></h3>
<pre><code class="language-bash"># Validate codebase passes default thresholds
debtmap validate /path/to/project

# Exit code 0 if passes, non-zero if validation fails
</code></pre>
<h3 id="debt-density-validation"><a class="header" href="#debt-density-validation">Debt Density Validation</a></h3>
<p><strong>Flag</strong>: <code>--max-debt-density &lt;number&gt;</code></p>
<p>Sets the maximum acceptable technical debt per 1000 lines of code.</p>
<pre><code class="language-bash"># Set maximum acceptable debt density (per 1000 LOC)
debtmap validate /path/to/project --max-debt-density 10.0

# Stricter threshold for critical projects
debtmap validate /path/to/project --max-debt-density 5.0

# Lenient threshold for legacy code
debtmap validate /path/to/project --max-debt-density 20.0
</code></pre>
<p><strong>Troubleshooting validation failures</strong>:</p>
<pre><code class="language-bash"># See which files exceed threshold
debtmap validate /path/to/project --max-debt-density 10.0 -v

# Get detailed breakdown
debtmap validate /path/to/project --max-debt-density 10.0 -vv

# Analyze specific files that failed
debtmap /path/to/problematic/file.rs -v
</code></pre>
<h3 id="cicd-integration-2"><a class="header" href="#cicd-integration-2">CI/CD Integration</a></h3>
<pre><code class="language-bash"># In CI pipeline (fails build if validation fails)
debtmap validate . --max-debt-density 10.0 || exit 1

# With verbose output for debugging
debtmap validate . --max-debt-density 10.0 -v

# Save validation report
debtmap validate . --max-debt-density 10.0 --format json --output validation.json
</code></pre>
<p><strong>Use cases</strong>:</p>
<ul>
<li>Enforce quality gates in CI/CD pipelines</li>
<li>Prevent accumulation of technical debt over time</li>
<li>Track debt density trends across releases</li>
<li>Set different thresholds for different parts of codebase</li>
</ul>
<h2 id="faq"><a class="header" href="#faq">FAQ</a></h2>
<h3 id="general-questions"><a class="header" href="#general-questions">General Questions</a></h3>
<p><strong>Q: Why is my analysis slow?</strong></p>
<p>A: Check several factors:</p>
<pre><code class="language-bash"># Check cache status
debtmap --cache-stats

# Ensure caching is enabled (default)
# Remove --no-cache if present

# Use all CPU cores
debtmap --jobs 0

# Check for large files or complex macros
debtmap -vv
</code></pre>
<p><strong>Q: What does ‚ÄòParse error‚Äô mean?</strong></p>
<p>A: File contains syntax debtmap cannot parse. Solutions:</p>
<ul>
<li>Try <code>--semantic-off</code> for fallback mode</li>
<li>Use <code>--verbose-macro-warnings</code> for Rust macros</li>
<li>Exclude problematic files in <code>.debtmap/config.toml</code></li>
<li>Report parse errors as potential bugs</li>
</ul>
<p><strong>Q: Why do scores differ between runs?</strong></p>
<p>A: Several factors affect scores:</p>
<ul>
<li>Coverage file changed (use <code>--coverage-file</code>)</li>
<li>Context providers enabled/disabled (<code>--context</code>)</li>
<li>Cache was cleared (<code>--clear-cache</code>)</li>
<li>Code changes (intended behavior)</li>
<li>Different threshold settings</li>
</ul>
<p><strong>Q: How do I reduce noise in results?</strong></p>
<p>A: Use filtering options:</p>
<pre><code class="language-bash"># Increase minimum priority
debtmap --min-priority 5

# Use threshold preset
debtmap --threshold-preset strict

# Filter categories
debtmap --filter "complexity,debt"

# Limit output
debtmap --top 20
</code></pre>
<h3 id="format-and-output"><a class="header" href="#format-and-output">Format and Output</a></h3>
<p><strong>Q: What‚Äôs the difference between legacy and unified JSON?</strong></p>
<p>A: Two JSON output formats:</p>
<ul>
<li><strong>Legacy</strong>: <code>{File: {...}}</code> - nested file-based structure</li>
<li><strong>Unified</strong>: Consistent structure with <code>type</code> field for each item</li>
</ul>
<pre><code class="language-bash"># Legacy (default)
debtmap --format json --output-format legacy

# Unified (recommended for parsing)
debtmap --format json --output-format unified
</code></pre>
<p><strong>Q: Can I analyze partial codebases?</strong></p>
<p>A: Yes, several approaches:</p>
<pre><code class="language-bash"># Limit file count
debtmap --max-files 100

# Analyze specific directory
debtmap src/specific/module

# Use filters in config
# .debtmap/config.toml:
# include = ["src/**/*.rs"]
</code></pre>
<h3 id="coverage-and-testing"><a class="header" href="#coverage-and-testing">Coverage and Testing</a></h3>
<p><strong>Q: How does coverage affect scores?</strong></p>
<p>A: Coverage dampens scores to surface untested code:</p>
<ul>
<li>Formula: <code>score_multiplier = 1.0 - coverage</code></li>
<li>0% coverage ‚Üí full score (highest priority)</li>
<li>100% coverage ‚Üí score multiplied by 0 (lowest priority)</li>
<li>Untested complex code rises to the top</li>
</ul>
<pre><code class="language-bash"># Use coverage file
debtmap --coverage-file coverage.info

# See coverage impact
debtmap --coverage-file coverage.info -v
</code></pre>
<h3 id="context-and-analysis"><a class="header" href="#context-and-analysis">Context and Analysis</a></h3>
<p><strong>Q: What are context providers?</strong></p>
<p>A: Additional analysis for prioritization:</p>
<ul>
<li><strong>critical_path</strong>: Call graph analysis, entry point distance</li>
<li><strong>dependency</strong>: Dependency relationships and coupling</li>
<li><strong>git_history</strong>: Change frequency and authorship</li>
</ul>
<pre><code class="language-bash"># Enable all
debtmap --context

# Specific providers
debtmap --context --context-providers critical_path,dependency

# See context impact
debtmap --context -v
</code></pre>
<h3 id="results-and-comparison"><a class="header" href="#results-and-comparison">Results and Comparison</a></h3>
<p><strong>Q: Why no output?</strong></p>
<p>A: Check verbosity and filtering:</p>
<pre><code class="language-bash"># Increase verbosity
debtmap -v

# Lower priority threshold
debtmap --min-priority 0

# Check if files were analyzed
debtmap -vv 2&gt;&amp;1 | grep "Processed"

# Ensure not using strict threshold
debtmap --threshold-preset lenient
</code></pre>
<p><strong>Q: How to compare results over time?</strong></p>
<p>A: Use the <code>compare</code> command:</p>
<pre><code class="language-bash"># Save baseline
debtmap --format json --output before.json

# Make changes...

# Analyze again
debtmap --format json --output after.json

# Compare
debtmap compare --before before.json --after after.json
</code></pre>
<p><strong>Q: Why does compare fail with ‚Äòincompatible formats‚Äô?</strong></p>
<p>A: The JSON files must use the same output format:</p>
<pre><code class="language-bash"># Use unified format for both
debtmap --format json --output-format unified --output before.json
# ... make changes ...
debtmap --format json --output-format unified --output after.json
debtmap compare --before before.json --after after.json

# Or use legacy format for both (but unified is recommended)
debtmap --format json --output-format legacy --output before.json
debtmap --format json --output-format legacy --output after.json
</code></pre>
<p><strong>Q: How do I compare results from different branches?</strong></p>
<p>A: Generate JSON output on each branch and compare:</p>
<pre><code class="language-bash"># On main branch
git checkout main
debtmap --format json --output main.json

# On feature branch
git checkout feature-branch
debtmap --format json --output feature.json

# Compare (from either branch)
debtmap compare --before main.json --after feature.json
</code></pre>
<p><strong>Q: Can I compare legacy and unified JSON formats?</strong></p>
<p>A: No, both files must use the same format. Regenerate with matching formats:</p>
<pre><code class="language-bash"># Convert both to unified format
debtmap --format json --output-format unified --output before.json
debtmap --format json --output-format unified --output after.json
debtmap compare --before before.json --after after.json
</code></pre>
<h3 id="performance-and-optimization"><a class="header" href="#performance-and-optimization">Performance and Optimization</a></h3>
<p><strong>Q: How many threads should I use?</strong></p>
<p>A: Depends on your machine:</p>
<pre><code class="language-bash"># Use all cores (default, recommended)
debtmap --jobs 0

# Limit to 4 threads (if other work running)
debtmap --jobs 4

# Single threaded (debugging only)
debtmap --no-parallel
</code></pre>
<p><strong>Q: Should I use shared or local cache?</strong></p>
<p>A: Depends on your workflow:</p>
<ul>
<li><strong>Local cache</strong> (<code>.debtmap/cache</code>): Isolated, automatic</li>
<li><strong>Shared cache</strong> (<code>~/.cache/debtmap</code>): Saves space across projects</li>
</ul>
<pre><code class="language-bash"># Shared cache
debtmap --cache-location ~/.cache/debtmap

# Set permanently
export DEBTMAP_CACHE_DIR=~/.cache/debtmap
</code></pre>
<h2 id="when-to-file-bug-reports"><a class="header" href="#when-to-file-bug-reports">When to File Bug Reports</a></h2>
<p>File a bug report when:</p>
<p>‚úÖ <strong>These are bugs</strong>:</p>
<ul>
<li>Parse errors on valid syntax</li>
<li>Crashes or panics</li>
<li>Incorrect complexity calculations</li>
<li>Cache corruption</li>
<li>Concurrency errors</li>
<li>Incorrect error messages</li>
</ul>
<p>‚ùå <strong>These are not bugs</strong>:</p>
<ul>
<li>Unsupported language constructs (file feature request)</li>
<li>Disagreement with complexity scores (subjective)</li>
<li>Performance on very large codebases (optimization request)</li>
<li>Missing documentation (docs issue, not code bug)</li>
</ul>
<h3 id="how-to-report-issues"><a class="header" href="#how-to-report-issues">How to Report Issues</a></h3>
<ol>
<li><strong>Reproduce with minimal example</strong></li>
<li><strong>Include debug output</strong>: <code>debtmap -vvv 2&gt;&amp;1 | tee error.log</code></li>
<li><strong>Include version</strong>: <code>debtmap --version</code></li>
<li><strong>Include platform</strong>: OS, Rust version if relevant</li>
<li><strong>Include configuration</strong>: <code>.debtmap/config.toml</code> if used</li>
<li><strong>Expected vs actual behavior</strong></li>
</ol>
<h3 id="before-filing"><a class="header" href="#before-filing">Before Filing</a></h3>
<ol>
<li>Check this troubleshooting guide</li>
<li>Try <code>--semantic-off</code> fallback mode</li>
<li>Clear cache with <code>--clear-cache</code></li>
<li>Update to latest version</li>
<li>Search existing issues on GitHub</li>
</ol>
<h2 id="related-documentation"><a class="header" href="#related-documentation">Related Documentation</a></h2>
<ul>
<li><strong><a href="./configuration.html">Configuration Guide</a></strong>: Configure debtmap behavior</li>
<li><strong><a href="./cli-reference.html">CLI Reference</a></strong>: Complete CLI flag documentation</li>
<li><strong><a href="./analysis-guide.html">Analysis Guide</a></strong>: Understanding analysis results</li>
<li><strong><a href="./examples.html">Examples</a></strong>: Practical usage examples</li>
<li><strong><a href="./api/index.html">API Documentation</a></strong>: Rust API documentation</li>
</ul>
<h2 id="troubleshooting-checklist"><a class="header" href="#troubleshooting-checklist">Troubleshooting Checklist</a></h2>
<p>When debugging issues, work through this checklist:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Run with <code>-vv</code> to see detailed output</li>
<li><input disabled="" type="checkbox"/>
Check <code>--cache-stats</code> for cache issues</li>
<li><input disabled="" type="checkbox"/>
Try <code>--clear-cache</code> to rule out cache corruption</li>
<li><input disabled="" type="checkbox"/>
Try <code>--semantic-off</code> to use fallback mode</li>
<li><input disabled="" type="checkbox"/>
Check file permissions and paths</li>
<li><input disabled="" type="checkbox"/>
Verify configuration in <code>.debtmap/config.toml</code></li>
<li><input disabled="" type="checkbox"/>
Test with <code>--max-files 10</code> to isolate issues</li>
<li><input disabled="" type="checkbox"/>
Try <code>--no-parallel</code> to rule out concurrency</li>
<li><input disabled="" type="checkbox"/>
Check <code>debtmap --version</code> for updates</li>
<li><input disabled="" type="checkbox"/>
Review error messages in this guide</li>
<li><input disabled="" type="checkbox"/>
Search GitHub issues for similar problems</li>
<li><input disabled="" type="checkbox"/>
Create minimal reproduction case</li>
<li><input disabled="" type="checkbox"/>
File bug report with debug output</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
