<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Scoring Strategies - Debtmap Documentation</title>


        <!-- Custom HTML head -->

        <meta name="description" content="Comprehensive guide to Debtmap code complexity and technical debt analyzer">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Debtmap Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/iepathos/debtmap" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="scoring-strategies"><a class="header" href="#scoring-strategies">Scoring Strategies</a></h1>
<p>Debtmap provides two complementary scoring approaches: <strong>file-level</strong> and <strong>function-level</strong>. Understanding when to use each approach helps you make better refactoring decisions and prioritize work effectively.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Different refactoring scenarios require different levels of granularity:</p>
<ul>
<li><strong>File-level scoring</strong>: Identifies architectural issues and planning major refactoring initiatives</li>
<li><strong>Function-level scoring</strong>: Pinpoints specific hot spots for targeted improvements</li>
</ul>
<p>This chapter explains both approaches, when to use each, and how to interpret the results.</p>
<h2 id="file-level-scoring"><a class="header" href="#file-level-scoring">File-Level Scoring</a></h2>
<p>File-level scoring aggregates metrics across all functions in a file to identify architectural problems and module-level refactoring opportunities.</p>
<h3 id="formula"><a class="header" href="#formula">Formula</a></h3>
<pre><code>File Score = Size × Complexity × Coverage Factor × Density × GodObject × FunctionScores
</code></pre>
<p><strong>Note</strong>: This is a conceptual formula showing the multiplicative relationship between factors. The actual implementation in <code>src/priority/file_metrics.rs</code> includes additional normalization steps and conditional adjustments. See source code for exact calculation details.</p>
<p>Where each factor is calculated as:</p>
<ul>
<li><strong>Size</strong> = <code>sqrt(total_lines / 100)</code></li>
<li><strong>Complexity</strong> = <code>(avg_complexity / 5.0) × sqrt(total_complexity / 50.0)</code></li>
<li><strong>Coverage Factor</strong> = <code>((1.0 - coverage_percent) × 2.0) + 1.0</code></li>
<li><strong>Density</strong> = <code>1.0 + ((function_count - 50) × 0.02)</code> if function_count &gt; 50, else 1.0</li>
<li><strong>GodObject</strong> = <code>2.0 + god_object_score</code> if detected</li>
<li><strong>FunctionScores</strong> = <code>sum(function_scores) / 10</code></li>
</ul>
<h3 id="factors"><a class="header" href="#factors">Factors</a></h3>
<p><strong>Size Factor</strong>: <code>sqrt(total_lines / 100)</code></p>
<ul>
<li>Larger files have higher impact</li>
<li>Square root dampens the effect to avoid over-penalizing large files</li>
<li>Rationale: Refactoring a 1000-line file affects more code than a 100-line file</li>
</ul>
<p><strong>Complexity Factor</strong>: Combines average and total complexity</p>
<ul>
<li><code>(average_cyclomatic + total_cyclomatic / function_count) / 2</code></li>
<li>Balances per-function and aggregate complexity</li>
<li>Rationale: Both concentrated complexity and spread-out complexity matter</li>
</ul>
<p><strong>Coverage Factor</strong>: <code>(coverage_gap × 2.0) + 1.0</code> where <code>coverage_gap = 1.0 - coverage_percent</code></p>
<ul>
<li>Lower coverage increases score multiplicatively</li>
<li>Range: 1.0 (100% coverage) to 3.0 (0% coverage)</li>
<li>Formula expands to: <code>((1.0 - coverage_percent) × 2.0) + 1.0</code></li>
<li>Example: 50% coverage → gap=0.5 → factor=(0.5×2.0)+1.0 = 2.0x</li>
<li>Rationale: Untested files amplify existing complexity and risk through a multiplicative factor greater than 1.0</li>
<li>Note: Earlier versions used <code>1.0 - coverage_percent</code> (range 0-1); current implementation uses expanded range 1-3 for stronger emphasis</li>
</ul>
<p><strong>Density Factor</strong>: Penalizes files with excessive function count</p>
<ul>
<li>Triggers when function count &gt; 50</li>
<li>Formula: <code>1.0 + ((function_count - 50) * 0.02)</code> if function_count &gt; 50, else 1.0</li>
<li>Creates a gradual linear increase: 51 functions = 1.02x, 75 functions = 1.50x, 100 functions = 2.0x</li>
<li>Example: A file with 75 functions gets 1.0 + ((75 - 50) * 0.02) = 1.0 + 0.50 = 1.50x multiplier</li>
<li>Rationale: Files with many functions likely violate single responsibility</li>
</ul>
<p><strong>God Object Multiplier</strong>: <code>2.0 + god_object_score</code> when detected</p>
<ul>
<li>Applies when god object detection flags the file</li>
<li>Range: 2.0 (borderline) to 3.0 (severe god object)</li>
<li>Rationale: God objects need immediate architectural attention</li>
</ul>
<p><strong>Function Scores</strong>: <code>sum(all_function_scores) / 10</code></p>
<ul>
<li>Normalized sum of individual function debt scores</li>
<li>Provides baseline before modifiers</li>
</ul>
<h3 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h3>
<p><strong>1. Planning Major Refactoring Initiatives</strong></p>
<pre><code class="language-bash"># Show top 10 files needing architectural refactoring
debtmap analyze . --aggregate-only --top 10
</code></pre>
<p>Use when:</p>
<ul>
<li>Planning sprint or quarterly refactoring work</li>
<li>Deciding which modules to split</li>
<li>Prioritizing architectural improvements</li>
<li>Allocating team resources</li>
</ul>
<p><strong>Note</strong>: File-level scoring is enabled with the <code>--aggregate-only</code> flag (a boolean flag—no value needed), which changes output to show only file-level metrics instead of function-level details.</p>
<p><strong>2. Identifying Architectural Issues</strong></p>
<p>File-level scoring excels at finding:</p>
<ul>
<li>God objects with too many responsibilities</li>
<li>Files with poor cohesion</li>
<li>Modules that should be split</li>
<li>Files with too many functions</li>
</ul>
<pre><code class="language-bash"># Focus on architectural problems
debtmap analyze . --aggregate-only --filter Architecture
</code></pre>
<p><strong>3. Breaking Up Monolithic Modules</strong></p>
<pre><code class="language-bash"># Find files with excessive function counts
debtmap analyze . --aggregate-only --min-problematic 50
</code></pre>
<p><strong>4. Evaluating Overall Codebase Health</strong></p>
<pre><code class="language-bash"># Generate file-level report for executive summary
debtmap analyze . --aggregate-only --format markdown -o report.md
</code></pre>
<h3 id="aggregation-methods"><a class="header" href="#aggregation-methods">Aggregation Methods</a></h3>
<p>Debtmap supports multiple aggregation methods for file-level scores, configurable via CLI or configuration file.</p>
<h4 id="weighted-sum-default"><a class="header" href="#weighted-sum-default">Weighted Sum (Default)</a></h4>
<p><strong>Formula</strong>: <code>Σ(function_score × complexity_weight × coverage_weight)</code></p>
<pre><code class="language-bash">debtmap analyze . --aggregation-method weighted_sum
</code></pre>
<p>Or via configuration:</p>
<pre><code class="language-toml">[aggregation]
method = "weighted_sum"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Weights functions by their complexity and coverage gaps</li>
<li>Emphasizes high-impact functions over trivial ones</li>
<li>Best for most use cases where you want to focus on significant issues</li>
</ul>
<p><strong>Best for</strong>: Standard codebases where you want proportional emphasis on complex, untested code</p>
<h4 id="simple-sum"><a class="header" href="#simple-sum">Simple Sum</a></h4>
<p><strong>Formula</strong>: <code>Σ(function_scores)</code></p>
<pre><code class="language-toml">[aggregation]
method = "sum"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Adds all function scores directly without weighting</li>
<li>Treats all functions equally regardless of complexity</li>
<li>Useful for broad overview and trend analysis</li>
</ul>
<p><strong>Best for</strong>: Getting a raw count-based view of technical debt across all functions</p>
<h4 id="logarithmic-sum"><a class="header" href="#logarithmic-sum">Logarithmic Sum</a></h4>
<p><strong>Formula</strong>: <code>log(1 + Σ(function_scores))</code></p>
<pre><code class="language-toml">[aggregation]
method = "logarithmic_sum"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Dampens impact of many small issues to prevent score explosion</li>
<li>Prevents files with hundreds of minor issues from dominating</li>
<li>Creates more balanced comparisons across files of different sizes</li>
</ul>
<p><strong>Best for</strong>: Legacy codebases with many small issues where you want to avoid extreme scores</p>
<h4 id="max-plus-average"><a class="header" href="#max-plus-average">Max Plus Average</a></h4>
<p><strong>Formula</strong>: <code>max_score × 0.6 + avg_score × 0.4</code></p>
<pre><code class="language-toml">[aggregation]
method = "max_plus_average"
</code></pre>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Considers worst function (60%) plus average of all functions (40%)</li>
<li>Balances worst-case and typical-case scenarios</li>
<li>Highlights files with both a critical hot spot and general issues</li>
</ul>
<p><strong>Best for</strong>: Identifying files with concentrated complexity alongside general code quality concerns</p>
<h4 id="choosing-an-aggregation-method"><a class="header" href="#choosing-an-aggregation-method">Choosing an Aggregation Method</a></h4>
<div class="table-wrapper"><table><thead><tr><th>Codebase Type</th><th>Recommended Method</th><th>Rationale</th></tr></thead><tbody>
<tr><td>New/Modern</td><td><code>weighted_sum</code></td><td>Proportional emphasis on real issues</td></tr>
<tr><td>Legacy with many small issues</td><td><code>logarithmic_sum</code></td><td>Prevents score explosion</td></tr>
<tr><td>Mixed quality</td><td><code>max_plus_average</code></td><td>Balances hot spots with overall quality</td></tr>
<tr><td>Trend analysis</td><td><code>sum</code></td><td>Simple, consistent metric over time</td></tr>
</tbody></table>
</div>
<p><strong>Performance Note</strong>: All aggregation methods have O(n) complexity where n = number of functions. Performance differences are negligible for typical codebases (&lt;100k functions). Choose based on prioritization strategy, not performance concerns.</p>
<h3 id="configuration"><a class="header" href="#configuration">Configuration</a></h3>
<blockquote>
<p><strong>IMPORTANT</strong>: The configuration file must be named <strong><code>.debtmap.toml</code></strong> (not <code>debtmap.yml</code> or other variants) and placed in your project root directory.</p>
</blockquote>
<pre><code class="language-toml">[aggregation]
method = "weighted_sum"
min_problematic = 3              # Need 3+ problematic functions for file-level score

[god_object_detection]
enabled = true
max_methods = 20
max_fields = 15
max_responsibilities = 5
</code></pre>
<h2 id="function-level-scoring"><a class="header" href="#function-level-scoring">Function-Level Scoring</a></h2>
<p>Function-level scoring identifies specific functions needing attention for targeted improvements.</p>
<h3 id="formula-1"><a class="header" href="#formula-1">Formula</a></h3>
<pre><code>Base Score = (Complexity Factor × 10 × 0.50) + (Dependency Factor × 10 × 0.25)
Coverage Multiplier = 1.0 - coverage_percent
Final Score = Base Score × Coverage Multiplier × Role Multiplier
</code></pre>
<p><strong>Formula Breakdown:</strong></p>
<ol>
<li><strong>Complexity Factor</strong>: Raw complexity / 2.0, clamped to 0-10 range (complexity of 20+ maps to 10.0)</li>
<li><strong>Dependency Factor</strong>: Upstream dependency count / 2.0, capped at 10.0 (20+ dependencies map to 10.0)</li>
<li><strong>Base Score</strong>: (Complexity Factor × 10 × 0.50) + (Dependency Factor × 10 × 0.25)
<ul>
<li>50% weight on complexity, 25% weight on dependencies</li>
</ul>
</li>
<li><strong>Coverage Multiplier</strong>: 1.0 - coverage_percent (0% coverage = 1.0, 100% coverage = 0.0)</li>
<li><strong>Final Score</strong>: Base Score × Coverage Multiplier × Role Multiplier</li>
</ol>
<p><strong>Why Hard-Coded Weights?</strong> The base weights (0.50 for complexity, 0.25 for dependencies) are intentionally not configurable to:</p>
<ul>
<li><strong>Ensure consistency</strong>: Scores remain comparable across projects and teams</li>
<li><strong>Prevent instability</strong>: Avoid extreme configurations that break prioritization</li>
<li><strong>Simplify configuration</strong>: Reduce cognitive load for users</li>
<li><strong>Maintain calibration</strong>: Weights are empirically tuned based on analysis of real codebases</li>
</ul>
<p>You can still customize prioritization significantly through configurable <code>role_multipliers</code>, <code>coverage_weights</code>, and normalization settings.</p>
<p><strong>Note</strong>: Coverage acts as a dampening multiplier rather than an additive factor. Lower coverage (higher multiplier) increases the final score, making untested complex code a higher priority. Role multipliers and coverage weights remain configurable to allow customization while maintaining stable base calculations.</p>
<p><strong>Migration Note</strong>: Earlier versions used an additive model with weights (Complexity × 0.35) + (Coverage × 0.50) + (Dependency × 0.15). The current model (spec 122) uses coverage as a multiplicative dampener, which better reflects that testing gaps amplify existing complexity rather than adding to it.</p>
<h3 id="metrics"><a class="header" href="#metrics">Metrics</a></h3>
<p><strong>Cyclomatic Complexity</strong></p>
<ul>
<li>Counts decision points (if, match, loops)</li>
<li>Guides test case count</li>
</ul>
<p><strong>Cognitive Complexity</strong></p>
<ul>
<li>Measures understanding difficulty</li>
<li>Accounts for nesting depth</li>
</ul>
<p><strong>Coverage Percentage</strong></p>
<ul>
<li>Direct line coverage from LCOV</li>
<li>0% coverage = maximum urgency</li>
</ul>
<p><strong>Dependency Count</strong></p>
<ul>
<li>Upstream callers + downstream callees</li>
<li>Higher dependencies = higher impact</li>
</ul>
<p><strong>Role Multiplier</strong></p>
<p>Functions are classified by role, and each role receives a multiplier based on its architectural importance:</p>
<div class="table-wrapper"><table><thead><tr><th>Role</th><th>Multiplier</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>Pure logic</strong></td><td>1.2x</td><td>Core business rules and algorithms</td></tr>
<tr><td><strong>Unknown</strong></td><td>1.0x</td><td>Functions without clear classification</td></tr>
<tr><td><strong>Entry point</strong></td><td>0.9x</td><td>Public APIs, main functions, HTTP handlers</td></tr>
<tr><td><strong>Orchestrator</strong></td><td>0.8x</td><td>Functions that coordinate other functions</td></tr>
<tr><td><strong>IO wrapper</strong></td><td>0.7x</td><td>Simple file/network I/O wrappers</td></tr>
<tr><td><strong>Pattern match</strong></td><td>0.6x</td><td>Functions primarily doing pattern matching</td></tr>
</tbody></table>
</div>
<p><strong>Note</strong>: Role multipliers are configurable via the <code>[role_multipliers]</code> section in <code>.debtmap.toml</code>. The multipliers have been rebalanced to be less extreme than earlier versions - pure logic was reduced from 1.5x to 1.2x, while orchestrator and IO wrapper were increased to better reflect their importance in modern codebases.</p>
<h3 id="constructor-detection"><a class="header" href="#constructor-detection">Constructor Detection</a></h3>
<p>Debtmap includes intelligent constructor detection to prevent false positives where trivial initialization functions are misclassified as critical business logic.</p>
<p><strong>Problem</strong>: Simple constructors like <code>new()</code>, <code>default()</code>, or <code>from_config()</code> often have low complexity but were being flagged as high-priority pure logic functions.</p>
<p><strong>Solution</strong>: Constructor detection automatically identifies and classifies these functions as <code>IOWrapper</code> (low priority) instead of <code>PureLogic</code> (high priority).</p>
<p><strong>Detection Criteria</strong>:</p>
<p>A function is considered a simple constructor if it meets ALL of the following:</p>
<ol>
<li>
<p><strong>Name matches a constructor pattern</strong> (configurable):</p>
<ul>
<li>Exact match: <code>new</code>, <code>default</code>, <code>empty</code>, <code>zero</code>, <code>any</code></li>
<li>Prefix match: <code>from_*</code>, <code>with_*</code>, <code>create_*</code>, <code>make_*</code>, <code>build_*</code>, <code>of_*</code></li>
</ul>
</li>
<li>
<p><strong>Low cyclomatic complexity</strong> (≤ 2 by default)</p>
</li>
<li>
<p><strong>Short length</strong> (&lt; 15 lines by default)</p>
</li>
<li>
<p><strong>Minimal nesting</strong> (≤ 1 level by default)</p>
</li>
<li>
<p><strong>Low cognitive complexity</strong> (≤ 3 by default)</p>
</li>
</ol>
<p><strong>Example</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Simple constructor - detected and classified as IOWrapper
fn new() -&gt; Self {
    Self {
        field1: 0,
        field2: String::new(),
    }
}

// Complex factory - NOT detected as constructor, remains PureLogic
fn create_with_validation(data: Data) -&gt; Result&lt;Self&gt; {
    validate(&amp;data)?;
    // ... 30 lines of logic
    Ok(Self { ... })
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Configuration</strong>:</p>
<p>Constructor detection is fully configurable in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[classification.constructors]
# Enable AST-based constructor detection (default: true)
# When enabled, uses Abstract Syntax Tree analysis for accurate detection
# Disable only if experiencing performance issues with very large codebases
ast_detection = true

# Constructor name patterns
patterns = [
    "new",
    "default",
    "from_",
    "with_",
    "create_",
    "make_",
    "build_",
    "of_",
    "empty",
    "zero",
    "any",
]

# Complexity thresholds
max_cyclomatic = 2     # Maximum cyclomatic complexity
max_cognitive = 3      # Maximum cognitive complexity
max_length = 15        # Maximum lines
max_nesting = 1        # Maximum nesting depth
</code></pre>
<p><strong>Customization Example</strong>:</p>
<p>To add custom constructor patterns or adjust thresholds:</p>
<pre><code class="language-toml">[classification.constructors]
ast_detection = true      # Keep AST detection enabled (recommended)

patterns = [
    "new",
    "default",
    "from_",
    "with_",
    "init_",        # Add custom pattern
    "setup_",       # Add custom pattern
]
max_cyclomatic = 3    # Allow slightly more complex constructors
max_length = 20       # Allow longer constructors
</code></pre>
<p>To disable AST-based detection (if experiencing performance issues):</p>
<pre><code class="language-toml">[classification.constructors]
ast_detection = false     # Fall back to pattern-only matching
# Note: May reduce detection accuracy but improves performance
</code></pre>
<p><strong>Performance and Disabling</strong>:</p>
<p>Constructor detection is <strong>always enabled</strong> and cannot be fully disabled, as it’s integral to accurate priority scoring. However, you can:</p>
<ol>
<li><strong>Disable AST analysis</strong> (shown above): Falls back to pattern-only matching, reducing accuracy but improving performance for very large codebases (100k+ functions)</li>
<li><strong>Adjust thresholds</strong>: Make detection more lenient by increasing <code>max_cyclomatic</code>, <code>max_cognitive</code>, or <code>max_length</code></li>
<li><strong>Remove patterns</strong>: Delete specific patterns from the <code>patterns</code> list to exclude them from detection</li>
</ol>
<p><strong>Performance Impact</strong>:</p>
<ul>
<li>AST-based detection: Negligible impact (&lt;5% overhead) for typical codebases</li>
<li>Pattern-only detection: Near-zero performance impact</li>
<li>Recommendation: Keep <code>ast_detection = true</code> unless profiling shows it’s a bottleneck</li>
</ul>
<p><strong>Accuracy Trade-offs</strong>:</p>
<ul>
<li>With AST: 95%+ accuracy in identifying simple constructors</li>
<li>Without AST: ~70% accuracy, more false negatives</li>
</ul>
<p>This feature is part of spec 117 and helps reduce false positives in priority scoring.</p>
<h3 id="role-based-adjustments"><a class="header" href="#role-based-adjustments">Role-Based Adjustments</a></h3>
<p>DebtMap uses a sophisticated two-stage role adjustment mechanism to ensure that scores accurately reflect both the testing strategy appropriate for each function type and the architectural importance of different roles.</p>
<h4 id="why-role-based-adjustments"><a class="header" href="#why-role-based-adjustments">Why Role-Based Adjustments?</a></h4>
<p><strong>Problem</strong>: Traditional scoring treats all functions equally, leading to false positives:</p>
<ol>
<li>
<p><strong>Entry points</strong> (CLI handlers, HTTP routes, <code>main</code> functions) typically use integration tests rather than unit tests</p>
<ul>
<li>Flagging them for “low unit test coverage” misses that they’re tested differently</li>
<li>They orchestrate other code but contain minimal business logic</li>
</ul>
</li>
<li>
<p><strong>Pure business logic</strong> functions should have comprehensive unit tests</p>
<ul>
<li>Easy to test in isolation with deterministic inputs/outputs</li>
<li>Core value of the application lives here</li>
</ul>
</li>
<li>
<p><strong>I/O wrappers</strong> are often tested implicitly through integration tests</p>
<ul>
<li>Thin abstractions over file system, network, or database operations</li>
<li>Unit testing them provides limited value compared to integration testing</li>
</ul>
</li>
</ol>
<p><strong>Solution</strong>: DebtMap applies role-based adjustments in two stages to address both coverage expectations and architectural importance.</p>
<h4 id="stage-1-role-based-coverage-weighting"><a class="header" href="#stage-1-role-based-coverage-weighting">Stage 1: Role-Based Coverage Weighting</a></h4>
<p>The first stage adjusts coverage penalty expectations based on function role. This prevents functions that use different testing strategies from unfairly dominating the priority list.</p>
<p><strong>How It Works</strong>:</p>
<p>For each function, DebtMap:</p>
<ol>
<li>Detects the function’s role (entry point, pure logic, I/O wrapper, etc.)</li>
<li>Applies a coverage weight multiplier based on that role</li>
<li>Reduces or increases the coverage penalty accordingly</li>
</ol>
<p><strong>Default Coverage Weights</strong> (configurable in <code>.debtmap.toml</code>):</p>
<div class="table-wrapper"><table><thead><tr><th>Function Role</th><th>Coverage Weight</th><th>Impact on Scoring</th></tr></thead><tbody>
<tr><td>Pure Logic</td><td>1.2</td><td>Higher coverage penalty (should have unit tests)</td></tr>
<tr><td>Unknown</td><td>1.0</td><td>Standard penalty</td></tr>
<tr><td>Pattern Match</td><td>1.0</td><td>Standard penalty</td></tr>
<tr><td>Orchestrator</td><td>0.8</td><td>Reduced penalty (partially integration tested)</td></tr>
<tr><td>I/O Wrapper</td><td>0.7</td><td>Reduced penalty (often integration tested)</td></tr>
<tr><td>Entry Point</td><td>0.6</td><td>Significantly reduced penalty (integration tested)</td></tr>
</tbody></table>
</div>
<p><strong>Example Score Changes</strong>:</p>
<p><strong>Before role-based coverage adjustment</strong>:</p>
<pre><code>Function: handle_request (Entry Point)
  Complexity: 5
  Coverage: 0%
  Raw Coverage Penalty: 1.0 (full penalty)
  Score: 8.5 (flagged as high priority)
</code></pre>
<p><strong>After role-based coverage adjustment</strong>:</p>
<pre><code>Function: handle_request (Entry Point)
  Complexity: 5
  Coverage: 0%
  Adjusted Coverage Penalty: 0.4 (60% reduction via 0.6 weight)
  Score: 4.2 (medium priority - more realistic)

  Rationale: Entry points are integration tested, not unit tested.
  This function is likely tested via API/CLI integration tests.
</code></pre>
<p><strong>Comparison with Pure Logic</strong>:</p>
<pre><code>Function: calculate_discount (Pure Logic)
  Complexity: 5
  Coverage: 0%
  Adjusted Coverage Penalty: 1.2 (20% increase via 1.2 weight)
  Score: 9.8 (critical priority)

  Rationale: Pure logic should have unit tests.
  This function needs immediate test coverage.
</code></pre>
<h4 id="stage-2-role-multiplier"><a class="header" href="#stage-2-role-multiplier">Stage 2: Role Multiplier</a></h4>
<p>The second stage applies a final role-based multiplier to reflect architectural importance. This multiplier is <strong>clamped by default</strong> to prevent extreme score swings.</p>
<p><strong>Configuration</strong> (<code>.debtmap.toml</code> under <code>[scoring.role_multiplier]</code>):</p>
<pre><code class="language-toml">[scoring.role_multiplier]
clamp_min = 0.3           # Minimum multiplier (default: 0.3)
clamp_max = 1.8           # Maximum multiplier (default: 1.8)
enable_clamping = true    # Enable clamping (default: true)
</code></pre>
<p><strong>Clamp Range Rationale</strong>:</p>
<ul>
<li><strong>Default [0.3, 1.8]</strong>: Balances differentiation with stability</li>
<li><strong>Lower bound (0.3)</strong>: I/O wrappers still contribute 30% of base score (not invisible)</li>
<li><strong>Upper bound (1.8)</strong>: Critical entry points don’t overwhelm other issues (max 180%)</li>
<li><strong>Configurable</strong>: Adjust based on project priorities</li>
</ul>
<p><strong>Example with Clamping</strong>:</p>
<pre><code>Function: process_data (Complex Pure Logic)
  Base Score: 45.0
  Unclamped Role Multiplier: 2.5
  Clamped Multiplier: 1.8 (clamp_max)
  Final Score: 45.0 × 1.8 = 81.0

  Effect: Prevents one complex function from dominating entire priority list
</code></pre>
<h4 id="why-two-stages"><a class="header" href="#why-two-stages">Why Two Stages?</a></h4>
<p>The separation of coverage weight adjustment and role multiplier ensures they work together without interfering:</p>
<p><strong>Stage 1 (Coverage Weight)</strong>: Adjusts testing expectations</p>
<ul>
<li><strong>Question</strong>: “How much should we penalize missing unit tests for this type of function?”</li>
<li><strong>Example</strong>: Entry points get 60% of normal coverage penalty (they’re integration tested)</li>
</ul>
<p><strong>Stage 2 (Role Multiplier)</strong>: Adjusts architectural importance</p>
<ul>
<li><strong>Question</strong>: “How important is this function relative to others with similar complexity?”</li>
<li><strong>Example</strong>: Critical entry points might get a 1.2x multiplier (clamped), while simple I/O wrappers get 0.5x (clamped)</li>
</ul>
<p><strong>Independent Contributions</strong>:</p>
<pre><code>1. Calculate base score from complexity + dependencies
2. Apply coverage weight by role → adjusted coverage penalty
3. Combine into preliminary score
4. Apply clamped role multiplier → final score
</code></pre>
<p>This approach ensures:</p>
<ul>
<li>Coverage adjustments don’t interfere with role multiplier</li>
<li>Both mechanisms contribute independently</li>
<li>Clamping prevents instability from extreme multipliers</li>
</ul>
<h4 id="how-this-reduces-false-positives"><a class="header" href="#how-this-reduces-false-positives">How This Reduces False Positives</a></h4>
<p><strong>False Positive #1: Entry Points Flagged for Low Coverage</strong></p>
<p><strong>Before</strong>:</p>
<pre><code>Top Priority Items:
1. main() - Score: 9.2 (0% unit test coverage)
2. handle_cli_command() - Score: 8.8 (5% unit test coverage)
3. run_server() - Score: 8.5 (0% unit test coverage)
</code></pre>
<p><strong>After</strong>:</p>
<pre><code>Top Priority Items:
1. calculate_tax() - Score: 9.8 (0% coverage, Pure Logic)
2. validate_payment() - Score: 9.2 (10% coverage, Pure Logic)
3. main() - Score: 4.2 (0% coverage, Entry Point - integration tested)
</code></pre>
<p><strong>Result</strong>: Business logic functions that actually need unit tests rise to the top.</p>
<p><strong>False Positive #2: I/O Wrappers Over-Prioritized</strong></p>
<p><strong>Before</strong>:</p>
<pre><code>Function: read_config_file
  Complexity: 3
  Coverage: 0%
  Score: 7.5 (high priority)

  Issue: This is a thin wrapper over std::fs::read_to_string.
  Unit testing it provides minimal value vs integration tests.
</code></pre>
<p><strong>After</strong>:</p>
<pre><code>Function: read_config_file
  Complexity: 3
  Coverage: 0%
  Adjusted Coverage Weight: 0.7
  Score: 3.2 (low priority)

  Rationale: I/O wrappers are integration tested.
  Focus on business logic instead.
</code></pre>
<h4 id="configuration-examples"><a class="header" href="#configuration-examples">Configuration Examples</a></h4>
<p><strong>Emphasize Pure Logic Testing</strong>:</p>
<pre><code class="language-toml">[scoring.role_coverage_weights]
pure_logic = 1.5        # Strong penalty for untested pure logic
entry_point = 0.5       # Minimal penalty for untested entry points
io_wrapper = 0.5        # Minimal penalty for untested I/O wrappers
</code></pre>
<p><strong>Conservative Approach (Smaller Adjustments)</strong>:</p>
<pre><code class="language-toml">[scoring.role_coverage_weights]
pure_logic = 1.1        # Slight increase
entry_point = 0.9       # Slight decrease
io_wrapper = 0.9        # Slight decrease
</code></pre>
<p><strong>Disable Multiplier Clamping</strong> (not recommended for production):</p>
<pre><code class="language-toml">[scoring.role_multiplier]
enable_clamping = false   # Allow unclamped multipliers
# Warning: May cause unstable prioritization
</code></pre>
<h4 id="verification"><a class="header" href="#verification">Verification</a></h4>
<p>To see how role-based adjustments affect your codebase:</p>
<pre><code class="language-bash"># Show detailed scoring breakdown
debtmap analyze . --verbose

# Compare with role adjustments disabled
debtmap analyze . --config minimal.toml
</code></pre>
<p><strong>Sample verbose output</strong>:</p>
<pre><code>Function: src/handlers/request.rs:handle_request
  Role: Entry Point
  Complexity: 5
  Coverage: 0%
  Coverage Weight: 0.6 (Entry Point adjustment)
  Adjusted Coverage Penalty: 0.4 (reduced from 1.0)
  Base Score: 15.0
  Role Multiplier: 1.2 (clamped from 1.5)
  Final Score: 18.0

  Interpretation:
    - Entry point gets 60% coverage penalty instead of 100%
    - Likely tested via integration tests
    - Still flagged due to complexity, but not over-penalized for coverage
</code></pre>
<h4 id="benefits-summary"><a class="header" href="#benefits-summary">Benefits Summary</a></h4>
<ul>
<li><strong>Fewer false positives</strong>: Entry points and I/O wrappers no longer dominate priority lists</li>
<li><strong>Better resource allocation</strong>: Testing efforts focus on pure logic where unit tests provide most value</li>
<li><strong>Recognition of testing strategies</strong>: Integration tests are valued equally with unit tests</li>
<li><strong>Stable prioritization</strong>: Clamping prevents extreme multipliers from causing volatile rankings</li>
<li><strong>Configurable</strong>: Adjust weights and clamp ranges to match your project’s testing philosophy</li>
</ul>
<h3 id="use-cases-1"><a class="header" href="#use-cases-1">Use Cases</a></h3>
<p><strong>1. Identifying Specific Hot Spots</strong></p>
<pre><code class="language-bash"># Show top 20 functions needing attention
debtmap analyze . --top 20
</code></pre>
<p>Use when:</p>
<ul>
<li>Planning individual developer tasks</li>
<li>Assigning specific refactoring work</li>
<li>Identifying functions to test first</li>
<li>Code review focus</li>
</ul>
<p><strong>2. Sprint Planning for Developers</strong></p>
<pre><code class="language-bash"># Get function-level tasks for this sprint
debtmap analyze . --top 10 --format json -o sprint-tasks.json
</code></pre>
<p><strong>3. Writing Unit Tests</strong></p>
<pre><code class="language-bash"># Find untested complex functions
debtmap analyze . --lcov coverage.lcov --filter Testing --top 15
</code></pre>
<p><strong>4. Targeted Performance Optimization</strong></p>
<pre><code class="language-bash"># Find complex hot paths
debtmap analyze . --filter Performance --context --top 10
</code></pre>
<h3 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h3>
<p>Complete configuration file example showing all scoring-related sections.</p>
<p><strong>File name</strong>: <code>.debtmap.toml</code> (must be placed in your project root)</p>
<pre><code class="language-toml"># .debtmap.toml - Complete scoring configuration

# Role multipliers (applied to final score after coverage multiplier)
[role_multipliers]
pure_logic = 1.2             # Core business rules and algorithms
unknown = 1.0                # Functions without clear classification
entry_point = 0.9            # Public APIs, main functions, HTTP handlers
orchestrator = 0.8           # Functions that coordinate other functions
io_wrapper = 0.7             # File/network I/O wrappers
pattern_match = 0.6          # Functions primarily doing pattern matching

# Aggregation settings (for file-level scoring)
[aggregation]
method = "weighted_sum"      # Options: weighted_sum, sum, logarithmic_sum, max_plus_average
min_problematic = 3          # Minimum number of problematic functions to report file

# Normalization settings (for advanced multi-phase normalization)
[normalization]
linear_threshold = 10.0       # Scores below this use linear scaling (1:1 mapping)
logarithmic_threshold = 100.0 # Scores above this use logarithmic dampening
sqrt_multiplier = 3.33        # Applied to scores between linear and log thresholds
log_multiplier = 10.0         # Applied to scores above logarithmic threshold
show_raw_scores = true        # Display both normalized (0-100) and raw scores in output
</code></pre>
<p><strong>Note on Scoring Weights</strong>: The base complexity and dependency weights are hard-coded for consistency across environments. However, you can customize prioritization significantly through configurable options:</p>
<p><strong>What’s Configurable:</strong></p>
<ul>
<li><code>role_multipliers</code> - Adjust importance of different function types (pure logic, entry points, I/O wrappers)</li>
<li><code>coverage_weights</code> - Role-specific coverage penalty adjustments</li>
<li><code>normalization</code> settings - Control score scaling and range</li>
<li><code>aggregation.method</code> - Choose how function scores combine into file scores</li>
</ul>
<p><strong>What’s Hard-Coded:</strong></p>
<ul>
<li>Base complexity weight (50%) and dependency weight (25%)</li>
<li>Coverage multiplier formula: <code>1.0 - coverage_percent</code></li>
</ul>
<p><strong>Impact</strong>: While base weights are fixed, the configurable multipliers and weights provide significant control over final rankings and priorities. A function with <code>role_multiplier = 1.5</code> and <code>coverage_weight = 1.2</code> can have 80% higher priority than the same function with default settings.</p>
<p><strong>Note</strong>: The configuration file must be named <code>.debtmap.toml</code> (not <code>debtmap.yml</code> or other variants) and placed in your project root directory.</p>
<h2 id="when-to-use-each-approach"><a class="header" href="#when-to-use-each-approach">When to Use Each Approach</a></h2>
<h3 id="use-file-level-scoring-when"><a class="header" href="#use-file-level-scoring-when">Use File-Level Scoring When:</a></h3>
<p>✅ Planning architectural refactoring
✅ Quarterly or annual planning
✅ Deciding which modules to split
✅ Executive summaries and high-level reports
✅ Team capacity planning
✅ Identifying god objects
✅ Module reorganization</p>
<p><strong>Command:</strong></p>
<pre><code class="language-bash">debtmap analyze . --aggregate-only
</code></pre>
<h3 id="use-function-level-scoring-when"><a class="header" href="#use-function-level-scoring-when">Use Function-Level Scoring When:</a></h3>
<p>✅ Sprint planning
✅ Individual developer task assignment
✅ Writing specific unit tests
✅ Code review preparation
✅ Pair programming sessions
✅ Daily or weekly development work
✅ Targeted hot spot fixes</p>
<p><strong>Command:</strong></p>
<pre><code class="language-bash">debtmap analyze . --top 20
</code></pre>
<h3 id="use-both-together"><a class="header" href="#use-both-together">Use Both Together:</a></h3>
<p>Many workflows benefit from both views:</p>
<pre><code class="language-bash"># Step 1: Identify problematic files
debtmap analyze . --aggregate-only --top 5 -o files.json

# Step 2: Drill into specific file
debtmap analyze src/problematic/module.rs --format terminal
</code></pre>
<h2 id="comparison-examples"><a class="header" href="#comparison-examples">Comparison Examples</a></h2>
<h3 id="example-1-god-object-detection"><a class="header" href="#example-1-god-object-detection">Example 1: God Object Detection</a></h3>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/services/user_service.rs --aggregate-only
</code></pre>
<p><strong>File-Level View:</strong></p>
<pre><code>src/services/user_service.rs - Score: 245.8
  - 850 lines, 45 methods
  - God Object: 78% score
  - Action: Split into UserAuth, UserProfile, UserNotifications
</code></pre>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/services/user_service.rs --top 5
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>src/services/user_service.rs:142 - authenticate_user() - Score: 8.5
src/services/user_service.rs:298 - update_profile() - Score: 7.2
src/services/user_service.rs:456 - send_notification() - Score: 6.8
</code></pre>
<p><strong>Decision</strong>: File-level score (245.8) correctly identifies architectural issue. Individual functions aren’t exceptionally complex, but the file has too many responsibilities. <strong>Solution</strong>: Split the file.</p>
<h3 id="example-2-targeted-function-fix"><a class="header" href="#example-2-targeted-function-fix">Example 2: Targeted Function Fix</a></h3>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/parsers/expression.rs --aggregate-only
</code></pre>
<p><strong>File-Level View:</strong></p>
<pre><code>src/parsers/expression.rs - Score: 45.2
  - 320 lines, 12 functions
  - No god object detected
</code></pre>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/parsers/expression.rs --top 5
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>src/parsers/expression.rs:89 - parse_complex_expression() - Score: 9.1
  - Cyclomatic: 22, Cognitive: 35
  - Coverage: 0%
  - Action: Add tests and refactor
</code></pre>
<p><strong>Decision</strong>: File as a whole is acceptable, but one function needs attention. <strong>Solution</strong>: Focus on that specific function.</p>
<h3 id="example-3-balanced-refactoring"><a class="header" href="#example-3-balanced-refactoring">Example 3: Balanced Refactoring</a></h3>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/analysis/scoring.rs --aggregate-only --coverage-file coverage.lcov
</code></pre>
<p><strong>File-Level View:</strong></p>
<pre><code>src/analysis/scoring.rs - Score: 125.6
  - 580 lines, 18 functions
  - High complexity, low coverage
</code></pre>
<p><strong>Command</strong>:</p>
<pre><code class="language-bash">debtmap analyze src/analysis/scoring.rs --coverage-file coverage.lcov --top 5
</code></pre>
<p><strong>Function-Level View:</strong></p>
<pre><code>calculate_score() - Score: 8.8 (15% coverage)
apply_weights() - Score: 8.2 (10% coverage)
normalize_results() - Score: 7.5 (0% coverage)
</code></pre>
<p><strong>Decision</strong>: Both file and functions need work. <strong>Solution</strong>: Add tests first (function-level), then consider splitting if complexity persists (file-level).</p>
<h2 id="score-normalization"><a class="header" href="#score-normalization">Score Normalization</a></h2>
<p>Both scoring approaches normalize to a 0-10 scale for consistency.</p>
<h3 id="normalization-strategies"><a class="header" href="#normalization-strategies">Normalization Strategies</a></h3>
<p><strong>Default: Linear Clamping</strong></p>
<p>The default normalization uses simple linear clamping to the 0-100 range:</p>
<ul>
<li><strong>Formula</strong>: Score is clamped between 0.0 and 100.0</li>
<li><strong>Behavior</strong>: No transformation, just boundary enforcement</li>
<li><strong>Usage</strong>: Production output uses this method</li>
</ul>
<p>This ensures scores stay within the expected range without additional transformations.</p>
<p><strong>Advanced: Multi-Phase Normalization</strong></p>
<p>For more sophisticated normalization, debtmap provides multi-phase scaling with different formulas for different score ranges:</p>
<p><strong>Phase 1 - Linear (scores &lt; 10)</strong>:</p>
<ul>
<li>Formula: <code>normalized = raw_score</code></li>
<li>Behavior: 1:1 mapping, no scaling</li>
<li>Rationale: Preserve low score distinctions</li>
</ul>
<p><strong>Phase 2 - Square Root (scores 10-100)</strong>:</p>
<ul>
<li>Formula: <code>normalized = 10.0 + sqrt(raw_score - 10.0) × 3.33</code></li>
<li>Behavior: Moderate dampening</li>
<li>Rationale: Balance between linear and logarithmic</li>
</ul>
<p><strong>Phase 3 - Logarithmic (scores &gt; 100)</strong>:</p>
<ul>
<li>Formula: <code>normalized = 41.59 + ln(raw_score / 100.0) × 10.0</code></li>
<li>Behavior: Strong dampening of extreme values</li>
<li>Rationale: Prevent outliers from dominating</li>
</ul>
<p>This multi-phase approach dampens extreme values while preserving distinctions in the normal range. Configure via <code>[normalization]</code> section in <code>.debtmap.toml</code>.</p>
<h3 id="configuration-2"><a class="header" href="#configuration-2">Configuration</a></h3>
<pre><code class="language-toml">[normalization]
linear_threshold = 10.0       # Scores below this use linear scaling (1:1 mapping)
logarithmic_threshold = 100.0 # Scores above this use logarithmic dampening
sqrt_multiplier = 3.33        # Applied to scores between linear and log thresholds
log_multiplier = 10.0         # Applied to scores above logarithmic threshold
show_raw_scores = true        # Display both normalized (0-10) and raw scores in output
</code></pre>
<p><strong>Explanation</strong>:</p>
<ul>
<li><strong>linear_threshold</strong>: Scores below this value are mapped 1:1 (no scaling)</li>
<li><strong>logarithmic_threshold</strong>: Scores above this value are dampened logarithmically to prevent extreme values</li>
<li><strong>sqrt_multiplier</strong>: Square root scaling applied to mid-range scores (between linear and logarithmic thresholds)</li>
<li><strong>log_multiplier</strong>: Logarithmic dampening factor for very high scores</li>
<li><strong>show_raw_scores</strong>: When enabled, output includes both the normalized 0-10 score and the raw calculated score</li>
</ul>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="workflow-integration"><a class="header" href="#workflow-integration">Workflow Integration</a></h3>
<p><strong>Week 1: File-Level Assessment</strong></p>
<pre><code class="language-bash"># Identify architectural problems
debtmap analyze . --aggregate-only --top 10
</code></pre>
<p><strong>Week 2-4: Function-Level Work</strong></p>
<pre><code class="language-bash"># Work through specific functions
debtmap analyze src/target/module.rs
</code></pre>
<p><strong>Monthly: Compare Progress</strong></p>
<pre><code class="language-bash">debtmap compare --before baseline.json --after current.json
</code></pre>
<h3 id="team-collaboration"><a class="header" href="#team-collaboration">Team Collaboration</a></h3>
<ul>
<li><strong>Architects</strong>: Use file-level scores for strategic planning</li>
<li><strong>Tech Leads</strong>: Use both for sprint planning</li>
<li><strong>Developers</strong>: Use function-level for daily work</li>
<li><strong>QA</strong>: Use function-level for test prioritization</li>
</ul>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<pre><code class="language-bash"># Gate: No new file-level regressions
debtmap analyze . --aggregate-only --format json -o file-scores.json

# Gate: No new critical function-level issues
debtmap analyze . --min-priority critical --format json -o critical-items.json
</code></pre>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<p><strong>Issue</strong>: File-level scores seem too high</p>
<p><strong>Solution</strong>: Check aggregation method:</p>
<pre><code class="language-toml">[aggregation]
method = "logarithmic_sum"  # Dampen scores
</code></pre>
<p><strong>Issue</strong>: Function-level scores all similar</p>
<p><strong>Solution</strong>: Adjust role multipliers to create more differentiation:</p>
<pre><code class="language-toml">[role_multipliers]
pure_logic = 1.5     # Emphasize business logic more
io_wrapper = 0.5     # De-emphasize I/O wrappers more
</code></pre>
<p><strong>Note</strong>: Base scoring weights (complexity 50%, dependency 25%) are hard-coded and cannot be configured.</p>
<p><strong>Issue</strong>: Too many low-priority items</p>
<p><strong>Solution</strong>: Use minimum thresholds:</p>
<pre><code class="language-toml">[thresholds]
minimum_debt_score = 3.0
</code></pre>
<h2 id="rebalanced-debt-scoring-spec-136"><a class="header" href="#rebalanced-debt-scoring-spec-136">Rebalanced Debt Scoring (Spec 136)</a></h2>
<p>Debtmap now includes an advanced <strong>rebalanced scoring algorithm</strong> that prioritizes actual code quality issues—complexity, coverage gaps, and structural problems—over pure file size concerns.</p>
<h3 id="enabling-rebalanced-scoring"><a class="header" href="#enabling-rebalanced-scoring">Enabling Rebalanced Scoring</a></h3>
<blockquote>
<p><strong>IMPORTANT</strong>: Rebalanced scoring is enabled through your <code>.debtmap.toml</code> configuration file, <strong>not via CLI flags</strong>. Add the <code>[scoring_rebalanced]</code> section to activate it.</p>
</blockquote>
<p><strong>Default Behavior</strong>: By default, debtmap uses the standard scoring algorithm described earlier in this chapter. To use rebalanced scoring, add the <code>[scoring_rebalanced]</code> section to your config:</p>
<pre><code class="language-toml"># .debtmap.toml
[scoring_rebalanced]
preset = "balanced"  # Activates rebalanced scoring with balanced preset
</code></pre>
<p><strong>Relationship to Standard Scoring</strong>:</p>
<ul>
<li>Rebalanced scoring <strong>supplements</strong> standard scoring, providing an alternative prioritization strategy</li>
<li>Both algorithms can coexist - choose which to use based on your needs</li>
<li>File-level and function-level scoring both work with rebalanced scoring</li>
<li>Output format remains the same, only score calculations differ</li>
</ul>
<p><strong>Migration Path</strong>:</p>
<ol>
<li><strong>Test first</strong>: Add <code>[scoring_rebalanced]</code> section to a test config file</li>
<li><strong>Compare</strong>: Run analysis with both standard and rebalanced scoring on same codebase</li>
<li><strong>Evaluate</strong>: Review how priorities change (large simple files rank lower, complex untested code ranks higher)</li>
<li><strong>Adopt</strong>: Once satisfied, switch your primary config to use rebalanced scoring</li>
<li><strong>Tune</strong>: Adjust preset or custom weights based on your team’s priorities</li>
</ol>
<p><strong>Quick Start</strong>:</p>
<pre><code class="language-bash"># Create test config with rebalanced scoring
cat &gt; .debtmap-rebalanced.toml &lt;&lt;EOF
[scoring_rebalanced]
preset = "balanced"
EOF

# Compare results
debtmap analyze . --format terminal                            # Standard scoring
debtmap analyze . --config .debtmap-rebalanced.toml --format terminal  # Rebalanced scoring
</code></pre>
<h3 id="philosophy"><a class="header" href="#philosophy">Philosophy</a></h3>
<p>Traditional scoring often over-emphasizes file size, causing large but simple files to rank higher than complex, untested code. The rebalanced algorithm fixes this by:</p>
<ol>
<li><strong>De-emphasizing size</strong>: Reduces size weight from ~1.5 to 0.3 (80% reduction)</li>
<li><strong>Emphasizing quality</strong>: Increases weights for complexity (1.0) and coverage gaps (1.0)</li>
<li><strong>Additive bonuses</strong>: Provides +20 bonus for complex + untested code (not multiplicative)</li>
<li><strong>Context-aware thresholds</strong>: Integrates with file type classification from Spec 135</li>
</ol>
<h3 id="multi-dimensional-scoring"><a class="header" href="#multi-dimensional-scoring">Multi-Dimensional Scoring</a></h3>
<p>The rebalanced algorithm computes five scoring components:</p>
<div class="table-wrapper"><table><thead><tr><th>Component</th><th>Weight</th><th>Range</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>Complexity</strong></td><td>1.0</td><td>0-100</td><td>Cyclomatic + cognitive complexity</td></tr>
<tr><td><strong>Coverage Gap</strong></td><td>1.0</td><td>0-80</td><td>Testing coverage deficit with complexity bonus</td></tr>
<tr><td><strong>Structural</strong></td><td>0.8</td><td>0-60</td><td>God objects and architectural issues</td></tr>
<tr><td><strong>Size</strong></td><td>0.3</td><td>0-30</td><td>File size (reduced from previous ~1.5)</td></tr>
<tr><td><strong>Code Smells</strong></td><td>0.6</td><td>0-40</td><td>Long functions, deep nesting, impure logic</td></tr>
</tbody></table>
</div>
<p><strong>Weighted Total Formula</strong>:</p>
<pre><code>weighted_total = (complexity × 1.0) + (coverage × 1.0) + (structural × 0.8)
                 + (size × 0.3) + (smells × 0.6)

normalized_score = (weighted_total / 237.0) × 200.0  // Normalize to 0-200 range
</code></pre>
<h3 id="scoring-presets"><a class="header" href="#scoring-presets">Scoring Presets</a></h3>
<p>Debtmap provides four presets for different prioritization strategies:</p>
<h4 id="balanced-default"><a class="header" href="#balanced-default">Balanced (Default)</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "balanced"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 1.0, Coverage: 1.0, Structural: 0.8, Size: 0.3, Smells: 0.6</li>
</ul>
<p><strong>Use when</strong>: Standard development with focus on actual code quality</p>
<h4 id="quality-focused"><a class="header" href="#quality-focused">Quality-Focused</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "quality-focused"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 1.2, Coverage: 1.1, Structural: 0.9, Size: 0.2, Smells: 0.7</li>
</ul>
<p><strong>Use when</strong>: Maximum emphasis on code quality, minimal concern for file size</p>
<h4 id="test-coverage-focused"><a class="header" href="#test-coverage-focused">Test-Coverage-Focused</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "test-coverage"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 0.8, Coverage: 1.3, Structural: 0.6, Size: 0.2, Smells: 0.5</li>
</ul>
<p><strong>Use when</strong>: Prioritizing test coverage improvements</p>
<h4 id="size-focused-legacy"><a class="header" href="#size-focused-legacy">Size-Focused (Legacy)</a></h4>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "size-focused"
</code></pre>
<p>Weights:</p>
<ul>
<li>Complexity: 0.5, Coverage: 0.4, Structural: 0.6, Size: 1.5, Smells: 0.3</li>
</ul>
<p><strong>Use when</strong>: Maintaining legacy scoring behavior, file size is primary concern</p>
<h3 id="custom-weights"><a class="header" href="#custom-weights">Custom Weights</a></h3>
<p>You can define custom weights in <code>.debtmap.toml</code>:</p>
<pre><code class="language-toml">[scoring_rebalanced]
complexity_weight = 1.2
coverage_weight = 1.0
structural_weight = 0.8
size_weight = 0.2
smell_weight = 0.7
</code></pre>
<h3 id="severity-levels"><a class="header" href="#severity-levels">Severity Levels</a></h3>
<p>The rebalanced algorithm assigns severity based on normalized score and risk factors:</p>
<div class="table-wrapper"><table><thead><tr><th>Severity</th><th>Criteria</th><th>Description</th></tr></thead><tbody>
<tr><td><strong>CRITICAL</strong></td><td>Score &gt; 120 OR (complexity &gt; 60 AND coverage &gt; 40)</td><td>Requires immediate attention</td></tr>
<tr><td><strong>HIGH</strong></td><td>Score &gt; 80 OR (complexity &gt; 40 AND coverage &gt; 20) OR structural &gt; 50</td><td>High priority for next sprint</td></tr>
<tr><td><strong>MEDIUM</strong></td><td>Score &gt; 40 OR single moderate issue</td><td>Plan for future sprint</td></tr>
<tr><td><strong>LOW</strong></td><td>Everything else</td><td>Minor concerns, size-only issues</td></tr>
</tbody></table>
</div>
<p><strong>Evaluation Logic</strong>: Severity is assigned based on the <strong>first matching criteria</strong> (logical OR). An item needs to satisfy <strong>only ONE condition</strong> to qualify for that severity level. For example, a function with score=90 is HIGH severity even if complexity and coverage are both low, because it meets the “Score &gt; 80” condition.</p>
<h3 id="example-prioritization"><a class="header" href="#example-prioritization">Example Prioritization</a></h3>
<p><strong>Complex Untested Function</strong> (HIGH priority):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn process_payment(cart: &amp;Cart, user: &amp;User) -&gt; Result&lt;Receipt&gt; {
    // 150 lines, cyclomatic: 42, cognitive: 77
    // Coverage: 38%

    // Rebalanced Score:
    // - Complexity: 100.0 (very high)
    // - Coverage: 57.2 (gap × 0.6 + 20 bonus for complex+untested)
    // - Structural: 0.0
    // - Size: 0.0 (function-level scoring)
    // - Smells: 25.0 (long function)
    // Total: 95.3 → CRITICAL severity
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Large Simple Function</strong> (LOW priority):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn format_report(data: &amp;ReportData) -&gt; String {
    // 2000 lines, cyclomatic: 3, cognitive: 5
    // Coverage: 100%

    // Rebalanced Score:
    // - Complexity: 0.0 (trivial)
    // - Coverage: 0.0 (well tested)
    // - Structural: 0.0
    // - Size: 0.0 (function-level scoring)
    // - Smells: 15.0 (long but simple)
    // Total: 3.2 → LOW severity
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Result</strong>: Complex untested code ranks 30× higher than large simple code.</p>
<h3 id="integration-with-file-classification-spec-135"><a class="header" href="#integration-with-file-classification-spec-135">Integration with File Classification (Spec 135)</a></h3>
<p>The rebalanced scoring integrates with context-aware file size thresholds:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use debtmap::organization::file_classifier::{classify_file, get_threshold};

let file_type = classify_file(source, path);
let threshold = get_threshold(&amp;file_type, function_count, lines);

// Apply context-aware scoring:
// - Generated code: 0.1× size multiplier
// - Test code: Lenient thresholds (650 lines)
// - Business logic: Strict thresholds (400 lines)
<span class="boring">}</span></code></pre></pre>
<h3 id="generated-code-detection"><a class="header" href="#generated-code-detection">Generated Code Detection</a></h3>
<p>The rebalanced scoring automatically detects and reduces scores for generated code:</p>
<p><strong>Detection Markers</strong> (first 20 lines):</p>
<ul>
<li>“DO NOT EDIT”</li>
<li>“automatically generated”</li>
<li>“AUTO-GENERATED”</li>
<li>“@generated”</li>
<li>“Code generated by”</li>
</ul>
<p><strong>Generated Code Score Adjustment</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if is_generated_code(source) {
    size_score *= 0.1;  // 90% reduction
}
<span class="boring">}</span></code></pre></pre>
<h3 id="scoring-rationale"><a class="header" href="#scoring-rationale">Scoring Rationale</a></h3>
<p>Each debt item includes a detailed rationale explaining the score:</p>
<pre><code>Debt Item: src/payment/processor.rs:142 - process_payment()
Score: 95.3 (CRITICAL)

Primary factors:
  - High cyclomatic complexity (+100.0)
  - Significant coverage gap (+57.2)

Bonuses:
  - Complex + untested: +20 bonus applied
  - Code smells detected (+25.0)

Context adjustments:
  - Size de-emphasized (weight: 0.3)
</code></pre>
<h3 id="migration-from-legacy-scoring"><a class="header" href="#migration-from-legacy-scoring">Migration from Legacy Scoring</a></h3>
<p><strong>Breaking Changes</strong>:</p>
<ul>
<li>Scores will change significantly for all debt items</li>
<li>Large files with low complexity will rank lower</li>
<li>Complex untested code will rank higher</li>
<li>Size-based prioritization reduced by 80%</li>
</ul>
<p><strong>Restoring Legacy Behavior</strong>:</p>
<pre><code class="language-toml">[scoring_rebalanced]
preset = "size-focused"
</code></pre>
<p><strong>Gradual Migration</strong>:</p>
<ol>
<li>Run analysis with both algorithms: <code>debtmap analyze . --legacy-scoring</code></li>
<li>Compare results to understand impact</li>
<li>Adjust team priorities based on new rankings</li>
<li>Switch to rebalanced scoring after validation</li>
</ol>
<p>See <a href="./migration-guide.html">Migration Guide</a> for detailed migration instructions.</p>
<h3 id="configuration-reference"><a class="header" href="#configuration-reference">Configuration Reference</a></h3>
<p>Complete configuration example:</p>
<pre><code class="language-toml"># .debtmap.toml

[scoring_rebalanced]
# Use a preset (balanced, quality-focused, test-coverage, size-focused)
preset = "balanced"

# Or define custom weights
complexity_weight = 1.0
coverage_weight = 1.0
structural_weight = 0.8
size_weight = 0.3
smell_weight = 0.6
</code></pre>
<h3 id="when-to-use-rebalanced-scoring"><a class="header" href="#when-to-use-rebalanced-scoring">When to Use Rebalanced Scoring</a></h3>
<p>✅ <strong>Use rebalanced scoring when</strong>:</p>
<ul>
<li>You want to prioritize code quality over file size</li>
<li>Complex untested code is a concern</li>
<li>You’re building new features and need quality focus</li>
<li>Your team values testability and maintainability</li>
</ul>
<p>❌ <strong>Use legacy/size-focused when</strong>:</p>
<ul>
<li>You’re managing a legacy codebase with large files</li>
<li>File size reduction is the primary concern</li>
<li>You need compatibility with existing workflows</li>
<li>Your team’s priority is file splitting over quality</li>
</ul>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<p>The rebalanced scoring algorithm has minimal performance impact:</p>
<ul>
<li>Same O(n) complexity as legacy scoring</li>
<li>No additional file I/O required</li>
<li>Parallel processing compatible</li>
<li>Adds ~5% to analysis time for rationale generation</li>
</ul>
<h3 id="see-also"><a class="header" href="#see-also">See Also</a></h3>
<ul>
<li><a href="./tiered-prioritization.html">Tiered Prioritization</a> - Understanding tier-based classification</li>
<li><a href="./configuration.html">Configuration</a> - Scoring and aggregation configuration</li>
<li><a href="./analysis-guide.html">Analysis Guide</a> - Detailed metric explanations</li>
<li><a href="./file-classification.html">File Classification</a> - Context-aware file size thresholds (Spec 135)</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="responsibility-analysis.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="tiered-prioritization.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="responsibility-analysis.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="tiered-prioritization.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
